{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>main()</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#test-example:-2d\" data-toc-modified-id=\"test-example:-2d-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>test example: 2d</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-connected-in-sklearn\" data-toc-modified-id=\"fully-connected-in-sklearn-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>fully connected in sklearn</a></span></li><li><span><a href=\"#fully-connected-in-keras\" data-toc-modified-id=\"fully-connected-in-keras-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>fully connected in keras</a></span></li><li><span><a href=\"#cnn\" data-toc-modified-id=\"cnn-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>cnn</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['flags', 'input files', 'EnergyBarrier', 'neural net', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "#\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "from scipy.stats import gaussian_kde\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            if irun == 0:\n",
    "                #--- same configurations!\n",
    "                self.descriptors  = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['data']]\n",
    "                self.shape        = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['shape']].flatten()\n",
    "                self.positions    = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz .'%(path,irun))\n",
    "            try:\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                #--- displacement data\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "#         pdb.set_trace()\n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        atom_ids.sort()\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "        descriptors_center_atoms = self.descriptors[atom_ids]\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystaliine atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        descriptors_crystalline = self.descriptors[filtr]\n",
    "\n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- merge descriptors\n",
    "        self.descriptors = np.concatenate([descriptors_center_atoms,descriptors_crystalline],axis=0)\n",
    "\n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "                                 \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "    @staticmethod\n",
    "    def zscore(slist):\n",
    "        tmp = np.copy(slist)\n",
    "        print(np.mean(tmp),np.std(tmp))\n",
    "        tmp -= np.mean(tmp)\n",
    "        tmp /= np.std(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def SklearnMLP(self,X_train,y_train):\n",
    "        #-----------------------\n",
    "        #--- parameter grid\n",
    "        #-----------------------\n",
    "#         param_grid = {\n",
    "#                         'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "#                          #'activation' : ['tanh', 'relu'],\n",
    "#                          'learning_rate_init':self.learning_rate_init,\n",
    "# #                         'alpha':self.alpha, #--- regularization \n",
    "#                          #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "#                         'n_iter_no_change':self.n_iter_no_change,\n",
    "# #                        'tol':self.tol,\n",
    "#                         'max_iter':self.max_iter,\n",
    "#                      } \n",
    "        mlp   =  MLPClassifier(random_state=1,\n",
    "                               hidden_layer_sizes = self.hidden_layer_sizes[0],\n",
    "                               learning_rate_init = self.learning_rate_init[0],\n",
    "                               n_iter_no_change   = self.n_iter_no_change[0],\n",
    "                               max_iter           = self.max_iter[0],\n",
    "                               verbose=self.verbose)\n",
    "#         clf  =  GridSearchCV(mlp, param_grid)\n",
    "#        clf.fit(X_train,y_train)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        model =  mlp #clf.best_estimator_\n",
    "        loss  =  model.loss_curve_\n",
    "        val_loss = loss\n",
    "        return (model, loss, val_loss)\n",
    "\n",
    "    def KerasANN(self, X_train, y_train,X_test, y_test, ndime):\n",
    "\n",
    "        model     = keras.Sequential([ #--- The network architecture\n",
    "                                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                #                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                                    layers.Dense(ndime, activation='softmax')\n",
    "                                    ])\n",
    "        \n",
    "#         shape         =  (self.shape[0]*self.shape[1]*self.shape[2],)\n",
    "#         inputs        =  keras.Input(shape=shape)\n",
    "#         #------------------------------\n",
    "#         #--- The network architecture\n",
    "#         #------------------------------\n",
    "#         x             =  layers.Dense(   self.hidden_layer_size, activation=self.activation\n",
    "#                                        )(inputs)\n",
    "#         for i in range( self.number_hidden_layers ):\n",
    "#             x       = layers.Dense( self.hidden_layer_size, activation=self.activation\n",
    "#                                      )(x)\n",
    "#         #--- output layer\n",
    "# #         x       = layers.Flatten()(x)\n",
    "#         outputs = layers.Dense( ndime, activation=self.activation)(x)\n",
    "#         model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        \n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "        model.compile( optimizer=optimizer,\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"mse\"]\n",
    "                     )\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"mse\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        model.fit( X_train, y_train, \n",
    "           validation_data      = ( X_test, y_test ),\n",
    "            callbacks           = callbacks,\n",
    "            epochs              = self.max_iter[0], \n",
    "            verbose             = self.verbose, \n",
    "            shuffle             = False, \n",
    "#             batch_size     = 32,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "         )        \n",
    "        loss      = model.history.history['loss']\n",
    "        val_loss  = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        return (best_model, loss, val_loss)\n",
    "                             \n",
    "    def TrainClassifier(self,y,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        ndime = 2 #--- binary classification\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "\n",
    "        #--- train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                (model, loss, val_loss) = self.SklearnMLP(X_train,y_train)\n",
    "                classes_x = model.predict(X_test) \n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                (model, loss, val_loss) = self.KerasANN(X_train, y_train,X_test, y_test, ndime)\n",
    "                predict_x = model.predict(X_test) \n",
    "                classes_x = np.argmax(predict_x,axis=1)\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkClassifier( y )\n",
    "            predict_x = model.predict(X_test) \n",
    "            classes_x = np.argmax(predict_x,axis=1)\n",
    "                    \n",
    "        #--- save loss data\n",
    "        !mkdir png\n",
    "        np.savetxt('png/val_loss_classification.txt',\n",
    "                   np.c_[range(len(loss)),loss,val_loss],\n",
    "                   header='epoch loss val_loss')\n",
    "\n",
    "        #--- confusion matrix\n",
    "        cm = confusion_matrix(y_test, classes_x,\n",
    "                         labels=[0, 1]\n",
    "                        )\n",
    "        np.savetxt('png/confusion.txt',np.c_[cm])\n",
    "\n",
    "        \n",
    "\n",
    "    def TrainRegressor(self,stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    "                       filtr = None,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "\n",
    "        ndime  = y.shape[1] #--- dimension of the target vector\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors[filtr]]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                #-----------------------\n",
    "                #--- parameter grid\n",
    "                #-----------------------\n",
    "                param_grid = {\n",
    "                                'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                                 #'activation' : ['tanh', 'relu'],\n",
    "                                 'learning_rate_init':self.learning_rate_init,\n",
    "                                'alpha':self.alpha, #--- regularization \n",
    "                                 #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                                'n_iter_no_change':self.n_iter_no_change,\n",
    "                                'tol':self.tol,\n",
    "                                'max_iter':self.max_iter,\n",
    "                             } \n",
    "                mlp   =  MLPRegressor(random_state=random_state,verbose=self.verbose) #--- mlp regressor\n",
    "                regr  =  GridSearchCV(mlp, param_grid)\n",
    "                regr.fit(X_train,y_train)\n",
    "                model =  regr.best_estimator_\n",
    "                loss  =  model.loss_curve_\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                model     = keras.Sequential([ #--- The network architecture\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(ndime, activation=self.activation)\n",
    "                    ])\n",
    "                optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4) #--- compilation step\n",
    "                model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "                               loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "                               metrics=[\"mse\"]\n",
    "                             )\n",
    "                model.fit(X_train, y_train, #--- “Fitting”\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          epochs=self.max_iter[0], verbose=self.verbose)#, batch_size=128)\n",
    "                loss      = model.history.history['loss']\n",
    "                val_loss  = model.history.history['val_loss']\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetwork(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred       = model.predict(X_test)        \n",
    "        y_pred_train = model.predict(X_train)        \n",
    "        for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "            ax = utl.PltErr(None,None,Plot=False)\n",
    "            #\n",
    "            utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "                       attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                       attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(None,None,Plot=False,\n",
    "                           title='png/scatter%s.png'%idime,\n",
    "                            ax=ax,\n",
    "                       xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "                       xlim=(-2,2),ylim=(-2,2),\n",
    "                           )\n",
    "        \n",
    "        #--- save in ovito\n",
    "        if printOvito:\n",
    "            X_train, X_test, _, _ = train_test_split(self.perAtomData[filtr]['id type x y z'.split()], y, stratify=stratify,\n",
    "                                                    random_state=random_state)\n",
    "#            pdb.set_trace()\n",
    "            with open('original.xyz','w') as fp:\n",
    "                utl.PrintOvito(self.perAtomData[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('train.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_train,y_pred_train],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('test.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_test,y_pred],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "                \n",
    "\n",
    "    def ConvNetwork(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "                                                   monitor=\"loss\",\n",
    "                                                  save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    def ConvNetworkClassifier(self,y,\n",
    "                               random_state=1\n",
    "                               ):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        \n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        if self.verbose:\n",
    "            print('X.shape:=',X.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- set model parameters\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss=\"binary_crossentropy\",#\"sparse_categorical_crossentropy\",\n",
    "                       metrics   =  [\"accuracy\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"accuracy\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "                    disp           = np.c_[self.perAtomData.iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.positions.T,self.descriptors[atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, 'disp = %s'%disp, attr_list='x y z mass'.split())\n",
    "#     def SaveConf(self,fout):\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[self.perAtomData],header=' '.join(list(self.perAtomData.keys())))\n",
    "\n",
    "#     def Test(self,y,\n",
    "#                                    random_state=1\n",
    "#                                    ):\n",
    "#             '''\n",
    "#             Convolutional neural network.\n",
    "\n",
    "#             Parameters\n",
    "#             ----------\n",
    "#             X_train : array-like training x input\n",
    "\n",
    "#             y_train : array-like, training y input\n",
    "\n",
    "#             X_test : array-like test x input\n",
    "\n",
    "#             y_test : array-like, training y input\n",
    "\n",
    "#             Return\n",
    "#             ---------- ( , loss,  )\n",
    "#             best_model : cnn object, best trained model based on on the validation loss\n",
    "\n",
    "#             loss : array-like, mse loss\n",
    "\n",
    "#             val_loss : array-like, validation loss\n",
    "\n",
    "#             '''\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('dim(y)=',y.shape)\n",
    "\n",
    "#             ndime  = y.shape[1] #--- dimension of the target vector\n",
    "\n",
    "\n",
    "#             #---------------\n",
    "#             #--- zscore X\n",
    "#             #---------------        \n",
    "#             X      = np.c_[self.descriptors ]\n",
    "#             scaler = StandardScaler()\n",
    "#             scaler.fit(X)\n",
    "#             X      = scaler.transform( X )\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('X.shape:=',X.shape)\n",
    "\n",
    "\n",
    "\n",
    "#             #-----------------------\n",
    "#             #--- train-test split\n",
    "#             #-----------------------\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "#                                                                 random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "#             #---- set model parameters\n",
    "#             shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "#             kernel_size   =  self.kernel_size \n",
    "#             epochs        =  self.max_iter[0]\n",
    "#             activation    =  self.activation\n",
    "#             padding       = 'same'\n",
    "#             filters       =  self.n_channels\n",
    "#             learning_rate = self.learning_rate_init[0]\n",
    "#             #\n",
    "#             ndime         =  y_train.shape[1]\n",
    "#             n_train       =  X_train.shape[0]\n",
    "#             n_test        =  X_test.shape[0]\n",
    "#             assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "#             inputs        =  keras.Input(shape=shape)\n",
    "#             #\n",
    "#     #         pdb.set_trace()\n",
    "#             #------------------------------\n",
    "#             #--- The network architecture\n",
    "#             #------------------------------\n",
    "#             model     = keras.Sequential([\n",
    "#                 layers.Dense(self.hidden_layer_size, activation=\"relu\"),\n",
    "#     #             layers.Dense(self.hidden_layer_size), #activation=\"relu\"),\n",
    "#                 layers.Dense(2, activation=\"softmax\")\n",
    "#                 ])\n",
    "#             optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "\n",
    "#             model.compile( optimizer=\"rmsprop\",\n",
    "#                            loss=\"sparse_categorical_crossentropy\",\n",
    "#                            metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "#             #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "#             X_train_reshaped =  X_train \n",
    "#             X_test_reshaped  =  X_test\n",
    "#             model.fit( X_train_reshaped, y_train, \n",
    "#                        validation_data      = ( X_test_reshaped, y_test ),\n",
    "#     #                     callbacks=callbacks,\n",
    "#                         epochs              = epochs, \n",
    "#                         verbose             = self.verbose, \n",
    "#                         shuffle             = False, \n",
    "#     #                     batch_size     = 128,\n",
    "#                         use_multiprocessing = True,\n",
    "#                         workers             = 4,\n",
    "#                      )        \n",
    "\n",
    "\n",
    "#             #--- save best model\n",
    "#             !mkdir best_model\n",
    "#     #         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#     #                                                    monitor=\"val_loss\",\n",
    "#     #                                                   save_freq=10,\n",
    "#     #                                                     save_best_only=True)]\n",
    "\n",
    "\n",
    "#             #--- validation loss\n",
    "#             loss       = model.history.history['loss']\n",
    "#             val_loss   = model.history.history['val_loss']\n",
    "#             best_model = model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "\n",
    "#             !mkdir png\n",
    "#             utl.PltErr(range(len(loss)), loss,\n",
    "#                        yscale='log',\n",
    "#                        xstr='epoch',ystr='loss',\n",
    "#                        title='png/loss_classification.png',\n",
    "#                       )\n",
    "\n",
    "#     #         pdb.set_trace()\n",
    "#             #--- confusion matrix\n",
    "#             cm = confusion_matrix(y_test, model.predict_classes(X_test),\n",
    "#                              labels=[0, 1]\n",
    "#                             )\n",
    "#             print('cm=',cm)\n",
    "#             np.savetxt('png/confusion.txt',np.c_[cm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "628ad42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Combine',\n",
       " 'ConvNetwork',\n",
       " 'ConvNetworkClassifier',\n",
       " 'GetCenterAtom',\n",
       " 'KerasANN',\n",
       " 'PCA',\n",
       " 'Parse',\n",
       " 'PrintDensityMap',\n",
       " 'SklearnMLP',\n",
       " 'Spectra',\n",
       " 'TrainClassifier',\n",
       " 'TrainRegressor',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'zscore']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(NeuralNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8fc70",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating descriptors ...\n",
      "mkdir: best_model: File exists\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f961628c3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f961628c3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f961628c3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 1/32 [..............................] - ETA: 17s - loss: 0.6944 - mse: 0.2522WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9608e6d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9608e6d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9608e6d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9606cbf050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9606cbf050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9606cbf050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/32 [========>.....................] - ETA: 1s - loss: 0.7395 - mse: 0.2605 WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9606cbf9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9606cbf9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9606cbf9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f960e4e9830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f960e4e9830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f960e4e9830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/32 [=================>............] - ETA: 0s - loss: 0.7222 - mse: 0.2586WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9605f499e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9605f499e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9605f499e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.7519 - mse: 0.2591 - val_loss: 0.7847 - val_mse: 0.2572\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7194 - mse: 0.2589 - val_loss: 0.7566 - val_mse: 0.2572\n",
      "Epoch 3/10\n",
      "11/32 [=========>....................] - ETA: 0s - loss: 0.6611 - mse: 0.2600WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9605f5a200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9605f5a200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9605f5a200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9605caed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9605caed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9605caed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6924 - mse: 0.2587 - val_loss: 0.7280 - val_mse: 0.2573\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6676 - mse: 0.2592 - val_loss: 0.6977 - val_mse: 0.2577\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6425 - mse: 0.2597 - val_loss: 0.6652 - val_mse: 0.2583\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6177 - mse: 0.2604 - val_loss: 0.6335 - val_mse: 0.2592\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5936 - mse: 0.2612 - val_loss: 0.6014 - val_mse: 0.2602\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5702 - mse: 0.2623 - val_loss: 0.5685 - val_mse: 0.2614\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5476 - mse: 0.2636 - val_loss: 0.5400 - val_mse: 0.2623\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5257 - mse: 0.2652 - val_loss: 0.5222 - val_mse: 0.2646\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9606ceb8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9606ceb8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9606ceb8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "mkdir: png: File exists\n"
     ]
    }
   ],
   "source": [
    " def main():\n",
    " \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes = eval(confParser['neural net']['hidden_layer_sizes']),\n",
    "                        learning_rate_init = eval(confParser['neural net']['learning_rate_init']),\n",
    "                        n_iter_no_change   = eval(confParser['neural net']['n_iter_no_change']),\n",
    "                        tol                = eval(confParser['neural net']['tol']),\n",
    "                        max_iter           = eval(confParser['neural net']['max_iter']),\n",
    "                        alpha              = eval(confParser['neural net']['alpha']),\n",
    "                        hidden_layer_size  = eval(confParser['neural net']['hidden_layer_size']),\n",
    "                        fully_connected    = eval(confParser['neural net']['fully_connected']),\n",
    "                        implementation     = eval(confParser['neural net']['implementation']),\n",
    "                        cnn                = eval(confParser['neural net']['cnn']),\n",
    "                        n_channels         = eval(confParser['neural net']['n_channels']),\n",
    "                        kernel_size        = eval(confParser['neural net']['kernel_size']),\n",
    "                        activation         = eval(confParser['neural net']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net']['number_hidden_layers']),\n",
    "                        verbose            = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net']['nruns']))\n",
    "\n",
    "    nn.Combine() #--- concat. descriptors\n",
    "    \n",
    "#     tmp = nn.df_combined.set_index('id')\n",
    "#    display(nn.perAtomData.iloc[:13])\n",
    "#    nn.PrintDensityMap(6,'density6.xyz')\n",
    "#    nn.PCA()\n",
    "#    nn.Spectra()\n",
    "\n",
    "\n",
    "    #--- classifier\n",
    "    if eval(confParser['neural net']['classification']):\n",
    "        nn.TrainClassifier(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "#        nn.Test(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    \n",
    "    \n",
    "    #--- filter data\n",
    "    train_type = int(eval(confParser['neural net']['train_type']))\n",
    "    \n",
    "    filtr      = {\n",
    "                     0: nn.perAtomData.defect_label == 1.0, #--- only non-crystalline atoms\n",
    "                     1: np.ones(len(nn.perAtomData),dtype=bool), #--- every atom\n",
    "                    }[train_type]\n",
    "    stratify   = {\n",
    "                    0:None,\n",
    "                    1:np.c_[nn.perAtomData.defect_label].astype(int), #--- ensure same ratio in test and training\n",
    "                    }[train_type]\n",
    "\n",
    "\n",
    "    \n",
    "    #--- train regressor\n",
    "    if eval(confParser['neural net']['regression']):\n",
    "\n",
    "        nn.TrainRegressor(  stratify=stratify,\n",
    "                            y=np.c_[nn.perAtomData[filtr]['ux uy uz'.split()]],\n",
    "                            printOvito = True,\n",
    "                            filtr=filtr,\n",
    "                         )\n",
    "    return nn\n",
    "\n",
    "!rm -r png;mkdir png\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aefa4",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b74daa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[279.  61.]\n",
      " [  1.   1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend = utl.Legends()\n",
    "legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "symbols = utl.Symbols()\n",
    "\n",
    "fp = ['confusion.txt', 'val_loss_classification.txt'][0]\n",
    "data = np.loadtxt('png/%s'%(fp))\n",
    "ax = utl.PltErr(None, None, Plot=False )\n",
    "if fp == 'confusion.txt':\n",
    "    accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "    accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "    print(data)\n",
    "    utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "       attrs=symbols.GetAttrs(count=0,nevery=800,\n",
    "            ), \n",
    "               Plot=False,\n",
    "               ax=ax,\n",
    "               )\n",
    "else:\n",
    "    epoch = data[:,0]\n",
    "    loss = data[:,1]\n",
    "    val_loss = data[:,2]\n",
    "\n",
    "    utl.PltErr(epoch, val_loss,\n",
    "       attrs=symbols.GetAttrs(count=0,nevery=10,\n",
    "            ), \n",
    "               Plot=False,\n",
    "               ax=ax,\n",
    "               )\n",
    "    \n",
    "ax = utl.PltErr(None, None,\n",
    "yscale='log',xscale='log',\n",
    "xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "ax=ax,\n",
    "# legend=legend.Get(),\n",
    "title='png/training_loss.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f1a5a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[323.  17.]\n",
      " [  1.   2.]]\n",
      "[[322.  18.]\n",
      " [  1.   2.]]\n",
      "[[327.  13.]\n",
      " [  0.   3.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "    #--- ann\n",
    "    number_hidden_layers  = dict(zip(range(4),[1]))\n",
    "    hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "    n_channels            = dict(zip(range(4),[1]))\n",
    "    activations           = dict(zip(range(20),['relu']))\n",
    "#     string[ inums ] = \"\\t\\'5\\':\\'neuralNet/20x20/ann/classifier/layer%s/channel%s/activation%s/layer_size%s\\',\\n\" % (key_n,key_c,key_a,key_h) #--- change job name\n",
    "    \n",
    "    #--- cnn\n",
    "#     number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "#     hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "#     n_channels            = dict(zip(range(4),[8,16,32,64]))\n",
    "#     activations           = dict(zip(range(20),['linear']))\n",
    "\n",
    "    runs = [0,1,2]\n",
    "    \n",
    "    legend = utl.Legends()\n",
    "    legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "    symbols = utl.Symbols()\n",
    "    \n",
    "    nphi = len(number_hidden_layers)\n",
    "    #---\n",
    "    count = 0\n",
    "    ax = utl.PltErr(None, None, Plot=False )\n",
    "    for key_n in number_hidden_layers:\n",
    "        number_hidden_layer = number_hidden_layers[key_n]\n",
    "#         if number_hidden_layer != 2:\n",
    "#             continue\n",
    "        for key_c in n_channels:\n",
    "            n_channel = n_channels[key_c]\n",
    "#             if n_channel != 16:\n",
    "#                 continue\n",
    "            for key_a in activations:\n",
    "                activation = activations[key_a]\n",
    "                for key_h in hidden_layer_size:\n",
    "                    nsize = hidden_layer_size[key_h]\n",
    "\n",
    "        #---\t\n",
    "#                    path = 'neuralNet/20x20/cnn/classifier/layer%s/channel%s/activation%s/layer_size%s'%(key_n,key_c,key_a,key_h) #--- change job name\n",
    "                    path = 'test' #--- change job name\n",
    "                    fp = ['confusion.txt', 'val_loss_classification.txt'][0]\n",
    "                    for irun in runs:\n",
    "                        try:\n",
    "                            data = np.loadtxt('%s/Run%s/png/%s'%(path,irun,fp))\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        if fp == 'confusion.txt':\n",
    "                            accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "                            accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "                            print(data)\n",
    "                            utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                        else:\n",
    "                            epoch = data[:,0]\n",
    "                            loss = data[:,1]\n",
    "                            val_loss = data[:,2]\n",
    "\n",
    "                            utl.PltErr(epoch, val_loss,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                    count += 1\n",
    "    ax = utl.PltErr(None, None,\n",
    "#                         yscale='log',xscale='log',\n",
    "                       xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "                    ax=ax,\n",
    "                    legend=legend.Get(),\n",
    "                       title='png/training_loss.png',\n",
    "                   )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506974a",
   "metadata": {},
   "source": [
    "## test example: 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1be92045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.725966 1.725967]]\n",
      "(3, 441)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# y=np.c_[[1.725966,1.725967],\n",
    "#             [-1.725966,1.725967],\n",
    "#             [-1.725966,-1.725967],\n",
    "#             [1.725966,-1.725967],\n",
    "#            ].T\n",
    "\n",
    "# X=np.concatenate([list(map(lambda x:np.load('png/descriptor%s.npy'%x).flatten(),range(4)))],axis=1)\n",
    "\n",
    "# #--- zscore\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_transfrmd = scaler.transform( X )\n",
    "\n",
    "# X_train_transfrmd, X_test_transfrmd, y_train, y_test = train_test_split(X_transfrmd, y, test_size=0.25)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# print(X_train_transfrmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69377834",
   "metadata": {},
   "source": [
    "### fully connected in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c56d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79024675\n",
      "Iteration 2, loss = 4.79153813\n",
      "Iteration 3, loss = 0.48272480\n",
      "Iteration 4, loss = 0.84242732\n",
      "Iteration 5, loss = 1.20200108\n",
      "Iteration 6, loss = 0.50029766\n",
      "Iteration 7, loss = 0.08083888\n",
      "Iteration 8, loss = 0.31471365\n",
      "Iteration 9, loss = 0.39602049\n",
      "Iteration 10, loss = 0.14417737\n",
      "Iteration 11, loss = 0.05911270\n",
      "Iteration 12, loss = 0.17784119\n",
      "Iteration 13, loss = 0.18843745\n",
      "Iteration 14, loss = 0.08671426\n",
      "Iteration 15, loss = 0.05304450\n",
      "Iteration 16, loss = 0.09624741\n",
      "Iteration 17, loss = 0.09671026\n",
      "Iteration 18, loss = 0.05631733\n",
      "Iteration 19, loss = 0.05017827\n",
      "Iteration 20, loss = 0.06458879\n",
      "Iteration 21, loss = 0.05694448\n",
      "Iteration 22, loss = 0.04181389\n",
      "Iteration 23, loss = 0.04398522\n",
      "Iteration 24, loss = 0.04448364\n",
      "Iteration 25, loss = 0.03786413\n",
      "Iteration 26, loss = 0.03483561\n",
      "Iteration 27, loss = 0.03725800\n",
      "Iteration 28, loss = 0.03546887\n",
      "Iteration 29, loss = 0.03089711\n",
      "Iteration 30, loss = 0.03086940\n",
      "Iteration 31, loss = 0.03225031\n",
      "Iteration 32, loss = 0.02917275\n",
      "Iteration 33, loss = 0.02726652\n",
      "Iteration 34, loss = 0.02892336\n",
      "Iteration 35, loss = 0.02808117\n",
      "Iteration 36, loss = 0.02537011\n",
      "Iteration 37, loss = 0.02600391\n",
      "Iteration 38, loss = 0.02698854\n",
      "Iteration 39, loss = 0.02494826\n",
      "Iteration 40, loss = 0.02394280\n",
      "Iteration 41, loss = 0.02572275\n",
      "Iteration 42, loss = 0.02497078\n",
      "Iteration 43, loss = 0.02293285\n",
      "Iteration 44, loss = 0.02413425\n",
      "Iteration 45, loss = 0.02455046\n",
      "Iteration 46, loss = 0.02270986\n",
      "Iteration 47, loss = 0.02347172\n",
      "Iteration 48, loss = 0.02360856\n",
      "Iteration 49, loss = 0.02255866\n",
      "Iteration 50, loss = 0.02314975\n",
      "Iteration 51, loss = 0.02309027\n",
      "Iteration 52, loss = 0.02259666\n",
      "Iteration 53, loss = 0.02288285\n",
      "Iteration 54, loss = 0.02297684\n",
      "Iteration 55, loss = 0.02300910\n",
      "Iteration 56, loss = 0.02306715\n",
      "Iteration 57, loss = 0.02287899\n",
      "Iteration 58, loss = 0.02262910\n",
      "Iteration 59, loss = 0.02261209\n",
      "Iteration 60, loss = 0.02282631\n",
      "Iteration 61, loss = 0.02271234\n",
      "Iteration 62, loss = 0.02245436\n",
      "Iteration 63, loss = 0.02261107\n",
      "Iteration 64, loss = 0.02257859\n",
      "Iteration 65, loss = 0.02275319\n",
      "Iteration 66, loss = 0.02301587\n",
      "Iteration 67, loss = 0.02290518\n",
      "Iteration 68, loss = 0.02263656\n",
      "Iteration 69, loss = 0.02244420\n",
      "Iteration 70, loss = 0.02264114\n",
      "Iteration 71, loss = 0.02285952\n",
      "Iteration 72, loss = 0.02284724\n",
      "Iteration 73, loss = 0.02254051\n",
      "Iteration 74, loss = 0.02253781\n",
      "Iteration 75, loss = 0.02259026\n",
      "Iteration 76, loss = 0.02266804\n",
      "Iteration 77, loss = 0.02250421\n",
      "Iteration 78, loss = 0.02246337\n",
      "Iteration 79, loss = 0.02244526\n",
      "Iteration 80, loss = 0.02255226\n",
      "Iteration 81, loss = 0.02250348\n",
      "Iteration 82, loss = 0.02240397\n",
      "Iteration 83, loss = 0.02242926\n",
      "Iteration 84, loss = 0.02245178\n",
      "Iteration 85, loss = 0.02249455\n",
      "Iteration 86, loss = 0.02250251\n",
      "Iteration 87, loss = 0.02240619\n",
      "Iteration 88, loss = 0.02238247\n",
      "Iteration 89, loss = 0.02239953\n",
      "Iteration 90, loss = 0.02242186\n",
      "Iteration 91, loss = 0.02243013\n",
      "Iteration 92, loss = 0.02237696\n",
      "Iteration 93, loss = 0.02237238\n",
      "Iteration 94, loss = 0.02236637\n",
      "Iteration 95, loss = 0.02241898\n",
      "Iteration 96, loss = 0.02244555\n",
      "Iteration 97, loss = 0.02243013\n",
      "Iteration 98, loss = 0.02236881\n",
      "Iteration 99, loss = 0.02236044\n",
      "Iteration 100, loss = 0.02237842\n",
      "mkdir: png: File exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEcCAYAAAB9B4nYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZIElEQVR4nO3de5hcVZ3u8e9r5KJMnqAEZIxgkEvm4qM4p1GQOZKYEYQxgGB0LtwcNIgXZPQccGZEbsrtMCLIAOYMGAW8oAExjwg4kAZRGNIZZEYZQPBEGAIxCEQGxITwO3+sXaRSqeqq3b2rd6/u9/M89eyuvXdX/1JP95u1V629liICM7McvKTuAszMeuXAMrNsOLDMLBsOLDPLhgPLzLLhwDKzbDiwxjlJC+quIQd+n3qX83vlwBr/xt0vl6R5ddfQxrh7n8DvVa96fZ8cWDYS4/GPcLzye9Wbnt4neaT7i+k+b+rUqR/cbbfd6i5nI6tXr2bbbbetu4yNrFmzhmnTptVdxkbG4/sEfq96tXz58meBK4ElEbGk03kOrCYDAwMxNDRUdxlmk46k5REx0O08XxKaWTYcWGaWDQeWmWXDgWVm2XBgmVk2HFhmlg0Hlpllw4FlZtlwYJlZNhxYZpYNB5aZZcOBZWbZcGCZWTYcWGaWDQeWmWXDgWVm2XBgmVk2HFhmlg0Hlpllw4FlZtlwYJlZNhxYZpYNB5aZZcOBZWbZcGCZWTYcWGaWDQeWmWXDgWVm2cg+sCRtI+kDkq6R9ICk30paI+k2SUdLyv7faGbJS+suoALzgYuBR4GlwEPAq4BDgH8G9pc0PyKivhLNrAoTIbDuBw4EvhcRLzR2Svp74E7gUFJ4La6nPDOrSvaXSxFxc0QsaQ6rYv9jwCXF09ljXpiZVS77wOpiXbF9vtYqzKwSEzawJL0UOKJ4en2dtZhZNSZsYAFnAa8HrouIG+ouxsxGb0IGlqTjgE8C9wKHdzl3gaQhSUOrV68ek/rMbBPTG3+HxWNBu5M00T7tl/RR4IvAPcDcovO9JwMDAzE0NNS32sysPUnLI2Kg23kTqoUl6XhSWP0UmFMmrMxs/JswgSXpROA84CeksPpVvRWZWdUmRGBJOonUyb6cdBn4eM0lmVkfZD/SXdKRwGnAeuCHwHGSWk9bERGLxrg0M6tY9oEF7FRspwDHdzjnFmDRWBRjZv2T/SVhRJwSEerymF13nWb9dPvtcOaZaTuRTYQWltmkdvvtMHcurF0Lm28ON90Ee+1Vd1X9kX0Ly2yyGxxMYbV+fdoODtZdUf84sMwyN3t2allNmZK2s2fXXVH/+JLQLHN77ZUuAwcHU1hN1MtBGCawJB3R6Vg3EfHVkX6vmZW3114TO6gahmthLQKabzRUy/N2Guc4sMyscsMF1vvb7DsEmEca1zQIPAZsD8wB3gZ8F7im2hLNzJKOgRURX2l+LukA4J3AQRGxpOX0UyUdBFzFhmmJzcwqVeZTwn8ArmkTVgBExLXAd4CTKqjLzGwTZQLrjcADXc55AHjDyMsxM+usTGCtJYXWcN7IhoUfzMwqVSawbgIOkPRRtUyHoORjwP7Av1RZoJlZQ5mBo58ifRp4PnC8pNuAVaRVlv+UNGvCE8V5ZmaV6zmwIuJBSXsCFwF/Bryu5ZQfAB+JiF9UWJ+Z2YtK3ZoTEQ8A+0qaAbwJmAasAe6KiEf6UJ+Z2YtGdC9hEU4OKDMbUyMKLEl/APwh8HsRcXm1JZmZtVdqehlJu0saAn4GfJumaYcl7SPpWUnzqi3RzCzpObAk7Ua6f3AW6ZPC77eccivpU8L3VFWcmVmzMi2sk4HNgbdExCeAZc0HIy0hfTuwR3XlmZltUCaw5gJXR8Q9w5zzMPDq0ZVkZtZemcB6BfBfXc4RqRVmZla5MoG1Ctilyzl/TGplmZlVrkxg3QzMkzSr3UFJe5AuG2+oojAzs1ZlAutM4HngVknHUvRVSfrj4vkS4Gng3MqrNDOj3L2E90k6FPg6cGGxW8C/F9ungEMi4qGqizQzg/L3El4vaSfgSGBPYBvSvYR3AF+OiCeqL9HMLCl9a05EPEUaOHp+5dWYmQ2jzEj3yyQd2OWcd0m6bPRljS1J8yQtXLNmTd2lmE1W0yQt7HZrX5lO96OA3buc80bS5WJWImJJRCyYNm1a3aWYTVZrImJBp0VuGkrd/NyDLYD1Fb+mmRlQPrA6rvwsaQvSYqqPjaoiM7MOhu10l9Q63fHfSmq3IvQUYFtSC8sLqZpZX3T7lPAlbGhVBWm8ldqctw74D9LKOp+trDozsybDBlZEzGx8LekF4LyIOK3fRZmZtVNmHNYcYEWf6jAz66rMrTm39LMQM7Nuygwc/bSkdZLaTtAnaYaktZJOrK48M7MNygxrmAcMRsTKdgeLpb+WAgdXUJeZ2SbKBNYuwHDTI1Mc7zbJn5nZiJQJrJcBz3Y55zlg6sjLMTPrrExg/RdpSpnh7IlXhDazPikTWNcDb5P0vnYHJf0FsA+brldoZlaJMuOwzgb+GvhaEVrXk1pTM4D9gQNJC6meVXWRZmZQbhzWI5L2A75F+iTwoKbDIg0qnR8R3ZYCMzMbkbJTJA8VS9bPI/VXbU2ay/0OYElErKu6QDOzhpFMkbwOuLp4mJmNmaon8DMz65uOLSxJRxRfXhMRTzc97yoivjrqyszMWgx3SbiINAfWHaQFUhvPh6PiHAeWmVVuuMD6G1L4PFo8bzfTqJnZmOkYWBGxqOX5V/pejZnZMNzpbmbZcGCZWTaG+5SwdcWcXkVE7DzC7zUz62i4TvfmFXMaNgd+v/h6PfA4MJ20zBekDvq1VRZoZtbQ8ZIwImZGxE6NB2kZ+kdIwxzmAFtGxO8DWwJvB/6VNAXNG/pftplNRmX6sD5HundwdkTcEhHrASJifUQMkkLslcV5ZmaVKxNY7waujYi2l3wR8RxwLXBIFYWVJek1ki6TtFLS7yStkPQFSa+oox4zq16Zm5+3ATbrcs5mxXljStLOwI+B7UiheS/wZuDjwDsl7R0Rvx7rusysWmVaWA8C75E0rd3BoiXzHmCkny6OxkWksDouIg6OiE9FxNuB84BZ+DLVbEIoE1iXAK8G7pR0hKSZkl5WbI8kdbpvD/xTPwrtpGhd7UuaQLD1Z58MPAMcLmmrsazLzKpXZsbRCyXtCnwM+HKbUwR8MSIuqqq4Hs0ptjdGxAvNB4pZJn5ECrQ9gZvGuDYzq1Cpke4R8XFgb+Ay4C7S5d9dwKXAnxbHx9qsYnt/h+M/L7a7jUEtZtZHI5lx9Hbg9j7UMlKNPrU1HY439m/d7qCkBcACgB133LHSwsysZ9MlDTU9XxgRC1tPKh1YE03xpiwEGBgY6Dbfl5n1x+MRMdDtpNI3P0uaJ+kbku6W9EDT/j+UdIKkGWVfc5QaLai2n1427X+q/6WYWT/13MKSJNKso4cVu35LWr6+4UngDFLn+9kV1deL+4ptpz6qXYttpz4uM8tEmRbWh4HDSZ8QvhI4t/lgRDwG/Aj488qq683SYruvpI3+PZKmkj4keJZ0D6SZZaxMYB0N3A18MCLW0H5+958DO1VRWK8i4kHgRmAm8JGWw6cCWwGXR8QzY1mXmVWvTKf7LOBLETFcx/SvgG1HV9KIfJh0a84FkuYC/wm8hTRG637gH2qoycwqVqaF9TxpKpnhzAD+e+TljEzRyhog9bG9BfgksDNwPrCn7yM0mxjKtLDuAWZLUrtWlqTGvFh3VVVcGRHxMF7Zx2xCK9PCuhz4A+C8Np3bU4DPk+41XFRZdWZmTcq0sL4EHAgcB8wnLa6KpG+T7tN7NWm+rCurLtLMDEq0sIoZRt8FnAZsQRr3JNKEfS8HTicFmZlZX5S6NScingdOkXQqKbC2IY00v7cxZbKZWb+UGem+HvhGRPx10el+X7fvMTOrUplO96eBh/pViJlZN2UC6y7gj/pViJlZN2UC62zgAEnv6FcxZmbDKdPpvh1wPfB9Sd8BlgGP0eaewoj4aiXVmZk1KRNYi0jh1BjK0Fh/sDmwVDx3YJlZ5coElm97MbNalVk15yv9LMTMrJvSUySbmdWl9CIUkn4PeDfwJtJ86WtIQx6uiYgxn1rGzCaPUoElaT5pBeitSR3sDQF8QdIxEfHt6sozM9ugzK057wC+DrxA+hRwkDSsYXvSzJ5/BXxd0lMR8S/Vl2pmk12ZFtZngN8B/zMi/q3l2FckXQjcWpznwDKzypXpdH8T8M02YQVARAwBVwF/UkVhZmatygTW74BHu5yzsjjPzKxyZQLrh6Q1/oazN+my0MyscmUC60TgDZLOkrRV8wFJW0k6B3g98KkqCzQzayjT6X4i8O/A/wYWSPo3YBXwKlK/1TRS6+rEtKr9iyIijq6mXDObzMoE1lFNX29NWtKr1T7Fo1mQVo02MxuVMoE1pkvQm5m1KnPz8y/7WYiZWTe++dnMsuHAMrNsOLAASfMkLVyzZk3dpZhNVtMkLZQ0b7iTlJYYNICBgYEYGhqquwyzSUfS8ogY6HaeW1hmlg0Hlpllw4FlZtnoObAk3S3pWElT+1mQmVknZVpYfwRcCKyU9H8lde0gMzOrUpnAeg1wErCadG/gv0oakvTB1tkbzMz6oefAiohVEXFGRLwO2B/4DvAG0qIUKyVdJGn3vlRpZsYIO90j4oaIOBTYgdTqehw4Blgu6Q5JR0nassI6zcxG9ylhRKwCzgQ+QZoeWcCbgUuBhyUdP9oCzcwaRhxYkmZIOhn4JXA1abmv7wIHA6cD64F/lHR6BXWamZULLCUHSLoW+H/AycBmwBnA6yLi4Ij4bkScAuwKLMeT95lZRcospHoSKXx2IF363QpcBFwdEc+3nh8RT0taApxSTalmNtmVmXH0VOA3pJC6OCLu6eF7lpNWiTYzG7UygfUh4MqIeKbXb4iI64DrSldlZtZGmSmSF/azEDOzbnzzs5llo0yn+y96PDUiYucR1mNm1lGZPqyXkNYYbLU1aRFVSINH142yJjOztsr0Yc3sdEzSLsAFwFbAfqMvy8xsU5X0YUXEA8AhwAzSYFIzs8pV1ukeEc8BPwD+sqrXNDNrVvWnhM+T7ik0M6tcZYElaTrwbuDhql7TerNwIey3X9qaTWRlhjV8ZpjX2AE4iPRp4d9VUJf1aOFCOOaY9PWNN6btggX11WPWT2WGNZzS5fhvgM9GxDkjL8fKWrx40+cOLJuoygTWnA77XwCeBO5tN2uD9dehh25oWTWem01UZcZh3dLPQmxkGq2pxYtTWLl1ZRNZmRaWjVMLFjiobHLI+uZnSbtKOlHSzZIelrRW0ipJ10rqdAlrZpnKvYV1OvA+4B7SvFtPALOAA4EDJX08Ii6osT4zq1DugXU9cHZE3NW8U9I+pFH3/0fStyLi0VqqM7NKZX1JGBGLWsOq2H8LMAhsDrx1rOsys/7IOrC6aExz46EWZhPEhAwsSa8F5gLPklb3MbMJIPc+rE1I2gK4EtgCOCEinqy5JDOrSO0tLEkrJEWJxxXDvNYU4HJgb+CbwLk9/PwFkoYkDa1evbq6f5iZlTG98XdYPNqOLBwPLawHgedKnL+y3c4irK4A5gNXAYdFRLspnTdSrAa0EGBgYKDr+WbWF49HxEC3k2oPrIiYO9rXkLQZ6TJwPvA14IiIWD/a1zWz8aX2wBotSZuTWlQHkVaZfn9EvFBvVWbWD7X3YY1G0cF+DSmsLsVhZTah5d7CugQ4AHgceAT4jKTWcwYjYnCM6zIbG+ecA3vsAXOabp1duhSWLYMTTqivrj7JPbB2KrbTgU4zokIa9W428eyxB7z3vXDVVSm0li7d8HwCyjqwImJ23TWY1WrOnBRO730vHHssXHzxhvCagLLuwzIzUjgdeyycfnraTtCwAgeWWf6WLk0tq5NOStulS+uuqG8cWGY5a+6zOu20DZeHEzS0HFhmOVu2bOM+q0af1rJl9dbVJ+rh7pVJY2BgIIaGhuouw2zSkbS8l1tz3MIys2w4sMwsGw4sM8uGA8vMsuHAMrNsOLDMLBsOLDPLhgPLzLLhwDKzbDiwzCwbDiwzy4YDy8yy4cAys2w4sMwsGw4sM8uGA8vMsuHAMrNsOLDMLBsOLDPLhgPLzLLhwDKzbDiwzCwbDiwzy4bXJWwiaTXwy7rraDEdeLzuIlpMA9bUXUSL8fg+gd+rXu0aEdO6nfTSsagkFxGxbd01tJI01MsCk2NJ0sKIWFB3Hc3G4/sEfq96JWlhL+f5ktBGYkndBWTE71VvenqfHFhWWkT4j7BHfq960+v75MAa/3pqKpvfpxKyfa/c6W5m2XALy8yy4cAys2w4sDIhaVdJJ0q6WdLDktZKWiXpWklz6q6vDpJeI+kySSsl/U7SCklfkPSKumsbLyRtI+kDkq6R9ICk30paI+k2SUdLyioD3IeVCUnfAN4H3APcBjwBzAIOBKYAH4+IC+qrcGxJ2hn4MbAdcC1wL/BmYA5wH7B3RPy6vgrHB0kfAi4GHgWWAg8BrwIOIQ1qXQzMj0yCwIGVCUlHAXdHxF0t+/cBfgAEMDMiHq2hvDEn6QZgX+C4iPhi0/7PA38LfCkiPlRXfeOFpLcDWwHfi4gXmvZvD9wJ7AC8JyIW11RiKQ6sCUDSjcA7yOgXbzSK1tUDwApg55Y/xKmk1oSA7SLimVqKzICkvwc+B1wYER+ru55eZHX9ah2tK7bP11rF2Gn02d3YHFYAEfE08CPg5cCeY11YZrL7vXFgZU7Sa4G5wLPArTWXM1ZmFdv7Oxz/ebHdbQxqyZKklwJHFE+vr7OWMnzzc8YkbQFcCWwBnBART9Zc0lhp3NXfaRaExv6t+19Kts4CXg9cFxE31F1Mr9zCGkPFx+5R4nHFMK81Bbgc2Bv4JnDuWP07LG+SjgM+Sfpk9fCayynFLayx9SDwXInzV7bbWYTVFcB84CrgsFw+lq5IowXVaf6kxv6n+l9KXiR9FDifNDxmbkQ8UXNJpTiwxlBEzB3ta0jajHQZOB/4GnBERKwf7etm5r5i26mPatdi26mPa1KSdDxwHvBTUlj9qt6KyvOwhoxI2pzUojoI+Crw/tZPySYDD2soT9KJpH6rnwDviIjxNuNoT9yHlYmig/0aUlhdyiQNK4CIeBC4EZgJfKTl8KmkgZKXO6wSSSeRwmo5qWWVZViBW1jZkPRl4CjSXNwXkUa2txqMiMExLKs2bW7N+U/gLaQxWvcDb/WtOSDpSGARsB74Iu0/WV0REYvGsKwRcx9WPnYqttOBzwxz3mD/S6lfRDwoaQA4DXgncADpUvB84NRJNMSjm8bvzRTg+A7n3EIKtXHPLSwzy4b7sMwsGw4sM8uGA8vMsuHAMrNsOLDMLBsOLDPLhgPLzLLhwDIbY5IGJXkA5Ag4sGxScVjkzYFlZtlwYJlZNhxYtglJs4spmk/pcHyFpBVNz48pzj+5w/nbS1on6T96/PlHSVos6RfFSsW/kfQjSYcN8z2vlPQ5ST+V9GyxuvHdks6StJWkmcWl4D7F+c1TUQ82vc5Gz1t+xqLi+MzR1msj49karApXAucAR0v6bJsZUP+G9Lv2pR5f72LgZ6RVgB4FtiHNxnC5pFkRcVLzyZJ2Iq1q/FrSnE8Xk/4z3o20qOolpOmSTyVN0fPa4uuGFT3WVUm9NgoR4YcfGz2A2aT5tk7pcHwFaQ6l5n0XFt/zrpb9An4BPANM6/Hn79xm3+bATaS19Ga0HPtx8bP/rs33TQe2bHo+mH7tO/7sIM0r1u7YIjassD2aeoetwY/OD18SWlUuLrbHtOzflzQn0zcjotOyXBuJNKNo6761wD+RWmovzo0v6X8Ae5Gm/j27zfc9HhFlFv4orUy9Njq+JLRKRMTPJN0K7C9ph4h4uDi0oNhe0utrSdoROJH0h74j8LKWU2Y0fd1Y3fmGqGnK6JL12ig4sKxKFwFvAz4AnCxpe+BA4CcRcWcvLyDpdcCdwCuAH5Lmbl9DmuJ3JnAkaeHYhq2L7SOjL7+8EdRro+DAsnYaLZVOvx9b037Nv6uBVaTO99Mo39kO8AlSp/X7o2WecUl/SQqAZo06qmrFBMP/u1uVrddGwX1Y1k5jPvQdWg9I2oUOC5hGxDrgn0nhMY/U0vpv0qeIvdql2C5uc2yfNvvuKLb7Serl93k9vLgYbTtP0v7fPQXYvc35Zeu1UXBgWTv3Ar8BDpK0XWOnpJcBF3T53oWkULiQ1Nn+tYh4usTPXlFsZzfvlLQfKQA3EhHLSZ8S7k7qR9qIpG0kbdm0q7GSzo4dfv6dwI6S9m3Z/2nScIhR1Wuj48CyTRQtpfNJLam7JF0o6RLSisFTgZXDfO9DwPfYcIlW5nIQUj/YWuBbkq6QdI6k64DvA9/u8D2HAQ8BZ0gaknSupH+U9F1S39b2TefeVGyvLgaaflrS4U3HzyVdFl5bDBT9vKQ7gA/TfkWikdRrI1X3uAo/xueDNH7qU8CDpD/Ih0iDQ19Om3FYLd97EOmPftkIf/ZbgZtJl2dPA7cBBzPM+DBSP9LZpGXsnyP1bf0E+Bzw8qbzpgBnkMaGraPNuCvSBwVDxev8GvgGqXW1iPbjsErVi8dhjfjhZb6scsUtPScDH4iIS2suxyYQB5ZVStJU4OfAZsAOEfFszSXZBOJhDVYJSX8O/Anp08FXAf/LYWVVc2BZVeaTxhytAs4Ezqu3HJuIfEloZtnwsAYzy4YDy8yy4cAys2w4sMwsGw4sM8uGA8vMsvH/Acj291k4T/DxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# #        pdb.set_trace()\n",
    "# #--- tune parameters\n",
    "\n",
    "# #--- train\n",
    "# mlp = MLPRegressor(random_state=1,\n",
    "#                     verbose=True,\n",
    "#                    n_iter_no_change=100000,\n",
    "#                     max_iter=100,#00,\n",
    "#                    hidden_layer_sizes=(1000,1000),\n",
    "# #                    shuffle=False,\n",
    "# #                     alpha=1e-1,\n",
    "\n",
    "#                   )\n",
    "# mlp.fit(X_train_transfrmd,y_train)\n",
    "\n",
    "# #--- validate\n",
    "# !mkdir png\n",
    "# utl.PltErr(range(len(mlp.loss_curve_)), mlp.loss_curve_,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            yscale='log',xscale='log',\n",
    "# #           xlim=(1,self.max_iter[0]),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )\n",
    "\n",
    "# # #         pdb.set_trace()\n",
    "# y_pred =mlp.predict(X_test_transfrmd)        \n",
    "# y_pred_train = mlp.predict(X_train_transfrmd)        \n",
    "# for idime, xstr in zip(range(2),'ux uy'.split()):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     #\n",
    "#     utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(None,None,Plot=False,\n",
    "#                    title='png/scatter%s.png'%idime,\n",
    "#                     ax=ax,\n",
    "#                xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                xlim=(-3,3),ylim=(-3,3),\n",
    "#                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.best_loss_, mlp.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=mlp.predict(X_test_transfrmd)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(2):\n",
    "#     utl.PltErr(range(data.descriptors[0,:].shape[0]),data.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n",
    "# utl.PltErr(range(data.descriptors[100,:].shape[0]),data.descriptors[100,:],\n",
    "#           attrs={'fmt':'-','color':'C0'},\n",
    "#            xscale='log',yscale='log',\n",
    "#            ax=ax,\n",
    "#            Plot=False,\n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d061978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     random_state=1)\n",
    "# regr = MLPRegressor(verbose=False,\n",
    "#                     random_state=1, \n",
    "# #                     learning_rate='adaptive',\n",
    "# #                    early_stopping=True, \n",
    "#                      n_iter_no_change=1, \n",
    "#                     tol=1e-2,\n",
    "#                      max_iter=10000000,\n",
    "# #                     solver='sgd',\n",
    "#                    ).fit(X_train, y_train)\n",
    "# regr.tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eecba",
   "metadata": {},
   "source": [
    "### fully connected in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--- The network architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512), #activation=\"relu\"),\n",
    "# #     layers.Dense(1000), #activation=\"relu\"),\n",
    "#     layers.Dense(2) #, activation=\"relu\")\n",
    "#     ])\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- Preparing the image data\n",
    "# # train_images = train_images.reshape((60000, 28 * 28))\n",
    "# # train_images = train_images.astype(\"float32\") / 255\n",
    "# # test_images = test_images.reshape((10000, 28 * 28))\n",
    "# # test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# model.fit(X_train_transfrmd, y_train, \n",
    "#             validation_data=(X_test_transfrmd, y_test),\n",
    "\n",
    "#           epochs=100, verbose=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,100),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262922c9",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f22b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.random.set_random_seed(812)\n",
    "\n",
    "# shape=(300,300,1)\n",
    "# kernel_size = (3,3)\n",
    "# epochs = 1000\n",
    "# activation = ['linear','sigmoid','relu'][0]\n",
    "# padding='same'\n",
    "# filters = 1\n",
    "# #\n",
    "# ndime = y_train.shape[1]\n",
    "# n_train = X_train_transfrmd.shape[0]\n",
    "# n_test = X_test_transfrmd.shape[0]\n",
    "# assert shape[0]*shape[1]*shape[2] == X_train_transfrmd.shape[1]\n",
    "# inputs = keras.Input(shape=shape)\n",
    "# #\n",
    "# x = layers.Conv2D(filters=filters, kernel_size=kernel_size,activation=activation,padding=padding)(inputs)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=2*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=4*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=8*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "\n",
    "# #--- The network architecture\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,epsilon=1e-08)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- save best model \n",
    "# callbacks=[keras.callbacks.ModelCheckpoint( filepath='png/convnet_from_scratch.keras',  \n",
    "#                                            monitor=\"val_loss\",\n",
    "#                                            save_freq=10,\n",
    "#                                             save_best_only=True)]\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# X_train_reshaped = X_train_transfrmd.reshape((n_train,shape[0],shape[1],1))\n",
    "# X_test_reshaped = X_test_transfrmd.reshape((n_test,shape[0],shape[1],1))\n",
    "# model.fit(X_train_reshaped, y_train, \n",
    "#             validation_data=(X_test_reshaped, y_test),\n",
    "#             #callbacks=callbacks,\n",
    "#           epochs=epochs, verbose=False, shuffle=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,epochs),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = keras.models.load_model(\"png/convnet_from_scratch.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=best_model.predict(X_test_reshaped)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf166dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (ux,uy), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e9080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "453.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
