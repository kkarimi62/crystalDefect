{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>main()</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#test-example:-2d\" data-toc-modified-id=\"test-example:-2d-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>test example: 2d</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-connected-in-sklearn\" data-toc-modified-id=\"fully-connected-in-sklearn-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>fully connected in sklearn</a></span></li><li><span><a href=\"#fully-connected-in-keras\" data-toc-modified-id=\"fully-connected-in-keras-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>fully connected in keras</a></span></li><li><span><a href=\"#cnn\" data-toc-modified-id=\"cnn-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>cnn</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['flags', 'input files', 'EnergyBarrier', 'neural net', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "#\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "from scipy.stats import gaussian_kde\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            if irun == 0:\n",
    "                #--- same configurations!\n",
    "                self.descriptors  = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['data']]\n",
    "                self.shape        = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['shape']].flatten()\n",
    "                self.positions    = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz .'%(path,irun))\n",
    "            try:\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                #--- displacement data\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "#         pdb.set_trace()\n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        atom_ids.sort()\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "        descriptors_center_atoms = self.descriptors[atom_ids]\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystaliine atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        descriptors_crystalline = self.descriptors[filtr]\n",
    "\n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- merge descriptors\n",
    "        self.descriptors = np.concatenate([descriptors_center_atoms,descriptors_crystalline],axis=0)\n",
    "\n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "                                 \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "    @staticmethod\n",
    "    def zscore(slist):\n",
    "        tmp = np.copy(slist)\n",
    "        print(np.mean(tmp),np.std(tmp))\n",
    "        tmp -= np.mean(tmp)\n",
    "        tmp /= np.std(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def SklearnMLP(self,X_train,y_train):\n",
    "        #-----------------------\n",
    "        #--- parameter grid\n",
    "        #-----------------------\n",
    "        param_grid = {\n",
    "                        'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                         #'activation' : ['tanh', 'relu'],\n",
    "                         'learning_rate_init':self.learning_rate_init,\n",
    "                        'alpha':self.alpha, #--- regularization \n",
    "                         #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                        'n_iter_no_change':self.n_iter_no_change,\n",
    "                        'tol':self.tol,\n",
    "                        'max_iter':self.max_iter,\n",
    "                     } \n",
    "        mlp   =  MLPClassifier(random_state=random_state,verbose=self.verbose)\n",
    "        clf  =  GridSearchCV(mlp, param_grid)\n",
    "        clf.fit(X_train,y_train)\n",
    "        model =  clf.best_estimator_\n",
    "        loss  =  model.loss_curve_\n",
    "        val_loss = loss\n",
    "        return (model, loss, val_loss)\n",
    "\n",
    "    def KerasANN(self, X_train, y_train,X_test, y_test, ndime):\n",
    "\n",
    "#         model     = keras.Sequential([ #--- The network architecture\n",
    "#             layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "#             layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "#             layers.Dense(ndime, activation='softmax')\n",
    "#             ])\n",
    "        \n",
    "        inputs        =  keras.Input() #shape=shape)\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Dense(   self.hidden_layer_size, activation=self.activation\n",
    "                                       )(inputs)\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.Dense( self.hidden_layer_size, activation=self.activation\n",
    "                                     )(x)\n",
    "        #--- output layer\n",
    "#         x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation='softmax')(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        \n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "        model.compile( optimizer=optimizer,\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"accuracy\"]\n",
    "                     )\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"accuracy\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        model.fit( X_train, y_train, \n",
    "           validation_data      = ( X_test, y_test ),\n",
    "            callbacks           = callbacks,\n",
    "            epochs              = self.max_iter[0], \n",
    "            verbose             = self.verbose, \n",
    "            shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "         )        \n",
    "        loss      = model.history.history['loss']\n",
    "        val_loss  = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        return (best_model, loss, val_loss)\n",
    "                             \n",
    "    def TrainClassifier(self,y,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        ndime = 2 #--- binary classification\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "\n",
    "        #--- train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                (model, loss, val_loss) = self.SklearnMLP(X_train,y_train)\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                (model, loss, val_loss) = self.KerasANN(X_train, y_train,X_test, y_test, ndime)\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkClassifier( y )\n",
    "                    \n",
    "        #--- save loss data\n",
    "        !mkdir png\n",
    "        np.savetxt('png/val_loss_classification.txt',\n",
    "                   np.c_[range(len(loss)),loss,val_loss],\n",
    "                   header='epoch loss val_loss')\n",
    "\n",
    "        #--- confusion matrix\n",
    "        predict_x = model.predict(X_test) \n",
    "        classes_x = np.argmax(predict_x,axis=1)\n",
    "        cm = confusion_matrix(y_test, classes_x,\n",
    "                         labels=[0, 1]\n",
    "                        )\n",
    "        np.savetxt('png/confusion.txt',np.c_[cm])\n",
    "\n",
    "        \n",
    "\n",
    "    def TrainRegressor(self,stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    "                       filtr = None,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "\n",
    "        ndime  = y.shape[1] #--- dimension of the target vector\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors[filtr]]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                #-----------------------\n",
    "                #--- parameter grid\n",
    "                #-----------------------\n",
    "                param_grid = {\n",
    "                                'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                                 #'activation' : ['tanh', 'relu'],\n",
    "                                 'learning_rate_init':self.learning_rate_init,\n",
    "                                'alpha':self.alpha, #--- regularization \n",
    "                                 #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                                'n_iter_no_change':self.n_iter_no_change,\n",
    "                                'tol':self.tol,\n",
    "                                'max_iter':self.max_iter,\n",
    "                             } \n",
    "                mlp   =  MLPRegressor(random_state=random_state,verbose=self.verbose) #--- mlp regressor\n",
    "                regr  =  GridSearchCV(mlp, param_grid)\n",
    "                regr.fit(X_train,y_train)\n",
    "                model =  regr.best_estimator_\n",
    "                loss  =  model.loss_curve_\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                model     = keras.Sequential([ #--- The network architecture\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(ndime, activation=self.activation)\n",
    "                    ])\n",
    "                optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4) #--- compilation step\n",
    "                model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "                               loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "                               metrics=[\"mse\"]\n",
    "                             )\n",
    "                model.fit(X_train, y_train, #--- “Fitting”\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          epochs=self.max_iter[0], verbose=self.verbose)#, batch_size=128)\n",
    "                loss      = model.history.history['loss']\n",
    "                val_loss  = model.history.history['val_loss']\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetwork(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred       = model.predict(X_test)        \n",
    "        y_pred_train = model.predict(X_train)        \n",
    "        for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "            ax = utl.PltErr(None,None,Plot=False)\n",
    "            #\n",
    "            utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "                       attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                       attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(None,None,Plot=False,\n",
    "                           title='png/scatter%s.png'%idime,\n",
    "                            ax=ax,\n",
    "                       xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "                       xlim=(-2,2),ylim=(-2,2),\n",
    "                           )\n",
    "        \n",
    "        #--- save in ovito\n",
    "        if printOvito:\n",
    "            X_train, X_test, _, _ = train_test_split(self.perAtomData[filtr]['id type x y z'.split()], y, stratify=stratify,\n",
    "                                                    random_state=random_state)\n",
    "#            pdb.set_trace()\n",
    "            with open('original.xyz','w') as fp:\n",
    "                utl.PrintOvito(self.perAtomData[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('train.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_train,y_pred_train],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('test.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_test,y_pred],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "                \n",
    "\n",
    "    def ConvNetwork(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "                                                   monitor=\"loss\",\n",
    "                                                  save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    def ConvNetworkClassifier(self,y,\n",
    "                               random_state=1\n",
    "                               ):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        \n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        if self.verbose:\n",
    "            print('X.shape:=',X.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- set model parameters\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation='softmax')(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss=\"binary_crossentropy\",#\"sparse_categorical_crossentropy\",\n",
    "                       metrics   =  [\"accuracy\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"accuracy\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "                    disp           = np.c_[self.perAtomData.iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.positions.T,self.descriptors[atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, 'disp = %s'%disp, attr_list='x y z mass'.split())\n",
    "#     def SaveConf(self,fout):\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[self.perAtomData],header=' '.join(list(self.perAtomData.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90cf3d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Combine',\n",
       " 'ConvNetwork',\n",
       " 'ConvNetworkClassifier',\n",
       " 'GetCenterAtom',\n",
       " 'KerasANN',\n",
       " 'PCA',\n",
       " 'Parse',\n",
       " 'PrintDensityMap',\n",
       " 'SklearnMLP',\n",
       " 'Spectra',\n",
       " 'TrainClassifier',\n",
       " 'TrainRegressor',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'zscore']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(NeuralNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8fc70",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating descriptors ...\n",
      "mkdir: best_model: File exists\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f831ba92170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f831ba92170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`logits` and `labels` must have the same shape, received ((32, 2) vs (32, 1)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2f60b1bb99ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-2f60b1bb99ef>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m    \u001b[0;31m#--- classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfParser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neural net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m        \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperAtomData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefect_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-850d29d5311a>\u001b[0m in \u001b[0;36mTrainClassifier\u001b[0;34m(self, y, random_state)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplementation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'keras'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#--- dense nn in keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasANN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#--- convolutional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-850d29d5311a>\u001b[0m in \u001b[0;36mKerasANN\u001b[0;34m(self, X_train, y_train, X_test, y_test, ndime)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mepochs\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mverbose\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mshuffle\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;31m#                     batch_size     = 128,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;31m#                     use_multiprocessing = True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gnnEnv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gnnEnv/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   5679\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5680\u001b[0m         return tf.nn.sigmoid_cross_entropy_with_logits(\n\u001b[0;32m-> 5681\u001b[0;31m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5682\u001b[0m         )\n\u001b[1;32m   5683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `logits` and `labels` must have the same shape, received ((32, 2) vs (32, 1))."
     ]
    }
   ],
   "source": [
    " def main():\n",
    " \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes = eval(confParser['neural net']['hidden_layer_sizes']),\n",
    "                        learning_rate_init = eval(confParser['neural net']['learning_rate_init']),\n",
    "                        n_iter_no_change   = eval(confParser['neural net']['n_iter_no_change']),\n",
    "                        tol                = eval(confParser['neural net']['tol']),\n",
    "                        max_iter           = eval(confParser['neural net']['max_iter']),\n",
    "                        alpha              = eval(confParser['neural net']['alpha']),\n",
    "                        hidden_layer_size  = eval(confParser['neural net']['hidden_layer_size']),\n",
    "                        fully_connected    = eval(confParser['neural net']['fully_connected']),\n",
    "                        implementation     = eval(confParser['neural net']['implementation']),\n",
    "                        cnn                = eval(confParser['neural net']['cnn']),\n",
    "                        n_channels         = eval(confParser['neural net']['n_channels']),\n",
    "                        kernel_size        = eval(confParser['neural net']['kernel_size']),\n",
    "                        activation         = eval(confParser['neural net']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net']['number_hidden_layers']),\n",
    "                        verbose            = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net']['nruns']))\n",
    "\n",
    "    nn.Combine() #--- concat. descriptors\n",
    "    \n",
    "#     tmp = nn.df_combined.set_index('id')\n",
    "#    display(nn.perAtomData.iloc[:13])\n",
    "#    nn.PrintDensityMap(6,'density6.xyz')\n",
    "#    nn.PCA()\n",
    "#    nn.Spectra()\n",
    "\n",
    "\n",
    "    #--- classifier\n",
    "    if eval(confParser['neural net']['classification']):\n",
    "        nn.TrainClassifier(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    \n",
    "    \n",
    "    #--- filter data\n",
    "    train_type = int(eval(confParser['neural net']['train_type']))\n",
    "    \n",
    "    filtr      = {\n",
    "                     0: nn.perAtomData.defect_label == 1.0, #--- only non-crystalline atoms\n",
    "                     1: np.ones(len(nn.perAtomData),dtype=bool), #--- every atom\n",
    "                    }[train_type]\n",
    "    stratify   = {\n",
    "                    0:None,\n",
    "                    1:np.c_[nn.perAtomData.defect_label].astype(int), #--- ensure same ratio in test and training\n",
    "                    }[train_type]\n",
    "\n",
    "\n",
    "    \n",
    "    #--- train regressor\n",
    "    if eval(confParser['neural net']['regression']):\n",
    "\n",
    "        nn.TrainRegressor(  stratify=stratify,\n",
    "                            y=np.c_[nn.perAtomData[filtr]['ux uy uz'.split()]],\n",
    "                            printOvito = True,\n",
    "                            filtr=filtr,\n",
    "                         )\n",
    "    return nn\n",
    "\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aefa4",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f1a5a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    number_hidden_layers  = dict(zip(range(4),[1]))\n",
    "    n_channels  = dict(zip(range(4),[8]))\n",
    "    activations = dict(zip(range(20),['relu']))\n",
    "    runs = [0,1,2]\n",
    "    \n",
    "    legend = utl.Legends()\n",
    "    legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "    symbols = utl.Symbols()\n",
    "    \n",
    "    nphi = len(number_hidden_layers)\n",
    "    #---\n",
    "    count = 0\n",
    "    ax = utl.PltErr(None, None, Plot=False )\n",
    "    for key_n in number_hidden_layers:\n",
    "        number_hidden_layer = number_hidden_layers[key_n]\n",
    "#         if number_hidden_layer != 2:\n",
    "#             continue\n",
    "        for key_c in n_channels:\n",
    "            n_channel = n_channels[key_c]\n",
    "#             if n_channel != 16:\n",
    "#                 continue\n",
    "            for key_a in activations:\n",
    "                activation = activations[key_a]\n",
    "\n",
    "        #---\t\n",
    "#                 path = 'neuralNet/ni/keras/20x20/cnn/classification3rd/layer%s/channel%s/activation%s'%(key_n,key_c,key_a) #--- change job name\n",
    "                path = 'neuralNet/ni/keras/20x20/ann/classifier' #--- change job name\n",
    "                fp = ['confusion.txt', 'val_loss_classification.txt'][1]\n",
    "                for irun in runs:\n",
    "                    try:\n",
    "                        data = np.loadtxt('%s/Run%s/png/%s'%(path,irun,fp))\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "                    if fp == 'confusion.txt':\n",
    "                        accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "                        accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "                        print(data)\n",
    "                        utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                   Plot=False,\n",
    "                                   ax=ax,\n",
    "                                   )\n",
    "                    else:\n",
    "                        epoch = data[:,0]\n",
    "                        loss = data[:,1]\n",
    "                        val_loss = data[:,2]\n",
    "\n",
    "                        utl.PltErr(epoch, val_loss,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                   Plot=False,\n",
    "                                   ax=ax,\n",
    "                                   )\n",
    "                count += 1\n",
    "    ax = utl.PltErr(None, None,\n",
    "                       yscale='log',xscale='log',\n",
    "                       xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "                    ax=ax,\n",
    "                    legend=legend.Get(),\n",
    "                       title='png/training_loss.png',\n",
    "                   )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506974a",
   "metadata": {},
   "source": [
    "## test example: 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be92045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# y=np.c_[[1.725966,1.725967],\n",
    "#             [-1.725966,1.725967],\n",
    "#             [-1.725966,-1.725967],\n",
    "#             [1.725966,-1.725967],\n",
    "#            ].T\n",
    "\n",
    "# X=np.concatenate([list(map(lambda x:np.load('png/descriptor%s.npy'%x).flatten(),range(4)))],axis=1)\n",
    "\n",
    "# #--- zscore\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_transfrmd = scaler.transform( X )\n",
    "\n",
    "# X_train_transfrmd, X_test_transfrmd, y_train, y_test = train_test_split(X_transfrmd, y, test_size=0.25)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# print(X_train_transfrmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69377834",
   "metadata": {},
   "source": [
    "### fully connected in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #        pdb.set_trace()\n",
    "# #--- tune parameters\n",
    "\n",
    "# #--- train\n",
    "# mlp = MLPRegressor(random_state=1,\n",
    "# #                    verbose=True,\n",
    "#                    n_iter_no_change=100000,\n",
    "#                     max_iter=10000,\n",
    "#                    hidden_layer_sizes=(1000,1000),\n",
    "# #                    shuffle=False,\n",
    "# #                     alpha=1e-1,\n",
    "\n",
    "#                   )\n",
    "# mlp.fit(X_train_transfrmd,y_train)\n",
    "\n",
    "# #--- validate\n",
    "# !mkdir png\n",
    "# utl.PltErr(range(len(mlp.loss_curve_)), mlp.loss_curve_,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            yscale='log',xscale='log',\n",
    "# #           xlim=(1,self.max_iter[0]),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )\n",
    "\n",
    "# # #         pdb.set_trace()\n",
    "# y_pred =mlp.predict(X_test_transfrmd)        \n",
    "# y_pred_train = mlp.predict(X_train_transfrmd)        \n",
    "# for idime, xstr in zip(range(2),'ux uy'.split()):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     #\n",
    "#     utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(None,None,Plot=False,\n",
    "#                    title='png/scatter%s.png'%idime,\n",
    "#                     ax=ax,\n",
    "#                xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                xlim=(-3,3),ylim=(-3,3),\n",
    "#                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.best_loss_, mlp.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=mlp.predict(X_test_transfrmd)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(2):\n",
    "#     utl.PltErr(range(data.descriptors[0,:].shape[0]),data.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n",
    "# utl.PltErr(range(data.descriptors[100,:].shape[0]),data.descriptors[100,:],\n",
    "#           attrs={'fmt':'-','color':'C0'},\n",
    "#            xscale='log',yscale='log',\n",
    "#            ax=ax,\n",
    "#            Plot=False,\n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d061978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     random_state=1)\n",
    "# regr = MLPRegressor(verbose=False,\n",
    "#                     random_state=1, \n",
    "# #                     learning_rate='adaptive',\n",
    "# #                    early_stopping=True, \n",
    "#                      n_iter_no_change=1, \n",
    "#                     tol=1e-2,\n",
    "#                      max_iter=10000000,\n",
    "# #                     solver='sgd',\n",
    "#                    ).fit(X_train, y_train)\n",
    "# regr.tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eecba",
   "metadata": {},
   "source": [
    "### fully connected in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--- The network architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512), #activation=\"relu\"),\n",
    "# #     layers.Dense(1000), #activation=\"relu\"),\n",
    "#     layers.Dense(2) #, activation=\"relu\")\n",
    "#     ])\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- Preparing the image data\n",
    "# # train_images = train_images.reshape((60000, 28 * 28))\n",
    "# # train_images = train_images.astype(\"float32\") / 255\n",
    "# # test_images = test_images.reshape((10000, 28 * 28))\n",
    "# # test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# model.fit(X_train_transfrmd, y_train, \n",
    "#             validation_data=(X_test_transfrmd, y_test),\n",
    "\n",
    "#           epochs=100, verbose=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,100),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262922c9",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f22b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.random.set_random_seed(812)\n",
    "\n",
    "# shape=(300,300,1)\n",
    "# kernel_size = (3,3)\n",
    "# epochs = 1000\n",
    "# activation = ['linear','sigmoid','relu'][0]\n",
    "# padding='same'\n",
    "# filters = 1\n",
    "# #\n",
    "# ndime = y_train.shape[1]\n",
    "# n_train = X_train_transfrmd.shape[0]\n",
    "# n_test = X_test_transfrmd.shape[0]\n",
    "# assert shape[0]*shape[1]*shape[2] == X_train_transfrmd.shape[1]\n",
    "# inputs = keras.Input(shape=shape)\n",
    "# #\n",
    "# x = layers.Conv2D(filters=filters, kernel_size=kernel_size,activation=activation,padding=padding)(inputs)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=2*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=4*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=8*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "\n",
    "# #--- The network architecture\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,epsilon=1e-08)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- save best model \n",
    "# callbacks=[keras.callbacks.ModelCheckpoint( filepath='png/convnet_from_scratch.keras',  \n",
    "#                                            monitor=\"val_loss\",\n",
    "#                                            save_freq=10,\n",
    "#                                             save_best_only=True)]\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# X_train_reshaped = X_train_transfrmd.reshape((n_train,shape[0],shape[1],1))\n",
    "# X_test_reshaped = X_test_transfrmd.reshape((n_test,shape[0],shape[1],1))\n",
    "# model.fit(X_train_reshaped, y_train, \n",
    "#             validation_data=(X_test_reshaped, y_test),\n",
    "#             #callbacks=callbacks,\n",
    "#           epochs=epochs, verbose=False, shuffle=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,epochs),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = keras.models.load_model(\"png/convnet_from_scratch.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=best_model.predict(X_test_reshaped)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf166dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (ux,uy), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e9080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "453.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
