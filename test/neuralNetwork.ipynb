{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#set-parameters\" data-toc-modified-id=\"set-parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>set parameters</a></span></li><li><span><a href=\"#Parse-Lammps-dump-file\" data-toc-modified-id=\"Parse-Lammps-dump-file-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Parse Lammps dump file</a></span></li><li><span><a href=\"#Energy\" data-toc-modified-id=\"Energy-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Energy</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>main()</a></span></li></ul></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Train NN</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['parameters', 'flags', 'MsdAnalysis', 'EnergyBarrier', 'SroAnalysis', 'input files', 'Atomic Radius']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(confParser['input files']['lib_path'])\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f9488",
   "metadata": {},
   "source": [
    "# set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc53f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- set dynamic parameters\n",
    "temp = confParser['parameters']['temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False):\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        descriptors = {}\n",
    "        self.perAtomData = {}\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                descriptors[irun]    = np.load('%s/Run%s/descriptors.npy'%(path,irun))\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "                if self.verbose:\n",
    "                    traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        \n",
    "        #--- same configurations\n",
    "        self.descriptors = descriptors[self.nruns[0]]\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystaliine atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        \n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- filter descriptors\n",
    "        filtr[atom_ids] = True\n",
    "        self.descriptors = self.descriptors[filtr]\n",
    "        \n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "                                 \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "    @staticmethod\n",
    "    def zscore(slist):\n",
    "        tmp = np.copy(slist)\n",
    "        print(np.mean(tmp),np.std(tmp))\n",
    "        tmp -= np.mean(tmp)\n",
    "        tmp /= np.std(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def TrainClassifier(self,y,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        #--- train-test split\n",
    "        X = np.c_[self.descriptors]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        #--- tune parameters\n",
    "        param_grid = {\n",
    "                        'hidden_layer_sizes':[(100,100)],\n",
    "        #                 'activation' : ['tanh', 'relu'],\n",
    "                         'learning_rate_init':[1e-4],\n",
    "        #                'alpha':[1e-4,1e-3,1e-2], #--- regularization \n",
    "        #               'learning_rate' : ['invscaling', 'adaptive'],\n",
    "\n",
    "                     } \n",
    "\n",
    "        #--- train\n",
    "        mlp = MLPClassifier(random_state=random_state)\n",
    "        clf = GridSearchCV(mlp, param_grid)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        #--- validate\n",
    "        !mkdir png\n",
    "        utl.PltErr(range(len(clf.best_estimator_.loss_curve_)), clf.best_estimator_.loss_curve_,\n",
    "                   yscale='log',\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "\n",
    "\n",
    "        #--- confusion matrix\n",
    "        cm = confusion_matrix(y_test, clf.predict(X_test),\n",
    "                         labels=[0, 1]\n",
    "                        )\n",
    "        print('cm=',cm)\n",
    "\n",
    "    def TrainRegressor(self,stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    "                       filtr = None,\n",
    "                       ):\n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        #--- train-test split\n",
    "        X = np.c_[self.descriptors[filtr]]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "#        pdb.set_trace()\n",
    "        #--- tune parameters\n",
    "        param_grid = {\n",
    "                        'hidden_layer_sizes':[(100,100),(100,100,100)],\n",
    " #                        'activation' : ['tanh', 'relu'],\n",
    "                         'learning_rate_init':[1e-4,1e-5,1e-6],\n",
    "        #                'alpha':[1e-4,1e-3,1e-2], #--- regularization \n",
    "        #               'learning_rate' : ['invscaling', 'adaptive'],\n",
    "\n",
    "                     } \n",
    "\n",
    "        #--- train\n",
    "        mlp = MLPRegressor(random_state=random_state,verbose=self.verbose)\n",
    "        clf = GridSearchCV(mlp, param_grid)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        #--- validate\n",
    "        !mkdir png\n",
    "        utl.PltErr(range(len(clf.best_estimator_.loss_curve_)), clf.best_estimator_.loss_curve_,\n",
    "                   yscale='log',\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "\n",
    "#         pdb.set_trace()\n",
    "        y_pred = clf.best_estimator_.predict(X_test)        \n",
    "        y_pred_train = clf.best_estimator_.predict(X_train)        \n",
    "        for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "            ax = utl.PltErr(None,None,Plot=False)\n",
    "            #\n",
    "#             utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "            #\n",
    "            utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                       attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(None,None,Plot=False,\n",
    "                           title='png/scatter%s.png'%idime,\n",
    "                            ax=ax,\n",
    "                       xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "                       xlim=(-2,2),ylim=(-2,2),\n",
    "                           )\n",
    "            \n",
    "        if printOvito:\n",
    "            X_train, X_test, _, _ = train_test_split(self.perAtomData[filtr]['id type x y z'.split()], y, stratify=stratify,\n",
    "                                                    random_state=random_state)\n",
    "#            pdb.set_trace()\n",
    "            with open('original.xyz','w') as fp:\n",
    "                utl.PrintOvito(self.perAtomData[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('train.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_train,y_pred_train],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bcd63",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " def main():\n",
    "        \n",
    "    nn = NeuralNetwork(verbose=False)\n",
    "    nn.Parse(path=confParser['neural net']['input_path'],\n",
    "             nruns=eval(confParser['neural net']['nruns']):)\n",
    "    nn.Combine()\n",
    "#     tmp = nn.df_combined.set_index('id')\n",
    "    display(nn.perAtomData.iloc[:13])\n",
    "    #    \n",
    "#    nn.PCA()\n",
    "#    nn.Spectra()\n",
    "#    nn.TrainClassifier(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    filtr = nn.perAtomData.defect_label == 1.0\n",
    "    nn.TrainRegressor( stratify=None,#np.c_[nn.perAtomData.defect_label].astype(int),\n",
    "                        y=np.c_[nn.perAtomData[filtr]['ux uy uz'.split()]],\n",
    "                      printOvito = True,\n",
    "                      filtr=filtr,\n",
    "                     )\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed37072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = NeuralNetwork(verbose=False)\n",
    "# nn.Parse(path='niNatom1KTemp1000K2nd',nruns=24)\n",
    "# nn.Combine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(11):\n",
    "#     utl.PltErr(range(nn.descriptors[0,:].shape[0]),nn.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a8977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystalDefect",
   "language": "python",
   "name": "crystaldefect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "476.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
