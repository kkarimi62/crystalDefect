{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#main():-classifier\" data-toc-modified-id=\"main():-classifier-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>main(): classifier</a></span></li><li><span><a href=\"#main():-regressor\" data-toc-modified-id=\"main():-regressor-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>main(): regressor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#test-example:-2d\" data-toc-modified-id=\"test-example:-2d-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>test example: 2d</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-connected-in-sklearn\" data-toc-modified-id=\"fully-connected-in-sklearn-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>fully connected in sklearn</a></span></li><li><span><a href=\"#fully-connected-in-keras\" data-toc-modified-id=\"fully-connected-in-keras-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>fully connected in keras</a></span></li><li><span><a href=\"#cnn\" data-toc-modified-id=\"cnn-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>cnn</a></span></li></ul></li></ul></li><li><span><a href=\"#neural-net\" data-toc-modified-id=\"neural-net-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>neural net</a></span><ul class=\"toc-item\"><li><span><a href=\"#main\" data-toc-modified-id=\"main-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>main</a></span></li></ul></li><li><span><a href=\"#subclasses-nn-model\" data-toc-modified-id=\"subclasses-nn-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>subclasses nn model</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>main()</a></span></li></ul></li><li><span><a href=\"#gnn\" data-toc-modified-id=\"gnn-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>gnn</a></span><ul class=\"toc-item\"><li><span><a href=\"#graph-net\" data-toc-modified-id=\"graph-net-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>graph net</a></span><ul class=\"toc-item\"><li><span><a href=\"#example-1d\" data-toc-modified-id=\"example-1d-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>example 1d</a></span></li><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>main()</a></span><ul class=\"toc-item\"><li><span><a href=\"#validation\" data-toc-modified-id=\"validation-5.1.2.1\"><span class=\"toc-item-num\">5.1.2.1&nbsp;&nbsp;</span>validation</a></span></li></ul></li></ul></li><li><span><a href=\"#gnn-classifier\" data-toc-modified-id=\"gnn-classifier-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>gnn classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>main()</a></span></li></ul></li><li><span><a href=\"#gnn-for-energy\" data-toc-modified-id=\"gnn-for-energy-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>gnn for energy</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>main()</a></span></li></ul></li><li><span><a href=\"#mpnn\" data-toc-modified-id=\"mpnn-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>mpnn</a></span></li><li><span><a href=\"#tf\" data-toc-modified-id=\"tf-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>tf</a></span></li><li><span><a href=\"#pytorch\" data-toc-modified-id=\"pytorch-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>pytorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#toturial\" data-toc-modified-id=\"toturial-5.6.1\"><span class=\"toc-item-num\">5.6.1&nbsp;&nbsp;</span>toturial</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "\n",
    "#--- system libs\n",
    "import os\n",
    "import sys\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "import pickle\n",
    "\n",
    "#--- ase\n",
    "# from dscribe.descriptors import SOAP, ACSF\n",
    "# import ase\n",
    "# import ase.io\n",
    "# import ase.build\n",
    "# from ase.io import lammpsdata\n",
    "\n",
    "\n",
    "#--- sklearn\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "#\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "#--- tensorflow\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# PyTorch geometric\n",
    "import torch_geometric\n",
    "import torch_geometric.data as geom_data\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# PyTorch Lightning\n",
    "# import lightning as L\n",
    "\n",
    "# PL callbacks\n",
    "#from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch import Tensor\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n",
    "\n",
    "#--- increase width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f17d1af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'debugging'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-652f19e2e9c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TensorFlow is using CPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mIsGpuAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-652f19e2e9c3>\u001b[0m in \u001b[0;36mIsGpuAvailable\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mIsGpuAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_device_placement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;31m# Check if GPU is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gnnEnv/lib/python3.7/site-packages/tensorflow_core/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'debugging'"
     ]
    }
   ],
   "source": [
    "def IsGpuAvailable():\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "   # Check if GPU is available\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name == '/device:GPU:0':\n",
    "        print('GPU device found:', device_name)\n",
    "    else:\n",
    "        print('GPU device not found')\n",
    "\n",
    "    # Check if TensorFlow is using GPU\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print('TensorFlow is using GPU')\n",
    "    else:\n",
    "        print('TensorFlow is using CPU')\n",
    "        \n",
    "IsGpuAvailable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47140428",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.2 0.6 0.8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 34)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def GenerateDate():\n",
    "#     disp=[]\n",
    "#     dx=0.2\n",
    "#     X=np.arange(0,1.0,dx) #linspace(0,1.0,n)\n",
    "#     n=len(X)\n",
    "#     assert n%2==1\n",
    "#     dx = X[1]-X[0]\n",
    "#     vacancy = 0\n",
    "#     while vacancy == 0 or vacancy == n-1:\n",
    "#         vacancy = int(np.random.random()*n)\n",
    "#     assert 0<vacancy<n-1\n",
    "# #     print('vacancy=%s'%vacancy)\n",
    "\n",
    "#     occupancy=np.ones(n,dtype=bool)\n",
    "#     occupancy[vacancy] =False\n",
    "#     filtr = occupancy\n",
    "\n",
    "#     disp=np.zeros(n*2).reshape((n,2))\n",
    "#     iposn = vacancy-1\n",
    "#     disp[iposn,0]=1.0\n",
    "#     iposn = vacancy+1\n",
    "#     disp[iposn,1]=-1\n",
    "\n",
    "#     disp = disp[filtr,:]\n",
    "#     disp = disp[:,~np.all([disp==0.0],axis=1).flatten()]\n",
    "\n",
    "#     np.random.shuffle(disp)\n",
    "\n",
    "#     adj_mat = torch.zeros((n, n), dtype=torch.float)\n",
    "#     for i in range(n):\n",
    "#         adj_mat[i,i]=1\n",
    "#         adj_mat[i,(i+1)%n]=1\n",
    "#         adj_mat[i,(i-1)%n]=1\n",
    "#     adj_mat = adj_mat[:,filtr][filtr]\n",
    "#     values = X[filtr]\n",
    "#     print(values)\n",
    "#     x = np.concatenate([list(map(lambda x:Density1d(X,x,filtr),values))])\n",
    "\n",
    "#     return x,disp,adj_mat\n",
    "\n",
    "# def Density1d(xv,query_point,filtr):\n",
    "#     #--- density\n",
    "#     position = query_point\n",
    "#     xrand = xv.copy()\n",
    "#     xrand -= position\n",
    "#     xrand += (xrand >= 0.5) * (-1.0)\n",
    "#     xrand += (xrand < -0.5) * (+1.0)\n",
    "#     assert np.all([-0.5 <= xrand,xrand <= 0.5])\n",
    "#     values = xrand[filtr]\n",
    "#     X =np.arange(-.5,0.5,0.03)\n",
    "#     kernel = gaussian_kde(values,bw_method=0.07)\n",
    "#     Z = kernel(X)\n",
    "#     ax=utl.PltErr(values,np.ones(len(values)),Plot=False)\n",
    "#     utl.PltErr(X,Z,title='rho.png',Plot=False,attrs={'fmt':'-'},ax=ax)\n",
    "#     return Z\n",
    "\n",
    "# # data=GenerateDate()\n",
    "# # data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "            \n",
    "            \n",
    "        !mkdir $self.best_model\n",
    "\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            if irun == 0:\n",
    "                #--- same configurations!\n",
    "                self.descriptors  = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['data']]\n",
    "                self.shape        = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['shape']].flatten()\n",
    "                self.positions    = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz .'%(path,irun))\n",
    "            try:\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                #--- displacement data\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "\n",
    "#     def Junk(self,path,nruns):\n",
    "#         self.perAtomData = {}\n",
    "#         self.Descriptors = {}\n",
    "#         self.Shape       = {}\n",
    "#         self.Positions   = {}\n",
    "#         self.Catalogs    = {}\n",
    "#         #\n",
    "#         rwjs = utl.ReadWriteJson()\n",
    "#         for irun in range(nruns):\n",
    "#             try:\n",
    "# #                 data_json               = rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]\n",
    "# #                 self.Descriptors[irun]  = np.c_[data_json['data']]\n",
    "# #                 self.Shape[irun]        = np.c_[data_json['shape']].flatten()\n",
    "# #                 self.Positions[irun]    = np.c_[data_json['xyz']]\n",
    "#                 os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "#                 data                    = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "#                 self.perAtomData[irun]  = pd.DataFrame(np.c_[data],\n",
    "#                                                        columns ='id type x y z'.split()\n",
    "#                                                       )\n",
    "#                 self.Catalogs[irun]     = pd.read_csv('%s/Run%s/catalog.txt'%(path,irun))\n",
    "#             except:\n",
    "# #                 if self.verbose:\n",
    "# #                     traceback.print_exc()\n",
    "#                 continue\n",
    "                \n",
    "        \n",
    "#         self.nruns     = list(self.perAtomData.keys())\n",
    "#         self.nruns.sort()\n",
    "\n",
    "#         self.Descriptors[ 0 ] = pd.DataFrame(np.random.random(size=9876))\n",
    "#         #--- assert shape and positions are the same for all realizations\n",
    "# #         self.shape     = self.Shape[ self.nruns[ 0 ] ]\n",
    "# #         self.positions = self.Positions[ self.nruns[ 0 ] ]\n",
    "\n",
    "        \n",
    "        \n",
    "    def Parse2nd(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        self.Descriptors = {}\n",
    "        self.Shape       = {}\n",
    "        self.Positions   = {}\n",
    "        self.Catalogs    = {}\n",
    "        #\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                data_json               = rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]\n",
    "                self.Descriptors[irun]  = np.c_[data_json['data']]\n",
    "                self.Shape[irun]        = np.c_[data_json['shape']].flatten()\n",
    "                self.Positions[irun]    = np.c_[data_json['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                data                    = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                self.perAtomData[irun]  = pd.DataFrame(np.c_[data],\n",
    "                                                       columns ='id type x y z'.split()\n",
    "                                                      )\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/catalog.txt'%(path,irun))\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns     = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "\n",
    "        #--- assert shape and positions are the same for all realizations\n",
    "        self.shape     = self.Shape[ self.nruns[ 0 ] ]\n",
    "        self.positions = self.Positions[ self.nruns[ 0 ] ]\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "#         pdb.set_trace()\n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        atom_ids.sort()\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "#        descriptors_center_atoms = self.descriptors[atom_ids]\n",
    "        descriptors_center_atoms = np.c_[list(map(lambda x:self.Descriptors[sdict[x]][x], atom_ids))]\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystalline atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        descriptors_crystalline = self.descriptors[filtr]\n",
    "\n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- merge descriptors\n",
    "        self.descriptors = np.concatenate([descriptors_center_atoms,descriptors_crystalline],axis=0)\n",
    "\n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "    def Combine2nd(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "            \n",
    "        irun = self.nruns[0]\n",
    "        keys = list( self.perAtomData[ irun ].keys() )\n",
    "\n",
    "        #--- center atoms\n",
    "        data_concat         = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[x]],self.nruns)),axis=0)\n",
    "        self.perAtomData    = pd.DataFrame(data_concat,\n",
    "                                 columns=keys\n",
    "                                )\n",
    "        self.descriptors    = np.concatenate(list(map(lambda x:self.Descriptors[x], self.nruns)))\n",
    "    \n",
    "#     def Junk2nd(self):\n",
    "        \n",
    "#         if self.verbose:\n",
    "#             print('concatenating descriptors ...')\n",
    "            \n",
    "#         irun = self.nruns[0]\n",
    "#         keys = list( self.perAtomData[ irun ].keys() )\n",
    "\n",
    "#         #--- center atoms\n",
    "#         data_concat         = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[x]],self.nruns)),axis=0)\n",
    "#         self.perAtomData    = pd.DataFrame(data_concat,\n",
    "#                                  columns=keys\n",
    "#                                 )\n",
    "#         self.descriptors    = None #self.Descriptors[0]\n",
    "\n",
    "    def Parse3rd(self,path,nruns):\n",
    "\n",
    "        self.Catalogs    = {}\n",
    "        self.transition_paths = []\n",
    "        self.transition_paths_discretized = []\n",
    "        #\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                self.transition_paths.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths.json'%(path,irun)) )\n",
    "                self.transition_paths_discretized.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths_discretized.json'%(path,irun)) )\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/saved_output/catalog.txt'%(path,irun))\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns     = list(self.Catalogs.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "    def DataBuilder( self ):\n",
    "        \n",
    "        ntrain        = self.ntrain\n",
    "        num_snapshots = len( self.transition_paths )\n",
    "        snapshots     = range(num_snapshots)\n",
    "        input_data    = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "        # Example target data (displacement vectors for each snapshot and each path)\n",
    "        target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots]\n",
    "\n",
    "        # Augment the dataset to have order 100 snapshots\n",
    "        augmented_input_data = []\n",
    "        augmented_target_displacements = []\n",
    "        input_data_tensor = torch.stack(input_data)\n",
    "        ntrain_initial = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "        n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input, augmented_target = GraphNet.augment_data(input_data, target_displacements, self.noise_std)\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "        adj_matrices = torch.stack(GraphNet.compute_adjacency_matrices(augmented_input_data, rcut=3.0)) \n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data_tensor = torch.stack(augmented_input_data)\n",
    "#        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "        # Standardize the augmented input data\n",
    "        mean = input_data_tensor.mean(dim=(0, 1))\n",
    "        std = input_data_tensor.std(dim=(0, 1))\n",
    "        standardized_input_data = [GraphNet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "\n",
    "\n",
    "        # Convert input data to tensors\n",
    "        target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data)):\n",
    "            x = input_data_tensor[i]  # Node features\n",
    "            edge_index = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "            y = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "            # Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            graphs.append(data)\n",
    "            \n",
    "        # Create a single large graph by concatenating Data objects\n",
    "        large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "        # Define batch size and create DataLoader\n",
    "        batch_size = len(input_data)\n",
    "#        loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "        train_ratio = 0.8\n",
    "\n",
    "        # Define batch sizes for training and test dataloaders\n",
    "        train_batch_size = int(batch_size * train_ratio)\n",
    "\n",
    "        # Create DataLoader for training dataset\n",
    "        loader = DataLoader(large_graph, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Accessing batches in the DataLoader\n",
    "        loader_iter=iter(loader)\n",
    "        self.dataset_train = next(loader_iter)\n",
    "        self.dataset_test = next(loader_iter)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('dataset_train:',self.dataset_train)\n",
    "            print('dataset_test:',self.dataset_test)\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def zscore(slist):\n",
    "#         tmp = np.copy(slist)\n",
    "#         print(np.mean(tmp),np.std(tmp))\n",
    "#         tmp -= np.mean(tmp)\n",
    "#         tmp /= np.std(tmp)\n",
    "#         return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def SklearnMLP(self,X_train,y_train):\n",
    "        #-----------------------\n",
    "        #--- parameter grid\n",
    "        #-----------------------\n",
    "#         param_grid = {\n",
    "#                         'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "#                          #'activation' : ['tanh', 'relu'],\n",
    "#                          'learning_rate_init':self.learning_rate_init,\n",
    "# #                         'alpha':self.alpha, #--- regularization \n",
    "#                          #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "#                         'n_iter_no_change':self.n_iter_no_change,\n",
    "# #                        'tol':self.tol,\n",
    "#                         'max_iter':self.max_iter,\n",
    "#                      } \n",
    "        mlp   =  MLPClassifier(random_state=1,\n",
    "                               hidden_layer_sizes = self.hidden_layer_sizes[0],\n",
    "                               learning_rate_init = self.learning_rate_init[0],\n",
    "                               n_iter_no_change   = self.n_iter_no_change[0],\n",
    "                               max_iter           = self.max_iter[0],\n",
    "                               verbose=self.verbose)\n",
    "#         clf  =  GridSearchCV(mlp, param_grid)\n",
    "#        clf.fit(X_train,y_train)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        model =  mlp #clf.best_estimator_\n",
    "        loss  =  model.loss_curve_\n",
    "        val_loss = loss\n",
    "        return (model, loss, val_loss)\n",
    "\n",
    "    def KerasANN(self, X_train, y_train,X_test, y_test, ndime):\n",
    "\n",
    "        model     = keras.Sequential([ #--- The network architecture\n",
    "                                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                #                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                                    layers.Dense(ndime, activation='softmax')\n",
    "                                    ])\n",
    "        \n",
    "#         shape         =  (self.shape[0]*self.shape[1]*self.shape[2],)\n",
    "#         inputs        =  keras.Input(shape=shape)\n",
    "#         #------------------------------\n",
    "#         #--- The network architecture\n",
    "#         #------------------------------\n",
    "#         x             =  layers.Dense(   self.hidden_layer_size, activation=self.activation\n",
    "#                                        )(inputs)\n",
    "#         for i in range( self.number_hidden_layers ):\n",
    "#             x       = layers.Dense( self.hidden_layer_size, activation=self.activation\n",
    "#                                      )(x)\n",
    "#         #--- output layer\n",
    "# #         x       = layers.Flatten()(x)\n",
    "#         outputs = layers.Dense( ndime, activation=self.activation)(x)\n",
    "#         model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        \n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "        model.compile( optimizer=optimizer,\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"mse\"]\n",
    "                     )\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#                                                     monitor=\"mse\",\n",
    "#                                                     save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        model.fit( X_train, y_train, \n",
    "           validation_data      = ( X_test, y_test ),\n",
    "#             callbacks           = callbacks,\n",
    "            epochs              = self.max_iter[0], \n",
    "            verbose             = self.verbose, \n",
    "            shuffle             = False, \n",
    "#             batch_size     = 32,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "         )    \n",
    "\n",
    "        model.save('best_model/convnetClassifier_from_scratch.tf')\n",
    "        loss      = model.history.history['loss']\n",
    "        val_loss  = model.history.history['val_loss']\n",
    "        best_model = model #keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        return (best_model, loss, val_loss)\n",
    "\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def MapClassIds( y ):\n",
    "        ndime         = len(set(y.flatten()))\n",
    "        class_ids     = list(set(y.flatten()))\n",
    "        class_ids.sort()\n",
    "        map_class_ids = dict(zip(class_ids,range(ndime)))        \n",
    "        return ndime, np.c_[list(map(lambda x:[map_class_ids[x]],y.flatten()))]\n",
    "    \n",
    "    @staticmethod\n",
    "    def GetSubSetCrystallineAtoms(X,y,n_train):\n",
    "        #--- data frame\n",
    "        df = pd.DataFrame( y, columns=['topoID'] )\n",
    "        #--- groups\n",
    "        sdict = df.groupby(by='topoID').groups\n",
    "        if sdict[ 0 ].shape[ 0 ] < n_train:\n",
    "            return X, y\n",
    "        indices = np.random.choice(sdict[ 0 ], size=n_train, replace=False)\n",
    "        sdict[ 0 ] = indices\n",
    "        indices_total = np.concatenate( list(map(lambda x:sdict[x],sdict)) )\n",
    "        return X[indices_total], y[ indices_total ]\n",
    "    \n",
    "    def GetLabels( self, irun ):\n",
    "        nsize                                  = self.Descriptors[ irun ].shape[ 0 ]\n",
    "        y_labels                               = np.zeros(nsize,dtype=int)\n",
    "        nonCrystallineAtomsIndices             = self.Catalogs[ irun ].AtomIndex\n",
    "        nonCrystallineAtomsTopoIds             = self.Catalogs[ irun ].IniTopoId.astype(int)\n",
    "        y_labels[ nonCrystallineAtomsIndices ] = nonCrystallineAtomsTopoIds\n",
    "        return y_labels.reshape( ( nsize, 1 ) )\n",
    "\n",
    "    \n",
    "    def TrainClassifier(self,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        #--- get labels\n",
    "        y_labels = np.concatenate( list( map(lambda x:self.GetLabels(x), self.nruns ) ) )\n",
    "        assert self.descriptors.shape[ 0 ] == y_labels.shape[ 0 ]\n",
    "        \n",
    "        #--- map topo ids to integers 0, 1 ... ndime\n",
    "        ndime, y = NeuralNetwork.MapClassIds( y_labels )\n",
    "\n",
    "        \n",
    "        X      = np.c_[self.descriptors]\n",
    "\n",
    "        #--- filter: only train a subset of crystalline atoms\n",
    "        X, y   = NeuralNetwork.GetSubSetCrystallineAtoms( X, y, self.n_train )\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/classifier.sav'%self.best_model )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.001 )\n",
    "\n",
    "\n",
    "        #--- exclude void\n",
    "#        filtr  = self.perAtomData.type==2\n",
    "#         X      = X[~filtr]\n",
    "#         y      = y[~filtr]\n",
    "\n",
    "        #--- sample from crystalline atoms\n",
    "        \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "#        train_size = self.n_train\n",
    "#        test_size  = int( self.n_train / 3 )\n",
    "        assert X.shape[0] >= self.n_train, 'increase nruns!' #train_size + train_size, 'increase nruns!'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "#                                                               test_size=test_size, train_size=train_size,\n",
    "                                                              random_state=random_state)\n",
    "        if len(set(y_train.flatten())) < ndime:\n",
    "            'warning: not every class present in train set!'\n",
    "        if len(set(y_test.flatten()))  < ndime: \n",
    "            'warning: not every class present in test set!'\n",
    "        \n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                (model, loss, val_loss) = self.SklearnMLP(X_train,y_train)\n",
    "                classes_x = model.predict(X_test) \n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                (model, loss, val_loss) = self.KerasANN(X_train, y_train,X_test, y_test, ndime)\n",
    "                predict_x = model.predict(X_test) \n",
    "                classes_x = np.argmax(predict_x,axis=1)\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkClassifier( y )\n",
    "            predict_x = model.predict(X_test) \n",
    "            classes_x = np.argmax(predict_x,axis=1)\n",
    "                    \n",
    "        #--- save loss data\n",
    "        !mkdir png\n",
    "        np.savetxt('png/val_loss_classification.txt',\n",
    "                   np.c_[range(len(loss)),loss,val_loss],\n",
    "                   header='epoch loss val_loss')\n",
    "\n",
    "        #--- confusion matrix\n",
    "        cm = confusion_matrix(y_test, classes_x,\n",
    "                         labels=range(ndime)\n",
    "                        )\n",
    "        np.savetxt('png/confusion.txt',np.c_[cm])\n",
    "\n",
    "        \n",
    "    def PrintDescriptors(self,descriptors,y,fout):\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        rwjs.Write([{'descriptors':np.c_[descriptors],\n",
    "                     'target':np.c_[y],\n",
    "                     'shape_descriptor':self.shape}],fout)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def GetTopoIds( catalog, key ): \n",
    "        TopoIds = list( catalog.groupby( by = key ).groups.keys())\n",
    "        TopoIds.sort()\n",
    "        return TopoIds \n",
    "    \n",
    "    @staticmethod\n",
    "    def MapTopoIds( TopoIds ):\n",
    "        ndime         = len( TopoIds )\n",
    "        map_TopoIds = dict(zip(TopoIds,range(ndime)))        \n",
    "        return map_TopoIds\n",
    "\n",
    "    def GetTopoArrayIndex( self, IniTopoId, FinTopoId ):\n",
    "        mappedIniTopoId = self.mappedTopoIds[ IniTopoId ]\n",
    "        mappedFinTopoId = self.mappedTopoIds[ FinTopoId ]\n",
    "        assert mappedIniTopoId < self.n_unique_transition_paths and\\\n",
    "               mappedFinTopoId < self.n_unique_transition_paths \n",
    "        return mappedIniTopoId * self.n_unique_transition_paths * self.ndime + mappedFinTopoId * self.ndime\n",
    "\n",
    "    def GetTopoArrayIndex2nd( self, ux, uy, uz ):\n",
    "        aa = np.c_[[ux,uy,uz]].T\n",
    "        H, bin_edges = np.histogramdd(aa,bins=self.bins)        \n",
    "        assert H.sum() == 1.0\n",
    "        \n",
    "        return H.astype(int).flatten()\n",
    "        \n",
    "\n",
    "    def FillTargetMatrix( self, item ):\n",
    "#        pdb.set_trace()\n",
    "        ux = item.inifin_dr * item.DirX\n",
    "        uy = item.inifin_dr * item.DirY\n",
    "        uz = item.inifin_dr * item.DirZ\n",
    "        assert np.abs( ux ) < self.umax and\\\n",
    "                np.abs( uy ) < self.umax and\\\n",
    "                np.abs( uz ) < self.umax,'ux=%e, uy=%e, uz=%e increase self.umax!'%(ux,uy,uz)\n",
    "        irow                                   = int( item.AtomIndex )\n",
    "#        icol                                   = int( self.GetTopoArrayIndex( item.IniTopoId, item.FinTopoId ) )\n",
    "        H                                   = self.GetTopoArrayIndex2nd( ux, uy, uz )\n",
    "\n",
    "        self.y_targets[ irow ] += H           \n",
    "\n",
    "    def DiscretizeTransitionPath( self ):\n",
    "         #--- hard-coded values\n",
    "        xlin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        ylin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        zlin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        self.nbinx = len(xlin)-1\n",
    "        self.nbiny = len(ylin)-1\n",
    "        self.nbinz = len(zlin)-1\n",
    "        self.bins = (xlin, ylin, zlin)\n",
    "        self.xv, self.yv, self.zv = np.meshgrid( self.bins[1][:-1], self.bins[0][:-1], self.bins[2][:-1] )\n",
    "\n",
    "#        print(yv[H==1],xv[H==1],zv[H==1])\n",
    "\n",
    "    def GetTargets( self, irun ):\n",
    "        #--- set-up y matrix\n",
    "#         IniTopoId                              = NeuralNetwork.GetTopoIds( self.Catalogs[ irun ], 'IniTopoId' )\n",
    "#         FinTopoId                              = NeuralNetwork.GetTopoIds( self.Catalogs[ irun ], 'FinTopoId' )\n",
    "#         TopoIds                                = list( set( FinTopoId + IniTopoId ) ) #--- transition path ids\n",
    "#         TopoIds.sort()\n",
    "#         self.mappedTopoIds                     = NeuralNetwork.MapTopoIds( TopoIds )\n",
    "        \n",
    "#         self.n_unique_transition_paths         = len( TopoIds )\n",
    "\n",
    "\n",
    "        nsize                                  = ( self.Descriptors[ irun ].shape[ 0 ], self.nbinx * self.nbiny * self.nbinz )\n",
    "        self.y_targets                         = np.zeros( nsize[ 0 ] * nsize[ 1 ], dtype=int ).reshape( nsize )\n",
    "        \n",
    "        #--- fill y matrix\n",
    "        self.Catalogs[ irun ].apply( lambda x: self.FillTargetMatrix( x ), axis = 1 )\n",
    "        \n",
    "        #--- assert self.y_targets is binary\n",
    "        assert set(self.y_targets.flatten()) == set(np.array([0,1])), 'decrease du!'\n",
    "        return self.y_targets\n",
    "        \n",
    "    def MaskCrystallineAtoms(self, irun ):\n",
    "        nsize                              = self.Descriptors[ irun ].shape[ 0 ]\n",
    "        mask                               = np.zeros(nsize,dtype=bool)\n",
    "        nonCrystallineAtomsIndices         = np.array( list( set( self.Catalogs[ irun ].AtomIndex ) ) )\n",
    "        mask[ nonCrystallineAtomsIndices ] = True\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def GetInputOutput( self, irun, indx ):\n",
    "        atomIndices     =  self.Catalogs[ irun ].AtomIndex\n",
    "        pixel_map_input =  self.Descriptors[ irun ][ atomIndices ]    \n",
    "        dr              =  np.c_[self.Catalogs[ irun ]['inifin_dr']].flatten()\n",
    "        dr_multi        = np.c_[ dr, dr, dr ]\n",
    "        vector_input    =  self.Catalogs[ irun ][ ' DirX      DirY      DirZ'.split() ] * dr_multi\n",
    "        output          =  self.Catalogs[ irun ][ 'barrier' ]\n",
    "        return [pixel_map_input, vector_input, output][ indx ]\n",
    "\n",
    "    def TrainRegressorBarriers(self,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #--- get transition path bitmap\n",
    "#        self.DiscretizeTransitionPath()\n",
    "#        self.ndime                                  = 4 #--- hard-coded: (ux,uy,uz,E)\n",
    "        pixel_maps_input = np.concatenate( list( map(lambda x:self.GetInputOutput(x,0), self.nruns ) ) )\n",
    "        vectors_input    = np.concatenate( list( map(lambda x:self.GetInputOutput(x,1), self.nruns ) ) )\n",
    "        scalar_output    = np.concatenate( list( map(lambda x:self.GetInputOutput(x,2), self.nruns ) ) )\n",
    "\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[pixel_maps_input,vectors_input]\n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/scaler_regression_barriers.sav'%self.best_model )\n",
    "        y      = np.c_[ scalar_output ]\n",
    "        \n",
    "        if X.shape[ 0 ] - self.n_train < 0 :  \n",
    "            X = NeuralNetwork.Duplicate(X, new_size = self.n_train )\n",
    "            y = NeuralNetwork.Duplicate(y, new_size = self.n_train )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.01 )\n",
    "        NeuralNetwork.AddGaussianNoise(y, scale = 0.01 )\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, #stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "\n",
    "                \n",
    "        (model, loss, val_loss), (X_train, X_test) = self.ConvNetworkMixedInput(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            \n",
    "            \n",
    "            #--- validation\n",
    "        NeuralNetwork.Validation(loss, val_loss, \n",
    "                                 model, \n",
    "                                 X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "    def TrainRegressorTransitionPaths(self,#stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    " #                      filtr = None,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #--- get transition path bitmaps\n",
    "        self.DiscretizeTransitionPath()\n",
    "#        self.ndime                                  = 4 #--- hard-coded: (ux,uy,uz,E)\n",
    "        y = np.concatenate( list( map(lambda x:self.GetTargets(x), self.nruns ) ) )\n",
    "\n",
    "        \n",
    "        #--- filtr crystalline atoms\n",
    "        filtr = np.concatenate( list( map(lambda x:self.MaskCrystallineAtoms(x), self.nruns ) ) )\n",
    "\n",
    "        y     = y[ filtr ]\n",
    "        \n",
    "#        pdb.set_trace()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "\n",
    "        ndime  = y.shape[1] #--- dimension of the target vector\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors[filtr]]\n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/scaler_regression.sav'%self.best_model )\n",
    "        \n",
    "        \n",
    "        if X.shape[ 0 ] - self.n_train < 0 :  \n",
    "            X = NeuralNetwork.Duplicate(X, new_size = self.n_train )\n",
    "            y = NeuralNetwork.Duplicate(y, new_size = self.n_train )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.1 )\n",
    "#        NeuralNetwork.AddGaussianNoise(y, scale = 0.1 )\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, #stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                #-----------------------\n",
    "                #--- parameter grid\n",
    "                #-----------------------\n",
    "                param_grid = {\n",
    "                                'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                                 #'activation' : ['tanh', 'relu'],\n",
    "                                 'learning_rate_init':self.learning_rate_init,\n",
    "                                'alpha':self.alpha, #--- regularization \n",
    "                                 #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                                'n_iter_no_change':self.n_iter_no_change,\n",
    "                                'tol':self.tol,\n",
    "                                'max_iter':self.max_iter,\n",
    "                             } \n",
    "                mlp   =  MLPRegressor(random_state=random_state,verbose=self.verbose) #--- mlp regressor\n",
    "                regr  =  GridSearchCV(mlp, param_grid)\n",
    "                regr.fit(X_train,y_train)\n",
    "                model =  regr.best_estimator_\n",
    "                loss  =  model.loss_curve_\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                model     = keras.Sequential([ #--- The network architecture\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "#                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(ndime, activation='softmax')\n",
    "                    ])\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "                model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "                               loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "                               metrics=[\"mse\"]\n",
    "                             )\n",
    "                model.fit(X_train, y_train, #--- Fitting\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          epochs=self.max_iter[0], verbose=self.verbose, batch_size=1)\n",
    "                loss      = model.history.history['loss']\n",
    "                val_loss  = model.history.history['val_loss']\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            \n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkMultiLabelClassifier(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            NeuralNetwork.ValidationMultiLabelClassification(loss, val_loss, #--- validation\n",
    "                                 model, \n",
    "                                 X_train, X_test, y_train, y_test)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "#             (model, loss, val_loss), (X_train, X_test) =\\\n",
    "#             self.ConvNetwork(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            \n",
    "            \n",
    "            #--- validation\n",
    "#             NeuralNetwork.Validation(loss, val_loss, \n",
    "#                                      model, \n",
    "#                                      X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        #--- save in ovito file\n",
    "#         if printOvito:\n",
    "#             m = self.descriptors.shape[ 0 ]\n",
    "#             indices = np.arange( m )[ filtr ]\n",
    "        \n",
    "#             if indices.shape[ 0 ] - self.n_train < 0 :  \n",
    "#                 indices = NeuralNetwork.Duplicate(indices, new_size = self.n_train )\n",
    "            \n",
    "#             indices_train, indices_test, _, _ = train_test_split(indices, indices, #stratify=stratify,\n",
    "#                                                                 random_state=random_state)\n",
    "#             self.PrintOvito( indices_test, model )\n",
    "\n",
    "    @staticmethod\n",
    "    def Validation(loss, val_loss, model, X_train, X_test, y_train, y_test):\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "#                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred_test  = model.predict(X_test)        \n",
    "        y_pred_train = model.predict(X_train)        \n",
    "#         for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "#             ax = utl.PltErr(None,None,Plot=False)\n",
    "#             #\n",
    "#             utl.PltErr(y_test[:,idime],y_pred_test[:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                        attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(None,None,Plot=False,\n",
    "#                            title='png/scatter%s.png'%idime,\n",
    "#                             ax=ax,\n",
    "#                        xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                        xlim=(-2,2),ylim=(-2,2),\n",
    "#                            )\n",
    "\n",
    "        #--- energy\n",
    "        idime = 0 #3\n",
    "        xstr  = 'energy'\n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        #\n",
    "        utl.PltErr(y_test[:,idime],y_pred_test[:,idime],\n",
    "                   attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "                   ax=ax,\n",
    "                   Plot = False,\n",
    "\n",
    "                  )\n",
    "        utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                   attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                   ax=ax,\n",
    "                   Plot = False,\n",
    "\n",
    "                  )\n",
    "        #\n",
    "        utl.PltErr(None,None,Plot=False,\n",
    "                       title='png/scatter%s.png'%idime,\n",
    "                        ax=ax,\n",
    "                   xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                   xlim=(-2,2),ylim=(-2,2),\n",
    "                       )\n",
    "\n",
    "    @staticmethod\n",
    "    def ValidationMultiLabelClassification(loss, val_loss, model, X_train, X_test, y_train, y_test):\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "#                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/lossMultiLabelClassification.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/lossMultiLabelClassification.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred_test              = model.predict(X_test)        \n",
    "        y_pred_train             = model.predict(X_train)\n",
    "        \n",
    "        threshold                = 0.5 #--- hard-coded threshold\n",
    "        binary_predictions_test  = (y_pred_test > threshold).astype(int)\n",
    "        binary_predictions_train = (y_pred_train > threshold).astype(int)\n",
    "        binary_actual_test       = (y_test > threshold).astype(int)\n",
    "        binary_actual_train      = (y_train > threshold).astype(int)\n",
    "\n",
    "        \n",
    "        \n",
    "        #--- Compute the multilabel confusion matrix\n",
    "        conf_matrix = multilabel_confusion_matrix( binary_actual_test, binary_predictions_test )\n",
    "        ndime       = conf_matrix.shape[ 1 ] * conf_matrix.shape[ 2 ]\n",
    "        conf_matrix = conf_matrix.reshape((conf_matrix.shape[0],ndime))\n",
    "        np.savetxt('png/confusionMultiLabelClassification.txt',np.c_[conf_matrix])\n",
    "        \n",
    "        \n",
    "        #--- predict displacements\n",
    "        #--- reshape y_pred\n",
    "        \n",
    "            \n",
    "        \n",
    "#         disps_predictions_test = np.concatenate([list(map(lambda x: self.GetDispsFromBinaryMaps( x ) , binary_predictions_test ))])\n",
    "#         disps_actual_test      = np.concatenate([list(map(lambda x: self.GetDispsFromBinaryMaps( x ) , binary_actual_test ))])\n",
    "        \n",
    "# #         #--- plot predictions\n",
    "# #         y_pred_test  = model.predict(X_test)        \n",
    "# #         y_pred_train = model.predict(X_train)        \n",
    "#         for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "#             ax = utl.PltErr(None,None,Plot=False)\n",
    "#             #\n",
    "#             utl.PltErr(disps_actual_test[:,idime],disps_predictions_test[:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "# #             utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "# #                        attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "# #                        ax=ax,\n",
    "# #                        Plot = False,\n",
    "\n",
    "# #                       )\n",
    "#             #\n",
    "#             utl.PltErr(None,None,Plot=False,\n",
    "#                            title='png/scatter%s.png'%idime,\n",
    "#                             ax=ax,\n",
    "#                        xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                        xlim=(-3,3),ylim=(-3,3),\n",
    "#                            )\n",
    "\n",
    "    def GetDispsFromBinaryMaps( self, binaryMap ):\n",
    "        binaryMapReshaped = binaryMap.reshape((self.nbinx, self.nbiny, self.nbinz ))\n",
    "        filtr = binaryMapReshaped == 1\n",
    "        return np.c_[self.yv[filtr],self.xv[filtr],self.zv[filtr]]\n",
    "\n",
    "        \n",
    "    def PrintOvito( self, filtr, model ):\n",
    "        #--- save in ovito\n",
    "        X          = np.c_[self.descriptors[filtr]]\n",
    "        X          = NeuralNetwork.Zscore( X )\n",
    "        X_reshaped =  X.reshape((X.shape[0],self.shape[0],self.shape[1],self.shape[2],1))\n",
    "        y_pred     = model.predict( X_reshaped )\n",
    "        with open('original.xyz','w') as fp:\n",
    "            utl.PrintOvito(self.perAtomData.iloc[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "        with open('test.xyz','w') as fp:\n",
    "            xyz = self.perAtomData.iloc[filtr]['id type x y z'.split()]\n",
    "            cordc = pd.DataFrame(np.c_[xyz,y_pred[:,:3]],columns='id type x y z ux uy uz'.split())\n",
    "            utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "                \n",
    "\n",
    "    def ConvNetworkMixedInput(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels: pixel map\n",
    "        shape_vector_input = 3\n",
    "        \n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ] - shape_vector_input\n",
    "        pixel_map_input        =  keras.Input(shape=shape)\n",
    "        vector_input           =  keras.Input(shape=(shape_vector_input,))\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(pixel_map_input)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "        x       = layers.Flatten()(x)\n",
    "            \n",
    "        #--- concatenate flattened map with vector\n",
    "        combined = keras.layers.concatenate( [ x, vector_input ] )\n",
    "        \n",
    "        #--- output layer\n",
    "        outputs = layers.Dense( ndime )( combined ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=[pixel_map_input,vector_input], outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        model.summary()\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- Fitting the model X_train_transfrmd, y_train\n",
    "        nn = X_train.shape[ 1 ]\n",
    "        X_train_pixels = X_train[:,0:nn-shape_vector_input]\n",
    "        X_test_pixels  = X_test[:,0:nn-shape_vector_input]\n",
    "        assert    X_train_pixels.shape[ 1 ] ==    shape[0] * shape[1] * shape[2]\n",
    "        X_train_vector = X_train[:,nn-shape_vector_input:nn]\n",
    "        X_test_vector  = X_test[:,nn-shape_vector_input:nn]\n",
    "        assert    X_train_vector.shape[ 1 ] ==   shape_vector_input\n",
    "        \n",
    "    \n",
    "        X_train_pixels =  X_train_pixels.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_pixels  =  X_test_pixels.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        \n",
    "        model.fit( [X_train_pixels,X_train_vector], y_train, \n",
    "                   validation_data      = ( [X_test_pixels,X_test_vector], y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetRegressorMixedInput_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), ([X_train_pixels,X_train_vector], [X_test_pixels,X_test_vector])\n",
    "    \n",
    "    def ConvNetwork(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime )( x ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- Fitting the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetRegressor_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "    def ConvNetworkMultiLabelClassifier(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  'relu' #self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation='sigmoid' )( x ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"binary_crossentropy\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- Fitting the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetMultiLabelClassifier_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "    def ConvNetworkClassifier(self,y,\n",
    "                               random_state=1\n",
    "                               ):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        \n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        if self.verbose:\n",
    "            print('X.shape:=',X.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- set model parameters\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss=[\"binary_crossentropy\",\"sparse_categorical_crossentropy\"][1],\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#                                                     monitor=\"accuracy\",\n",
    "#                                                     save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- Fitting the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetClassifier_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = model #keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def Duplicate(X, new_size = 100 ):\n",
    "        m = m0 = X.shape[ 0 ]\n",
    "#        n = X.shape[ 1 ]\n",
    "        augmented_x = np.copy( X )\n",
    "\n",
    "        while m <= new_size:\n",
    "            augmented_x = np.concatenate([augmented_x,X],axis = 0)\n",
    "            #\n",
    "            m = augmented_x.shape[ 0 ]\n",
    "\n",
    "        assert m > new_size\n",
    "\n",
    "        return augmented_x[:new_size]\n",
    "\n",
    "    @staticmethod    \n",
    "    def AddGaussianNoise(X,scale = 0.1):\n",
    "\n",
    "        epsilon_x = np.random.normal(scale=scale,size=X.size).reshape(X.shape)\n",
    "        X += epsilon_x\n",
    "        \n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, irun, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "                    disp           = np.c_[self.perAtomData[ irun ].iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.Positions[ irun ].T,self.Descriptors[ irun ][atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, 'disp = %s'%disp, attr_list='x y z mass'.split())\n",
    "                    \n",
    "    @staticmethod\n",
    "    def Zscore( X, **kwargs ):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        \n",
    "        if 'save_model' in kwargs:\n",
    "            pickle.dump( scaler, open( kwargs[ 'save_model' ], 'wb' ) )\n",
    "        return scaler.transform( X )\n",
    "\n",
    "#     def SaveConf(self,fout):\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[self.perAtomData],header=' '.join(list(self.perAtomData.keys())))\n",
    "\n",
    "#     def Test(self,y,\n",
    "#                                    random_state=1\n",
    "#                                    ):\n",
    "#             '''\n",
    "#             Convolutional neural network.\n",
    "\n",
    "#             Parameters\n",
    "#             ----------\n",
    "#             X_train : array-like training x input\n",
    "\n",
    "#             y_train : array-like, training y input\n",
    "\n",
    "#             X_test : array-like test x input\n",
    "\n",
    "#             y_test : array-like, training y input\n",
    "\n",
    "#             Return\n",
    "#             ---------- ( , loss,  )\n",
    "#             best_model : cnn object, best trained model based on on the validation loss\n",
    "\n",
    "#             loss : array-like, mse loss\n",
    "\n",
    "#             val_loss : array-like, validation loss\n",
    "\n",
    "#             '''\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('dim(y)=',y.shape)\n",
    "\n",
    "#             ndime  = y.shape[1] #--- dimension of the target vector\n",
    "\n",
    "\n",
    "#             #---------------\n",
    "#             #--- zscore X\n",
    "#             #---------------        \n",
    "#             X      = np.c_[self.descriptors ]\n",
    "#             scaler = StandardScaler()\n",
    "#             scaler.fit(X)\n",
    "#             X      = scaler.transform( X )\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('X.shape:=',X.shape)\n",
    "\n",
    "\n",
    "\n",
    "#             #-----------------------\n",
    "#             #--- train-test split\n",
    "#             #-----------------------\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "#                                                                 random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "#             #---- set model parameters\n",
    "#             shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "#             kernel_size   =  self.kernel_size \n",
    "#             epochs        =  self.max_iter[0]\n",
    "#             activation    =  self.activation\n",
    "#             padding       = 'same'\n",
    "#             filters       =  self.n_channels\n",
    "#             learning_rate = self.learning_rate_init[0]\n",
    "#             #\n",
    "#             ndime         =  y_train.shape[1]\n",
    "#             n_train       =  X_train.shape[0]\n",
    "#             n_test        =  X_test.shape[0]\n",
    "#             assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "#             inputs        =  keras.Input(shape=shape)\n",
    "#             #\n",
    "#     #         pdb.set_trace()\n",
    "#             #------------------------------\n",
    "#             #--- The network architecture\n",
    "#             #------------------------------\n",
    "#             model     = keras.Sequential([\n",
    "#                 layers.Dense(self.hidden_layer_size, activation=\"relu\"),\n",
    "#     #             layers.Dense(self.hidden_layer_size), #activation=\"relu\"),\n",
    "#                 layers.Dense(2, activation=\"softmax\")\n",
    "#                 ])\n",
    "#             optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "\n",
    "#             model.compile( optimizer=\"rmsprop\",\n",
    "#                            loss=\"sparse_categorical_crossentropy\",\n",
    "#                            metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "#             #--- Fitting the model X_train_transfrmd, y_train\n",
    "#             X_train_reshaped =  X_train \n",
    "#             X_test_reshaped  =  X_test\n",
    "#             model.fit( X_train_reshaped, y_train, \n",
    "#                        validation_data      = ( X_test_reshaped, y_test ),\n",
    "#     #                     callbacks=callbacks,\n",
    "#                         epochs              = epochs, \n",
    "#                         verbose             = self.verbose, \n",
    "#                         shuffle             = False, \n",
    "#     #                     batch_size     = 128,\n",
    "#                         use_multiprocessing = True,\n",
    "#                         workers             = 4,\n",
    "#                      )        \n",
    "\n",
    "\n",
    "#             #--- save best model\n",
    "#             !mkdir best_model\n",
    "#     #         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#     #                                                    monitor=\"val_loss\",\n",
    "#     #                                                   save_freq=10,\n",
    "#     #                                                     save_best_only=True)]\n",
    "\n",
    "\n",
    "#             #--- validation loss\n",
    "#             loss       = model.history.history['loss']\n",
    "#             val_loss   = model.history.history['val_loss']\n",
    "#             best_model = model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "\n",
    "#             !mkdir png\n",
    "#             utl.PltErr(range(len(loss)), loss,\n",
    "#                        yscale='log',\n",
    "#                        xstr='epoch',ystr='loss',\n",
    "#                        title='png/loss_classification.png',\n",
    "#                       )\n",
    "\n",
    "#     #         pdb.set_trace()\n",
    "#             #--- confusion matrix\n",
    "#             cm = confusion_matrix(y_test, model.predict_classes(X_test),\n",
    "#                              labels=[0, 1]\n",
    "#                             )\n",
    "#             print('cm=',cm)\n",
    "#             np.savetxt('png/confusion.txt',np.c_[cm])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8fc70",
   "metadata": {},
   "source": [
    "## main(): classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def main():\n",
    " \n",
    "    if not eval(confParser['neural net classification']['classification']):\n",
    "        return\n",
    "    \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes   = eval(confParser['neural net classification']['hidden_layer_sizes']),\n",
    "                        learning_rate_init   = eval(confParser['neural net classification']['learning_rate_init']),\n",
    "                        n_iter_no_change     = eval(confParser['neural net classification']['n_iter_no_change']),\n",
    "                        tol                  = eval(confParser['neural net classification']['tol']),\n",
    "                        max_iter             = eval(confParser['neural net classification']['max_iter']),\n",
    "                        alpha                = eval(confParser['neural net classification']['alpha']),\n",
    "                        hidden_layer_size    = eval(confParser['neural net classification']['hidden_layer_size']),\n",
    "                        fully_connected      = eval(confParser['neural net classification']['fully_connected']),\n",
    "                        implementation       = eval(confParser['neural net classification']['implementation']),\n",
    "                        cnn                  = eval(confParser['neural net classification']['cnn']),\n",
    "                        n_channels           = eval(confParser['neural net classification']['n_channels']),\n",
    "                        kernel_size          = eval(confParser['neural net classification']['kernel_size']),\n",
    "                        activation           = eval(confParser['neural net classification']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net classification']['number_hidden_layers']),\n",
    "                        n_train              = eval(confParser['neural net classification']['n_train']),\n",
    "                        best_model           = 'best_model',\n",
    "                        verbose              = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse2nd( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net classification']['nruns']))\n",
    "\n",
    "    nn.Combine2nd() #--- concat. descriptors\n",
    "\n",
    "    #--- classifier\n",
    "    nn.TrainClassifier()\n",
    "#        nn.Test(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    \n",
    "    \n",
    "    return nn\n",
    "\n",
    "#model_clf = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0db348",
   "metadata": {},
   "source": [
    "## main(): regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01971ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " def main():\n",
    " \n",
    "    if not eval(confParser['neural net regression']['regression']):\n",
    "        return\n",
    "\n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes   = eval(confParser['neural net regression']['hidden_layer_sizes']),\n",
    "                        learning_rate_init   = eval(confParser['neural net regression']['learning_rate_init']),\n",
    "                        n_iter_no_change     = eval(confParser['neural net regression']['n_iter_no_change']),\n",
    "                        tol                  = eval(confParser['neural net regression']['tol']),\n",
    "                        max_iter             = eval(confParser['neural net regression']['max_iter']),\n",
    "                        alpha                = eval(confParser['neural net regression']['alpha']),\n",
    "                        hidden_layer_size    = eval(confParser['neural net regression']['hidden_layer_size']),\n",
    "                        fully_connected      = eval(confParser['neural net regression']['fully_connected']),\n",
    "                        implementation       = eval(confParser['neural net regression']['implementation']),\n",
    "                        cnn                  = eval(confParser['neural net regression']['cnn']),\n",
    "                        n_channels           = eval(confParser['neural net regression']['n_channels']),\n",
    "                        kernel_size          = eval(confParser['neural net regression']['kernel_size']),\n",
    "                        activation           = eval(confParser['neural net regression']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net regression']['number_hidden_layers']),\n",
    "                        n_train              = eval(confParser['neural net regression']['n_train']),\n",
    "                        du                   = eval(confParser['neural net regression']['du']),\n",
    "                        umax                 = eval(confParser['neural net regression']['umax']),\n",
    "                        best_model           = 'best_model',\n",
    "                        verbose              = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse2nd( path  = confParser['neural net']['input_path'],\n",
    "                 nruns = eval(confParser['neural net regression']['nruns'])\n",
    "               )\n",
    "\n",
    "    nn.Combine2nd() #--- concat. descriptors\n",
    "\n",
    "    nn.TrainRegressorTransitionPaths()\n",
    "    nn.TrainRegressorBarriers()\n",
    "    \n",
    "    return nn\n",
    "\n",
    "#model_regr = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aefa4",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1a5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "    #--- ann\n",
    "    number_hidden_layers  = dict(zip(range(4),[1]))\n",
    "    hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "    n_channels            = dict(zip(range(4),[1]))\n",
    "    activations           = dict(zip(range(20),['relu']))\n",
    "#     string[ inums ] = \"\\t\\'5\\':\\'neuralNet/20x20/ann/classifier/layer%s/channel%s/activation%s/layer_size%s\\',\\n\" % (key_n,key_c,key_a,key_h) #--- change job name\n",
    "    \n",
    "    #--- cnn\n",
    "#     number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "#     hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "#     n_channels            = dict(zip(range(4),[8,16,32,64]))\n",
    "#     activations           = dict(zip(range(20),['linear']))\n",
    "\n",
    "    runs = range(8)\n",
    "    \n",
    "    legend = utl.Legends()\n",
    "    legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "    symbols = utl.Symbols()\n",
    "    \n",
    "    nphi = len(number_hidden_layers)\n",
    "    #---\n",
    "    count = 0\n",
    "    ax = utl.PltErr(None, None, Plot=False )\n",
    "    for key_n in number_hidden_layers:\n",
    "        number_hidden_layer = number_hidden_layers[key_n]\n",
    "#         if number_hidden_layer != 2:\n",
    "#             continue\n",
    "        for key_c in n_channels:\n",
    "            n_channel = n_channels[key_c]\n",
    "#             if n_channel != 16:\n",
    "#                 continue\n",
    "            for key_a in activations:\n",
    "                activation = activations[key_a]\n",
    "                for key_h in hidden_layer_size:\n",
    "                    nsize = hidden_layer_size[key_h]\n",
    "\n",
    "        #---\n",
    "#                    path = 'neuralNet/20x20/cnn/classifier/layer%s/channel%s/activation%s/layer_size%s'%(key_n,key_c,key_a,key_h) #--- change job name\n",
    "                    path = 'neuralNet/ni/interestitials/test2nd' #--- change job name\n",
    "                    fp = ['confusion.txt', 'val_loss_classification.txt','loss.txt'][ 2 ]\n",
    "                    for irun in runs:\n",
    "                        try:\n",
    "                            data = np.loadtxt('%s/Run%s/png/%s'%(path,irun,fp))\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        if fp == 'confusion.txt':\n",
    "                            accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "                            accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "                            print(data)\n",
    "                            utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                        else:\n",
    "                            epoch = data[:,0]\n",
    "                            loss = data[:,1]\n",
    "                            val_loss = data[:,2]\n",
    "\n",
    "                            utl.PltErr(epoch, loss,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=10,\n",
    "                                    label='train:%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                            utl.PltErr(epoch, val_loss,\n",
    "                               attrs=symbols.GetAttrs(count=(count+1)%7,nevery=10,\n",
    "                                    label='test:%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                    count += 1\n",
    "    ax = utl.PltErr(None, None,\n",
    "                        yscale='log',xscale='log',\n",
    "                       xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "                    ax=ax,\n",
    "                    legend=legend.Get(),\n",
    "                       title='png/training_loss.png',\n",
    "                   )\n",
    "\n",
    "\n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6dc865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm=np.loadtxt('neuralNet/ni/interestitials/test2nd/Run0/png/confusionMultiLabelClassification.txt').astype(int)\n",
    "# falseNegative = list(map(lambda x: 1.0*x[0]/(x[0]+x[1]), cm))\n",
    "# truePositive  = list(map(lambda x: 1.0*x[3]/(x[2]+x[3]), cm))\n",
    "# filtr  = cm[:,3] > 0\n",
    "# cm[filtr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74daa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend = utl.Legends()\n",
    "# legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "# symbols = utl.Symbols()\n",
    "\n",
    "# fp = ['confusion.txt', 'val_loss_classification.txt'][0]\n",
    "# data = np.loadtxt('neuralNet/ni/kmc/inactive/Run0/png/%s'%(fp))\n",
    "# ax = utl.PltErr(None, None, Plot=False )\n",
    "# if fp == 'confusion.txt':\n",
    "#     accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "#     accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "#     print(data)\n",
    "#     utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "#        attrs=symbols.GetAttrs(count=0,nevery=800,\n",
    "#             ), \n",
    "#                Plot=False,\n",
    "#                ax=ax,\n",
    "#                )\n",
    "# else:\n",
    "#     epoch = data[:,0]\n",
    "#     loss = data[:,1]\n",
    "#     val_loss = data[:,2]\n",
    "\n",
    "#     utl.PltErr(epoch, val_loss,\n",
    "#        attrs=symbols.GetAttrs(count=0,nevery=10,\n",
    "#             ), \n",
    "#                Plot=False,\n",
    "#                ax=ax,\n",
    "#                )\n",
    "    \n",
    "# ax = utl.PltErr(None, None,\n",
    "# yscale='log',xscale='log',\n",
    "# xstr='epoch',ystr='validation loss',\n",
    "# #                     ylim=(1e-1,1e1),\n",
    "# ax=ax,\n",
    "# # legend=legend.Get(),\n",
    "# title='png/training_loss.png',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506974a",
   "metadata": {},
   "source": [
    "## test example: 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be92045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# y=np.c_[[1.725966,1.725967],\n",
    "#             [-1.725966,1.725967],\n",
    "#             [-1.725966,-1.725967],\n",
    "#             [1.725966,-1.725967],\n",
    "#            ].T\n",
    "\n",
    "# X=np.concatenate([list(map(lambda x:np.load('png/descriptor%s.npy'%x).flatten(),range(4)))],axis=1)\n",
    "\n",
    "# #--- zscore\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_transfrmd = scaler.transform( X )\n",
    "\n",
    "# X_train_transfrmd, X_test_transfrmd, y_train, y_test = train_test_split(X_transfrmd, y, test_size=0.25)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# print(X_train_transfrmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69377834",
   "metadata": {},
   "source": [
    "### fully connected in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c56d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #        pdb.set_trace()\n",
    "# #--- tune parameters\n",
    "\n",
    "# #--- train\n",
    "# mlp = MLPRegressor(random_state=1,\n",
    "#                     verbose=True,\n",
    "#                    n_iter_no_change=100000,\n",
    "#                     max_iter=100,#00,\n",
    "#                    hidden_layer_sizes=(1000,1000),\n",
    "# #                    shuffle=False,\n",
    "# #                     alpha=1e-1,\n",
    "\n",
    "#                   )\n",
    "# mlp.fit(X_train_transfrmd,y_train)\n",
    "\n",
    "# #--- validate\n",
    "# !mkdir png\n",
    "# utl.PltErr(range(len(mlp.loss_curve_)), mlp.loss_curve_,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            yscale='log',xscale='log',\n",
    "# #           xlim=(1,self.max_iter[0]),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )\n",
    "\n",
    "# # #         pdb.set_trace()\n",
    "# y_pred =mlp.predict(X_test_transfrmd)        \n",
    "# y_pred_train = mlp.predict(X_train_transfrmd)        \n",
    "# for idime, xstr in zip(range(2),'ux uy'.split()):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     #\n",
    "#     utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(None,None,Plot=False,\n",
    "#                    title='png/scatter%s.png'%idime,\n",
    "#                     ax=ax,\n",
    "#                xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                xlim=(-3,3),ylim=(-3,3),\n",
    "#                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e1353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.best_loss_, mlp.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157c537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=mlp.predict(X_test_transfrmd)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a952ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(2):\n",
    "#     utl.PltErr(range(data.descriptors[0,:].shape[0]),data.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n",
    "# utl.PltErr(range(data.descriptors[100,:].shape[0]),data.descriptors[100,:],\n",
    "#           attrs={'fmt':'-','color':'C0'},\n",
    "#            xscale='log',yscale='log',\n",
    "#            ax=ax,\n",
    "#            Plot=False,\n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d061978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     random_state=1)\n",
    "# regr = MLPRegressor(verbose=False,\n",
    "#                     random_state=1, \n",
    "# #                     learning_rate='adaptive',\n",
    "# #                    early_stopping=True, \n",
    "#                      n_iter_no_change=1, \n",
    "#                     tol=1e-2,\n",
    "#                      max_iter=10000000,\n",
    "# #                     solver='sgd',\n",
    "#                    ).fit(X_train, y_train)\n",
    "# regr.tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eecba",
   "metadata": {},
   "source": [
    "### fully connected in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a27a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--- The network architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512), #activation=\"relu\"),\n",
    "# #     layers.Dense(1000), #activation=\"relu\"),\n",
    "#     layers.Dense(2) #, activation=\"relu\")\n",
    "#     ])\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- Preparing the image data\n",
    "# # train_images = train_images.reshape((60000, 28 * 28))\n",
    "# # train_images = train_images.astype(\"float32\") / 255\n",
    "# # test_images = test_images.reshape((10000, 28 * 28))\n",
    "# # test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# #--- Fitting the model X_train_transfrmd,y_train\n",
    "# model.fit(X_train_transfrmd, y_train, \n",
    "#             validation_data=(X_test_transfrmd, y_test),\n",
    "\n",
    "#           epochs=100, verbose=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,100),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262922c9",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70f22b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.random.set_random_seed(812)\n",
    "\n",
    "# shape=(300,300,1)\n",
    "# kernel_size = (3,3)\n",
    "# epochs = 1000\n",
    "# activation = ['linear','sigmoid','relu'][0]\n",
    "# padding='same'\n",
    "# filters = 1\n",
    "# #\n",
    "# ndime = y_train.shape[1]\n",
    "# n_train = X_train_transfrmd.shape[0]\n",
    "# n_test = X_test_transfrmd.shape[0]\n",
    "# assert shape[0]*shape[1]*shape[2] == X_train_transfrmd.shape[1]\n",
    "# inputs = keras.Input(shape=shape)\n",
    "# #\n",
    "# x = layers.Conv2D(filters=filters, kernel_size=kernel_size,activation=activation,padding=padding)(inputs)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=2*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=4*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=8*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "\n",
    "# #--- The network architecture\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,epsilon=1e-08)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- save best model \n",
    "# callbacks=[keras.callbacks.ModelCheckpoint( filepath='png/convnet_from_scratch.keras',  \n",
    "#                                            monitor=\"val_loss\",\n",
    "#                                            save_freq=10,\n",
    "#                                             save_best_only=True)]\n",
    "\n",
    "# #--- Fitting the model X_train_transfrmd,y_train\n",
    "# X_train_reshaped = X_train_transfrmd.reshape((n_train,shape[0],shape[1],1))\n",
    "# X_test_reshaped = X_test_transfrmd.reshape((n_test,shape[0],shape[1],1))\n",
    "# model.fit(X_train_reshaped, y_train, \n",
    "#             validation_data=(X_test_reshaped, y_test),\n",
    "#             #callbacks=callbacks,\n",
    "#           epochs=epochs, verbose=False, shuffle=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,epochs),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "673ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = keras.models.load_model(\"png/convnet_from_scratch.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fa9c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=best_model.predict(X_test_reshaped)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaf166dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (ux,uy), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e1c0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rd = lp.ReadDumpFile( '%s/lammps_data.dat'%confParser['input files']['input_path'] )\n",
    "# rd.ReadData()\n",
    "# # box = \n",
    "# natoms = rd.coord_atoms_broken[ 0 ].shape[0]\n",
    "# atom_indices = ' '.join(map(str,range(natoms)))\n",
    "\n",
    "# fp = '%s/lammps_data.dat'%confParser['input files']['input_path']\n",
    "# fout = 'neighbor_list.xyz'\n",
    "# cutoff = 3.0\n",
    "# lib_path = confParser['input files']['lib_path'].split()[0]\n",
    "# #--- neighbor list\n",
    "# os.system('ovitos %s/OvitosCna.py %s %s 1 6 %s %s'%(lib_path,fp,fout,cutoff,atom_indices))\n",
    "\n",
    "\n",
    "# nl = lp.ReadDumpFile(fout)\n",
    "# nl.GetCords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dab4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GetIndex(dff, key, vals ):\n",
    "# #    dff = rd.coord_atoms_broken[ 0 ]\n",
    "#     dff['index'] = range(natoms)\n",
    "#     indices = dff.set_index(key, drop = True, append=False, inplace= False).loc[vals]['index']\n",
    "#     return np.c_[indices].flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e3578bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# from scipy.sparse import lil_matrix\n",
    "\n",
    "# #--- adj matrix\n",
    "\n",
    "# df_xyz = rd.coord_atoms_broken[ 0 ]\n",
    "# df = nl.coord_atoms_broken[0]\n",
    "# df\n",
    "# center_ids = df.groupby(by='id').groups\n",
    "\n",
    "# #--- sparse\n",
    "# # Adj_mat = sparse_mat(natoms,natoms)\n",
    "# Adj_mat_total = lil_matrix((natoms, natoms),dtype=int)\n",
    "\n",
    "# for center_id in center_ids:\n",
    "#     center_indx = GetIndex(df_xyz,'id',[center_id])[ 0 ]\n",
    "#     neibor_ids  = df['J'].iloc[ center_ids[ center_id ] ].astype( int )\n",
    "#     neibor_indices = GetIndex(df_xyz,'id',np.c_[neibor_ids].flatten())\n",
    "#     Adj_mat_total[center_indx, neibor_indices ] = 1\n",
    "# #     if Adj_mat_total[center_indx].sum() != 12:\n",
    "# #         print('center_indx=%s'%center_indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f771e15",
   "metadata": {},
   "source": [
    "# neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17a84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNets:\n",
    "\n",
    "    def __init__(self,confParser,verbose=True):\n",
    "        self.ntrain               = eval(confParser['NeuralNets']['ntrain'])    \n",
    "        self.noise_std            = eval(confParser['NeuralNets']['noise_std'])\n",
    "        self.verbose              = verbose\n",
    "        self.kernel_size          =  (3,3,3)\n",
    "        self.max_iter             =  eval(confParser['NeuralNets']['max_iter'])\n",
    "        self.activation           =  eval(confParser['NeuralNets']['activation'])\n",
    "        self.n_channels           = 32\n",
    "        self.learning_rate        = eval(confParser['NeuralNets']['learning_rate'])\n",
    "        self.number_hidden_layers = eval(confParser['NeuralNets']['number_hidden_layers'])\n",
    "            \n",
    "    def Parse(self,path,nruns):\n",
    "\n",
    "        self.Catalogs    = {}\n",
    "        self.transition_paths = []\n",
    "        self.transition_paths_atoms = []\n",
    "        #\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                self.transition_paths.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths_discretized.json'%(path,irun)) )\n",
    "                self.transition_paths_atoms.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths.json'%(path,irun)) )\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/saved_output/catalog.txt'%(path,irun))\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns     = list(self.Catalogs.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "        self.shape = tuple(np.loadtxt('%s/Run%s/saved_output/shape.txt'%(path,0)).astype(int))\n",
    "        \n",
    "        \n",
    "    def DataBuilder( self ):\n",
    "        \n",
    "        ntrain        = self.ntrain\n",
    "        num_snapshots = len( self.transition_paths )\n",
    "        snapshots     = range(num_snapshots)\n",
    "        input_data    = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['rho'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "        # Example target data (displacement vectors for each snapshot and each path)\n",
    "        target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots]\n",
    "\n",
    "        # Augment the dataset to have order 100 snapshots\n",
    "        augmented_input_data = []\n",
    "        augmented_target_displacements = []\n",
    "        input_data_tensor = torch.stack(input_data)\n",
    "        ntrain_initial = input_data_tensor.shape[0]\n",
    "        n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input, augmented_target = NeuralNets.augment_data(input_data, target_displacements, self.noise_std)\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data_tensor = torch.stack(augmented_input_data)\n",
    "#        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "        # Standardize the augmented input data\n",
    "        mean = input_data_tensor.mean(dim=(0))\n",
    "        std = input_data_tensor.std(dim=(0))\n",
    "        standardized_input_data = ( input_data_tensor - mean ) / std\n",
    "        assert torch.all(standardized_input_data.mean(dim=(0)).abs() < 1.0e-6 )\n",
    "        assert torch.all((standardized_input_data.std(dim=(0)) - 1.0).abs() < 1.0e-6 )\n",
    "\n",
    "\n",
    "        # Convert input data to tensors\n",
    "        target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "        input_data_tensor           = standardized_input_data #torch.stack(standardized_input_data)\n",
    "\n",
    "\n",
    "        X = input_data_tensor\n",
    "        y = target_displacements_tensor\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                               test_size=test_size, train_size=train_size,\n",
    "                                                              random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "        # Define batch sizes for training and test dataloaders\n",
    "        self.dataset_train = {}\n",
    "        self.dataset_test = {}\n",
    "        self.dataset_train['x'] = X_train\n",
    "        self.dataset_train['y'] = y_train\n",
    "        self.dataset_test['x']  = X_test\n",
    "        self.dataset_test['y']  = y_test\n",
    "\n",
    "\n",
    "        if self.verbose:\n",
    "            print('dataset_train:',self.dataset_train['x'].shape)\n",
    "            print('dataset_test:',self.dataset_test['x'].shape)\n",
    "            \n",
    "    def CreateModel(self):\n",
    "        shape         =  (self.shape[0], self.shape[1], self.shape[2], 1)  # Bitmap size 24x24x24 with 1 channel\n",
    "        ndime         = 3\n",
    "        kernel_size   =  self.kernel_size \n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "\n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = layers.Dense( 256, activation=activation )( x )\n",
    "        x = layers.Dense( 512, activation=activation )( x )\n",
    "        x = layers.Dense( shape[0] * shape[1] * shape[2] * ndime )( x )\n",
    "        outputs = layers.Reshape((shape[0], shape[1], shape[2], ndime))(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:', model.summary())\n",
    "            \n",
    "            \n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = self.learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        return model\n",
    "            \n",
    "\n",
    "\n",
    "    def autoencoder_3d(self):\n",
    "        input_shape         =  (self.shape[0], self.shape[1], self.shape[2], 1)  # Bitmap size 24x24x24 with 1 channel\n",
    "        ndime         = 3\n",
    "\n",
    "        # Encoder\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "        x = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "        x = layers.MaxPooling3D((2, 2, 2), padding='same')(x)\n",
    "        encoded = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = layers.UpSampling3D((2, 2, 2))(x)\n",
    "        decoded = layers.Conv3D(3, (3, 3, 3), activation='linear', padding='same')(x)\n",
    "\n",
    "        # Autoencoder model\n",
    "        autoencoder = keras.Model(inputs, decoded)\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = self.learning_rate )\n",
    "        autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:', autoencoder.summary())\n",
    "        return autoencoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Training(self):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "\n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "\n",
    "        model = self.autoencoder_3d() #CreateModel()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #\n",
    "        shape         = self.shape\n",
    "        assert        shape[0] * shape[1] * shape[2] == self.dataset_train['x'].shape[1]\n",
    "        ndime         = self.dataset_train['y'].shape[2]\n",
    "        n_train       =  self.dataset_train['x'].shape[0]\n",
    "        n_test        =  self.dataset_test['x'].shape[0]\n",
    "        #\n",
    "\n",
    "\n",
    "        #--- Fitting the model\n",
    "        X_train_reshaped =  self.dataset_train['x'].reshape((n_train, shape[0], shape[1], shape[2], 1)).numpy()\n",
    "        X_test_reshaped  =  self.dataset_test['x'].reshape((n_test, shape[0], shape[1], shape[2], 1)).numpy()\n",
    "        y_train = self.dataset_train['y'].reshape((n_train,shape[0],shape[1],shape[2],ndime)).numpy()\n",
    "        y_test  = self.dataset_test['y'].reshape((n_test,shape[0],shape[1],shape[2],ndime)).numpy()\n",
    "        if self.verbose:\n",
    "            print('y_train.shape:',y_train.shape)\n",
    "\n",
    "\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   epochs              = self.max_iter, \n",
    "                   verbose             = self.verbose, \n",
    "                   shuffle             = False,\n",
    "                  batch_size           = 128\n",
    "                 )\n",
    "\n",
    "        #--- Save the model\n",
    "        os.system('mkdir best_model')\n",
    "        model.save('best_model/convnetRegressor_from_scratch.tf')\n",
    "        self.loss       = model.history.history['loss']\n",
    "        self.val_loss   = model.history.history['val_loss']\n",
    "        self.best_model = model\n",
    "        \n",
    "        #--- save reshaped dataset\n",
    "        self.dataset_train['x_reshaped'] =  X_train_reshaped\n",
    "        self.dataset_train['y_reshaped'] =  y_train\n",
    "        self.dataset_test['x_reshaped']  =  X_test_reshaped\n",
    "        self.dataset_test['y_reshaped'] =   y_test\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_data(input_data, target_displacements, noise_std):\n",
    "        augmented_input_data = []\n",
    "        augmented_target_displacements = []\n",
    "\n",
    "        for data, target in zip(input_data, target_displacements):\n",
    "            # Add Gaussian noise to input data\n",
    "            noisy_data = data + torch.randn_like(data) * noise_std\n",
    "            augmented_input_data.append(noisy_data)\n",
    "\n",
    "            # Add Gaussian noise to target displacements\n",
    "            noisy_target = target + torch.randn_like(target) * noise_std\n",
    "            augmented_target_displacements.append(noisy_target)\n",
    "\n",
    "        return augmented_input_data, augmented_target_displacements\n",
    "    \n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def standardize_data(data, mean, std):\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    \n",
    "    \n",
    "    def Validation(self):\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        os.system('mkdir png')         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(self.val_loss)), self.val_loss,\n",
    "                   attrs={'fmt':'-','color':'red'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(self.loss)), self.loss,\n",
    "                   attrs={'fmt':'-','color':'C0'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "#                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(self.loss)),self.loss,self.val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        \n",
    "        #--- plot actual vs. prediction\n",
    "        y_pred_test  = self.best_model.predict(self.dataset_test['x_reshaped'])        \n",
    "        y_pred_train = self.best_model.predict(self.dataset_train['x_reshaped'])  \n",
    "        \n",
    "        grid_pts = np.c_[pd.DataFrame(self.transition_paths[0])['x y z'.split()]]\n",
    "        os.system('rm png/training.xyz png/actual_train.xyz png/actual_test.xyz png/test.xyz')\n",
    "        for indx, disps_map in enumerate( y_pred_train ):\n",
    "            with open('png/training.xyz','a') as fp:\n",
    "                udisp = disps_map.reshape((self.shape[0]*self.shape[1]*self.shape[2],3))\n",
    "                cordc = pd.DataFrame(np.c_[grid_pts,udisp],columns='x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "\n",
    "\n",
    "            with open('png/actual_train.xyz','a') as fp:\n",
    "                udisp = self.dataset_train['y'][indx]\n",
    "                cordc = pd.DataFrame(np.c_[grid_pts,udisp],columns='x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "\n",
    "        for indx, disps_map in enumerate( y_pred_test ):\n",
    "            with open('png/actual_test.xyz','a') as fp:\n",
    "                udisp = self.dataset_test['y'][indx]\n",
    "                cordc = pd.DataFrame(np.c_[grid_pts,udisp],columns='x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "\n",
    "            with open('png/test.xyz','a') as fp:\n",
    "                udisp = disps_map.reshape((self.shape[0]*self.shape[1]*self.shape[2],3))\n",
    "                cordc = pd.DataFrame(np.c_[grid_pts,udisp],columns='x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "\n",
    "            \n",
    "        \n",
    "        #--- find disp at query points\n",
    "#         self.Mesh()\n",
    "#         udisp_pred_train = []\n",
    "#         udisp_actual_train = []\n",
    "#         !rm png/training.xyz\n",
    "#         for indx, disps_map in enumerate( y_pred_train ): #--- loop over maps\n",
    "#             query_points = np.c_[pd.DataFrame(self.transition_paths_atoms[ indx ])['x y z'.split()]] #--- query points from atom-based data\n",
    "#             udisp = list( map(lambda x: disps_map[self.GetIndex( x )].flatten(),query_points) )\n",
    "#             with open('png/query.xyz','a') as fp:\n",
    "#                 cordc = pd.DataFrame(np.c_[query_points,udisp],columns='x y z ux uy uz'.split())\n",
    "#                 utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "#             udisp_pred_train.extend(udisp) #--- extract disps from query points\n",
    "#             udisp_actual_train.extend(np.c_[pd.DataFrame(self.transition_paths_atoms[ indx ])['ux_fin    uy_fin    uz_fin'.split()]]) #--- actual disps\n",
    "\n",
    "#         #--- testing \n",
    "#         udisp_pred_test = []\n",
    "#         udisp_actual_test = []\n",
    "#         for indx, disps_map in enumerate( y_pred_test ):\n",
    "#             query_points = np.c_[pd.DataFrame(self.transition_paths_atoms[ indx ])['x y z'.split()]]\n",
    "#             udisp_pred_test.extend(list( map(lambda x: disps_map[self.GetIndex( x )].flatten(),query_points) ))\n",
    "#             udisp_actual_test.extend(np.c_[pd.DataFrame(self.transition_paths_atoms[ indx ])['ux_fin    uy_fin    uz_fin'.split()]])\n",
    "\n",
    "#         #--- plot\n",
    "#         for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "#             ax = utl.PltErr(None,None,Plot=False)\n",
    "#             #\n",
    "#             utl.PltErr(np.c_[udisp_actual_test][:,idime],np.c_[udisp_pred_test][:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(np.c_[udisp_actual_train][:,idime],np.c_[udisp_pred_train][:,idime],\n",
    "#                        attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(None,None,Plot=False,\n",
    "#                            title='png/scatter%s.png'%idime,\n",
    "#                             ax=ax,\n",
    "#                        xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                        xlim=(-2,2),ylim=(-2,2),\n",
    "#                            )\n",
    "\n",
    "    def GetIndex( self, query_point ):\n",
    "        aa = np.c_[query_point].T\n",
    "        H, bin_edges = np.histogramdd(aa,bins=self.bins)        \n",
    "        assert H.sum() == 1.0        \n",
    "        return H.astype(bool)\n",
    "        \n",
    "    def Mesh(self):\n",
    "        xv = np.c_[pd.DataFrame(self.transition_paths[0]).x].flatten().reshape(self.shape)\n",
    "        yv = np.c_[pd.DataFrame(self.transition_paths[0]).y].flatten().reshape(self.shape)\n",
    "        zv = np.c_[pd.DataFrame(self.transition_paths[0]).z].flatten().reshape(self.shape)\n",
    "        xlin = xv[:,0,0]\n",
    "        ylin = yv[0,:,0]\n",
    "        zlin = zv[0,0,:]\n",
    "        dx = xlin[1]-xlin[0]\n",
    "        dy = ylin[1]-ylin[0]\n",
    "        dz = zlin[1]-zlin[0]\n",
    "        xlin = np.append(xlin,xlin[-1]+dx) \n",
    "        ylin = np.append(ylin,ylin[-1]+dy) \n",
    "        zlin = np.append(zlin,zlin[-1]+dz) \n",
    "        self.bins = [xlin,ylin,zlin]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3680c39",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d384052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nn = NeuralNets(confParser)\n",
    "    nn.Parse( path  = confParser['neural net']['input_path'],\n",
    "             nruns = eval(confParser['neural net regression']['nruns'])\n",
    "           )\n",
    "\n",
    "    nn.DataBuilder()\n",
    "    nn.Training()\n",
    "    nn.Validation()\n",
    "\n",
    "#main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca956e6",
   "metadata": {},
   "source": [
    "# subclasses nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fbc2e9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5483b167858d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMyConvNetModel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gnnEnv/lib/python3.7/site-packages/tensorflow_core/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "class DataSet:\n",
    "\n",
    "    def __init__(self,confParser,verbose=True): \n",
    "        self.noise_std            = eval(confParser['neural net']['noise_std'])\n",
    "        self.DBSCANcluster_length = eval(confParser['neural net']['DBSCANcluster_length'])\n",
    "        self.verbose              = verbose\n",
    "        self.cutoff               = 3.0\n",
    "\n",
    "    def Parse(self,path,nruns, **kwargs):\n",
    "        '''\n",
    "        Parse dataset\n",
    "        '''\n",
    "        #\n",
    "        self.Catalogs         = {}\n",
    "        self.transition_paths = []\n",
    "        self.descriptors      = []\n",
    "        self.dumpFiles        = []\n",
    "        self.neighlists       = []\n",
    "        #\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%path)\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "\n",
    "        #--- dirs and files to be parsed\n",
    "        file_dirs = ['saved_output/descriptorsEveryAtom.json',\n",
    "             'saved_output/transition_paths.json',\n",
    "             'neighList/neigh_list.xyz',\n",
    "             'dumpFile/dump.xyz',\n",
    "             'saved_output/catalog.txt'\n",
    "            ]\n",
    "        for irun in range(nruns):\n",
    "            if not self.fileExists(path,irun,file_dirs):\n",
    "                continue            \n",
    "            self.descriptors.extend( rwjs.Read('%s/Run%s/saved_output/descriptorsEveryAtom.json'%(path,irun)) )\n",
    "            self.transition_paths.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths.json'%(path,irun)) )\n",
    "            self.neighlists.append( '%s/Run%s/neighList/neigh_list.xyz'%(path,irun))\n",
    "            self.dumpFiles.append(  '%s/Run%s/dumpFile/dump.xyz'%(path,irun))\n",
    "            os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "            self.Catalogs[irun]     = pd.read_csv('%s/Run%s/saved_output/catalog.txt'%(path,irun))\n",
    "        #        \n",
    "        self.nruns     = list(self.Catalogs.keys())\n",
    "        self.nruns.sort()\n",
    "\n",
    "    def fileExists(self,path,irun,file_dirs):\n",
    "        '''\n",
    "        return True if passed dirs exist\n",
    "        '''\n",
    "        file_exist = []\n",
    "        for myfile in file_dirs:\n",
    "            file_exist.append( os.path.isfile('%s/Run%s/%s'%(path,irun,myfile)) )\n",
    "        return np.all(np.array(file_exist))\n",
    "    \n",
    "    def Process2nd( self, Ovito_Output = False, train_ratio = 1.0, Standardize=True ):\n",
    "        '''\n",
    "        Build dataloader in pytorch\n",
    "        '''\n",
    "        #\n",
    "        ntrain        = 1000\n",
    "        num_snapshots = len( self.transition_paths ) #--- total no. of transition paths\n",
    "        snapshots     = range(num_snapshots)\n",
    "        #--- include the center atom within each cluster\n",
    "#        filtrs        = list(map(lambda x: np.array(np.ones(len(self.transition_paths[x]['center_atom_index']))).flatten().astype(bool), snapshots))\n",
    "        filtrs = list(map(lambda x: np.array(self.transition_paths[x]['center_atom_index']).flatten().astype(bool), snapshots))\n",
    "        #--- nodal cords\n",
    "        input_data    = [np.log10(np.array(self.transition_paths[ i ]['descriptors']))[filtrs[i]].astype(float) for i in      snapshots]\n",
    "        #--- atom indices\n",
    "        \n",
    "        #--- target data (displacement vectors for each path)\n",
    "        target_displacements = [np.array(self.transition_paths[ i ]['multi_hot_encoded_diffusion_paths'])[filtrs[i]].astype(float) for i in snapshots]\n",
    "\n",
    "        #--- grouping\n",
    "        #--- Standardize the augmented input data\n",
    "        input_data           = DataSet.augment_data( input_data, self.noise_std )\n",
    "        input_data_vstacked  = np.vstack( input_data )\n",
    "\n",
    "        mean = np.zeros(input_data_vstacked.shape[1])\n",
    "        std  = np.ones(input_data_vstacked.shape[1])\n",
    "        if Standardize:\n",
    "            mean                 = input_data_vstacked.mean( axis = 0 )\n",
    "            std                  = input_data_vstacked.std( axis = 0 )\n",
    "        assert np.all( std > 0 ), 'std == 0!'\n",
    "        standardized_input_data = np.vstack([DataSet.standardize_data(data, mean, std) for data in input_data])\n",
    "        self.mean               = mean \n",
    "        self.std                = std\n",
    "        \n",
    "        #--- vary eps to get a robust estimate of cluster no.\n",
    "        yclusters            = DataSet.DBSCANcluster(standardized_input_data,self.DBSCANcluster_length)\n",
    "        input_data_grouped   = DataSet.Group(standardized_input_data,yclusters,operation='mean' )\n",
    "        target_displacements_grouped = DataSet.Group(np.vstack(target_displacements),yclusters, operation='union' )    \n",
    "#        print('num_clusters:',len(set(yclusters)))\n",
    "\n",
    "\n",
    "        #--- add gaussian noise\n",
    "        augmented_input_data           = []\n",
    "        augmented_target_displacements = []\n",
    "        ntrain_initial = input_data_grouped.shape[0]\n",
    "        n_repeat                       = np.max([1,int(ntrain/ntrain_initial)])\n",
    "        #\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input  = DataSet.augment_data( input_data_grouped,           self.noise_std )\n",
    "            augmented_target = DataSet.augment_data( target_displacements_grouped, 0.0) #self.noise_std )\n",
    "            #\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "        #--- adjacency matrix\n",
    "    #    adj_matrices      = self.compute_adjacency_matrices(augmented_input_xyz, rcut=self.cutoff)\n",
    "        \n",
    "        #--- verify adj matrix?\n",
    "     #   if Ovito_Output:\n",
    "      #      self.PrintOvito(adjacency = adj_matrices, input_data=input_data)\n",
    "\n",
    "        #--- Concatenate input data along a new dimension to form a single tensor\n",
    "#        input_data = np.vstack(augmented_input_data) \n",
    "\n",
    "        #--- Standardize the augmented input data\n",
    "#        mean              = input_data.mean(axis=0)\n",
    "#        std               = input_data.std(axis=0)\n",
    "#        assert np.all( std > 0 ), 'std == 0!'\n",
    "        standardized_input_data = augmented_input_data #[DataSet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "        \n",
    "        #--- Standardize edge attributes\n",
    "#         mean              = edge_attrs.mean(dim=(0, 1))\n",
    "#         std               = edge_attrs.std(dim=(0, 1))\n",
    "#         standardized_edge_attrs = [GraphNet.standardize_data(data, mean, std) for data in edge_attrs]\n",
    "\n",
    "\n",
    "        #--- Convert input data to tensors\n",
    "        target_displacements_tensor = augmented_target_displacements\n",
    "        input_data_tensor           = standardized_input_data\n",
    "\n",
    "        #--- Concatenate nodes and edges for each graph\n",
    "\n",
    "        #--- Define batch size and create DataLoader\n",
    "        batch_size = len(input_data_tensor)\n",
    "        \n",
    "        #--- Define batch sizes for  training and test dataloaders\n",
    "        train_batch_size = int( np.max([1,int(batch_size * train_ratio)]) )\n",
    "        test_batch_size  =  batch_size - train_batch_size\n",
    "        \n",
    "        #--- Create DataLoader for training dataset\n",
    "\n",
    "        #--- Accessing batches in the DataLoader\n",
    "        indices= np.arange(batch_size)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        setattr(self,'dataset_train', {'x':np.vstack(input_data_tensor)[indices[:train_batch_size]],\n",
    "                                       'y':np.vstack(target_displacements_tensor)[indices[:train_batch_size]]})\n",
    "        setattr(self,'dataset_test', {'x':np.vstack(input_data_tensor)[indices[train_batch_size:]],\n",
    "                                       'y':np.vstack(target_displacements_tensor)[indices[train_batch_size:]]})\n",
    "\n",
    "    def Process( self, Ovito_Output = False, train_ratio = 0.8, Standardize = True ):\n",
    "        '''\n",
    "        Build dataloader in pytorch\n",
    "        '''\n",
    "        #\n",
    "        ntrain        = 1\n",
    "        num_snapshots = len( self.transition_paths ) #--- total no. of transition paths\n",
    "        snapshots     = range(num_snapshots)\n",
    "        #--- include the center atom within each cluster\n",
    "#        filtrs        = list(map(lambda x: np.array(np.ones(len(self.transition_paths[x]['center_atom_index']))).flatten().astype(bool), snapshots))\n",
    "        filtrs = list(map(lambda x: np.array(self.transition_paths[x]['center_atom_index']).flatten().astype(bool), snapshots))\n",
    "        #--- nodal cords\n",
    "        input_xyz     = [torch.from_numpy( np.c_[np.c_[self.transition_paths[ i ]['x'],\\\n",
    "                                                       self.transition_paths[ i ]['y'],\\\n",
    "                                                       self.transition_paths[ i ]['z']][filtrs[i]]] ).float() for i in snapshots]\n",
    "        #--- nodal descriptors\n",
    "        input_data    = [torch.from_numpy( np.c_[np.log10(np.array(self.transition_paths[ i ]['descriptors']))][filtrs[i]] ).float() for i in      snapshots]\n",
    "        #--- atom indices\n",
    "        input_atom_indx  = [torch.from_numpy( np.c_[self.transition_paths[ i ]['atom_indx']][filtrs[i]] ).int() for i in      snapshots]\n",
    "        \n",
    "        #--- target data (displacement vectors for each path)\n",
    "        displacement_vecs    = [torch.from_numpy(np.array(self.transition_paths[ i ]['diffusion_paths'])[:,:3]).float() for i in snapshots]\n",
    "        target_displacements = [torch.from_numpy(np.array(self.transition_paths[ i ]['multi_hot_encoded_diffusion_paths'])[filtrs[i]]).float() for i in snapshots]\n",
    "\n",
    "        #--- add gaussian noise\n",
    "        augmented_input_data           = []\n",
    "        augmented_input_xyz            = []\n",
    "        augmented_target_displacements = []\n",
    "        augmented_displacement_vecs    = []\n",
    "        n_repeat                       = 1 #np.max([1,int(ntrain/ntrain_initial)])\n",
    "        #\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input  = DataSet.augment_data( input_data,           self.noise_std )\n",
    "            augmented_target = DataSet.augment_data( target_displacements, 0.0) #self.noise_std )\n",
    "            augmented_vecs   = DataSet.augment_data( displacement_vecs,  0.0) #self.noise_std )\n",
    "            augmented_xyz    = DataSet.augment_data( input_xyz,            self.noise_std )\n",
    "            #\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_input_xyz.extend(augmented_xyz)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "            augmented_displacement_vecs.extend(augmented_vecs)\n",
    "\n",
    "        #--- adjacency matrix\n",
    "        adj_matrices      = self.compute_adjacency_matrices(augmented_input_xyz, rcut=self.cutoff)\n",
    "        \n",
    "        #--- verify adj matrix?\n",
    "        if Ovito_Output:\n",
    "            self.PrintOvito(adjacency = adj_matrices, input_data=input_data)\n",
    "\n",
    "        #--- Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data = np.vstack(augmented_input_data) \n",
    "\n",
    "        #--- Standardize the augmented input data\n",
    "        mean = np.zeros(input_data.shape[1])\n",
    "        std  = np.ones(input_data.shape[1])\n",
    "        if Standardize:\n",
    "            mean              = input_data.mean(axis=0)\n",
    "            std               = input_data.std(axis=0)\n",
    "        assert np.all( std > 0 ), 'std == 0!'\n",
    "        standardized_input_data = [DataSet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "        self.mean               = mean \n",
    "        self.std                = std\n",
    "\n",
    "        #--- Standardize edge attributes\n",
    "#         mean              = edge_attrs.mean(dim=(0, 1))\n",
    "#         std               = edge_attrs.std(dim=(0, 1))\n",
    "#         standardized_edge_attrs = [GraphNet.standardize_data(data, mean, std) for data in edge_attrs]\n",
    "\n",
    "\n",
    "        #--- Convert input data to tensors\n",
    "        target_displacements_tensor = augmented_target_displacements\n",
    "        target_disps_tensor         = augmented_displacement_vecs \n",
    "        input_data_tensor           = standardized_input_data\n",
    "        input_xyz_tensor            = augmented_input_xyz\n",
    "#         edge_attrs_tensor           = torch.stack(standardized_edge_attrs)\n",
    "\n",
    "        #--- Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data_tensor)):\n",
    "            x             = input_data_tensor[i]  # Node features\n",
    "            cords         = input_xyz_tensor[i]  # Node features\n",
    "            edge_index    = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "#             edge_features = edge_attrs_tensor[ i ][ :, : self.edge_dim ]\n",
    "            atom_indx     = input_atom_indx[ i ]\n",
    "            y             = target_displacements_tensor[i]  # Target displacements\n",
    "            y_atom_wise   = target_disps_tensor[i]  # Target displacements\n",
    "\n",
    "            # Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, y=y, pos=cords, atom_indx=atom_indx, y_atom_wise=y_atom_wise) #edge_attr = edge_features)\n",
    "            graphs.append(data)\n",
    "        \n",
    "        #--- Create a single large graph by concatenating Data objects\n",
    "        self.large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "        #--- Define batch size and create DataLoader\n",
    "        batch_size = len(input_data_tensor)\n",
    "        \n",
    "        #--- Define batch sizes for  training and test dataloaders\n",
    "        train_batch_size = int( np.max([1,int(batch_size * train_ratio)]) )\n",
    "        test_batch_size  =  batch_size - train_batch_size\n",
    "        \n",
    "        #--- Create DataLoader for training dataset\n",
    "        loader           = DataLoader(self.large_graph, batch_size=train_batch_size, shuffle=False)\n",
    "\n",
    "        #--- Accessing batches in the DataLoader\n",
    "        loader_iter      = iter(loader)\n",
    "        self.dataset_train = next(loader_iter)\n",
    "        if self.verbose:\n",
    "            print('dataset_train:',self.dataset_train)\n",
    "        self.dataset_test = self.dataset_train\n",
    "        if test_batch_size > 0:\n",
    "            self.dataset_test = next(loader_iter)\n",
    "            if self.verbose:\n",
    "                print('dataset_test:',self.dataset_test)\n",
    "\n",
    "    def DataBuilderForClassifier( self, Ovito_Output = False, Standardize=True ):\n",
    "        \n",
    "        ntrain        = 1 #self.ntrain\n",
    "        num_snapshots = len( self.descriptors )\n",
    "        snapshots     = range(num_snapshots)\n",
    "        #--- nodal cords\n",
    "        input_xyz     = [torch.from_numpy( np.c_[np.c_[self.descriptors[ i ]['x'],\\\n",
    "                                                       self.descriptors[ i ]['y'],\\\n",
    "                                                       self.descriptors[ i ]['z']]] ).float() for i in snapshots]\n",
    "        #--- nodal descriptors\n",
    "#         input_data   = [torch.from_numpy( np.c_[np.log10(np.array(self.descriptors[ i ]['descriptors'])),\\\n",
    "#                                                  ] ).float() for i in      snapshots]\n",
    "        input_data    = [torch.from_numpy( np.c_[self.descriptors[ i ]['x'],\\\n",
    "                                         self.descriptors[ i ]['y'],\\\n",
    "                                         self.descriptors[ i ]['z'],\\\n",
    "                                         np.array(self.descriptors[ i ]['descriptors_acsf'])]).float() for i in snapshots]\n",
    "\n",
    "        #--- target data\n",
    "        labels        = [torch.from_numpy(np.array(self.descriptors[ i ]['isNonCrystalline']).flatten()).long() for i in snapshots]\n",
    "        \n",
    "        #--- Augment the dataset \n",
    "        augmented_input_data           = []\n",
    "        augmented_input_xyz            = []\n",
    "        augmented_labels               = []\n",
    "        n_repeat                       = 1 #np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input  = DataSet.augment_data(input_data, self.noise_std)\n",
    "            augmented_target = labels #GraphNet.augment_data(labels, 0)\n",
    "            augmented_xyz    = DataSet.augment_data(input_xyz, self.noise_std)\n",
    "            #\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_input_xyz.extend(augmented_xyz)\n",
    "            augmented_labels.extend(augmented_target)\n",
    "           \n",
    "        #--- adj. matrix\n",
    "        adj_matrices_attrs      = self.compute_adjacency_matrices2nd(self.descriptors, rcut=self.cutoff)\n",
    "        adj_matrices            = adj_matrices_attrs[ 0 ]\n",
    "        edge_attrs              = adj_matrices_attrs[ 1 ]\n",
    "        \n",
    "        #--- verify adj matrix??\n",
    "        if Ovito_Output:\n",
    "            self.PrintOvito(adjacency = adj_matrices, input_data=input_data)\n",
    "\n",
    "        #--- Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data_tensor = np.vstack(augmented_input_data)\n",
    "\n",
    "        #--- Standardize the augmented input data\n",
    "        mean = np.zeros(input_data_tensor.shape[1])\n",
    "        std  = np.ones(input_data_tensor.shape[1])\n",
    "        if Standardize:\n",
    "            mean              = input_data_tensor.mean(axis=0)#dim=(0, 1))\n",
    "            std               = input_data_tensor.std(axis=0)#dim=(0, 1))\n",
    "        assert np.all( std > 0 ), 'std == 0!'\n",
    "        standardized_input_data = [DataSet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "        self.mean               = mean \n",
    "        self.std                = std\n",
    "        #--- Standardize edge attributes\n",
    "#         mean              = edge_attrs.mean(dim=(0, 1))\n",
    "#         std               = edge_attrs.std(dim=(0, 1))\n",
    "#         standardized_edge_attrs = [GraphNet.standardize_data(data, mean, std) for data in edge_attrs]\n",
    "\n",
    "\n",
    "        #--- Convert input data to tensors\n",
    "        labels_tensor               = augmented_labels\n",
    "        input_data_tensor           = standardized_input_data\n",
    "        input_xyz_tensor            = augmented_input_xyz\n",
    "#         edge_attrs_tensor           = torch.stack(standardized_edge_attrs)\n",
    "\n",
    "\n",
    "\n",
    "        #--- Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data_tensor)):\n",
    "            x             = input_data_tensor[i]  # Node features\n",
    "            cords         = input_xyz_tensor[i]  # Node features\n",
    "            edge_index    = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "#             edge_features = edge_attrs_tensor[ i ][ :, : self.edge_dim ]\n",
    "            y             = labels_tensor[i]  # Target displacements\n",
    "\n",
    "            #--- Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, y=y, pos=cords) #edge_attr = edge_features)\n",
    "            graphs.append(data)\n",
    "\n",
    "        np.random.shuffle(graphs)\n",
    "\n",
    "        #--- Define batch size and create DataLoader\n",
    "        batch_size  = len(input_data)\n",
    "        \n",
    "        # Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "        train_ratio = 0.8\n",
    "\n",
    "        #--- Define batch sizes for training and test dataloaders\n",
    "        train_batch_size = int( np.max([1,int(batch_size * train_ratio)]) )\n",
    "        test_batch_size  = batch_size - train_batch_size\n",
    "        assert test_batch_size > 0, 'test_batch_size = %s'%test_batch_size\n",
    "\n",
    "        large_graph_train = torch_geometric.data.Batch.from_data_list(graphs[:train_batch_size])\n",
    "        large_graph_test  = torch_geometric.data.Batch.from_data_list(graphs[train_batch_size:])\n",
    "\n",
    "        #--- Create DataLoader for training dataset\n",
    "        self.train_dataloaders = DataLoader(large_graph_train, batch_size=train_batch_size, shuffle=False)\n",
    "        self.test_dataloaders  = DataLoader(large_graph_test, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    def compute_adjacency_matrices(self,input_data, rcut):\n",
    "        adj_matrices = []\n",
    "        for indx, positions in enumerate(input_data):\n",
    "            #\n",
    "            num_atoms = positions.shape[0]\n",
    "            adj_matrix = torch.zeros((num_atoms, num_atoms), dtype=torch.float)\n",
    "            #\n",
    "            for i in range(num_atoms):\n",
    "                adj_matrix[i, i] = 1\n",
    "                for j in range(i + 1, num_atoms):\n",
    "                    drij = abs(positions[i] - positions[j])\n",
    "#                    assert drij[0] <= 0.5 * lx and drij[1] <= 0.5 * ly and drij[2] <= 0.5 * lz, 'cutoff > 0.5 L!'\n",
    "                    distance = torch.norm(drij)\n",
    "                    if distance <= rcut:\n",
    "                        adj_matrix[i, j] = 1\n",
    "                        adj_matrix[j, i] = 1\n",
    "                assert adj_matrix[i,:].sum() > 0, 'dangling node : increase the cutoff!'\n",
    "            adj_matrices.append(adj_matrix)\n",
    "\n",
    "        #--- assert no \n",
    "        return adj_matrices\n",
    "\n",
    "    def BuildNeighborList( self, indx, atom_indices,cutoff ):\n",
    "#         atom_indices = ' '.join(map(str,atom_indices))\n",
    "\n",
    "#         fp = self.dumpFiles[ indx ] #'%s/lammps_data.dat'%confParser['input files']['input_path']\n",
    "        fout = self.neighlists[ indx ] #'neighbor_list.xyz'\n",
    "#         os.system('rm %s'%fout)\n",
    "#         lib_path = confParser['input files']['lib_path'].split()[0]\n",
    "#         #--- neighbor list\n",
    "#         os.system('ovitos %s/OvitosCna.py %s %s 1 6 %s %s'%(lib_path,fp,fout,cutoff,atom_indices))\n",
    "        nl = lp.ReadDumpFile(fout)\n",
    "        nl.GetCords()\n",
    "        return nl.coord_atoms_broken[0]\n",
    "\n",
    "    def GetIndxById( self, df, atom_ids ):\n",
    "        df['indices']   = range(df.shape[0])\n",
    "        atom_indices    = utl.FilterDataFrame(df,key='id',val=atom_ids)['indices']\n",
    "        return np.c_[atom_indices].flatten()\n",
    "            \n",
    "    def compute_adjacency_matrices2nd(self,input_data, rcut):\n",
    "        adj_matrices       = []\n",
    "        edge_attrs         = []\n",
    "        for indx, positions in enumerate( input_data ):\n",
    "            df             = pd.DataFrame(positions)\n",
    "            num_atoms      = df.shape[0]\n",
    "            adj_matrix     = torch.zeros((num_atoms, num_atoms), dtype=torch.float)\n",
    "            nl             = self.BuildNeighborList(indx,range(num_atoms),rcut) #--- neighbor list\n",
    "            #--- add \"index\" columns\n",
    "            nl['index_i']  = self.GetIndxById( df, np.c_[nl.id].flatten() )\n",
    "            nl['index_j']  = self.GetIndxById( df, np.c_[nl.J].flatten() )\n",
    "            adj_matrix[nl['index_i'],nl['index_j']] = 1\n",
    "            #--- edge attributes\n",
    "#             keys = 'DX  DY  DZ  PBC_SHIFT_X PBC_SHIFT_Y PBC_SHIFT_Z'.split()\n",
    "#             indices = adj_matrix.nonzero().numpy()\n",
    "#             nl_reindexed = nl.set_index(['index_i','index_j'],drop=False)\n",
    "#             edge_attr = list(map(lambda x: list(nl_reindexed[keys].loc[tuple(x)]),indices))\n",
    "#             edge_attrs.append( torch.Tensor( edge_attr ) )\n",
    "            adj_matrices.append( adj_matrix )\n",
    "\n",
    "        #--- assert no \n",
    "        return adj_matrices, edge_attrs\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_data(input_data, noise_std):\n",
    "        augmented_input_data = []\n",
    "        \n",
    "        for data in input_data:\n",
    "            # Add Gaussian noise to input data\n",
    "            noisy_data = data + np.random.randn(*data.shape) * noise_std\n",
    "            augmented_input_data.append(noisy_data)\n",
    "            \n",
    "            \n",
    "        return augmented_input_data\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def standardize_data(data, mean, std):\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    @staticmethod\n",
    "    def DBSCANcluster(X,eps):\n",
    "         dbscan = DBSCAN(eps=eps, min_samples=5)\n",
    "         y_dbscan = dbscan.fit_predict(X)\n",
    "\n",
    "        # Visualize the clusters using PCA\n",
    "         pca = PCA(n_components=2)\n",
    "         X_pca = pca.fit_transform(X)\n",
    "\n",
    "         fig=plt.figure();ax=fig.add_subplot(111);\n",
    "#         for i, label in enumerate(np.unique(y_dbscan)):\n",
    "#            ax.scatter(X_pca[y_dbscan == label, 0], X_pca[y_dbscan == label, 1], label=f'Cluster {label}')\n",
    "#         fig.savefig('cluster.png') \n",
    "         return y_dbscan\n",
    "\n",
    "    @staticmethod\n",
    "    def Group(data, yclusters, operation='mean'):\n",
    "        if operation == 'mean':\n",
    "            return np.vstack( list( map(lambda x: data[ yclusters == x ].mean(axis=0) , set(yclusters) ) ))\n",
    "        if operation == 'union':\n",
    "            return np.vstack( list( map(lambda x: np.any(data[ yclusters == x ],axis=0).astype(int) , set(yclusters) ) ) )\n",
    "\n",
    "    \n",
    "\n",
    "class MyConvNetModel( tf.keras.Model ):\n",
    "    def __init__(self,reshape = (3,3,3), filters=16, num_hidden_layers=1, **kwargs):\n",
    "        super().__init__()\n",
    "#        self.myLayers = []\n",
    "        self.myLayers = [tf.keras.layers.BatchNormalization()]\n",
    "        self.myLayers.append(tf.keras.layers.Reshape(reshape))\n",
    "        self.myLayers.append( tf.keras.layers.Conv3D( filters=filters,**kwargs))\n",
    "        filters       *=  2\n",
    "        for i in range( num_hidden_layers ):\n",
    "            self.myLayers.append(tf.keras.layers.AveragePooling3D( pool_size = 2 ))\n",
    "            self.myLayers.append(tf.keras.layers.Conv3D( filters=filters,**kwargs ))\n",
    "            filters *= 2\n",
    "        self.myLayers.append(tf.keras.layers.Flatten())\n",
    "        \n",
    "    def call( self, inputs ):\n",
    "        x = inputs\n",
    "        for layer in self.myLayers:\n",
    "            x = layer( x )\n",
    "        return x\n",
    "\n",
    "class MyDenseNetModel( tf.keras.Model ):\n",
    "    def __init__(self,num_hidden_layers=1,units = 10,input_shape=(100,),  **kwargs):\n",
    "        super().__init__()\n",
    "        self.myLayers = [tf.keras.layers.BatchNormalization(input_shape=input_shape)]\n",
    "        self.myLayers += [ tf.keras.layers.Dense(units, **kwargs) ]\n",
    "        for i in range( num_hidden_layers-1 ):\n",
    "            self.myLayers.append( tf.keras.layers.Dense( units,**kwargs))\n",
    "        \n",
    "    def call( self, inputs ):\n",
    "        x = inputs\n",
    "        for layer in self.myLayers:\n",
    "            x = layer( x )\n",
    "        return x\n",
    "    \n",
    "class MyConvNetClassifier( tf.keras.Model ):\n",
    "    def __init__(self, cout = 10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.convnet =  MyConvNetModel( **kwargs )\n",
    "        self.flat    = tf.keras.layers.Flatten()\n",
    "        self.classifier = tf.keras.layers.Dense( cout, activation='sigmoid' )\n",
    "        \n",
    "    def call( self, inputs ):\n",
    "        x = self.convnet( inputs )\n",
    "        x = self.flat( x )\n",
    "        return self.classifier( x ) \n",
    "\n",
    "class MyDenseNetClassifier( tf.keras.Model ):\n",
    "    def __init__(self, cout = 1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.convnet =  MyDenseNetModel( **kwargs )\n",
    "        self.classifier = tf.keras.layers.Dense( cout, activation='sigmoid' )\n",
    "        \n",
    "    def call( self, inputs ):\n",
    "        x = self.convnet( inputs )\n",
    "        return self.classifier( x ) \n",
    "\n",
    "def MyConvNetClassifier2nd(\n",
    "        shape         =  (10,10,10,1), \n",
    "        kernel_size   =  (3,3,3),\n",
    "        activation    =  'relu',\n",
    "        padding       = 'same',\n",
    "        filters       =  16,\n",
    "        ndime         =  1000, #ds.dataset_train['y'].shape[1] #shape[0]*shape[1]*shape[2]\n",
    "        number_hidden_layers = 3\n",
    "                        ):\n",
    "        inputs        =  keras.Input(shape=(shape[0]*shape[1]*shape[2],))\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x=tf.keras.layers.Reshape(shape)(inputs)\n",
    "\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(x)\n",
    "        filters       *=  2\n",
    "        for i in range( number_hidden_layers ):\n",
    "            x       = tf.keras.layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = tf.keras.layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = tf.keras.layers.Flatten()(x)\n",
    "        outputs = tf.keras.layers.Dense( ndime, activation='sigmoid' )( x ) #, activation=activation)(x)\n",
    "        return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#@tf.function\n",
    "def TrainingLoop( model, data_train, data_test, **kwargs):\n",
    "        if kwargs['torch_geom_loader']:\n",
    "            x_train = data_train.x.numpy()\n",
    "            y_train = data_train.y.numpy()\n",
    "            x_test  = data_test.x.numpy()\n",
    "            y_test  = data_test.y.numpy()\n",
    "        else:\n",
    "            x_train = data_train['x']\n",
    "            y_train = data_train['y']\n",
    "            x_test  = data_test['x']\n",
    "            y_test  = data_test['y']\n",
    "    \n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = kwargs['learning_rate'] )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  kwargs['loss'],\n",
    "#                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        history = model.fit( x_train, y_train, \n",
    "                   validation_data      = ( x_test, y_test ),\n",
    "                    epochs              = kwargs['epochs'], \n",
    "                    verbose             = False,\n",
    "                     batch_size     = 10,\n",
    "                 )\n",
    "        \n",
    "        #--- plot val. loss\n",
    "        loss      = history.history['loss']\n",
    "        val_loss  = history.history['val_loss']\n",
    "        os.system( 'mkdir -p %s'%kwargs['filepath'] ) \n",
    "        ax        = utl.PltErr(range(len(loss)), val_loss,\n",
    "                               attrs={'fmt':'-','color':'C0'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(val_loss)), loss,\n",
    "                   attrs = {'fmt':'-','color':'red'},\n",
    "                   ax    = ax,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xstr  ='epoch',ystr='loss',\n",
    "                   title ='%s/loss.png'%kwargs['filepath'],\n",
    "                  )\n",
    "\n",
    "        \n",
    "        model.save(kwargs['checkpoint_file'])\n",
    "\n",
    "\n",
    "class ModelValidation:\n",
    "    def __init__(self, **kwargs ):\n",
    "        for (key,val) in kwargs.items():\n",
    "            setattr(self,key,val)\n",
    "            os.system('mkdir -p %s'%val )   \n",
    "            \n",
    "    def SetModel(self, model):\n",
    "         self.model = model\n",
    "\n",
    "    def ConfusionMatrix(self, data, fout):\n",
    "        y_pred = ( self.model.predict(data.x.numpy()) > 0.5 ).astype(int)\n",
    "        cm     = confusion_matrix(data.y, y_pred,\n",
    "                         labels=[0,1]\n",
    "                        )\n",
    "        np.savetxt(fout,np.c_[cm])\n",
    "\n",
    "    def GetDispsFromBinaryMaps( self, binaryMap, xv,yv,zv,ev,nbinx, nbiny,nbinz,nbine ):\n",
    "        binaryMapReshaped = binaryMap.reshape((nbinx, nbiny, nbinz, nbine ))\n",
    "        filtr = binaryMapReshaped == 1\n",
    "        return np.c_[yv[filtr],xv[filtr],zv[filtr],ev[filtr]]\n",
    "\n",
    "    def TransitionPaths(self, data, title,umax=2.0,du=0.2,emax=2.0,de=0.2):\n",
    "        binary_maps_pred = ( self.model.predict(data.x.numpy()) > 0.5 ).astype(int)\n",
    "        binary_maps_true  = data.y\n",
    "\n",
    "        xlin = np.arange(-umax,umax+du,du);\n",
    "        ylin = np.arange(-umax,umax+du,du);\n",
    "        zlin = np.arange(-umax,umax+du,du);\n",
    "        elin = np.arange(0,emax+de,de);\n",
    "        nbinx = len(xlin)-1;\n",
    "        nbiny = len(ylin)-1;\n",
    "        nbinz = len(zlin)-1;\n",
    "        nbine = len(elin)-1;\n",
    "        bins = (xlin, ylin, zlin, elin );\n",
    "        xv, yv, zv, ev = np.meshgrid( bins[1][:-1], bins[0][:-1], bins[2][:-1], bins[3][:-1] )\n",
    "\n",
    "        u_pred = np.concatenate(list(map(lambda x: self.GetDispsFromBinaryMaps( x,xv,yv,zv,ev,nbinx, nbiny,nbinz,nbine), \n",
    "                                          binary_maps_pred )))\n",
    "        u_true = np.concatenate(list(map(lambda x: self.GetDispsFromBinaryMaps( x,xv,yv,zv,ev,nbinx, nbiny,nbinz,nbine),\n",
    "                                          binary_maps_true )))\n",
    "\n",
    "        #--- plot e\n",
    "        self.PrintOvito(data,u_pred,'%s/u_pred.xyz'%title)\n",
    "        self.PrintOvito(data,u_true, '%s/u_act.xyz'%title)\n",
    "        \n",
    "    def Predictions( self, data, title ):\n",
    "        X      = data['x']\n",
    "        y_true = data['y']\n",
    "        y_pred = self.model.predict( X )\n",
    "        figure = plt.figure()\n",
    "        ax     = figure.add_subplot(111)\n",
    "        ax.plot( y_true.flatten(), y_pred.flatten() ,'x')\n",
    "        figure.savefig('%s/y_true_pred.png'%title)\n",
    "\n",
    "        figure=plt.figure()\n",
    "        ax=figure.add_subplot(111)\n",
    "        ax.imshow(X,aspect='auto')\n",
    "        figure.savefig('%s/x.png'%title)\n",
    "        \n",
    "        figure=plt.figure()\n",
    "        ax=figure.add_subplot(111)\n",
    "        ax.imshow(y_true,aspect='auto',cmap='gray')\n",
    "        figure.savefig('%s/y_true.png'%title)\n",
    "        \n",
    "        figure=plt.figure()\n",
    "        ax=figure.add_subplot(111)\n",
    "        ax.imshow(y_pred,aspect='auto',cmap='gray')\n",
    "        figure.savefig('%s/y_pred.png'%title)\n",
    "   \n",
    " \n",
    "    def PrintOvito( self,data, disps, fout ):\n",
    "        os.system('rm %s'%fout)\n",
    "        ndime = 3\n",
    "        box        = lp.Box(BoxBounds=np.array([[0,10.62],[0,10.62],[0,10.62]]),\\\n",
    "                            AddMissing=np.array([0,0,0]))\n",
    "\n",
    "        atom_indx_init = data.ptr[ 0 ]\n",
    "        for indx, _ in enumerate( data.ptr ):\n",
    "            if indx == 0:\n",
    "                continue\n",
    "            atom_indx_fin = data.ptr[ indx ]\n",
    "            atom_ids      = np.arange(atom_indx_init.cpu(),atom_indx_fin.cpu())+1\n",
    "            natoms        = atom_ids.shape[ 0 ]\n",
    "            types         = np.ones( natoms )\n",
    "            xyz           = data.pos[ atom_indx_init : atom_indx_fin] \n",
    "            tmp           = xyz.cpu()# * std + mean\n",
    "            cordc         = pd.DataFrame( tmp[:,:ndime], columns='x y z'.split())\n",
    "            disp          = disps[ atom_indx_init ][:ndime] # : atom_indx_fin, : ]\n",
    "            path          = disp\n",
    "            df            = pd.DataFrame(np.c_[atom_ids,types,cordc,path.reshape((1,3))],\\\n",
    "                              columns = 'id type x y z DisplacementX DisplacementY DisplacementZ'.split())\n",
    "            atom          = lp.Atoms(**df.to_dict(orient='series'))\n",
    "            wd            = lp.WriteDumpFile(atom, box)\n",
    "            with open(fout,'a') as fp:\n",
    "                wd.Write(fp, itime=0, \n",
    "                         attrs='id type x y z DisplacementX DisplacementY DisplacementZ'.split(), \n",
    "                         fmt='%d %d %4.3e %4.3e %4.3e %4.3e %4.3e %4.3e')\n",
    "            atom_indx_init = atom_indx_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a465c",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not eval( confParser['neural net']['NeuralNet'] ):\n",
    "        return\n",
    "    \n",
    "    ds       = DataSet( confParser )\n",
    "    ds.Parse( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net']['nruns']))\n",
    "\n",
    "    #--- write call backs\n",
    "    \n",
    "    #----------------------------------\n",
    "    #--- identification of defects\n",
    "    #----------------------------------\n",
    "\n",
    "    #--- load data\n",
    "    ds.DataBuilderForClassifier(Standardize = False)\n",
    "\n",
    "    #--- build model\n",
    "    myModel  = MyDenseNetClassifier( input_shape       = (255,), \n",
    "                                     cout              = 1,\n",
    "                                     units             = 64, \n",
    "                                     num_hidden_layers = 3,\n",
    "                                     activation        ='relu')\n",
    "\n",
    "    #--- training\n",
    "    checkpoint_path = 'best_model_defect_classification'\n",
    "    os.makedirs( checkpoint_path, exist_ok = True )\n",
    "    TrainingLoop( myModel, ds.train_dataloaders.dataset, ds.test_dataloaders.dataset,\n",
    "                 torch_geom_loader= True,\n",
    "                  learning_rate   = 1e-4,\n",
    "                  epochs          = 50, \n",
    "                  loss            = 'binary_crossentropy',\n",
    "                  checkpoint_file = '%s/model.tf'%checkpoint_path,\n",
    "                  filepath        =  '%s/evaluation'%checkpoint_path\n",
    "                )\n",
    "#    np.savetxt('%s/mean_std.txt'%checkpoint_path,np.c_[ds.mean, ds.std],header='mean std')\n",
    "    \n",
    "    #--- validation\n",
    "    model    = tf.keras.models.load_model( '%s/model.tf'%checkpoint_path )\n",
    "    #    pdb.set_trace()\n",
    "    mv       = ModelValidation( filepath = 'defect_classification_validation' )\n",
    "    mv.SetModel( model )\n",
    "    mv.ConfusionMatrix( ds.train_dataloaders.dataset, '%s/cm_train.txt'%mv.filepath) \n",
    "    mv.ConfusionMatrix( ds.test_dataloaders.dataset,  '%s/cm_test.txt'%mv.filepath ) \n",
    "\n",
    "    #----------------------------------\n",
    "    #--- predict reaction paths/energies\n",
    "    #----------------------------------\n",
    "\n",
    "    #--- load data\n",
    "    ds.Process2nd( Standardize = False, train_ratio = 0.8 )\n",
    "    \n",
    "    #--- create model\n",
    "#     myModel  = MyConvNetClassifier(\n",
    "#                                 reshape           = (10,10,10,1),\n",
    "#                                 cout              = ds.dataset_train['y'].shape[1],\n",
    "#                                 filters           = 16, \n",
    "#                                 num_hidden_layers = 3,\n",
    "#                                 kernel_size       = (3,3,3), \n",
    "#                                 activation        = 'relu',\n",
    "#                                 padding           = 'same',\n",
    "#                               )\n",
    "\n",
    "    myModel = MyConvNetClassifier2nd(\n",
    "            shape         =  (10,10,10,1), \n",
    "            kernel_size   =  (3,3,3),\n",
    "            activation    =  'relu',\n",
    "            padding       = 'same',\n",
    "            filters       =  16*2,\n",
    "            ndime         =  ds.dataset_train['y'].shape[1],\n",
    "            number_hidden_layers = 2\n",
    "                            )\n",
    "    #--- training\n",
    "    checkpoint_path = 'best_model_transition_paths'\n",
    "    os.makedirs( checkpoint_path, exist_ok = True )\n",
    "    TrainingLoop( myModel, ds.dataset_train, ds.dataset_test,\n",
    "                  torch_geom_loader = False,\n",
    "                  learning_rate   = 1e-3,\n",
    "                  loss            ='binary_crossentropy',\n",
    "                  epochs          = 50,\n",
    "                  checkpoint_file = '%s/model.tf'%checkpoint_path,\n",
    "                  filepath        =  '%s/evaluation'%checkpoint_path\n",
    "                 )\n",
    "#    np.savetxt('%s/mean_std.txt'%checkpoint_path,np.c_[ds.mean, ds.std],header='mean std')\n",
    "    \n",
    "    #--- inference & validation\n",
    "    model    = tf.keras.models.load_model('%s/model.tf'%checkpoint_path)\n",
    "    mv       = ModelValidation( filepath0 = 'defect_transitionPaths_validation/train',\n",
    "                                filepath1 = 'defect_transitionPaths_validation/test' )\n",
    "    mv.SetModel( model )\n",
    "#     mv.TransitionPaths( ds.dataset_train, title = mv.filepath0 )\n",
    "#     mv.TransitionPaths( ds.dataset_test,  title = mv.filepath1  )\n",
    "    mv.Predictions( ds.dataset_train, title = mv.filepath0 )\n",
    "    mv.Predictions( ds.dataset_test,  title = mv.filepath1  )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258765c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Group(data, yclusters, operation='mean'):\n",
    "#     if operation == 'mean':\n",
    "#         return torch.stack( list( map(lambda x: data[ yclusters == x ].mean(axis=0) , set(yclusters) ) ) )\n",
    "#     if operation == 'union':\n",
    "#         return torch.stack( list( map(lambda x: torch.any(data[ yclusters == x ]).int() , set(yclusters) ) ) )\n",
    "\n",
    "# yclusters = DBSCANcluster(ds.dataset_train.x,100.0)\n",
    "# ds.dataset_train.x = Group(ds.dataset_train.x,yclusters,operation='mean' )\n",
    "# ds.dataset_train.y = Group(ds.dataset_train.x,yclusters, operation='union' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- E\n",
    "\n",
    "# ds.Process();os.system('rm cluster.png');\n",
    "# yclusters = DBSCANcluster(ds.dataset_train.x,40.0);print(set(yclusters))\n",
    "# ds.dataset_train.x = Group(ds.dataset_train.x,yclusters,operation='mean' );ds.dataset_train.y = Group(ds.dataset_train.y,yclusters, operation='union' );\n",
    "# ds.dataset_test.x = ds.dataset_train.x;ds.dataset_test.y = ds.dataset_train.y   \n",
    "\n",
    "\n",
    "#------------------------------\n",
    "#--- The network architecture\n",
    "#------------------------------\n",
    "# shape =  (10,10,10,1);ndime =ds.dataset_train.y.shape[1];number_hidden_layers=3;filters=16;x=tf.keras.layers.Reshape(shape)(inputs);x=layers.Conv3D(filters=filters,kernel_size =  kernel_size,activation  =  activation,padding     =  padding)(x);filters*=2;\n",
    "# for i in range( number_hidden_layers ):x       = tf.keras.layers.AveragePooling3D( pool_size = 2 )( x );x       = tf.keras.layers.Conv3D( filters       =  filters,kernel_size   =  kernel_size,activation    =  activation,padding       =  padding)(x);filters *= 2\n",
    "# #--- output layer\n",
    "# x       = tf.keras.layers.Flatten()(x);outputs = tf.keras.layers.Dense( ndime, activation='sigmoid' )( x );myModel   = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "# TrainingLoop( myModel, ds.dataset_train, ds.dataset_test,learning_rate   = 1e-3,loss ='BinaryCrossentropy',epochs = 50,checkpoint_file = '%s/model.tf'%checkpoint_path,filepath =  '%s/evaluation'%checkpoint_path)\n",
    "\n",
    "# model    = tf.keras.models.load_model('%s/model.tf'%checkpoint_path)\n",
    "# y_true=ds.dataset_test['y'];y_pred=model.predict(ds.dataset_test['x']);loss = tf.keras.losses.mse(y_true, y_pred);\n",
    "# os.system('rm pred.png');figure=plt.figure();ax=figure.add_subplot(111);ax.plot(y_true.flatten(),y_pred.flatten(),'x');figure.savefig('pred.png')\n",
    "\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam( learning_rate = 1e-3 );myModel.compile( optimizer =  optimizer,loss      = 'BinaryCrossentropy')\n",
    "# history = myModel.fit( ds.dataset_train['x'], ds.dataset_train['y'],\n",
    "#                       validation_data= ( ds.dataset_test['x'],ds.dataset_test['y']),epochs= 50,verbose= True,batch_size= 10)\n",
    "# myModel.save('best_model_transition_paths/model.tf')\n",
    "\n",
    "# os.system('rm x.png');figure=plt.figure();ax=figure.add_subplot(111);ax.imshow(ds.dataset_train.x,aspect='auto');figure.savefig('x.png')\n",
    "# os.system('rm y.png');figure=plt.figure();ax=figure.add_subplot(111);ax.imshow(ds.dataset_train.y,aspect='auto',cmap='gray');figure.savefig('y.png')\n",
    "# os.system('rm y_pred.png');figure=plt.figure();ax=figure.add_subplot(111);ax.imshow(y_pred,aspect='auto',cmap='gray');figure.savefig('y_pred.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2efd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- defect\n",
    "\n",
    "# myModel  = MyDenseNetClassifier( input_shape= (255,),cout= 1,units= 64,num_hidden_layers = 3,activation='relu')\n",
    "\n",
    "# #--- training\n",
    "# optimizer = tf.keras.optimizers.Adam( learning_rate = 1e-3 );myModel.compile( optimizer =  optimizer,loss      = 'BinaryCrossentropy')\n",
    "# history = myModel.fit( ds.train_dataloaders.dataset.x.numpy(), ds.train_dataloaders.dataset.y.numpy(),\n",
    "#                       validation_data= ( ds.test_dataloaders.dataset.x.numpy(),ds.test_dataloaders.dataset.y.numpy()),\n",
    "#                       epochs= 50,verbose= True,batch_size= 10)\n",
    "# myModel.save('best_model_defect_classification/model.tf')\n",
    "\n",
    "# TrainingLoop( myModel, ds.train_dataloaders.dataset, ds.test_dataloaders.dataset,learning_rate   = 1e-4,epoch = 1000, loss            = 'binary_crossentropy',checkpoint_file = '%s/model.tf'%checkpoint_path,filepath        =  '%s/evaluation'%checkpoint_path)\n",
    "\n",
    "#--- validation\n",
    "# model    = tf.keras.models.load_model( '%s/model.tf'%checkpoint_path )\n",
    "# #    pdb.set_trace()\n",
    "# mv       = ModelValidation( filepath = 'defect_classification_validation' )\n",
    "# mv.SetModel( model )\n",
    "# mv.ConfusionMatrix( ds.train_dataloaders.dataset, '%s/cm_train.txt'%mv.filepath) \n",
    "# mv.ConfusionMatrix( ds.test_dataloaders.dataset,  '%s/cm_test.txt'%mv.filepath )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54845305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn import datasets\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Load the Iris dataset\n",
    "# iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "\n",
    "# # Standardize the dataset\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# # Apply K-means clustering\n",
    "# kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "# y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "# # Visualize the clusters using PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# X_pca = pca.fit_transform(X)\n",
    "\n",
    "# plt.figure()\n",
    "# for i, label in enumerate(np.unique(y_kmeans)):\n",
    "#     plt.scatter(X_pca[y_kmeans == label, 0], X_pca[y_kmeans == label, 1], label=f'Cluster {label}')\n",
    "# plt.xlabel('PCA Component 1')\n",
    "# plt.ylabel('PCA Component 2')\n",
    "# plt.title('K-means Clustering')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94d7af52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn import datasets\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Load the Iris dataset\n",
    "# iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "\n",
    "# # Standardize the dataset\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# # Apply DBSCAN clustering\n",
    "# dbscan = DBSCAN(eps=1.0/4, min_samples=5)\n",
    "# y_dbscan = dbscan.fit_predict(X)\n",
    "\n",
    "# # Visualize the clusters using PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# X_pca = pca.fit_transform(X)\n",
    "\n",
    "# plt.figure()\n",
    "# for i, label in enumerate(np.unique(y_dbscan)):\n",
    "#     plt.scatter(X_pca[y_dbscan == label, 0], X_pca[y_dbscan == label, 1], label=f'Cluster {label}')\n",
    "# plt.xlabel('PCA Component 1')\n",
    "# plt.ylabel('PCA Component 2')\n",
    "# plt.title('DBSCAN Clustering')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dffc5fe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn import datasets\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from sklearn.decomposition import PCA\n",
    "# from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# # Load the Iris dataset\n",
    "# iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "\n",
    "# # Standardize the dataset\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# # Apply Hierarchical clustering\n",
    "# hierarchical = AgglomerativeClustering(n_clusters=3)\n",
    "# y_hierarchical = hierarchical.fit_predict(X)\n",
    "\n",
    "# # Visualize the clusters using PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# X_pca = pca.fit_transform(X)\n",
    "\n",
    "# plt.figure()\n",
    "# for i, label in enumerate(np.unique(y_hierarchical)):\n",
    "#     plt.scatter(X_pca[y_hierarchical == label, 0], X_pca[y_hierarchical == label, 1], label=f'Cluster {label}')\n",
    "# plt.xlabel('PCA Component 1')\n",
    "# plt.ylabel('PCA Component 2')\n",
    "# plt.title('Hierarchical Clustering')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot dendrogram\n",
    "# plt.figure()\n",
    "# Z = linkage(X, 'ward')\n",
    "# dendrogram(Z, truncate_mode='level', p=5)\n",
    "# plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plt.xlabel('Sample index')\n",
    "# plt.ylabel('Distance')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a451788",
   "metadata": {},
   "source": [
    "# gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2142613",
   "metadata": {},
   "source": [
    "## graph net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f8e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GNNModel(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         c_in,\n",
    "#         c_hidden,\n",
    "#         c_out,\n",
    "#         edge_dim,\n",
    "#         num_layers=1,\n",
    "#         layer_name=\"GCN\",\n",
    "#         dp_rate=0.1,\n",
    "#         verbose=True,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         \"\"\"GNNModel.\n",
    "\n",
    "#         Args:\n",
    "#             c_in: Dimension of input features\n",
    "#             c_hidden: Dimension of hidden features\n",
    "#             c_out: Dimension of the output features. Usually number of classes in classification\n",
    "#             num_layers: Number of \"hidden\" graph layers\n",
    "#             layer_name: String of the graph layer to use\n",
    "#             dp_rate: Dropout rate to apply throughout the network\n",
    "#             kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         gnn_layer_by_name = {\"linear\":geom_nn.Linear,\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \n",
    "#                              \"GraphConv\": geom_nn.GraphConv}\n",
    "#         gnn_layer         = gnn_layer_by_name[layer_name]\n",
    "#         layers = []\n",
    "#         in_channels       = c_in\n",
    "#         for l_idx in range(num_layers-1):\n",
    "#             out_channels      = c_hidden[ l_idx ]\n",
    "#             layers       += [\n",
    "#                 geom_nn.GINEConv(gnn_layer(in_channels=in_channels, \n",
    "#                                            out_channels=out_channels, \n",
    "#                                            **kwargs),edge_dim=edge_dim),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "# #                 nn.Dropout(dp_rate),\n",
    "#             ]\n",
    "#             in_channels       = out_channels\n",
    "#         layers            += [geom_nn.GINEConv(gnn_layer(in_channels=in_channels, \n",
    "#                                                          out_channels=c_out, \n",
    "#                                                          **kwargs),edge_dim=edge_dim)]\n",
    "#         self.layers        = nn.ModuleList(layers)\n",
    "\n",
    "#         if verbose:\n",
    "#             for indx, layer in enumerate( self.layers ):\n",
    "#                  print('layer %s'%indx, layer )\n",
    "\n",
    "\n",
    "#     def forward(self, x, edge_index, edge_attr ):\n",
    "#         \"\"\"Forward.\n",
    "\n",
    "#         Args:\n",
    "#             x: Input features per node\n",
    "#             edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "#         \"\"\"\n",
    "#         for layer in self.layers:\n",
    "#             # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "#             # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "#             # we can simply check the class type.\n",
    "#             if isinstance(layer, geom_nn.MessagePassing):\n",
    "#                 if isinstance(layer, geom_nn.GINEConv):\n",
    "#                       x    = layer(x, edge_index, edge_attr)\n",
    "#                 else:   \n",
    "#                       x    = layer(x, edge_index)\n",
    "    \n",
    "#             else:\n",
    "#                 x          = layer(x)\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        c_hidden,\n",
    "        c_out,\n",
    "        edge_dim,\n",
    "        num_layers=1,\n",
    "        layer_name=\"GCN\",\n",
    "        dp_rate=0.1,\n",
    "        verbose=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"GNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of \"hidden\" graph layers\n",
    "            layer_name: String of the graph layer to use\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "            kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer_by_name = {\"linear\":geom_nn.Linear,\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \n",
    "                             \"GraphConv\": geom_nn.GraphConv}\n",
    "        gnn_layer         = gnn_layer_by_name[layer_name]\n",
    "        layers = []\n",
    "        in_channels       = c_in\n",
    "        for l_idx in range(num_layers-1):\n",
    "            out_channels      = c_hidden[ l_idx ]\n",
    "            layers       += [\n",
    "                gnn_layer(in_channels=in_channels, \n",
    "                                           out_channels=out_channels, \n",
    "                                           **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                 nn.Dropout(dp_rate),\n",
    "            ]\n",
    "            in_channels       = out_channels\n",
    "        layers            += [gnn_layer(in_channels=in_channels, \n",
    "                                                         out_channels=c_out, \n",
    "                                                         **kwargs)]\n",
    "        self.layers        = nn.ModuleList(layers)\n",
    "\n",
    "        if verbose:\n",
    "            for indx, layer in enumerate( self.layers ):\n",
    "                 print('layer %s'%indx, layer )\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index ):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "                x    = layer(x, edge_index)\n",
    "            else:\n",
    "                x          = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e36b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNet:\n",
    "    num_instantiated  = 0\n",
    "    def __init__(self,**kwargs):\n",
    "        '''\n",
    "        GraphNet constructor call\n",
    "        '''        \n",
    "        for key in kwargs:\n",
    "            setattr(self, key, kwargs[key])\n",
    "\n",
    "    def GnnModel( self, model_name='gnn_regressor',layer_name='GCN'):\n",
    "        '''\n",
    "        Create Gnn model\n",
    "        '''\n",
    "        model_name_dic = {'gnn_regressor':GNNModel} #, 'gnn_classifier':GNNClassifier}\n",
    "        self.model = model_name_dic[model_name]( \n",
    "                            c_in       = self.c_in,\n",
    "                            c_hidden   = self.c_hidden,\n",
    "                            c_out      = self.c_out,\n",
    "                            edge_dim   = self.edge_dim,\n",
    "                            num_layers = self.num_layers,\n",
    "                            layer_name = layer_name,\n",
    "                            dp_rate    = 0.1,\n",
    "                        ).to(self.device)\n",
    "    \n",
    "    def Parse(self,path,nruns, **kwargs):\n",
    "        '''\n",
    "        Parse dataset\n",
    "        '''\n",
    "        \n",
    "        if GraphNet.num_instantiated == 0:\n",
    "            self.Catalogs         = {}\n",
    "            self.transition_paths = []\n",
    "            self.descriptors      = []\n",
    "            self.dumpFiles        = []\n",
    "            self.neighlists       = []\n",
    "    #\n",
    "            if self.verbose:\n",
    "                print('parsing %s'%path)\n",
    "            rwjs = utl.ReadWriteJson()\n",
    "\n",
    "            #--- dirs and files to be parsed\n",
    "            file_dirs = ['saved_output/descriptorsEveryAtom.json',\n",
    "                 'saved_output/transition_paths.json',\n",
    "                 'neighList/neigh_list.xyz',\n",
    "                 'dumpFile/dump.xyz',\n",
    "                 'saved_output/catalog.txt'\n",
    "                ]\n",
    "#            pdb.set_trace()\n",
    "            for irun in range(nruns):\n",
    "                if not self.fileExists(path,irun,file_dirs):\n",
    "                    continue            \n",
    "                self.descriptors.extend( rwjs.Read('%s/Run%s/saved_output/descriptorsEveryAtom.json'%(path,irun)) )\n",
    "                self.transition_paths.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths.json'%(path,irun)) )\n",
    "                self.neighlists.append( '%s/Run%s/neighList/neigh_list.xyz'%(path,irun))\n",
    "                self.dumpFiles.append(  '%s/Run%s/dumpFile/dump.xyz'%(path,irun))\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/saved_output/catalog.txt'%(path,irun))\n",
    "                \n",
    "            GraphNet.num_instantiated += 1\n",
    "        elif 'prev_gnn' in kwargs:\n",
    "            prev_gnn         = kwargs['prev_gnn']\n",
    "            self.Catalogs         = prev_gnn.Catalogs\n",
    "            self.transition_paths = prev_gnn.transition_paths\n",
    "            self.descriptors      = prev_gnn.descriptors\n",
    "            self.dumpFiles        = prev_gnn.dumpFiles\n",
    "            self.neighlists       = prev_gnn.neighlists\n",
    "\n",
    "\n",
    "        \n",
    "        self.nruns     = list(self.Catalogs.keys())\n",
    "        self.nruns.sort()\n",
    "                                                \n",
    "    def fileExists(self,path,irun,file_dirs):\n",
    "        '''\n",
    "        return True if passed dirs exist\n",
    "        '''\n",
    "        file_exist = []\n",
    "        for myfile in file_dirs:\n",
    "            file_exist.append( os.path.isfile('%s/Run%s/%s'%(path,irun,myfile)) )\n",
    "        return np.all(np.array(file_exist))\n",
    "\n",
    "#     def GenerateDate(self,n):\n",
    "#         assert n>2,'increase n'\n",
    "#         disp=[]\n",
    "        \n",
    "        \n",
    "#         X=np.linspace(0,1.0,n)\n",
    "#         dx = X[1]-X[0]\n",
    "#         vacancy = 0\n",
    "#         while vacancy == 0 or vacancy == n-1:\n",
    "#             vacancy = int(np.random.random()*n)\n",
    "#         assert 0<vacancy<n-1\n",
    "#         print('vacancy=%s'%vacancy)\n",
    "        \n",
    "#         x=list(X.copy())\n",
    "#         x.pop(vacancy)\n",
    "#         n -= 1\n",
    "        \n",
    "#         u=np.zeros(n)\n",
    "#         u[vacancy-1]=1.0\n",
    "#         disp.append(u)\n",
    "#         u=np.zeros(n)\n",
    "#         u[vacancy]=-1\n",
    "#         disp.append(u)\n",
    "\n",
    "#         adj_mat = torch.zeros((n, n), dtype=torch.float)\n",
    "#         for i in range(n):\n",
    "#             adj_mat[i,i]=1\n",
    "#             for j in range(i+1,n):\n",
    "#                 if abs(x[i]-x[j]) <= 1.1*dx:\n",
    "#                     adj_mat[i,j]=1\n",
    "#                     adj_mat[j,i]=1\n",
    "\n",
    "#         print(adj_mat)\n",
    "#         return x,disp,adj_mat\n",
    "        \n",
    "#     def DataBuilder2nd( self ):\n",
    "#         num_snapshots = 2\n",
    "        \n",
    "#         data = list(map(lambda x: self.GenerateDate(5),range(num_snapshots)))\n",
    "\n",
    "        \n",
    "#         graphs = []\n",
    "\n",
    "#         snapshots     = range(num_snapshots)\n",
    "#         input_data    = [torch.from_numpy( np.c_[data[i][0]] ).float() for i in snapshots]  \n",
    "\n",
    "#         # Example target data (displacement vectors for each snapshot and each path)\n",
    "# #        target_displacements = [torch.from_numpy( np.c_[u] ).float() for u in disp]\n",
    "#         target_displacements = [torch.from_numpy( np.c_[data[i][1]].T ).float() for i in snapshots]\n",
    "\n",
    "#         adj_matrices = [data[0][2] for i in snapshots]\n",
    "#         adj_matrices = torch.stack(adj_matrices) \n",
    "\n",
    "\n",
    "\n",
    "#         # Concatenate input data along a new dimension to form a single tensor\n",
    "# #        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "#         # Standardize the augmented input data\n",
    "# #         mean = input_data_tensor.mean(dim=(0, 1))\n",
    "# #         std = input_data_tensor.std(dim=(0, 1))\n",
    "# #         standardized_input_data = [GraphNet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "\n",
    "\n",
    "#         # Convert input data to tensors\n",
    "#         target_displacements_tensor = torch.stack(target_displacements)\n",
    "#         input_data_tensor           = torch.stack(input_data)\n",
    "\n",
    "\n",
    "\n",
    "#         # Concatenate nodes and edges for each graph\n",
    "#         graphs = []\n",
    "#         for i in range(len(input_data)):\n",
    "#             x = input_data_tensor[i]  # Node features\n",
    "#             edge_index = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "#             y = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "#             # Create a Data object for each graph\n",
    "#             data = Data(x=x, edge_index=edge_index, y=y)\n",
    "#             graphs.append(data)\n",
    "            \n",
    "#         # Create a single large graph by concatenating Data objects\n",
    "#         large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "#         # Define batch size and create DataLoader\n",
    "#         # Create DataLoader for training dataset\n",
    "#         loader = DataLoader(large_graph, batch_size=2, shuffle=True)\n",
    "\n",
    "#         # Accessing batches in the DataLoader\n",
    "#         self.dataset_train = loader.dataset\n",
    "#         if self.verbose:\n",
    "#             print('dataset_train:',self.dataset_train)\n",
    "#         self.dataset_test = loader.dataset\n",
    "#         if self.verbose:\n",
    "#             print('dataset_test:',self.dataset_test)\n",
    "\n",
    "\n",
    "    def DataBuilder( self, Ovito_Output = False, train_ratio = 0.8 ):\n",
    "        '''\n",
    "        Build dataloader in pytorch\n",
    "        '''\n",
    "        \n",
    "        ntrain        = 1\n",
    "        num_snapshots = len( self.transition_paths ) #--- total no. of transition paths\n",
    "        snapshots     = range(num_snapshots)\n",
    "        \n",
    "        #--- nodal cords\n",
    "        input_xyz     = [torch.from_numpy( np.c_[np.c_[self.transition_paths[ i ]['x'],\\\n",
    "                                                       self.transition_paths[ i ]['y'],\\\n",
    "                                                       self.transition_paths[ i ]['z']]] ).float() for i in snapshots]\n",
    "        #--- nodal descriptors\n",
    "        input_data    = [torch.from_numpy( np.c_[np.log10(np.array(self.transition_paths[ i ]['descriptors'])),\\\n",
    "                                                 self.transition_paths[ i ]['center_atom_index']] ).float() for i in      snapshots]\n",
    "        #--- atom indices\n",
    "        input_atom_indx  = [torch.from_numpy( np.c_[self.transition_paths[ i ]['atom_indx']] ).int() for i in      snapshots]\n",
    "        \n",
    "        # Example target data (displacement vectors for each path)\n",
    "        target_displacements = [torch.from_numpy(np.array(self.transition_paths[ i ]['diffusion_paths'])[:,:self.c_out]).float() for i in snapshots]\n",
    "        \n",
    "        #--- add gaussian noise\n",
    "        augmented_input_data           = []\n",
    "        augmented_input_xyz            = []\n",
    "        augmented_target_displacements = []\n",
    "        n_repeat                       = 1 #np.max([1,int(ntrain/ntrain_initial)])\n",
    "        #\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input  = GraphNet.augment_data( input_data,           self.noise_std )\n",
    "            augmented_target = GraphNet.augment_data( target_displacements, self.noise_std )\n",
    "            augmented_xyz    = GraphNet.augment_data( input_xyz,            self.noise_std )\n",
    "            #\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_input_xyz.extend(augmented_xyz)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "        #--- adjacency matrix\n",
    "        adj_matrices      = self.compute_adjacency_matrices(augmented_input_xyz, rcut=self.cutoff)\n",
    "        \n",
    "        #--- verify adj matrix????\n",
    "        if Ovito_Output:\n",
    "            self.PrintOvito(adjacency = adj_matrices, input_data=input_data)\n",
    "\n",
    "        #--- Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data = np.vstack(augmented_input_data) \n",
    "\n",
    "        #--- Standardize the augmented input data\n",
    "        mean              = input_data.mean(axis=0)\n",
    "        std               = input_data.std(axis=0)\n",
    "        assert np.all( std > 0 ), 'std == 0!'\n",
    "        standardized_input_data = [GraphNet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "        \n",
    "        #--- Standardize edge attributes\n",
    "#         mean              = edge_attrs.mean(dim=(0, 1))\n",
    "#         std               = edge_attrs.std(dim=(0, 1))\n",
    "#         standardized_edge_attrs = [GraphNet.standardize_data(data, mean, std) for data in edge_attrs]\n",
    "\n",
    "\n",
    "        #--- Convert input data to tensors\n",
    "        target_displacements_tensor = augmented_target_displacements\n",
    "        input_data_tensor           = standardized_input_data\n",
    "        input_xyz_tensor            = augmented_input_xyz\n",
    "#         edge_attrs_tensor           = torch.stack(standardized_edge_attrs)\n",
    "\n",
    "        #--- Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data_tensor)):\n",
    "            x             = input_data_tensor[i]  # Node features\n",
    "            cords         = input_xyz_tensor[i]  # Node features\n",
    "            edge_index    = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "#             edge_features = edge_attrs_tensor[ i ][ :, : self.edge_dim ]\n",
    "            atom_indx     = input_atom_indx[ i ]\n",
    "            y             = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "            # Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, y=y, pos=cords, atom_indx=atom_indx) #edge_attr = edge_features)\n",
    "            graphs.append(data)\n",
    "        \n",
    "        #--- Create a single large graph by concatenating Data objects\n",
    "        self.large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "        #--- Define batch size and create DataLoader\n",
    "        batch_size = len(input_data_tensor)\n",
    "#        loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "#        train_ratio = 0.8\n",
    "\n",
    "        # Define batch sizes for  training and test dataloaders\n",
    "        train_batch_size = int( np.max([1,int(batch_size * train_ratio)]) )\n",
    "        test_batch_size  =  batch_size - train_batch_size\n",
    "        # Create DataLoader for training dataset\n",
    "        loader           = DataLoader(self.large_graph, batch_size=train_batch_size, shuffle=False)\n",
    "\n",
    "        # Accessing batches in the DataLoader\n",
    "        loader_iter      = iter(loader)\n",
    "        self.dataset_train = next(loader_iter)\n",
    "        if self.verbose:\n",
    "            print('dataset_train:',self.dataset_train)\n",
    "        if test_batch_size > 0:\n",
    "            self.dataset_test = next(loader_iter)\n",
    "            if self.verbose:\n",
    "                print('dataset_test:',self.dataset_test)\n",
    "\n",
    "    def DataBuilderForClassifier( self, Ovito_Output = False ):\n",
    "        \n",
    "        ntrain        = 1 #self.ntrain\n",
    "        num_snapshots = len( self.descriptors )\n",
    "        snapshots     = range(num_snapshots)\n",
    "        #\n",
    "        input_xyz     = [torch.from_numpy( np.c_[np.c_[self.descriptors[ i ]['x'],\\\n",
    "                                                       self.descriptors[ i ]['y'],\\\n",
    "                                                       self.descriptors[ i ]['z']]] ).float() for i in snapshots]\n",
    "\n",
    "#         input_data   = [torch.from_numpy( np.c_[np.log10(np.array(self.descriptors[ i ]['descriptors'])),\\\n",
    "#                                                  ] ).float() for i in      snapshots]\n",
    "        input_data    = [torch.from_numpy( np.c_[self.descriptors[ i ]['x'],\\\n",
    "                                         self.descriptors[ i ]['y'],\\\n",
    "                                         self.descriptors[ i ]['z'],\\\n",
    "                                         np.array(self.descriptors[ i ]['descriptors_acsf'])]).float() for i in snapshots]\n",
    "\n",
    "        # Example target data (displacement vectors for each snapshot and each path)\n",
    "        labels        = [torch.from_numpy(np.array(self.descriptors[ i ]['isNonCrystalline']).flatten()).long() for i in snapshots]\n",
    "\n",
    "        \n",
    "        # Augment the dataset to have order 100 single graphs\n",
    "        augmented_input_data           = []\n",
    "        augmented_input_xyz            = []\n",
    "        augmented_labels               = []\n",
    "#        input_data_tensor              = torch.stack(input_data)\n",
    "#        ntrain_initial                 = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "        n_repeat                       = 1 #np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input  = GraphNet.augment_data(input_data, self.noise_std)\n",
    "            augmented_target = labels #GraphNet.augment_data(labels, 0)\n",
    "            augmented_xyz    = GraphNet.augment_data(input_xyz, self.noise_std)\n",
    "            #\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_input_xyz.extend(augmented_xyz)\n",
    "            augmented_labels.extend(augmented_target)\n",
    "\n",
    "#        t0=time.time()\n",
    "        adj_matrices_attrs      = self.compute_adjacency_matrices2nd(self.descriptors, rcut=self.cutoff)\n",
    "#        print('elapsed time for compute_adjacency_matrices2nd:',time.time()-t0)\n",
    "        adj_matrices            = adj_matrices_attrs[ 0 ]\n",
    "        edge_attrs              = adj_matrices_attrs[ 1 ]\n",
    "#        adj_matrices      = torch.stack(self.compute_adjacency_matrices2nd(self.descriptors, rcut=self.cutoff)) \n",
    "        \n",
    "        \n",
    "        #--- verify adj matrix????\n",
    "        if Ovito_Output:\n",
    "            self.PrintOvito(adjacency = adj_matrices, input_data=input_data)\n",
    "\n",
    "\n",
    "        # Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data_tensor = np.vstack(augmented_input_data)\n",
    "#        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "        # Standardize the augmented input data\n",
    "        mean              = input_data_tensor.mean(axis=0)#dim=(0, 1))\n",
    "        std               = input_data_tensor.std(axis=0)#dim=(0, 1))\n",
    "        assert np.all( std > 0 ), 'std == 0!'\n",
    "        standardized_input_data = [GraphNet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "        \n",
    "        # Standardize edge attributes\n",
    "#         mean              = edge_attrs.mean(dim=(0, 1))\n",
    "#         std               = edge_attrs.std(dim=(0, 1))\n",
    "#         standardized_edge_attrs = [GraphNet.standardize_data(data, mean, std) for data in edge_attrs]\n",
    "\n",
    "\n",
    "        # Convert input data to tensors\n",
    "        labels_tensor               = augmented_labels\n",
    "        input_data_tensor           = standardized_input_data\n",
    "        input_xyz_tensor            = augmented_input_xyz\n",
    "#         edge_attrs_tensor           = torch.stack(standardized_edge_attrs)\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data_tensor)):\n",
    "            x             = input_data_tensor[i]  # Node features\n",
    "            cords         = input_xyz_tensor[i]  # Node features\n",
    "            edge_index    = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "#             edge_features = edge_attrs_tensor[ i ][ :, : self.edge_dim ]\n",
    "            y             = labels_tensor[i]  # Target displacements\n",
    "\n",
    "            # Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, y=y, pos=cords) #edge_attr = edge_features)\n",
    "            graphs.append(data)\n",
    "        np.random.shuffle(graphs)\n",
    "        \n",
    "        # Create a single large graph by concatenating Data objects\n",
    "\n",
    "        # Define batch size and create DataLoader\n",
    "        batch_size  = len(input_data)\n",
    "#        loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "        train_ratio = 0.8\n",
    "\n",
    "        # Define batch sizes for training and test dataloaders\n",
    "        train_batch_size = int( np.max([1,int(batch_size * train_ratio)]) )\n",
    "        test_batch_size  = batch_size - train_batch_size\n",
    "        assert test_batch_size > 0, 'test_batch_size = %s'%test_batch_size\n",
    "\n",
    "        large_graph_train = torch_geometric.data.Batch.from_data_list(graphs[:train_batch_size])\n",
    "        large_graph_test  = torch_geometric.data.Batch.from_data_list(graphs[train_batch_size:])\n",
    "\n",
    "        \n",
    "        # Create DataLoader for training dataset\n",
    "        self.train_dataloaders = DataLoader(large_graph_train, batch_size=train_batch_size, shuffle=False)\n",
    "        self.test_dataloaders  = DataLoader(large_graph_test, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "        # Accessing batches in the DataLoader\n",
    "#         loader_iter = iter(loader)\n",
    "#         self.dataset_train = next(loader_iter)\n",
    "#         if self.verbose:\n",
    "#             print('dataset_train:',self.dataset_train)\n",
    "#         self.dataset_test = next(loader_iter)\n",
    "#         if self.verbose:\n",
    "#             print('dataset_test:',self.dataset_test)\n",
    "\n",
    "    def DataBuilderForEnergy( self, Ovito_Output = False ):\n",
    "        \n",
    "        ntrain        = 1\n",
    "        num_snapshots = len( self.transition_paths )\n",
    "        snapshots     = range(num_snapshots)\n",
    "        #--- only include center atoms within clusters\n",
    "        filtrs        = list(map(lambda x: np.array(np.ones(len(self.transition_paths[x]['center_atom_index']))).flatten().astype(bool), snapshots))\n",
    "#        filtrs = list(map(lambda x: np.array(self.transition_paths[x]['center_atom_index']).flatten().astype(bool), snapshots))\n",
    "        #\n",
    "        input_xyz     = [torch.from_numpy( np.c_[np.c_[self.transition_paths[ i ]['x'],\\\n",
    "                                                       self.transition_paths[ i ]['y'],\\\n",
    "                                                       self.transition_paths[ i ]['z']][filtrs[i]]] ).float() for i in snapshots]\n",
    "\n",
    "        input_data    = [torch.from_numpy( np.c_[self.transition_paths[ i ]['x'],\\\n",
    "                                         self.transition_paths[ i ]['y'],\\\n",
    "                                         self.transition_paths[ i ]['z'],\\\n",
    "#                                         np.log10(np.array(self.transition_paths[ i ]['descriptors_acsf'])),\\\n",
    "                                         np.array(self.transition_paths[ i ]['descriptors_acsf']),\\\n",
    "                                         self.transition_paths[ i ]['center_atom_index']\\\n",
    "                                            ][filtrs[i]] ).float() for i in      snapshots]\n",
    "#        input_data    =  [torch.from_numpy( np.c_[np.log10(np.array(self.transition_paths[ i ]['descriptors']))] ).float() for i in      snapshots]\n",
    "\n",
    "        input_atom_indx  = [torch.from_numpy( np.c_[self.transition_paths[ i ]['atom_indx']][filtrs[i]] ).int() for i in      snapshots]\n",
    "\n",
    "        \n",
    "        # Example target data (displacement vectors for each snapshot and each path)\n",
    "        target_displacements = [torch.from_numpy(np.array(self.transition_paths[ i ]['energy_barrier'])).float() for i in snapshots]\n",
    "\n",
    "        \n",
    "        # Augment the dataset to have order 100 single graphs\n",
    "        augmented_input_data           = []\n",
    "        augmented_input_xyz            = []\n",
    "        augmented_target_displacements = []\n",
    "#        input_data_tensor              = torch.stack(input_data)\n",
    "#        ntrain_initial                 = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "        n_repeat                       = 1 #np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input  = GraphNet.augment_data( input_data,           self.noise_std )\n",
    "            augmented_target = GraphNet.augment_data( target_displacements, self.noise_std )\n",
    "            augmented_xyz    = GraphNet.augment_data( input_xyz,            self.noise_std )\n",
    "            #\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_input_xyz.extend(augmented_xyz)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "#         adj_matrices_attrs      = self.compute_adjacency_matrices2nd(augmented_input_data, rcut=self.cutoff)\n",
    "#         adj_matrices            = torch.stack(adj_matrices_attrs[ 0 ])\n",
    "#         edge_attrs              = torch.stack(adj_matrices_attrs[ 1 ])\n",
    "#        adj_matrices      = torch.stack(self.compute_adjacency_matrices2nd(augmented_input_data, rcut=self.cutoff)) \n",
    "        adj_matrices      = self.compute_adjacency_matrices(augmented_input_xyz, rcut=self.cutoff)\n",
    "        \n",
    "        \n",
    "        #--- verify adj matrix????\n",
    "        if Ovito_Output:\n",
    "            self.PrintOvito(adjacency = adj_matrices, input_data=input_data)\n",
    "\n",
    "\n",
    "        # Concatenate input data along a new dimension to form a single tensor\n",
    "#        input_data_tensor = torch.stack(augmented_input_data)\n",
    "        input_data = np.vstack(augmented_input_data) \n",
    "#        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "        # Standardize the augmented input data\n",
    "        mean              = input_data.mean(axis=0) #input_data_tensor.mean(dim=(0, 1))\n",
    "        std               = input_data.std(axis=0) #input_data_tensor.std(dim=(0, 1))\n",
    "        assert np.all( std > 0 ), 'std == 0!'\n",
    "        standardized_input_data = [GraphNet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "        \n",
    "        # Standardize edge attributes\n",
    "#         mean              = edge_attrs.mean(dim=(0, 1))\n",
    "#         std               = edge_attrs.std(dim=(0, 1))\n",
    "#         standardized_edge_attrs = [GraphNet.standardize_data(data, mean, std) for data in edge_attrs]\n",
    "\n",
    "\n",
    "        # Convert input data to tensors\n",
    "        target_displacements_tensor = augmented_target_displacements #torch.stack(augmented_target_displacements)\n",
    "        input_data_tensor           = standardized_input_data #torch.stack(standardized_input_data)\n",
    "        input_xyz_tensor            = augmented_input_xyz #torch.stack(augmented_input_xyz)\n",
    "#         edge_attrs_tensor           = torch.stack(standardized_edge_attrs)\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data_tensor)):\n",
    "            x             = input_data_tensor[i]  # Node features\n",
    "            cords         = input_xyz_tensor[i]  # Node features\n",
    "            edge_index    = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "#             edge_features = edge_attrs_tensor[ i ][ :, : self.edge_dim ]\n",
    "            atom_indx     = input_atom_indx[ i ]\n",
    "            y             = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "            # Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, y=y, pos=cords, atom_indx=atom_indx) #edge_attr = edge_features)\n",
    "            graphs.append(data)\n",
    "        np.random.shuffle(graphs)\n",
    "        self.graphs = graphs\n",
    "        # Create a single large graph by concatenating Data objects\n",
    "\n",
    "        # Define batch size and create DataLoader\n",
    "        batch_size  = len(input_data_tensor)\n",
    "#        loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "        train_ratio = 0.8\n",
    "\n",
    "        # Define batch sizes for training and test dataloaders\n",
    "        train_batch_size = int( np.max([1,int(batch_size * train_ratio)]) )\n",
    "        test_batch_size  = batch_size - train_batch_size\n",
    "        assert test_batch_size > 0, 'test_batch_size = %s'%test_batch_size\n",
    "\n",
    "        large_graph_train = torch_geometric.data.Batch.from_data_list(graphs[:train_batch_size])\n",
    "        large_graph_test  = torch_geometric.data.Batch.from_data_list(graphs[train_batch_size:])\n",
    "\n",
    "        \n",
    "        # Create DataLoader for training dataset\n",
    "        self.train_dataloaders = DataLoader(large_graph_train, batch_size=train_batch_size, shuffle=False)\n",
    "        self.test_dataloaders  = DataLoader(large_graph_test, batch_size=test_batch_size, shuffle=False)\n",
    "            \n",
    "    def compute_adjacency_matrices(self,input_data, rcut):\n",
    "        adj_matrices = []\n",
    "        for indx, positions in enumerate(input_data):\n",
    "            #\n",
    "            num_atoms = positions.shape[0]\n",
    "            adj_matrix = torch.zeros((num_atoms, num_atoms), dtype=torch.float)\n",
    "            #\n",
    "            for i in range(num_atoms):\n",
    "                adj_matrix[i, i] = 1\n",
    "                for j in range(i + 1, num_atoms):\n",
    "                    drij = abs(positions[i] - positions[j])\n",
    "#                    assert drij[0] <= 0.5 * lx and drij[1] <= 0.5 * ly and drij[2] <= 0.5 * lz, 'cutoff > 0.5 L!'\n",
    "                    distance = torch.norm(drij)\n",
    "                    if distance <= rcut:\n",
    "                        adj_matrix[i, j] = 1\n",
    "                        adj_matrix[j, i] = 1\n",
    "                assert adj_matrix[i,:].sum() > 0, 'dangling node : increase the cutoff!'\n",
    "            adj_matrices.append(adj_matrix)\n",
    "\n",
    "        #--- assert no \n",
    "        return adj_matrices\n",
    "\n",
    "        \n",
    "    def BuildNeighborList( self, indx, atom_indices,cutoff ):\n",
    "#         atom_indices = ' '.join(map(str,atom_indices))\n",
    "\n",
    "#         fp = self.dumpFiles[ indx ] #'%s/lammps_data.dat'%confParser['input files']['input_path']\n",
    "        fout = self.neighlists[ indx ] #'neighbor_list.xyz'\n",
    "#         os.system('rm %s'%fout)\n",
    "#         lib_path = confParser['input files']['lib_path'].split()[0]\n",
    "#         #--- neighbor list\n",
    "#         os.system('ovitos %s/OvitosCna.py %s %s 1 6 %s %s'%(lib_path,fp,fout,cutoff,atom_indices))\n",
    "        \n",
    "        \n",
    "        nl = lp.ReadDumpFile(fout)\n",
    "        nl.GetCords()\n",
    "        return nl.coord_atoms_broken[0]\n",
    "\n",
    "    def GetIndxById( self, df, atom_ids ):\n",
    "        df['indices']   = range(df.shape[0])\n",
    "        atom_indices    = utl.FilterDataFrame(df,key='id',val=atom_ids)['indices']\n",
    "        return np.c_[atom_indices].flatten()\n",
    "            \n",
    "    def compute_adjacency_matrices2nd(self,input_data, rcut):\n",
    "        adj_matrices       = []\n",
    "        edge_attrs         = []\n",
    "        for indx, positions in enumerate( input_data ):\n",
    "            df             = pd.DataFrame(positions)\n",
    "            num_atoms      = df.shape[0]\n",
    "            adj_matrix     = torch.zeros((num_atoms, num_atoms), dtype=torch.float)\n",
    "            nl             = self.BuildNeighborList(indx,range(num_atoms),rcut) #--- neighbor list\n",
    "            #--- add \"index\" columns\n",
    "            nl['index_i']  = self.GetIndxById( df, np.c_[nl.id].flatten() )\n",
    "            nl['index_j']  = self.GetIndxById( df, np.c_[nl.J].flatten() )\n",
    "#             groups         = nl.groupby(by='id').groups\n",
    "#             atom_i_ids     = list(groups.keys())\n",
    "#             atom_i_indices = self.GetIndxById( df, atom_i_ids )\n",
    "#             for i, atom_id in zip(atom_i_indices,atom_i_ids):\n",
    "# #                adj_matrix[i, i] = 1\n",
    "#                 atom_j_ids       = nl.iloc[groups[ atom_id ]].J\n",
    "#                 atom_j_indices   = self.GetIndxById( df, atom_j_ids )\n",
    "#                 for j, jatom_id in zip(atom_j_indices, atom_j_ids ): #[ atom_j_indices > i ]:\n",
    "#                     if j <= i :\n",
    "#                         continue\n",
    "# #                    filtr = np.all([nl.id==atom_id,nl.J==jatom_id],axis=0)\n",
    "# #                    edge_features = nl.iloc[ filtr ][ ''.split() ]\n",
    "#                     adj_matrix[i, j] = 1\n",
    "#                     adj_matrix[j, i] = 1\n",
    "#                 assert adj_matrix[i,:].sum() > 0, 'dangling node : increase the cutoff!'\n",
    "#            pdb.set_trace()\n",
    "            adj_matrix[nl['index_i'],nl['index_j']] = 1\n",
    "            #--- edge attributes\n",
    "#             keys = 'DX  DY  DZ  PBC_SHIFT_X PBC_SHIFT_Y PBC_SHIFT_Z'.split()\n",
    "#             indices = adj_matrix.nonzero().numpy()\n",
    "#             nl_reindexed = nl.set_index(['index_i','index_j'],drop=False)\n",
    "#             edge_attr = list(map(lambda x: list(nl_reindexed[keys].loc[tuple(x)]),indices))\n",
    "\n",
    "# #            pdb.set_trace()\n",
    "#             edge_attrs.append( torch.Tensor( edge_attr ) )\n",
    "            adj_matrices.append( adj_matrix )\n",
    "\n",
    "        #--- assert no \n",
    "        return adj_matrices, edge_attrs\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def augment_data(input_data, noise_std):\n",
    "        augmented_input_data = []\n",
    "        \n",
    "        for data in input_data:\n",
    "            # Add Gaussian noise to input data\n",
    "            noisy_data = data + torch.randn_like(data) * noise_std\n",
    "            augmented_input_data.append(noisy_data)\n",
    "            \n",
    "            \n",
    "        return augmented_input_data\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def standardize_data(data, mean, std):\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_best_model(model, optimizer, epoch, loss, best_loss, path):\n",
    "        \"\"\"Save the best model.\"\"\"\n",
    "        if loss < best_loss:\n",
    "#             state = {\n",
    "#                 'epoch': epoch,\n",
    "#                 'model_state_dict': model.state_dict(),\n",
    "#                 'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                 'loss': loss,\n",
    "#             }\n",
    "#             torch.save(state, path)\n",
    "            torch.save(model, path)\n",
    "            print(f'Saved the best model with loss: {loss:4.3e}')\n",
    "            return loss\n",
    "        else:\n",
    "            return best_loss\n",
    "    \n",
    "    # Save checkpoint during training\n",
    "#    @staticmethod\n",
    "#    def save_checkpoint(model, filename):\n",
    "#         checkpoint = {\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': loss,\n",
    "#         }\n",
    "#        torch.save(checkpoint, filename)\n",
    "#        torch.save(model.state_dict(), filename)\n",
    "\n",
    "    # Save checkpoint during training\n",
    "    @staticmethod\n",
    "    def save_checkpoint(model, optimizer, epoch, filename):\n",
    "        checkpoint = {\n",
    "         'epoch': epoch,\n",
    "         'model_state_dict': model.state_dict(),\n",
    "         'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #             'loss': loss,\n",
    "        }\n",
    "        torch.save(checkpoint, filename)\n",
    "        \n",
    "    def PrintOvito(self, **kwargs ):\n",
    "        os.system('rm clusters.xyz density.xyz')\n",
    "        ndime = 3\n",
    "        for indx, item in enumerate( self.transition_paths ):\n",
    "            cordc           = pd.DataFrame(np.c_[item['id'],item['x'],item['y'],item['z']],columns='id x y z'.split())\n",
    "            diffusion_paths = np.array(item['diffusion_paths'])\n",
    "            density         = np.c_[item['descriptor_center']].flatten()\n",
    "            grid            = np.c_[item['grid']]\n",
    "            nmode           = int( diffusion_paths.shape[ 1 ] / ndime )\n",
    "            for imode in range(nmode):\n",
    "                diffusion_path = diffusion_paths[:,imode*ndime:(imode+1)*ndime]\n",
    "                df = pd.DataFrame(np.c_[np.ones(cordc.shape[0]),cordc,diffusion_path],\\\n",
    "                                  columns = 'type id x y z DisplacementX  DisplacementY  DisplacementZ'.split())\n",
    "                with open('clusters.xyz','a') as fp:\n",
    "                    atom = lp.Atoms(**df.to_dict(orient='series'))\n",
    "                    rd         = lp.ReadDumpFile(self.dumpFiles[0])\n",
    "                    rd.GetCords()\n",
    "                    box        = lp.Box(BoxBounds=rd.BoxBounds[0],AddMissing=np.array([0,0,0]))\n",
    "                    wd   = lp.WriteDumpFile( atom, box )\n",
    "                    wd.Write(fp, itime=0, attrs='id type x y z DisplacementX  DisplacementY  DisplacementZ'.split(),\\\n",
    "                             fmt='%i %i %4.3e %4.3e %4.3e %4.3e %4.3e %4.3e')\n",
    "                \n",
    "            with open('density.xyz','a') as fp:\n",
    "                cords = pd.DataFrame(np.c_[grid,density],columns='x y z mass'.split())\n",
    "                utl.PrintOvito(cords, fp, 'itime=%s'%indx, attr_list='x y z mass'.split())\n",
    "\n",
    "                \n",
    "        lx,ly,lz   =np.diag(box.CellVector)\n",
    "        if 'adjacency' in kwargs:\n",
    "            natom = cordc.shape[ 0 ]\n",
    "            cordc.id = range(1,natom+1)\n",
    "            df = pd.DataFrame(np.c_[cordc.id,np.ones(natom),np.ones(natom),cordc['x y z'.split()]],\\\n",
    "                              columns = 'id junk0 junk1 x y z'.split())\n",
    "            adj_matrix = kwargs[ 'adjacency' ][0]\n",
    "            bonds = adj_matrix.nonzero()\n",
    "            bonds += 1\n",
    "            nbond = bonds.shape[ 0 ]\n",
    "            with open('lammps.data','w') as fout:\n",
    "                fout.write('# LAMMPS data file written by OVITO\\n%s atoms\\n%s bonds\\n1 atom types\\n1 bond types\\n%s %s xlo xhi\\n%s %s ylo yhi\\n%s %s zlo zhi\\n\\n'\\\n",
    "                           %(natom,nbond,0,lx,0,ly,0,lz))\n",
    "                fout.write('Atoms # bond\\n\\n')\n",
    "                np.savetxt(fout,np.c_[df],'%d %d %d %e %e %e')\n",
    "        \n",
    "                fout.write('\\nBonds\\n\\n')\n",
    "                np.savetxt(fout,np.c_[np.arange(1,nbond+1), np.ones(nbond),bonds[:,0],bonds[:,1]],fmt='%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf7798",
   "metadata": {},
   "source": [
    "### example 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b62ce99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "No GPUs available. Please check your CUDA installation.\n",
      "layer 0 Linear(1, 64, bias=True)\n",
      "layer 1 ReLU(inplace=True)\n",
      "layer 2 Dropout(p=0.1, inplace=False)\n",
      "layer 3 Linear(64, 64, bias=True)\n",
      "layer 4 ReLU(inplace=True)\n",
      "layer 5 Dropout(p=0.1, inplace=False)\n",
      "layer 6 Linear(64, 2, bias=True)\n",
      "vacancy=3\n",
      "tensor([[1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "vacancy=2\n",
      "tensor([[1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 1., 1.]])\n",
      "dataset_train: DataBatch(x=[8, 1], edge_index=[2, 16], y=[8, 2], batch=[8], ptr=[3])\n",
      "dataset_test: DataBatch(x=[8, 1], edge_index=[2, 16], y=[8, 2], batch=[8], ptr=[3])\n",
      "mkdir: best_model: File exists\n",
      "Epoch 0, Training Loss: 2.487e-01, Validation Loss: 2.311e-01\n"
     ]
    }
   ],
   "source": [
    "def main(): \n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    \n",
    "    # Check if GPUs are available\n",
    "    if torch.cuda.is_available():\n",
    "        # Get the number of available GPUs\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"{num_gpus} GPU(s) available\")\n",
    "\n",
    "        # Assert that at least one GPU is allocated\n",
    "        assert num_gpus > 0, \"No GPUs available. Please check your CUDA installation.\"\n",
    "\n",
    "        # Print information about each GPU\n",
    "        for i in range(num_gpus):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            print(f\"GPU {i}: {gpu_name}\")\n",
    "    else:\n",
    "        print(\"No GPUs available. Please check your CUDA installation.\")\n",
    "\n",
    "    gnn = GraphNet(\n",
    "                     c_in       = 1,\n",
    "                     c_hidden   = [64,64],\n",
    "                     c_out      = 2,\n",
    "                     num_layers = 3,\n",
    "                     num_epochs = 1000,\n",
    "                     noise_std  = 0.0,\n",
    "                     lr         = 0.001,\n",
    "        edge_dim=1,\n",
    "        layer_name = \"GCN\",\n",
    "                     verbose    = True \n",
    "                ).to(device)  # Move model to GPU\n",
    "\n",
    "#     gnn.Parse( path  = confParser['gnn']['input_path'],\n",
    "#                  nruns = eval(confParser['gnn']['nruns']))\n",
    "    \n",
    "    #--- build dataset based on the input catalogs\n",
    "    gnn.DataBuilder2nd()\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(gnn.parameters(), lr=gnn.lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    epoch0 = 0\n",
    "    best_loss = np.inf\n",
    "    restart = eval(confParser['gnn']['restart'])\n",
    "    if restart == True:\n",
    "        PATH='checkpoint.pth'\n",
    "        checkpoint = torch.load(PATH)\n",
    "        gnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch0 = checkpoint['epoch']\n",
    "    \n",
    "    # training loop\n",
    "    training_loss_hist   = []\n",
    "    validation_loss_hist = []\n",
    "    !mkdir best_model\n",
    "    for epoch in range( epoch0, epoch0+gnn.num_epochs ):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_displacements = gnn(gnn.dataset_train.x.to(device), \n",
    "                                      gnn.dataset_train.edge_index.to(device))\n",
    "        training_loss              = criterion(predicted_displacements, gnn.dataset_train.y.to(device))\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss_hist += [training_loss.detach().cpu().numpy()]  # Move loss back to CPU\n",
    "\n",
    "        #--- validation loss\n",
    "        gnn.eval()\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "                predicted_displacements = gnn(gnn.dataset_test.x.to(device), gnn.dataset_test.edge_index.to(device))\n",
    "                validation_loss         = criterion(predicted_displacements, gnn.dataset_test.y.to(device))\n",
    "\n",
    "                validation_loss_hist += [validation_loss.cpu().numpy()]  # Move loss back to CPU\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f'Epoch {epoch}, Training Loss: {training_loss.item():4.3e}, Validation Loss: {validation_loss.item():4.3e}')\n",
    "\n",
    "            # Update best_loss if validation loss improves and save the model\n",
    "#             best_loss = GraphNet.save_best_model(gnn, optimizer, \n",
    "#                                         epoch, training_loss.detach().cpu().numpy(), best_loss, \n",
    "#                                         'best_model/best_model.pth')\n",
    "\n",
    "    #--- plot loss vs epoch\n",
    "    !mkdir png\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    utl.PltErr(range(gnn.num_epochs),training_loss_hist,\n",
    "               attrs={'fmt':'-','color':'C0'},\n",
    "               ax=ax,Plot=False\n",
    "          )\n",
    "    utl.PltErr(range(gnn.num_epochs),validation_loss_hist,\n",
    "               attrs={'fmt':'-','color':'red'},\n",
    "              xscale='log',yscale='log',\n",
    "               title='png/loss.png',\n",
    "               Plot=False,\n",
    "               ax=ax\n",
    "          )\n",
    "    return gnn.dataset_train, gnn.dataset_test\n",
    "\n",
    "\n",
    "#data_train, data_test = main()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65badb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, data, title):\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    u_pred = model(data.x, data.edge_index)\n",
    "        \n",
    "    u_pred = u_pred.cpu().detach().numpy()\n",
    "    u_act  = data.y.cpu()\n",
    "\n",
    "    colors='black red green'.split()\n",
    "    for idime in range(2):\n",
    "        utl.PltErr(u_act[:,idime],u_pred[:,idime],\n",
    "               attrs={'fmt':'x','color':colors[idime]},\n",
    "              ax=ax, Plot=False,\n",
    "              )\n",
    "\n",
    "    utl.PltErr( None,None,\n",
    "               Plot=False,\n",
    "    ax=ax,\n",
    "            xlim=(-2,2),ylim=(-2,2),\n",
    "               title=title\n",
    "              )\n",
    "    \n",
    "def main(data_train, data_test):\n",
    "# Example usage\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    model = torch.load('best_model/best_model.pth').to(device)\n",
    "    make_prediction(model, data_train.to(device), title='png/disp_train.png')\n",
    "    make_prediction(model, data_test.to(device), title='png/disp_test.png')\n",
    "\n",
    "#main(data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0cd67",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205eee0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "No GPUs available. Please check your CUDA installation.\n",
      "parsing ./descriptors/ni/interstitial/results/kmc\n"
     ]
    }
   ],
   "source": [
    "def main(): \n",
    "    if not eval(confParser['gnn']['regression']):\n",
    "        return None, None\n",
    "    \n",
    "    device = isGpuAvailable()\n",
    "    gnn    = GraphNet(\n",
    "                     c_in       = eval(confParser['gnn']['c_in']),\n",
    "                     c_hidden   = eval(confParser['gnn']['c_hidden']),\n",
    "                     c_out      = eval(confParser['gnn']['c_out']),\n",
    "                     edge_dim   = eval(confParser['gnn']['edge_dim']),\n",
    "                     num_layers = eval(confParser['gnn']['num_layers']),\n",
    "                     num_epochs = eval(confParser['gnn']['num_epochs']),\n",
    "                     cutoff     = eval(confParser['gnn']['cutoff']),\n",
    "                     noise_std  = eval(confParser['gnn']['noise_std']),\n",
    "                     lr         = eval(confParser['gnn']['lr']),\n",
    "                     device     = device,\n",
    "                     verbose    = True \n",
    "                )\n",
    "\n",
    "    gnn.Parse(   path  = confParser['gnn']['input_path'],\n",
    "                 nruns = eval(confParser['gnn']['nruns']))\n",
    "        \n",
    "    #--- build dataset based on the input catalogs\n",
    "    gnn.DataBuilder()\n",
    "    \n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    gnn.GnnModel(model_name = 'gnn_regressor',\n",
    "                 layer_name = 'linear')\n",
    "    optimizer = optim.Adam(gnn.model.parameters(), lr=gnn.lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    epoch0    = 0\n",
    "    best_loss = np.inf\n",
    "    restart   = eval(confParser['gnn']['restart'])\n",
    "    if restart == True:\n",
    "        PATH   ='checkpoint.pth'\n",
    "        checkpoint = torch.load(PATH)\n",
    "        gnn.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch0 = checkpoint['epoch']\n",
    "        \n",
    "    # training loop\n",
    "    training_loss_hist   = []\n",
    "    validation_loss_hist = []\n",
    "    os.system('mkdir best_model')\n",
    "    for epoch in range( epoch0, epoch0+gnn.num_epochs ):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_displacements = gnn.model(gnn.dataset_train.x.to(device), \\\n",
    "                                      gnn.dataset_train.edge_index.to(device),\\\n",
    "#                                       gnn.dataset_train.edge_attr.to(device)\n",
    "                                     )\n",
    "        training_loss              = criterion(predicted_displacements, gnn.dataset_train.y.to(device))\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch == 0:\n",
    "            num_weights = 0\n",
    "            for item in gnn.model.parameters():\n",
    "                 num_weights += item.flatten().detach().cpu().numpy().shape[0]\n",
    "            print('num_weights=',num_weights)\n",
    "\n",
    "        training_loss_hist += [training_loss.detach().cpu().numpy()]  # Move loss back to CPU\n",
    "\n",
    "        #--- validation loss\n",
    "        gnn.model.eval()\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "                predicted_displacements = gnn.model(gnn.dataset_test.x.to(device),gnn.dataset_test.edge_index.to(device),\\\n",
    "#                                               gnn.dataset_test.edge_attr.to(device)\n",
    "                                             )\n",
    "                validation_loss         = criterion(predicted_displacements, gnn.dataset_test.y.to(device))\n",
    "\n",
    "                validation_loss_hist += [validation_loss.cpu().numpy()]  # Move loss back to CPU\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Training Loss: {training_loss.item():4.3e}, Validation Loss: {validation_loss.item():4.3e}')\n",
    "\n",
    "            # Update best_loss if validation loss improves and save the model\n",
    "            best_loss = GraphNet.save_best_model(gnn.model, optimizer, \n",
    "                                epoch, validation_loss.detach().cpu().numpy(), best_loss, \n",
    "                                'best_model/best_model.pth')\n",
    "\n",
    "    #--- save \n",
    "    # Usage during training loop\n",
    "    GraphNet.save_checkpoint(gnn.model, optimizer, epoch, 'checkpoint.pth')\n",
    "            \n",
    "    #--- plot loss vs epoch\n",
    "    os.system('mkdir png')\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    utl.PltErr(range(gnn.num_epochs),training_loss_hist,\n",
    "               attrs={'fmt':'-','color':'C0'},\n",
    "               ax=ax,Plot=False\n",
    "          )\n",
    "    utl.PltErr(range(gnn.num_epochs),validation_loss_hist,\n",
    "               attrs={'fmt':'-','color':'red'},\n",
    "              xscale='log',yscale='log',\n",
    "               title='png/loss.png',\n",
    "               Plot=False,\n",
    "               ax=ax\n",
    "          )\n",
    "    return gnn.dataset_train, gnn.dataset_test, gnn\n",
    "\n",
    "def isGpuAvailable():\n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    \n",
    "    # Check if GPUs are available\n",
    "    if torch.cuda.is_available():\n",
    "        # Get the number of available GPUs\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"{num_gpus} GPU(s) available\")\n",
    "\n",
    "        # Assert that at least one GPU is allocated\n",
    "        assert num_gpus > 0, \"No GPUs available. Please check your CUDA installation.\"\n",
    "\n",
    "        # Print information about each GPU\n",
    "        for i in range(num_gpus):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            print(f\"GPU {i}: {gpu_name}\")\n",
    "    else:\n",
    "        print(\"No GPUs available. Please check your CUDA installation.\")\n",
    "    return device \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#      data_train, data_test, gnn = main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab48d6",
   "metadata": {},
   "source": [
    "#### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, data, title):\n",
    "    u_pred = model(data.x, data.edge_index)#, data.edge_attr)        \n",
    "    u_pred = u_pred.cpu().detach().numpy()\n",
    "    u_act  = data.y.cpu()\n",
    "    ndime  = u_act.shape[ 1 ]\n",
    "\n",
    "    #--- plot prediction vs. actual\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    for idime in range(ndime):\n",
    "        utl.PltErr(u_act[:,idime],u_pred[:,idime],\n",
    "               attrs={'fmt':'x'},\n",
    "              ax=ax, Plot=False,\n",
    "              )\n",
    "\n",
    "    utl.PltErr( None,None,\n",
    "               Plot=False,\n",
    "    ax=ax,\n",
    "            xlim=(-2,2),ylim=(-2,2),\n",
    "               title='%s/disp.png'%title\n",
    "              )\n",
    "    \n",
    "    PrintOvito(data,u_pred,'%s/u_pred.xyz'%title)\n",
    "    PrintOvito(data,u_act, '%s/u_act.xyz'%title)\n",
    "    \n",
    "def PrintOvito( data, disps, fout ):\n",
    "    !rm $fout\n",
    "    ndime = 3\n",
    "    box        = lp.Box(BoxBounds=np.array([[0,10.62],[0,10.62],[0,10.62]]),\\\n",
    "                        AddMissing=np.array([0,0,0]))\n",
    "\n",
    "    atom_indx_init = data.ptr[ 0 ]\n",
    "    for indx, _ in enumerate( data.ptr ):\n",
    "        if indx == 0:\n",
    "            continue\n",
    "        atom_indx_fin = data.ptr[ indx ]\n",
    "        atom_ids      = np.arange(atom_indx_init.cpu(),atom_indx_fin.cpu())+1\n",
    "        types         = np.ones(atom_ids.shape[0])\n",
    "        xyz           = data.pos[ atom_indx_init : atom_indx_fin] \n",
    "        tmp           = xyz.cpu()# * std + mean\n",
    "        cordc         = pd.DataFrame( tmp[:,:ndime], columns='x y z'.split())\n",
    "        disp          = disps[ atom_indx_init : atom_indx_fin, : ]\n",
    "        \n",
    "        nmode         = int( disp.shape[ 1 ] / ndime )\n",
    "        for imode in range(nmode):\n",
    "            diffusion_path = disp[:,imode*ndime:(imode+1)*ndime]\n",
    "            df             = pd.DataFrame(np.c_[atom_ids,types,cordc,diffusion_path],\\\n",
    "                              columns = 'id type x y z DisplacementX DisplacementY DisplacementZ'.split())\n",
    "            atom           = lp.Atoms(**df.to_dict(orient='series'))\n",
    "#             with open(fout,'a') as fp:\n",
    "#                 utl.PrintOvito(df, fp, 'irun=%s,imode=%s'%(indx-1,imode), \n",
    "#                                attr_list='x y z ux uy uz'.split())\n",
    "            wd             = lp.WriteDumpFile(atom, box)\n",
    "            with open(fout,'a') as fp:\n",
    "                wd.Write(fp, itime=0, \n",
    "                         attrs='id type x y z DisplacementX DisplacementY DisplacementZ'.split(), \n",
    "                         fmt='%d %d %4.3e %4.3e %4.3e %4.3e %4.3e %4.3e')\n",
    "\n",
    "        atom_indx_init = atom_indx_fin\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "            #--- save dump files\n",
    "                \n",
    "\n",
    "    \n",
    "def main(data_train, data_test):\n",
    "    if not eval(confParser['gnn']['regression']):\n",
    "        return\n",
    "    # Example usage\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    model = torch.load('best_model/best_model.pth').to(device)\n",
    "    !mkdir -p png/train\n",
    "    !mkdir -p png/test\n",
    "    make_prediction(model, data_train.to(device), title='png/train')\n",
    "    make_prediction(model, data_test.to(device), title='png/test')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#      main(data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbf141",
   "metadata": {},
   "source": [
    "## gnn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel2nd(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        c_hidden,\n",
    "        c_out,\n",
    "        num_layers=2,\n",
    "        layer_name=\"GCN\",\n",
    "        dp_rate=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"GNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of \"hidden\" graph layers\n",
    "            layer_name: String of the graph layer to use\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "            kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer_by_name = {\"linear\":geom_nn.Linear,\n",
    "                             \"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers - 1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels, out_channels=out_channels, **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate),\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels, out_channels=c_out, **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "#                 pdb.set_trace()\n",
    "                x = layer(x, edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class GraphGNNModel(nn.Module):\n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"GraphGNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of output features (usually number of classes)\n",
    "            dp_rate_linear: Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "            kwargs: Additional arguments for the GNNModel object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel2nd(c_in=c_in, c_hidden=c_hidden, c_out=c_hidden, **kwargs)  # Not our prediction output yet!\n",
    "        self.head = nn.Sequential(nn.Dropout(dp_rate_linear), nn.Linear(c_hidden, c_out))\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "            batch_idx: Index of batch element for each node\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "class GraphLevelGNN(): #L.LightningModule):\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = GraphGNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "\n",
    "        if self.hparams.c_out == 1:\n",
    "            preds = (x > 0).float()\n",
    "            data.y = data.y.float()\n",
    "        else:\n",
    "            preds = x.argmax(dim=-1)\n",
    "        #pdb.set_trace()\n",
    "        loss = self.loss_module(x, data.y)\n",
    "        acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # High lr because of small dataset and small model\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"train\")\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"val\")\n",
    "        self.log(\"val_acc\", acc)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"test\")\n",
    "        self.log(\"test_acc\", acc)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "\n",
    "        if self.hparams.c_out == 1:\n",
    "            preds = (x > 0).float()\n",
    "            data.y = data.y.float()\n",
    "        else:\n",
    "            preds = x.argmax(dim=-1)\n",
    "        #--- visuaize predictions\n",
    "        if 'PrintOvito' in kwargs and kwargs['PrintOvito']:\n",
    "            save_dir = kwargs['ovito_dir']\n",
    "            os.system('mkdir -p %s'%save_dir)\n",
    "            self.PrintOvito( data, preds, '%s/pred.xyz'%save_dir)\n",
    "            self.PrintOvito( data, data.y , '%s/act.xyz'%save_dir)\n",
    "        return preds\n",
    "    \n",
    "    def ConfusionMatrix(self, data):\n",
    "        return confusion_matrix(data.y,self.predict(data))\n",
    "\n",
    "    \n",
    "    def PrintOvito( self, data, disps, fout ):\n",
    "        os.system('rm %s'%fout)\n",
    "        ndime = 3\n",
    "        box        = lp.Box(BoxBounds=np.array([[0,10.62],[0,10.62],[0,10.62]]),\\\n",
    "                            AddMissing=np.array([0,0,0]))\n",
    "\n",
    "        atom_indx_init = data.ptr[ 0 ]\n",
    "        for indx, _ in enumerate( data.ptr ):\n",
    "            if indx == 0:\n",
    "                continue\n",
    "            atom_indx_fin = data.ptr[ indx ]\n",
    "            atom_ids      = np.arange(atom_indx_init.cpu(),atom_indx_fin.cpu())+1\n",
    "            types         = np.ones(atom_ids.shape[0])\n",
    "            xyz           = data.pos[ atom_indx_init : atom_indx_fin] \n",
    "            tmp           = xyz.cpu()# * std + mean\n",
    "            cordc         = pd.DataFrame( tmp[:,:ndime], columns='x y z'.split())\n",
    "            disp          = disps[ atom_indx_init : atom_indx_fin ]\n",
    "\n",
    "            df            = pd.DataFrame(np.c_[atom_ids,types,cordc,disp],\\\n",
    "                                  columns = 'id type x y z Mass'.split())\n",
    "            atom          = lp.Atoms(**df.to_dict(orient='series'))\n",
    "            wd            = lp.WriteDumpFile(atom, box)\n",
    "            with open(fout,'a') as fp:\n",
    "                wd.Write(fp, itime=0, \n",
    "                         attrs='id type x y z Mass'.split(), \n",
    "                         fmt='%d %d %4.3e %4.3e %4.3e %4.3e')\n",
    "            atom_indx_init = atom_indx_fin\n",
    "\n",
    "def train_graph_classifier(model_name, data_loader, **model_kwargs):\n",
    "    \n",
    "    #--- initialize\n",
    "    L.seed_everything(42)\n",
    "    CHECKPOINT_PATH = '.'\n",
    "    #--- Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join( CHECKPOINT_PATH, \"GraphLevel\" + model_name )\n",
    "    os.system( 'mkdir %s'%root_dir )\n",
    "    trainer = L.Trainer(\n",
    "                        default_root_dir=root_dir,\n",
    "                        callbacks=[ModelCheckpoint(save_weights_only=True, verbose = True, mode=\"min\", monitor=\"val_loss\")],\n",
    "                #        accelerator=\"cuda\",\n",
    "                #        devices=AVAIL_GPUS,\n",
    "                        max_epochs = data_loader.num_epochs,\n",
    "                        enable_progress_bar = False,\n",
    "                    )\n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    #--- Check whether pretrained model exists. If yes, load it and skip training\n",
    "#    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"GraphLevel%s.ckpt\" % model_name)\n",
    "#     if os.path.isfile(pretrained_filename):\n",
    "#         print(\"Found pretrained model, loading...\")\n",
    "#         model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "#     else:\n",
    "\n",
    "    model = GraphLevelGNN(\n",
    "                            c_in  = data_loader.c_in,\n",
    "                            c_out = data_loader.c_out,\n",
    "                            **model_kwargs,\n",
    "                        )\n",
    "    trainer.fit( model, data_loader.train_dataloaders, data_loader.test_dataloaders )\n",
    "    \n",
    "    #--- load best model\n",
    "    # save trainer.checkpoint_callback.best_model_path\n",
    "    model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    #--- Test best model on validation and test set\n",
    "    train_result = trainer.test( model, dataloaders = data_loader.train_dataloaders, verbose=True)\n",
    "    test_result  = trainer.test( model, dataloaders = data_loader.test_dataloaders,  verbose=True)\n",
    "    \n",
    "    #--- conf. matrix for training and test data\n",
    "    cm_train = model.ConfusionMatrix( data_loader.train_dataloaders.dataset )\n",
    "    cm_test  = model.ConfusionMatrix( data_loader.test_dataloaders.dataset )\n",
    "    \n",
    "    #--- save predictions in ovito\n",
    "    model.predict( data_loader.train_dataloaders.dataset, PrintOvito = True, ovito_dir = 'ovito_dir/train')\n",
    "    model.predict( data_loader.test_dataloaders.dataset,  PrintOvito = True, ovito_dir = 'ovito_dir/test')\n",
    "\n",
    "    result       = {\"test\":  test_result[0][\"test_acc\"], \n",
    "                    \"train\": train_result[0][\"test_acc\"],\n",
    "                    \"train_cm\": cm_train,\n",
    "                    \"test_cm\": cm_test,\n",
    "                   }\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940816f2",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7071aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Softmax in module torch.nn.modules.activation:\n",
      "\n",
      "class Softmax(torch.nn.modules.module.Module)\n",
      " |  Softmax(dim: Union[int, NoneType] = None) -> None\n",
      " |  \n",
      " |  Applies the Softmax function to an n-dimensional input Tensor\n",
      " |  rescaling them so that the elements of the n-dimensional output Tensor\n",
      " |  lie in the range [0,1] and sum to 1.\n",
      " |  \n",
      " |  Softmax is defined as:\n",
      " |  \n",
      " |  .. math::\n",
      " |      \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n",
      " |  \n",
      " |  When the input Tensor is a sparse tensor then the unspecifed\n",
      " |  values are treated as ``-inf``.\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(*)` where `*` means, any number of additional\n",
      " |        dimensions\n",
      " |      - Output: :math:`(*)`, same shape as the input\n",
      " |  \n",
      " |  Returns:\n",
      " |      a Tensor of the same dimension and shape as the input with\n",
      " |      values in the range [0, 1]\n",
      " |  \n",
      " |  Args:\n",
      " |      dim (int): A dimension along which Softmax will be computed (so every slice\n",
      " |          along dim will sum to 1).\n",
      " |  \n",
      " |  .. note::\n",
      " |      This module doesn't work directly with NLLLoss,\n",
      " |      which expects the Log to be computed between the Softmax and itself.\n",
      " |      Use `LogSoftmax` instead (it's faster and has better numerical properties).\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> m = nn.Softmax(dim=1)\n",
      " |      >>> input = torch.randn(2, 3)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Softmax\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dim: Union[int, NoneType] = None) -> None\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'dim': typing.Union[int, NoneType]}\n",
      " |  \n",
      " |  __constants__ = ['dim']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be pickleable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Registers a post hook to be run after module's ``load_state_dict``\n",
      " |      is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearning out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main( prev_gnn ): \n",
    "    if not eval(confParser['gnn classifier']['classification']):\n",
    "        return\n",
    "\n",
    "    device = isGpuAvailable()\n",
    "\n",
    "    gnn = GraphNet(\n",
    "                     c_in       = eval(confParser['gnn classifier']['c_in']),\n",
    "                     c_hidden   = eval(confParser['gnn classifier']['c_hidden']),\n",
    "                     c_out      = eval(confParser['gnn classifier']['c_out']),\n",
    "                     edge_dim   = eval(confParser['gnn classifier']['edge_dim']),\n",
    "                     num_layers = eval(confParser['gnn classifier']['num_layers']),\n",
    "                     num_epochs = eval(confParser['gnn classifier']['num_epochs']),\n",
    "                     cutoff     = eval(confParser['gnn classifier']['cutoff']),\n",
    "                     noise_std  = eval(confParser['gnn classifier']['noise_std']),\n",
    "                     lr         = eval(confParser['gnn classifier']['lr']),\n",
    "                     device     = device,\n",
    "                     verbose    = True \n",
    "                )  # Move model to GPU\n",
    "\n",
    "    gnn.Parse( path  = confParser['gnn classifier']['input_path'],\n",
    "               nruns = eval(confParser['gnn classifier']['nruns']),\n",
    "               prev_gnn = prev_gnn\n",
    "             )\n",
    "        \n",
    "    #--- build dataset based on the input catalogs\n",
    "    gnn.DataBuilderForClassifier()\n",
    "    \n",
    "    #--- training loop\n",
    "    model, result = train_graph_classifier( model_name = \"GraphConv\", \n",
    "                                        data_loader    = gnn,\n",
    "                                            c_hidden   = gnn.c_hidden, \n",
    "                                           layer_name  = \"GraphConv\", \n",
    "                                           num_layers  = gnn.num_layers, \n",
    "                                        dp_rate_linear = 0.5, \n",
    "                                           dp_rate     = 0.0\n",
    "                                           )\n",
    "    \n",
    "    #--- save results\n",
    "    os.system('mkdir confusion_matrix')\n",
    "    np.savetxt('confusion_matrix/cm_train.txt', np.c_[result['train_cm']],header='confusion matrix')\n",
    "    np.savetxt('confusion_matrix/cm_test.txt', np.c_[result['test_cm']],header='confusion matrix')\n",
    "\n",
    "\n",
    "    return gnn\n",
    "# if __name__ == '__main__':\n",
    "#     if GraphNet.num_instantiated == 0:\n",
    "#         gnn = None\n",
    "#     gnn = main( gnn )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78da04d1",
   "metadata": {},
   "source": [
    "## gnn for energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel3rd(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        c_hidden,\n",
    "        c_out,\n",
    "        num_layers=2,\n",
    "        layer_name=\"GCN\",\n",
    "        dp_rate=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"GNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of \"hidden\" graph layers\n",
    "            layer_name: String of the graph layer to use\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "            kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer_by_name = {\"linear\":geom_nn.Linear,\n",
    "                             \"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers - 1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels, out_channels=out_channels, **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate),\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels, out_channels=c_out, **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, edge_index,batch_idx):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "#                 pdb.set_trace()\n",
    "                x = layer(x, edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = geom_nn.global_mean_pool(x, batch_idx)  #--- Average pooling\n",
    "        return x\n",
    "\n",
    "\n",
    "class GraphGNNModel_energy(nn.Module):\n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"GraphGNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of output features (usually number of classes)\n",
    "            dp_rate_linear: Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "            kwargs: Additional arguments for the GNNModel object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel2nd(c_in=c_in, c_hidden=c_hidden, c_out=c_hidden, **kwargs)  # Not our prediction output yet!\n",
    "        self.head = nn.Sequential(nn.Dropout(dp_rate_linear), nn.Linear(c_hidden, c_out))\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "            batch_idx: Index of batch element for each node\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "#        pdb.set_trace()\n",
    "        x = geom_nn.global_mean_pool(x, batch_idx)  #--- Average pooling\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "class GraphLevelGNN_energy(): #L.LightningModule):\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = GraphGNNModel_energy(**model_kwargs)\n",
    "        self.loss_module = nn.MSELoss() #nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "\n",
    "        preds = x.float()\n",
    "        data.y = data.y.float()\n",
    "        loss = self.loss_module(x, data.y)\n",
    "        return loss, loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # High lr because of small dataset and small model\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _ = self.forward(batch, mode=\"train\")\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, _ = self.forward(batch, mode=\"val\")\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, _ = self.forward(batch, mode=\"test\")\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "        #\n",
    "        data.y = data.y.float()\n",
    "        #--- visuaize predictions\n",
    "        if 'PrintOvito' in kwargs and kwargs['PrintOvito']:\n",
    "            save_dir = kwargs['ovito_dir']\n",
    "            os.system('mkdir -p %s'%save_dir)\n",
    "            utl.PltErr(data.y.detach().numpy(),x.detach().numpy(),\n",
    "                      attrs={'fmt':'x'},\n",
    "                      xlim=(-2,2),ylim=(-2,2),\n",
    "                      xstr='E_act',ystr='E_pred',\n",
    "                      title='%s/energy.png'%save_dir\n",
    "                      )\n",
    "        return x.detach().numpy()\n",
    "    \n",
    "def train_graph_energy(model_name, data_loader, lr, **model_kwargs):\n",
    "    \n",
    "    #--- initialize\n",
    "#     L.seed_everything(42)\n",
    "#     CHECKPOINT_PATH = '.'\n",
    "#     #--- Create a PyTorch Lightning trainer with the generation callback\n",
    "#     root_dir = os.path.join( CHECKPOINT_PATH, \"Energy\" + model_name )\n",
    "#     os.system( 'mkdir %s'%root_dir )\n",
    "#     trainer = L.Trainer(\n",
    "#                         default_root_dir=root_dir,\n",
    "#                         callbacks=[ModelCheckpoint(save_weights_only=True, verbose=False, mode=\"min\", monitor=\"val_loss\")],\n",
    "#                 #        accelerator=\"cuda\",\n",
    "#                 #        devices=AVAIL_GPUS,\n",
    "#                         max_epochs = data_loader.num_epochs,\n",
    "#                         enable_progress_bar = False,\n",
    "#                     )\n",
    "#     trainer.logger._default_hp_metric = None\n",
    "\n",
    "\n",
    "#     model = GraphLevelGNN_energy(\n",
    "#                             c_in  = data_loader.c_in,\n",
    "#                             c_out = data_loader.c_out,\n",
    "#                             **model_kwargs,\n",
    "#                         )\n",
    "#     trainer.fit( model, data_loader.train_dataloaders, data_loader.test_dataloaders )\n",
    "    \n",
    "    #--- load best model\n",
    "    # save trainer.checkpoint_callback.best_model_path\n",
    "#     model = GraphLevelGNN_energy.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "#     #--- Test best model on validation and test set\n",
    "#     train_result = trainer.test( model, dataloaders = data_loader.train_dataloaders, verbose=True)\n",
    "#     test_result  = trainer.test( model, dataloaders = data_loader.test_dataloaders, verbose=True)\n",
    "    \n",
    "    \n",
    "#     #--- save predictions in ovito\n",
    "#     model.predict( data_loader.train_dataloaders.dataset, PrintOvito = True, ovito_dir = 'energy_dir/train')\n",
    "#     model.predict( data_loader.test_dataloaders.dataset,  PrintOvito = True, ovito_dir = 'energy_dir/test')\n",
    "\n",
    "#     result       = {\"test\":  test_result[0][\"test_loss\"], \n",
    "#                     \"train\": train_result[0][\"test_loss\"],\n",
    "#                    }\n",
    "#     return model, result\n",
    "\n",
    "    model=GNNModel3rd(data_loader.c_in, data_loader.c_hidden, data_loader.c_out, **model_kwargs) \n",
    "\n",
    "    print('model:',model)    \n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_loss = np.inf\n",
    "    training_loss_hist   = []\n",
    "    validation_loss_hist = []\n",
    "    os.system('mkdir best_model_energy')\n",
    "\n",
    "    for epoch in range( data_loader.num_epochs ):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #      predicted_displacements=model(data_loader.train_dataloaders.dataset) #.x,data_loader.train_dataloaders.dataset.edge_index)\n",
    "        predicted_displacements=model(data_loader.train_dataloaders.dataset.x,\n",
    "                                      data_loader.train_dataloaders.dataset.edge_index,\n",
    "                                   data_loader.train_dataloaders.dataset.batch)\n",
    "\n",
    "        training_loss              = criterion(predicted_displacements, data_loader.train_dataloaders.dataset.y)\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss_hist += [training_loss.detach().cpu().numpy()]  # Move loss back to CPU\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "                predicted_displacements=model(data_loader.test_dataloaders.dataset.x,\n",
    "                                              data_loader.test_dataloaders.dataset.edge_index,\n",
    "                                   data_loader.test_dataloaders.dataset.batch)\n",
    "        #                predicted_displacements = model(data_loader.test_dataloaders.dataset)\n",
    "                validation_loss         = criterion(predicted_displacements, \n",
    "                                                    data_loader.test_dataloaders.dataset.y)\n",
    "\n",
    "                validation_loss_hist += [validation_loss.cpu().numpy()]  # Move loss back to CPU\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Training Loss: {training_loss.item():4.3e}, Validation Loss: {validation_loss.item():4.3e}')\n",
    "\n",
    "            # Update best_loss if validation loss improves and save the model\n",
    "            best_loss = GraphNet.save_best_model(model, optimizer, \n",
    "                                epoch, validation_loss.detach().cpu().numpy(), best_loss, \n",
    "                                'best_model_energy/best_model.pth')\n",
    "\n",
    "#    trainer.fit( model, data_loader.train_dataloaders, data_loader.test_dataloaders )\n",
    " \n",
    "    #--- load best model\n",
    "    # save trainer.checkpoint_callback.best_model_path\n",
    "#    model = GraphLevelGNN_energy.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    #--- Test best model on validation and test set\n",
    "#    train_result = trainer.test( model, dataloaders = data_loader.train_dataloaders, verbose=True)\n",
    "#    test_result  = trainer.test( model, dataloaders = data_loader.test_dataloaders, verbose=True)\n",
    "    \n",
    "    \n",
    "    #--- save predictions in ovito\n",
    "#    model.predict( data_loader.train_dataloaders.dataset, PrintOvito = True, ovito_dir = 'energy_dir/train')\n",
    "#    model.predict( data_loader.test_dataloaders.dataset,  PrintOvito = True, ovito_dir = 'energy_dir/test')\n",
    "\n",
    "#    result       = {\"test\":  test_result[0][\"test_loss\"], \n",
    "#                    \"train\": train_result[0][\"test_loss\"],\n",
    "#                   }\n",
    "    utl.PltErr(data_loader.test_dataloaders.dataset.y, predicted_displacements,\n",
    "               xlim=(0,2),ylim=(0,2),\n",
    "               attrs={'color':'C0','fmt':'x'},\n",
    "               title='en.png',\n",
    "          )\n",
    "\n",
    "#     print('pred vs actual:\\n',np.c_[predicted_displacements,data_loader.test_dataloaders.dataset.y]) \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73729d36",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(prev_gnn): \n",
    "    if not eval(confParser['gnn energy']['regression']):\n",
    "        return\n",
    "\n",
    "    device = isGpuAvailable()\n",
    "\n",
    "    gnn = GraphNet(\n",
    "                     c_in       = eval(confParser['gnn energy']['c_in']),\n",
    "                     c_hidden   = eval(confParser['gnn energy']['c_hidden']),\n",
    "                     c_out      = eval(confParser['gnn energy']['c_out']),\n",
    "                     edge_dim   = eval(confParser['gnn energy']['edge_dim']),\n",
    "                     num_layers = eval(confParser['gnn energy']['num_layers']),\n",
    "                     num_epochs = eval(confParser['gnn energy']['num_epochs']),\n",
    "                     cutoff     = eval(confParser['gnn energy']['cutoff']),\n",
    "                     noise_std  = eval(confParser['gnn energy']['noise_std']),\n",
    "                     lr         = eval(confParser['gnn energy']['lr']),\n",
    "                     dp_rate    = eval(confParser['gnn energy']['dp_rate']),\n",
    "                     device     = device,\n",
    "                     verbose    = True \n",
    "                )  # Move model to GPU\n",
    "\n",
    "    gnn.Parse( path  = confParser['gnn energy']['input_path'],\n",
    "               nruns = eval(confParser['gnn energy']['nruns']),\n",
    "               prev_gnn=prev_gnn )\n",
    "        \n",
    "    #---   build dataset based on the input catalogs\n",
    "    gnn.DataBuilderForEnergy()\n",
    "    \n",
    "    #--- training loop\n",
    "    model = train_graph_energy( model_name = \"GraphConv\", \n",
    "                                        data_loader    = gnn,\n",
    "                               lr  = eval(confParser['gnn energy']['lr']),\n",
    "                                           layer_name  = \"linear\", \n",
    "                                           num_layers  = gnn.num_layers, \n",
    "                                           dp_rate     = gnn.dp_rate\n",
    "                                           )\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     if GraphNet.num_instantiated == 0:\n",
    "#         gnn = None\n",
    "         \n",
    "#     main(gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bdc7e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# class GraphNeuralNet(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dims, output_dims, activation):\n",
    "#         super(GraphNeuralNet, self).__init__()\n",
    "#         self.output_dims = output_dims\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
    "#         self.hidden_layers = nn.ModuleList()\n",
    "#         for i in range(len(hidden_dims) - 1):\n",
    "#             self.hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "#         self.fc_out = nn.ModuleList([nn.Linear(hidden_dims[-1], dim) for dim in output_dims])\n",
    "#         self.activation = activation\n",
    "\n",
    "#     def forward(self, x, adj_matrices):\n",
    "#         x = self.activation(self.fc1(x))\n",
    "#         for hidden_layer in self.hidden_layers:\n",
    "#             x = self.activation(hidden_layer(x))\n",
    "#         outputs = []\n",
    "#         for adj_matrix in adj_matrices:\n",
    "#             hidden = torch.matmul(adj_matrix, x)\n",
    "#             for fc_out in self.fc_out:\n",
    "#                 outputs.append(fc_out(hidden))\n",
    "#         return outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(): # Example usage\n",
    "#     input_dim = eval(confParser['gnn']['input_dim']) #3  # Dimensionality of atom positions (e.g., x, y, z coordinates)\n",
    "#     hidden_dim = eval(confParser['gnn']['hidden_dim']) #[64]  # Dimensionality of hidden layers\n",
    "#     output_dims = eval(confParser['gnn']['output_dims']) #[3]  # Dimensionality of displacement vectors for each snapshot\n",
    "#     activation = eval(confParser['gnn']['activation']) #nn.ReLU() #nn.Identity()) #F.relu)\n",
    "#     lr = eval(confParser['gnn']['lr'])# 1.0e-4\n",
    "#     ntrain = eval(confParser['gnn']['ntrain'])#100\n",
    "#     num_epochs = eval(confParser['gnn']['num_epochs'])#20000\n",
    "#     noise_std   = eval(confParser['gnn']['noise_std'])#0.1\n",
    "\n",
    "#     num_snapshots = len( transition_paths )\n",
    "#     snapshots     = range(num_snapshots)\n",
    "\n",
    "#     model = GraphNeuralNet(input_dim, hidden_dim, output_dims,activation) #\n",
    "\n",
    "\n",
    "#     # Define optimizer and loss function\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "#     # Example training data\n",
    "#     num_atoms = [ len(transition_paths[ i ]['id']) for i in snapshots ]\n",
    "#     input_data = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "\n",
    "\n",
    "#     # Example target data (displacement vectors for each snapshot and each path)\n",
    "#     target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots for dim in output_dims]\n",
    "\n",
    "\n",
    "#     # Augment the dataset to have order 100 snapshots\n",
    "#     augmented_input_data = []\n",
    "#     augmented_target_displacements = []\n",
    "#     input_data_tensor = torch.stack(input_data)\n",
    "#     ntrain_initial = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "#     n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "#     for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "#         augmented_input, augmented_target = augment_data(input_data, target_displacements, noise_std)\n",
    "#         augmented_input_data.extend(augmented_input)\n",
    "#         augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "#     adj_matrices = compute_adjacency_matrices(augmented_input_data, rcut=3.0) #[torch.randint(0, 2, (num_atoms[i], num_atoms[i])).float() for i in range(num_snapshots)]  # Random adjacency matrices for each snapshot\n",
    "\n",
    "\n",
    "\n",
    "#     # Concatenate input data along a new dimension to form a single tensor\n",
    "#     input_data_tensor = torch.stack(augmented_input_data)\n",
    "#     print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "#     # Standardize the augmented input data\n",
    "#     mean = input_data_tensor.mean(dim=(0, 1))\n",
    "#     std = input_data_tensor.std(dim=(0, 1))\n",
    "#     standardized_input_data = [standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "\n",
    "\n",
    "#     # Convert input data to tensors\n",
    "#     #input_data_tensor = torch.stack(augmented_input_data)\n",
    "#     target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "\n",
    "#     total_loss_hist = []\n",
    "#     for epoch in range(num_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         predicted_displacements = model(input_data_tensor, adj_matrices)\n",
    "#     #    predicted_displacements_tensor = torch.stack( predicted_displacements )\n",
    "#         losses = []\n",
    "#         for indx, i in enumerate(snapshots):\n",
    "#             pred = predicted_displacements[ indx ][ indx ]\n",
    "#             snapshot_losses = criterion(pred, augmented_target_displacements[indx])\n",
    "#     #        snapshot_losses = [criterion(pred, augmented_target_displacements[indx]) for pred in predicted_displacements[indx]]\n",
    "#     #        pdb.set_trace()\n",
    "#             losses.append(snapshot_losses)\n",
    "#     #        losses.extend(snapshot_losses)\n",
    "#     #    loss = criterion(predicted_displacements_tensor, target_displacements_tensor)\n",
    "#         total_loss = sum(losses)\n",
    "#         total_loss.backward()\n",
    "#     #    loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss_hist += [total_loss.detach().numpy()]\n",
    "#         if epoch % 100 == 0:\n",
    "#             print(f'Epoch {epoch}, Total Loss: {total_loss.item()}')\n",
    "\n",
    "# #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09399b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d',)\n",
    "\n",
    "# batch_indx = 0\n",
    "# filtr = data.batch == batch_indx\n",
    "\n",
    "# xyz = data.x \n",
    "# adj_mat = data.edge_index.T\n",
    "\n",
    "\n",
    "# ax.plot(xyz[filtr][:,0],xyz[filtr][:,1],xyz[filtr][:,2],\n",
    "#         '.', ms=20,\n",
    "#         )\n",
    "\n",
    "# min_node_indx = data.ptr[ batch_indx ]\n",
    "# max_node_indx = data.ptr[ batch_indx + 1 ]\n",
    "# for nodes in (adj_mat):\n",
    "#     i = nodes[0]\n",
    "#     j = nodes[1]\n",
    "#     if i < min_node_indx or i >= max_node_indx: \n",
    "#         continue\n",
    "#     if j < min_node_indx or j >= max_node_indx: \n",
    "#         continue\n",
    "#     ax.plot([xyz[i,0],xyz[j,0]],[xyz[i,1],xyz[j,1]],[xyz[i,2],xyz[j,2]],\n",
    "#             '-', color='black',\n",
    "#             )\n",
    "\n",
    "#     u = data.y\n",
    "\n",
    "# ax.plot(([xyz[filtr][17,0],xyz[filtr][17,0]+u[filtr][17,0]]),\n",
    "#         ([xyz[filtr][17,1],xyz[filtr][17,1]+u[filtr][17,1]]),\n",
    "#         ([xyz[filtr][17,2],xyz[filtr][17,2]+u[filtr][17,2]]),\n",
    "#         '-', color='red',\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3c829",
   "metadata": {},
   "source": [
    "## mpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c862a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# class MPNN(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(MPNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def message_passing_layer(self, x, adj_matrices):\n",
    "#         # Ensure adj_matrices is a list of tensors\n",
    "#         adj_matrices = [adj.unsqueeze(0) for adj in adj_matrices]\n",
    "\n",
    "#         # Expand node features to include neighboring node features\n",
    "# #        expanded_x = [torch.matmul(adj.unsqueeze(0), x.unsqueeze(0)).squeeze(0) for adj in adj_matrices]\n",
    "#         expanded_x = [torch.matmul(adj,yy) for adj, yy in zip(adj_matrices,x)]\n",
    "# #        expanded_x = [torch.matmul(adj.unsqueeze(0), adj).squeeze(0) for adj in adj_matrices]\n",
    "\n",
    "#         # Concatenate node features with neighboring node features\n",
    "#         pdb.set_trace()\n",
    "#         concatenated_x = [torch.cat((x, exp_x), dim=1) for exp_x in expanded_x]\n",
    "\n",
    "#         # Apply linear transformation\n",
    "#         transformed_x = [self.fc1(cat_x) for cat_x in concatenated_x]\n",
    "\n",
    "#         # Apply activation function\n",
    "#         x = [F.relu(trans_x) for trans_x in transformed_x]\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "#     def readout_layer(self, x):\n",
    "#         # Concatenate tensors in the list along the batch dimension\n",
    "#         concatenated_x = torch.stack(x, dim=0)\n",
    "\n",
    "#         # Apply global pooling operation (e.g., mean or sum) along the batch dimension\n",
    "#         return torch.mean(concatenated_x, dim=0)\n",
    "\n",
    "#     def forward(self, x, adj_matrices):\n",
    "#         x = self.message_passing_layer(x, adj_matrices)\n",
    "#         output = self.readout_layer(x)\n",
    "#         return output\n",
    "\n",
    "# # Example usage\n",
    "# input_dim = 3  # Dimensionality of atom positions (e.g., x, y, z coordinates)\n",
    "# hidden_dim = 64  # Dimensionality of hidden layers\n",
    "# output_dim = 3  # Dimensionality of displacement vectors for each snapshot\n",
    "\n",
    "# # Create model instance\n",
    "# model = MPNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# # Define optimizer and loss function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1.0e-4)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# # Example training data\n",
    "# # Assuming input_data is a list of tensors containing initial positions for each snapshot\n",
    "# # Assuming adj_matrices is a list of adjacency matrices for each snapshot\n",
    "# # Assuming target_displacements is a list of tensors containing displacement vectors for each snapshot\n",
    "# # You need to replace these with your actual data\n",
    "# input_data = [torch.randn(10, input_dim).float() for _ in range(10)]  # Example random initial positions\n",
    "# adj_matrices = [torch.randint(0, 2, (10, 10)).float() for _ in range(10)]  # Example random adjacency matrices\n",
    "# target_displacements = [torch.randn(10, output_dim) for _ in range(10)]  # Example random target displacements\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 1000\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     predicted_displacements = model(input_data, adj_matrices)\n",
    "#     loss = criterion(predicted_displacements, target_displacements)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     if epoch % 100 == 0:\n",
    "#         print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d47449",
   "metadata": {},
   "source": [
    "## tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7268a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# class GraphNeuralNetwork(tf.keras.Model):\n",
    "#     def __init__(self, hidden_dim, output_dim):\n",
    "#         super(GraphNeuralNetwork, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.output_dim = output_dim\n",
    "        \n",
    "#         # Define layers\n",
    "#         self.fc1 = tf.keras.layers.Dense(hidden_dim, activation='relu')\n",
    "#         self.fc2 = tf.keras.layers.Dense(hidden_dim, activation='relu')\n",
    "#         self.fc_out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "#     def call(self, x, adj_matrices):\n",
    "#         # x: Node features (batch_size, num_nodes, input_dim)\n",
    "#         # adj_matrices: Adjacency matrices (batch_size, num_nodes, num_nodes)\n",
    "        \n",
    "#         # Apply first fully connected layer\n",
    "#         x = self.fc1(x)\n",
    "        \n",
    "#         # Iterate over adjacency matrices and update node features\n",
    "#         for adj_matrix in adj_matrices:\n",
    "#             x = tf.matmul(adj_matrix, x)\n",
    "#             x = self.fc2(x)\n",
    "        \n",
    "#         # Apply output fully connected layer\n",
    "#         output = self.fc_out(x)\n",
    "        \n",
    "#         return output\n",
    "\n",
    "# def compute_adjacency_matrices_tf(input_data, rcut):\n",
    "#     adj_matrices = []\n",
    "    \n",
    "#     for positions in input_data:\n",
    "#         num_atoms = positions.shape[0]\n",
    "#         adj_matrix = np.zeros(num_atoms*num_atoms).reshape((num_atoms, num_atoms))\n",
    "        \n",
    "#         for i in range(num_atoms):\n",
    "#             for j in range(i + 1, num_atoms):\n",
    "#                 distance = torch.norm(positions[i] - positions[j])\n",
    "#                 if distance <= rcut:\n",
    "#                     adj_matrix[i, j] = 1\n",
    "#                     adj_matrix[j, i] = 1\n",
    "#             assert adj_matrix[i,:].sum() > 0, 'dangling node : increase the cutoff!'\n",
    "#         adj_matrices.append(adj_matrix)\n",
    "    \n",
    "#     #--- assert no \n",
    "#     return np.c_[adj_matrices]\n",
    "\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     hidden_dim = 32  # Dimensionality of hidden layers\n",
    "#     output_dim = 3  # Dimensionality of output vectors\n",
    "#     snapshots = [0] #range(len(transition_paths))\n",
    "\n",
    "#     model = GraphNeuralNetwork(hidden_dim, output_dim)\n",
    "\n",
    "#     # Define optimizer and loss function\n",
    "#     optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#     loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "#     # Generate dummy input data and adjacency matrices\n",
    "# #     batch_size = 2\n",
    "# #     num_nodes = 10\n",
    "#     input_dim = 3\n",
    "\n",
    "#     #x = tf.random.normal((batch_size, num_nodes, input_dim))\n",
    "#     x = np.c_[[np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] for i in snapshots]]\n",
    "#     x = tf.convert_to_tensor(x,dtype=tf.float32)\n",
    "\n",
    "#     #adj_matrices = tf.random.uniform((batch_size, num_nodes, num_nodes)) # for _ in range(2)]  # Example with 2 adjacency matrices\n",
    "#     input_data = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "#     adj_matrices = compute_adjacency_matrices_tf(torch.stack(input_data), rcut=3.0)\n",
    "#     adj_matrices = tf.convert_to_tensor(adj_matrices,dtype=tf.float32)\n",
    "\n",
    "#     # Example target data\n",
    "#     #target = tf.random.normal((batch_size, num_nodes, output_dim))\n",
    "#     target = np.c_[[np.c_[pd.DataFrame(transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] for i in snapshots]]\n",
    "#     target = tf.convert_to_tensor(target,dtype=tf.float32)\n",
    "\n",
    "\n",
    "#     # Training loop\n",
    "#     total_loss_hist = []\n",
    "#     num_epochs = 5000 #100000\n",
    "#     for epoch in range(num_epochs):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             predictions = model(x, adj_matrices)\n",
    "#     #         pdb.set_trace()\n",
    "#             loss = loss_fn(target, predictions)\n",
    "\n",
    "#         gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#         optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "#         if epoch == 0:\n",
    "#             loss_min = loss.numpy()\n",
    "#             best_model = model\n",
    "#         total_loss_hist.append(loss.numpy())\n",
    "#         if epoch % 100 == 0: \n",
    "#             print('Epoch %s, Loss: %e'%(epoch,loss.numpy()))\n",
    "#             if loss.numpy() < loss_min:\n",
    "#                 loss_min = loss.numpy()\n",
    "#                 best_model = model     \n",
    "#     print('min loss:%e'%loss_min)\n",
    "#     return best_model, num_epochs, total_loss_hist\n",
    "\n",
    "# #model, num_epochs, total_loss_hist = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff93c42",
   "metadata": {},
   "source": [
    "## pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc7122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# # # Standard libraries\n",
    "# # import os\n",
    "\n",
    "# # # For downloading pre-trained models\n",
    "# import urllib.request\n",
    "# from urllib.error import HTTPError\n",
    "\n",
    "# # # PyTorch Lightning\n",
    "# import lightning as L\n",
    "\n",
    "# # # PyTorch\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # # PyTorch geometric\n",
    "# import torch_geometric\n",
    "# import torch_geometric.data as geom_data\n",
    "# import torch_geometric.nn as geom_nn\n",
    "\n",
    "# # # PL callbacks\n",
    "# from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "# from torch import Tensor\n",
    "\n",
    "# AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "# BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "# # Path to the folder where the datasets are/should be downloaded\n",
    "# DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# # Path to the folder where the pretrained models are saved\n",
    "# CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/GNNs/\")\n",
    "\n",
    "# # # Setting the seed\n",
    "# L.seed_everything(42)\n",
    "\n",
    "# # # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22a5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Github URL where saved models are stored for this tutorial\n",
    "# base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "# # Files to download\n",
    "# pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "# # Create checkpoint path if it doesn't exist yet\n",
    "# os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# # For each file, check whether it already exists. If not, try downloading it.\n",
    "# for file_name in pretrained_files:\n",
    "#     file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "#     if \"/\" in file_name:\n",
    "#         os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "#     if not os.path.isfile(file_path):\n",
    "#         file_url = base_url + file_name\n",
    "#         print(\"Downloading %s...\" % file_url)\n",
    "#         try:\n",
    "#             urllib.request.urlretrieve(file_url, file_path)\n",
    "#         except HTTPError as e:\n",
    "#             print(\n",
    "#                 \"Something went wrong. Please try to download the file from the GDrive folder,\"\n",
    "#                 \" or contact the author with the full output including the following error:\\n\",\n",
    "#                 e,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78ccb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCNLayer(nn.Module):\n",
    "#     def __init__(self, c_in, c_out):\n",
    "#         super().__init__()\n",
    "#         self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "#     def forward(self, node_feats, adj_matrix):\n",
    "#         \"\"\"Forward.\n",
    "\n",
    "#         Args:\n",
    "#             node_feats: Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
    "#             adj_matrix: Batch of adjacency matrices of the graph. If there is an edge from i to j,\n",
    "#                          adj_matrix[b,i,j]=1 else 0. Supports directed edges by non-symmetric matrices.\n",
    "#                          Assumes to already have added the identity connections.\n",
    "#                          Shape: [batch_size, num_nodes, num_nodes]\n",
    "#         \"\"\"\n",
    "#         # Num neighbours = number of incoming edges\n",
    "#         num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "#         node_feats = self.projection(node_feats)\n",
    "#         node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "#         node_feats = node_feats / num_neighbours\n",
    "#         return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abf8390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "# adj_matrix = Tensor([[[1, 1, 0, 0], [1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1]]])\n",
    "\n",
    "# print(\"Node features:\\n\", node_feats)\n",
    "# print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31269515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [4., 5.],\n",
      "         [4., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "# layer = GCNLayer(c_in=2, c_out=2)\n",
    "# layer.projection.weight.data = Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "# layer.projection.bias.data = Tensor([0.0, 0.0])\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "# print(\"Adjacency matrix\", adj_matrix)\n",
    "# print(\"Input features\", node_feats)\n",
    "# print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777baf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482df1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cora_dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df43541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Small function for printing the test scores\n",
    "# def print_results(result_dict):\n",
    "#     if \"train\" in result_dict:\n",
    "#         print(\"Train accuracy: %4.2f%%\" % (100.0 * result_dict[\"train\"]))\n",
    "#     if \"val\" in result_dict:\n",
    "#         print(\"Val accuracy:   %4.2f%%\" % (100.0 * result_dict[\"val\"]))\n",
    "#     print(\"Test accuracy:  %4.2f%%\" % (100.0 * result_dict[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e976a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12a3ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Data object:\", tu_dataset.data)\n",
    "# print(\"Length:\", len(tu_dataset))\n",
    "# print(\"Average label: %4.2f\" % (tu_dataset.data.y.float().mean().item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "181abf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# tu_dataset.shuffle()\n",
    "# train_dataset = tu_dataset[:150]\n",
    "# test_dataset = tu_dataset[150:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42627b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MUTAG(150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BATCH_SIZE\n",
    "# train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3726f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=BATCH_SIZE)  # Additional loader for a larger datasets\n",
    "# graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "926dec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: DataBatch(edge_index=[2, 1512], x=[687, 7], edge_attr=[1512, 4], y=[38], batch=[687], ptr=[39])\n",
      "Labels: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
      "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# batch = next(iter(graph_test_loader))\n",
    "# print(\"Batch:\", batch)\n",
    "# print(\"Labels:\", batch.y[:10])\n",
    "# print(\"Batch indices:\", batch.batch[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "205ccddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebadc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GNNModel(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         c_in,\n",
    "#         c_hidden,\n",
    "#         c_out,\n",
    "#         num_layers=2,\n",
    "#         layer_name=\"GCN\",\n",
    "#         dp_rate=0.1,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         \"\"\"GNNModel.\n",
    "\n",
    "#         Args:\n",
    "#             c_in: Dimension of input features\n",
    "#             c_hidden: Dimension of hidden features\n",
    "#             c_out: Dimension of the output features. Usually number of classes in classification\n",
    "#             num_layers: Number of \"hidden\" graph layers\n",
    "#             layer_name: String of the graph layer to use\n",
    "#             dp_rate: Dropout rate to apply throughout the network\n",
    "#             kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         gnn_layer_by_name = {\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}\n",
    "#         gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "#         layers = []\n",
    "#         in_channels, out_channels = c_in, c_hidden\n",
    "#         for l_idx in range(num_layers - 1):\n",
    "#             layers += [\n",
    "#                 gnn_layer(in_channels=in_channels, out_channels=out_channels, **kwargs),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Dropout(dp_rate),\n",
    "#             ]\n",
    "#             in_channels = c_hidden\n",
    "#         layers += [gnn_layer(in_channels=in_channels, out_channels=c_out, **kwargs)]\n",
    "#         self.layers = nn.ModuleList(layers)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         \"\"\"Forward.\n",
    "\n",
    "#         Args:\n",
    "#             x: Input features per node\n",
    "#             edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "#         \"\"\"\n",
    "#         for layer in self.layers:\n",
    "#             # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "#             # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "#             # we can simply check the class type.\n",
    "#             if isinstance(layer, geom_nn.MessagePassing):\n",
    "# #                 pdb.set_trace()\n",
    "#                 x = layer(x, edge_index)\n",
    "#             else:\n",
    "#                 x = layer(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c1b18",
   "metadata": {},
   "source": [
    "### toturial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cd6f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def main(): # Example usage\n",
    "\n",
    "    \n",
    "#     c_in=input_dim=3\n",
    "#     c_hidden = 16\n",
    "#     hidden_dim = [c_hidden]\n",
    "#     c_out  = 3\n",
    "#     output_dims=[c_out]\n",
    "#     num_layers = 2\n",
    "#     ntrain = 100\n",
    "#     num_epochs=100\n",
    "#     noise_std=0.001\n",
    "#     lr=1e-4\n",
    "#     batch_size = 12  # or any desired batch size\n",
    "\n",
    "\n",
    "#     num_snapshots = len( transition_paths )\n",
    "#     print('num_snapshots=',num_snapshots)\n",
    "#     snapshots     = range(num_snapshots)\n",
    "\n",
    "# #     model = GraphNeuralNet(input_dim, hidden_dim, output_dims,activation) #\n",
    "#     model = GNNModel(c_in,\n",
    "#         c_hidden,\n",
    "#         c_out,\n",
    "#         num_layers=num_layers,\n",
    "# )\n",
    "\n",
    "\n",
    "#     # Define optimizer and loss function\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "#     # Example training data\n",
    "#     input_data = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     # Example target data (displacement vectors for each snapshot and each path)\n",
    "#     target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots for dim in output_dims]\n",
    "\n",
    "\n",
    "#     # Augment the dataset to have order 100 snapshots\n",
    "#     augmented_input_data = []\n",
    "#     augmented_target_displacements = []\n",
    "#     input_data_tensor = torch.stack(input_data)\n",
    "#     ntrain_initial = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "#     n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "#     for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "#         augmented_input, augmented_target = augment_data(input_data, target_displacements, noise_std)\n",
    "#         augmented_input_data.extend(augmented_input)\n",
    "#         augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "#     adj_matrices = torch.stack(compute_adjacency_matrices(augmented_input_data, rcut=3.0)) \n",
    "    \n",
    "\n",
    "\n",
    "#     # Concatenate input data along a new dimension to form a single tensor\n",
    "#     input_data_tensor = torch.stack(augmented_input_data)\n",
    "#     print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "#     # Standardize the augmented input data\n",
    "#     mean = input_data_tensor.mean(dim=(0, 1))\n",
    "#     std = input_data_tensor.std(dim=(0, 1))\n",
    "#     standardized_input_data = [standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "\n",
    "\n",
    "#     # Convert input data to tensors\n",
    "#     target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Concatenate nodes and edges for each graph\n",
    "#     graphs = []\n",
    "#     for i in range(len(input_data)):\n",
    "#         x = input_data_tensor[i]  # Node features\n",
    "#         edge_index = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "#         y = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "#         # Create a Data object for each graph\n",
    "#         data = Data(x=x, edge_index=edge_index, y=y)\n",
    "#         graphs.append(data)\n",
    "#     # Create a single large graph by concatenating Data objects\n",
    "#     large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "#     # Define batch size and create DataLoader\n",
    "#     loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# #     # Accessing batches in the DataLoader\n",
    "#     data=loader.dataset #next(iter(loader))\n",
    "# #     pdb.set_trace()\n",
    "# #    for data in loader:\n",
    "# #    print(data)\n",
    "\n",
    "\n",
    "#     total_loss_hist = []\n",
    "#     for epoch in range(num_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         predicted_displacements = model(data.x, data.edge_index)\n",
    "#         total_loss = criterion(predicted_displacements,data.y )\n",
    "#         total_loss.backward()\n",
    "#     #    loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss_hist += [total_loss.detach().numpy()]\n",
    "#         if epoch % 100 == 0:\n",
    "#             print(f'Epoch {epoch}, Total Loss: {total_loss.item()}')\n",
    "\n",
    "#     return model, num_epochs, total_loss_hist, data\n",
    "\n",
    "\n",
    "\n",
    "# gnn_layer_by_name = {\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}\n",
    "\n",
    "# model, num_epochs, total_loss_hist, data = main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89f676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GraphGNNModel(nn.Module):\n",
    "#     def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "#         \"\"\"GraphGNNModel.\n",
    "\n",
    "#         Args:\n",
    "#             c_in: Dimension of input features\n",
    "#             c_hidden: Dimension of hidden features\n",
    "#             c_out: Dimension of output features (usually number of classes)\n",
    "#             dp_rate_linear: Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "#             kwargs: Additional arguments for the GNNModel object\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.GNN = GNNModel(c_in=c_in, c_hidden=c_hidden, c_out=c_hidden, **kwargs)  # Not our prediction output yet!\n",
    "#         self.head = nn.Sequential(nn.Dropout(dp_rate_linear), nn.Linear(c_hidden, c_out))\n",
    "\n",
    "#     def forward(self, x, edge_index, batch_idx):\n",
    "#         \"\"\"Forward.\n",
    "\n",
    "#         Args:\n",
    "#             x: Input features per node\n",
    "#             edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "#             batch_idx: Index of batch element for each node\n",
    "#         \"\"\"\n",
    "#         pdb.set_trace()\n",
    "#         x = self.GNN(x, edge_index)\n",
    "# #        pdb.set_trace()\n",
    "#         x = geom_nn.global_mean_pool(x, batch_idx)  #--- Average pooling\n",
    "#         x = self.head(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5968c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GraphLevelGNN(L.LightningModule):\n",
    "#     def __init__(self, **model_kwargs):\n",
    "#         super().__init__()\n",
    "#         # Saving hyperparameters\n",
    "#         self.save_hyperparameters()\n",
    "\n",
    "#         self.model = GraphGNNModel(**model_kwargs)\n",
    "#         self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, data, mode=\"train\"):\n",
    "#         x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "#         x = self.model(x, edge_index, batch_idx)\n",
    "#         x = x.squeeze(dim=-1)\n",
    "\n",
    "#         if self.hparams.c_out == 1:\n",
    "#             preds = (x > 0).float()\n",
    "#             data.y = data.y.float()\n",
    "#         else:\n",
    "#             preds = x.argmax(dim=-1)\n",
    "#         loss = self.loss_module(x, data.y)\n",
    "#         acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "#         return loss, acc\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         # High lr because of small dataset and small model\n",
    "#         optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "#         return optimizer\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         loss, acc = self.forward(batch, mode=\"train\")\n",
    "#         self.log(\"train_loss\", loss)\n",
    "#         self.log(\"train_acc\", acc)\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         _, acc = self.forward(batch, mode=\"val\")\n",
    "#         self.log(\"val_acc\", acc)\n",
    "\n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         _, acc = self.forward(batch, mode=\"test\")\n",
    "#         self.log(\"test_acc\", acc)\n",
    "        \n",
    "#     def predict(self, data):\n",
    "#         x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "#         x = self.model(x, edge_index, batch_idx)\n",
    "#         x = x.squeeze(dim=-1)\n",
    "\n",
    "#         if self.hparams.c_out == 1:\n",
    "#             preds = (x > 0).float()\n",
    "#             data.y = data.y.float()\n",
    "#         else:\n",
    "#             preds = x.argmax(dim=-1)\n",
    "#         return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9456fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_graph_classifier(model_name, **model_kwargs):\n",
    "#     L.seed_everything(42)\n",
    "\n",
    "#     # Create a PyTorch Lightning trainer with the generation callback\n",
    "#     root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
    "#     os.makedirs(root_dir, exist_ok=True)\n",
    "#     trainer = L.Trainer(\n",
    "#         default_root_dir=root_dir,\n",
    "#         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "# #        accelerator=\"cuda\",\n",
    "# #        devices=AVAIL_GPUS,\n",
    "#         max_epochs=500,\n",
    "#         enable_progress_bar=False,\n",
    "#     )\n",
    "#     trainer.logger._default_hp_metric = None\n",
    "\n",
    "#     # Check whether pretrained model exists. If yes, load it and skip training\n",
    "#     pretrained_filename = os.path.join(CHECKPOINT_PATH, \"GraphLevel%s.ckpt\" % model_name)\n",
    "# #     if os.path.isfile(pretrained_filename):\n",
    "# #         print(\"Found pretrained model, loading...\")\n",
    "# #         model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "# #     else:\n",
    "#     L.seed_everything(42)\n",
    "\n",
    "#     model = GraphLevelGNN(\n",
    "#         c_in=tu_dataset.num_node_features,\n",
    "#         c_out=1 if tu_dataset.num_classes == 2 else tu_dataset.num_classes,\n",
    "#         **model_kwargs,\n",
    "#     )\n",
    "#     trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "#     model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "#     # Test best model on validation and test set\n",
    "#     train_result = trainer.test(model, dataloaders=graph_train_loader, verbose=False)\n",
    "#     test_result = trainer.test(model, dataloaders=graph_test_loader, verbose=False)\n",
    "#     result = {\"test\": test_result[0][\"test_acc\"], \"train\": train_result[0][\"test_acc\"]}\n",
    "#     return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff892dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | model       | GraphGNNModel     | 266 K \n",
      "1 | loss_module | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------\n",
      "266 K     Trainable params\n",
      "0         Non-trainable params\n",
      "266 K     Total params\n",
      "1.067     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-20-a35bcec6ca88>\u001b[0m(25)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeom_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#--- Average pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-20-a35bcec6ca88>\u001b[0m(26)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     24 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeom_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#--- Average pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# model, result = train_graph_classifier(\n",
    "#     model_name=\"GraphConv\", c_hidden=256, layer_name=\"GraphConv\", num_layers=3, dp_rate_linear=0.5, dp_rate=0.0\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
