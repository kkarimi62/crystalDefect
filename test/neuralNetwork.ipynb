{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#main():-classifier\" data-toc-modified-id=\"main():-classifier-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>main(): classifier</a></span></li><li><span><a href=\"#main():-regressor\" data-toc-modified-id=\"main():-regressor-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>main(): regressor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#test-example:-2d\" data-toc-modified-id=\"test-example:-2d-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>test example: 2d</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-connected-in-sklearn\" data-toc-modified-id=\"fully-connected-in-sklearn-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>fully connected in sklearn</a></span></li><li><span><a href=\"#fully-connected-in-keras\" data-toc-modified-id=\"fully-connected-in-keras-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>fully connected in keras</a></span></li><li><span><a href=\"#cnn\" data-toc-modified-id=\"cnn-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>cnn</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['flags', 'input files', 'descriptors', 'neural net', 'neural net classification', 'neural net regression', 'gnn', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "import pickle\n",
    "#\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "from scipy.stats import gaussian_kde\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n",
    "\n",
    "#--- increase width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "            \n",
    "            \n",
    "        !mkdir $self.best_model\n",
    "\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            if irun == 0:\n",
    "                #--- same configurations!\n",
    "                self.descriptors  = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['data']]\n",
    "                self.shape        = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['shape']].flatten()\n",
    "                self.positions    = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz .'%(path,irun))\n",
    "            try:\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                #--- displacement data\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "\n",
    "#     def Junk(self,path,nruns):\n",
    "#         self.perAtomData = {}\n",
    "#         self.Descriptors = {}\n",
    "#         self.Shape       = {}\n",
    "#         self.Positions   = {}\n",
    "#         self.Catalogs    = {}\n",
    "#         #\n",
    "#         rwjs = utl.ReadWriteJson()\n",
    "#         for irun in range(nruns):\n",
    "#             try:\n",
    "# #                 data_json               = rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]\n",
    "# #                 self.Descriptors[irun]  = np.c_[data_json['data']]\n",
    "# #                 self.Shape[irun]        = np.c_[data_json['shape']].flatten()\n",
    "# #                 self.Positions[irun]    = np.c_[data_json['xyz']]\n",
    "#                 os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "#                 data                    = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "#                 self.perAtomData[irun]  = pd.DataFrame(np.c_[data],\n",
    "#                                                        columns ='id type x y z'.split()\n",
    "#                                                       )\n",
    "#                 self.Catalogs[irun]     = pd.read_csv('%s/Run%s/catalog.txt'%(path,irun))\n",
    "#             except:\n",
    "# #                 if self.verbose:\n",
    "# #                     traceback.print_exc()\n",
    "#                 continue\n",
    "                \n",
    "        \n",
    "#         self.nruns     = list(self.perAtomData.keys())\n",
    "#         self.nruns.sort()\n",
    "\n",
    "#         self.Descriptors[ 0 ] = pd.DataFrame(np.random.random(size=9876))\n",
    "#         #--- assert shape and positions are the same for all realizations\n",
    "# #         self.shape     = self.Shape[ self.nruns[ 0 ] ]\n",
    "# #         self.positions = self.Positions[ self.nruns[ 0 ] ]\n",
    "\n",
    "        \n",
    "        \n",
    "    def Parse2nd(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        self.Descriptors = {}\n",
    "        self.Shape       = {}\n",
    "        self.Positions   = {}\n",
    "        self.Catalogs    = {}\n",
    "        #\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                data_json               = rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]\n",
    "                self.Descriptors[irun]  = np.c_[data_json['data']]\n",
    "                self.Shape[irun]        = np.c_[data_json['shape']].flatten()\n",
    "                self.Positions[irun]    = np.c_[data_json['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                data                    = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                self.perAtomData[irun]  = pd.DataFrame(np.c_[data],\n",
    "                                                       columns ='id type x y z'.split()\n",
    "                                                      )\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/catalog.txt'%(path,irun))\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns     = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "\n",
    "        #--- assert shape and positions are the same for all realizations\n",
    "        self.shape     = self.Shape[ self.nruns[ 0 ] ]\n",
    "        self.positions = self.Positions[ self.nruns[ 0 ] ]\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "#         pdb.set_trace()\n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        atom_ids.sort()\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "#        descriptors_center_atoms = self.descriptors[atom_ids]\n",
    "        descriptors_center_atoms = np.c_[list(map(lambda x:self.Descriptors[sdict[x]][x], atom_ids))]\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystalline atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        descriptors_crystalline = self.descriptors[filtr]\n",
    "\n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- merge descriptors\n",
    "        self.descriptors = np.concatenate([descriptors_center_atoms,descriptors_crystalline],axis=0)\n",
    "\n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "    def Combine2nd(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "            \n",
    "        irun = self.nruns[0]\n",
    "        keys = list( self.perAtomData[ irun ].keys() )\n",
    "\n",
    "        #--- center atoms\n",
    "        data_concat         = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[x]],self.nruns)),axis=0)\n",
    "        self.perAtomData    = pd.DataFrame(data_concat,\n",
    "                                 columns=keys\n",
    "                                )\n",
    "        self.descriptors    = np.concatenate(list(map(lambda x:self.Descriptors[x], self.nruns)))\n",
    "    \n",
    "#     def Junk2nd(self):\n",
    "        \n",
    "#         if self.verbose:\n",
    "#             print('concatenating descriptors ...')\n",
    "            \n",
    "#         irun = self.nruns[0]\n",
    "#         keys = list( self.perAtomData[ irun ].keys() )\n",
    "\n",
    "#         #--- center atoms\n",
    "#         data_concat         = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[x]],self.nruns)),axis=0)\n",
    "#         self.perAtomData    = pd.DataFrame(data_concat,\n",
    "#                                  columns=keys\n",
    "#                                 )\n",
    "#         self.descriptors    = None #self.Descriptors[0]\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def zscore(slist):\n",
    "#         tmp = np.copy(slist)\n",
    "#         print(np.mean(tmp),np.std(tmp))\n",
    "#         tmp -= np.mean(tmp)\n",
    "#         tmp /= np.std(tmp)\n",
    "#         return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def SklearnMLP(self,X_train,y_train):\n",
    "        #-----------------------\n",
    "        #--- parameter grid\n",
    "        #-----------------------\n",
    "#         param_grid = {\n",
    "#                         'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "#                          #'activation' : ['tanh', 'relu'],\n",
    "#                          'learning_rate_init':self.learning_rate_init,\n",
    "# #                         'alpha':self.alpha, #--- regularization \n",
    "#                          #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "#                         'n_iter_no_change':self.n_iter_no_change,\n",
    "# #                        'tol':self.tol,\n",
    "#                         'max_iter':self.max_iter,\n",
    "#                      } \n",
    "        mlp   =  MLPClassifier(random_state=1,\n",
    "                               hidden_layer_sizes = self.hidden_layer_sizes[0],\n",
    "                               learning_rate_init = self.learning_rate_init[0],\n",
    "                               n_iter_no_change   = self.n_iter_no_change[0],\n",
    "                               max_iter           = self.max_iter[0],\n",
    "                               verbose=self.verbose)\n",
    "#         clf  =  GridSearchCV(mlp, param_grid)\n",
    "#        clf.fit(X_train,y_train)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        model =  mlp #clf.best_estimator_\n",
    "        loss  =  model.loss_curve_\n",
    "        val_loss = loss\n",
    "        return (model, loss, val_loss)\n",
    "\n",
    "    def KerasANN(self, X_train, y_train,X_test, y_test, ndime):\n",
    "\n",
    "        model     = keras.Sequential([ #--- The network architecture\n",
    "                                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                #                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                                    layers.Dense(ndime, activation='softmax')\n",
    "                                    ])\n",
    "        \n",
    "#         shape         =  (self.shape[0]*self.shape[1]*self.shape[2],)\n",
    "#         inputs        =  keras.Input(shape=shape)\n",
    "#         #------------------------------\n",
    "#         #--- The network architecture\n",
    "#         #------------------------------\n",
    "#         x             =  layers.Dense(   self.hidden_layer_size, activation=self.activation\n",
    "#                                        )(inputs)\n",
    "#         for i in range( self.number_hidden_layers ):\n",
    "#             x       = layers.Dense( self.hidden_layer_size, activation=self.activation\n",
    "#                                      )(x)\n",
    "#         #--- output layer\n",
    "# #         x       = layers.Flatten()(x)\n",
    "#         outputs = layers.Dense( ndime, activation=self.activation)(x)\n",
    "#         model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        \n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "        model.compile( optimizer=optimizer,\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"mse\"]\n",
    "                     )\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#                                                     monitor=\"mse\",\n",
    "#                                                     save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        model.fit( X_train, y_train, \n",
    "           validation_data      = ( X_test, y_test ),\n",
    "#             callbacks           = callbacks,\n",
    "            epochs              = self.max_iter[0], \n",
    "            verbose             = self.verbose, \n",
    "            shuffle             = False, \n",
    "#             batch_size     = 32,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "         )    \n",
    "\n",
    "        model.save('best_model/convnetClassifier_from_scratch.tf')\n",
    "        loss      = model.history.history['loss']\n",
    "        val_loss  = model.history.history['val_loss']\n",
    "        best_model = model #keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        return (best_model, loss, val_loss)\n",
    "\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def MapClassIds( y ):\n",
    "        ndime         = len(set(y.flatten()))\n",
    "        class_ids     = list(set(y.flatten()))\n",
    "        class_ids.sort()\n",
    "        map_class_ids = dict(zip(class_ids,range(ndime)))        \n",
    "        return ndime, np.c_[list(map(lambda x:[map_class_ids[x]],y.flatten()))]\n",
    "    \n",
    "    @staticmethod\n",
    "    def GetSubSetCrystallineAtoms(X,y,n_train):\n",
    "        #--- data frame\n",
    "        df = pd.DataFrame( y, columns=['topoID'] )\n",
    "        #--- groups\n",
    "        sdict = df.groupby(by='topoID').groups\n",
    "        if sdict[ 0 ].shape[ 0 ] < n_train:\n",
    "            return X, y\n",
    "        indices = np.random.choice(sdict[ 0 ], size=n_train, replace=False)\n",
    "        sdict[ 0 ] = indices\n",
    "        indices_total = np.concatenate( list(map(lambda x:sdict[x],sdict)) )\n",
    "        return X[indices_total], y[ indices_total ]\n",
    "    \n",
    "    def GetLabels( self, irun ):\n",
    "        nsize                                  = self.Descriptors[ irun ].shape[ 0 ]\n",
    "        y_labels                               = np.zeros(nsize,dtype=int)\n",
    "        nonCrystallineAtomsIndices             = self.Catalogs[ irun ].AtomIndex\n",
    "        nonCrystallineAtomsTopoIds             = self.Catalogs[ irun ].IniTopoId.astype(int)\n",
    "        y_labels[ nonCrystallineAtomsIndices ] = nonCrystallineAtomsTopoIds\n",
    "        return y_labels.reshape( ( nsize, 1 ) )\n",
    "\n",
    "    \n",
    "    def TrainClassifier(self,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        #--- get labels\n",
    "        y_labels = np.concatenate( list( map(lambda x:self.GetLabels(x), self.nruns ) ) )\n",
    "        assert self.descriptors.shape[ 0 ] == y_labels.shape[ 0 ]\n",
    "        \n",
    "        #--- map topo ids to integers 0, 1 ... ndime\n",
    "        ndime, y = NeuralNetwork.MapClassIds( y_labels )\n",
    "\n",
    "        \n",
    "        X      = np.c_[self.descriptors]\n",
    "\n",
    "        #--- filter: only train a subset of crystalline atoms\n",
    "        X, y   = NeuralNetwork.GetSubSetCrystallineAtoms( X, y, self.n_train )\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/classifier.sav'%self.best_model )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.001 )\n",
    "\n",
    "\n",
    "        #--- exclude void\n",
    "#        filtr  = self.perAtomData.type==2\n",
    "#         X      = X[~filtr]\n",
    "#         y      = y[~filtr]\n",
    "\n",
    "        #--- sample from crystalline atoms\n",
    "        \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "#        train_size = self.n_train\n",
    "#        test_size  = int( self.n_train / 3 )\n",
    "        assert X.shape[0] >= self.n_train, 'increase nruns!' #train_size + train_size, 'increase nruns!'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "#                                                               test_size=test_size, train_size=train_size,\n",
    "                                                              random_state=random_state)\n",
    "        if len(set(y_train.flatten())) < ndime:\n",
    "            'warning: not every class present in train set!'\n",
    "        if len(set(y_test.flatten()))  < ndime: \n",
    "            'warning: not every class present in test set!'\n",
    "        \n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                (model, loss, val_loss) = self.SklearnMLP(X_train,y_train)\n",
    "                classes_x = model.predict(X_test) \n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                (model, loss, val_loss) = self.KerasANN(X_train, y_train,X_test, y_test, ndime)\n",
    "                predict_x = model.predict(X_test) \n",
    "                classes_x = np.argmax(predict_x,axis=1)\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkClassifier( y )\n",
    "            predict_x = model.predict(X_test) \n",
    "            classes_x = np.argmax(predict_x,axis=1)\n",
    "                    \n",
    "        #--- save loss data\n",
    "        !mkdir png\n",
    "        np.savetxt('png/val_loss_classification.txt',\n",
    "                   np.c_[range(len(loss)),loss,val_loss],\n",
    "                   header='epoch loss val_loss')\n",
    "\n",
    "        #--- confusion matrix\n",
    "        cm = confusion_matrix(y_test, classes_x,\n",
    "                         labels=range(ndime)\n",
    "                        )\n",
    "        np.savetxt('png/confusion.txt',np.c_[cm])\n",
    "\n",
    "        \n",
    "    def PrintDescriptors(self,descriptors,y,fout):\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        rwjs.Write([{'descriptors':np.c_[descriptors],\n",
    "                     'target':np.c_[y],\n",
    "                     'shape_descriptor':self.shape}],fout)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def GetTopoIds( catalog, key ): \n",
    "        TopoIds = list( catalog.groupby( by = key ).groups.keys())\n",
    "        TopoIds.sort()\n",
    "        return TopoIds \n",
    "    \n",
    "    @staticmethod\n",
    "    def MapTopoIds( TopoIds ):\n",
    "        ndime         = len( TopoIds )\n",
    "        map_TopoIds = dict(zip(TopoIds,range(ndime)))        \n",
    "        return map_TopoIds\n",
    "\n",
    "    def GetTopoArrayIndex( self, IniTopoId, FinTopoId ):\n",
    "        mappedIniTopoId = self.mappedTopoIds[ IniTopoId ]\n",
    "        mappedFinTopoId = self.mappedTopoIds[ FinTopoId ]\n",
    "        assert mappedIniTopoId < self.n_unique_transition_paths and\\\n",
    "               mappedFinTopoId < self.n_unique_transition_paths \n",
    "        return mappedIniTopoId * self.n_unique_transition_paths * self.ndime + mappedFinTopoId * self.ndime\n",
    "\n",
    "    def GetTopoArrayIndex2nd( self, ux, uy, uz ):\n",
    "        aa = np.c_[[ux,uy,uz]].T\n",
    "        H, bin_edges = np.histogramdd(aa,bins=self.bins)        \n",
    "        assert H.sum() == 1.0\n",
    "        \n",
    "        return H.astype(int).flatten()\n",
    "        \n",
    "\n",
    "    def FillTargetMatrix( self, item ):\n",
    "#        pdb.set_trace()\n",
    "        ux = item.inifin_dr * item.DirX\n",
    "        uy = item.inifin_dr * item.DirY\n",
    "        uz = item.inifin_dr * item.DirZ\n",
    "        assert np.abs( ux ) < self.umax and\\\n",
    "                np.abs( uy ) < self.umax and\\\n",
    "                np.abs( uz ) < self.umax,'ux=%e, uy=%e, uz=%e increase self.umax!'%(ux,uy,uz)\n",
    "        irow                                   = int( item.AtomIndex )\n",
    "#        icol                                   = int( self.GetTopoArrayIndex( item.IniTopoId, item.FinTopoId ) )\n",
    "        H                                   = self.GetTopoArrayIndex2nd( ux, uy, uz )\n",
    "\n",
    "        self.y_targets[ irow ] += H           \n",
    "\n",
    "    def DiscretizeTransitionPath( self ):\n",
    "         #--- hard-coded values\n",
    "        xlin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        ylin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        zlin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        self.nbinx = len(xlin)-1\n",
    "        self.nbiny = len(ylin)-1\n",
    "        self.nbinz = len(zlin)-1\n",
    "        self.bins = (xlin, ylin, zlin)\n",
    "        self.xv, self.yv, self.zv = np.meshgrid( self.bins[1][:-1], self.bins[0][:-1], self.bins[2][:-1] )\n",
    "\n",
    "#        print(yv[H==1],xv[H==1],zv[H==1])\n",
    "\n",
    "    def GetTargets( self, irun ):\n",
    "        #--- set-up y matrix\n",
    "#         IniTopoId                              = NeuralNetwork.GetTopoIds( self.Catalogs[ irun ], 'IniTopoId' )\n",
    "#         FinTopoId                              = NeuralNetwork.GetTopoIds( self.Catalogs[ irun ], 'FinTopoId' )\n",
    "#         TopoIds                                = list( set( FinTopoId + IniTopoId ) ) #--- transition path ids\n",
    "#         TopoIds.sort()\n",
    "#         self.mappedTopoIds                     = NeuralNetwork.MapTopoIds( TopoIds )\n",
    "        \n",
    "#         self.n_unique_transition_paths         = len( TopoIds )\n",
    "\n",
    "\n",
    "        nsize                                  = ( self.Descriptors[ irun ].shape[ 0 ], self.nbinx * self.nbiny * self.nbinz )\n",
    "        self.y_targets                         = np.zeros( nsize[ 0 ] * nsize[ 1 ], dtype=int ).reshape( nsize )\n",
    "        \n",
    "        #--- fill y matrix\n",
    "        self.Catalogs[ irun ].apply( lambda x: self.FillTargetMatrix( x ), axis = 1 )\n",
    "        \n",
    "        #--- assert self.y_targets is binary\n",
    "        assert set(self.y_targets.flatten()) == set(np.array([0,1])), 'decrease du!'\n",
    "        return self.y_targets\n",
    "        \n",
    "    def MaskCrystallineAtoms(self, irun ):\n",
    "        nsize                              = self.Descriptors[ irun ].shape[ 0 ]\n",
    "        mask                               = np.zeros(nsize,dtype=bool)\n",
    "        nonCrystallineAtomsIndices         = np.array( list( set( self.Catalogs[ irun ].AtomIndex ) ) )\n",
    "        mask[ nonCrystallineAtomsIndices ] = True\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def GetInputOutput( self, irun, indx ):\n",
    "        atomIndices     =  self.Catalogs[ irun ].AtomIndex\n",
    "        pixel_map_input =  self.Descriptors[ irun ][ atomIndices ]    \n",
    "        dr              =  np.c_[self.Catalogs[ irun ]['inifin_dr']].flatten()\n",
    "        dr_multi        = np.c_[ dr, dr, dr ]\n",
    "        vector_input    =  self.Catalogs[ irun ][ ' DirX      DirY      DirZ'.split() ] * dr_multi\n",
    "        output          =  self.Catalogs[ irun ][ 'barrier' ]\n",
    "        return [pixel_map_input, vector_input, output][ indx ]\n",
    "\n",
    "    def TrainRegressorBarriers(self,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #--- get transition path bitmap\n",
    "#        self.DiscretizeTransitionPath()\n",
    "#        self.ndime                                  = 4 #--- hard-coded: (ux,uy,uz,E)\n",
    "        pixel_maps_input = np.concatenate( list( map(lambda x:self.GetInputOutput(x,0), self.nruns ) ) )\n",
    "        vectors_input    = np.concatenate( list( map(lambda x:self.GetInputOutput(x,1), self.nruns ) ) )\n",
    "        scalar_output    = np.concatenate( list( map(lambda x:self.GetInputOutput(x,2), self.nruns ) ) )\n",
    "\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[pixel_maps_input,vectors_input]\n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/scaler_regression_barriers.sav'%self.best_model )\n",
    "        y      = np.c_[ scalar_output ]\n",
    "        \n",
    "        if X.shape[ 0 ] - self.n_train < 0 :  \n",
    "            X = NeuralNetwork.Duplicate(X, new_size = self.n_train )\n",
    "            y = NeuralNetwork.Duplicate(y, new_size = self.n_train )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.01 )\n",
    "        NeuralNetwork.AddGaussianNoise(y, scale = 0.01 )\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, #stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "\n",
    "                \n",
    "        (model, loss, val_loss), (X_train, X_test) = self.ConvNetworkMixedInput(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            \n",
    "            \n",
    "            #--- validation\n",
    "        NeuralNetwork.Validation(loss, val_loss, \n",
    "                                 model, \n",
    "                                 X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "    def TrainRegressorTransitionPaths(self,#stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    " #                      filtr = None,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #--- get transition path bitmaps\n",
    "        self.DiscretizeTransitionPath()\n",
    "#        self.ndime                                  = 4 #--- hard-coded: (ux,uy,uz,E)\n",
    "        y = np.concatenate( list( map(lambda x:self.GetTargets(x), self.nruns ) ) )\n",
    "\n",
    "        \n",
    "        #--- filtr crystalline atoms\n",
    "        filtr = np.concatenate( list( map(lambda x:self.MaskCrystallineAtoms(x), self.nruns ) ) )\n",
    "\n",
    "        y     = y[ filtr ]\n",
    "        \n",
    "#        pdb.set_trace()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "\n",
    "        ndime  = y.shape[1] #--- dimension of the target vector\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors[filtr]]\n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/scaler_regression.sav'%self.best_model )\n",
    "        \n",
    "        \n",
    "        if X.shape[ 0 ] - self.n_train < 0 :  \n",
    "            X = NeuralNetwork.Duplicate(X, new_size = self.n_train )\n",
    "            y = NeuralNetwork.Duplicate(y, new_size = self.n_train )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.1 )\n",
    "#        NeuralNetwork.AddGaussianNoise(y, scale = 0.1 )\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, #stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                #-----------------------\n",
    "                #--- parameter grid\n",
    "                #-----------------------\n",
    "                param_grid = {\n",
    "                                'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                                 #'activation' : ['tanh', 'relu'],\n",
    "                                 'learning_rate_init':self.learning_rate_init,\n",
    "                                'alpha':self.alpha, #--- regularization \n",
    "                                 #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                                'n_iter_no_change':self.n_iter_no_change,\n",
    "                                'tol':self.tol,\n",
    "                                'max_iter':self.max_iter,\n",
    "                             } \n",
    "                mlp   =  MLPRegressor(random_state=random_state,verbose=self.verbose) #--- mlp regressor\n",
    "                regr  =  GridSearchCV(mlp, param_grid)\n",
    "                regr.fit(X_train,y_train)\n",
    "                model =  regr.best_estimator_\n",
    "                loss  =  model.loss_curve_\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                model     = keras.Sequential([ #--- The network architecture\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "#                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(ndime, activation='softmax')\n",
    "                    ])\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "                model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "                               loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "                               metrics=[\"mse\"]\n",
    "                             )\n",
    "                model.fit(X_train, y_train, #--- “Fitting”\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          epochs=self.max_iter[0], verbose=self.verbose, batch_size=1)\n",
    "                loss      = model.history.history['loss']\n",
    "                val_loss  = model.history.history['val_loss']\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            \n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkMultiLabelClassifier(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            NeuralNetwork.ValidationMultiLabelClassification(loss, val_loss, #--- validation\n",
    "                                 model, \n",
    "                                 X_train, X_test, y_train, y_test)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "#             (model, loss, val_loss), (X_train, X_test) =\\\n",
    "#             self.ConvNetwork(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            \n",
    "            \n",
    "            #--- validation\n",
    "#             NeuralNetwork.Validation(loss, val_loss, \n",
    "#                                      model, \n",
    "#                                      X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        #--- save in ovito file\n",
    "#         if printOvito:\n",
    "#             m = self.descriptors.shape[ 0 ]\n",
    "#             indices = np.arange( m )[ filtr ]\n",
    "        \n",
    "#             if indices.shape[ 0 ] - self.n_train < 0 :  \n",
    "#                 indices = NeuralNetwork.Duplicate(indices, new_size = self.n_train )\n",
    "            \n",
    "#             indices_train, indices_test, _, _ = train_test_split(indices, indices, #stratify=stratify,\n",
    "#                                                                 random_state=random_state)\n",
    "#             self.PrintOvito( indices_test, model )\n",
    "\n",
    "    @staticmethod\n",
    "    def Validation(loss, val_loss, model, X_train, X_test, y_train, y_test):\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "#                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred_test  = model.predict(X_test)        \n",
    "        y_pred_train = model.predict(X_train)        \n",
    "#         for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "#             ax = utl.PltErr(None,None,Plot=False)\n",
    "#             #\n",
    "#             utl.PltErr(y_test[:,idime],y_pred_test[:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                        attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(None,None,Plot=False,\n",
    "#                            title='png/scatter%s.png'%idime,\n",
    "#                             ax=ax,\n",
    "#                        xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                        xlim=(-2,2),ylim=(-2,2),\n",
    "#                            )\n",
    "\n",
    "        #--- energy\n",
    "        idime = 0 #3\n",
    "        xstr  = 'energy'\n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        #\n",
    "        utl.PltErr(y_test[:,idime],y_pred_test[:,idime],\n",
    "                   attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "                   ax=ax,\n",
    "                   Plot = False,\n",
    "\n",
    "                  )\n",
    "        utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                   attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                   ax=ax,\n",
    "                   Plot = False,\n",
    "\n",
    "                  )\n",
    "        #\n",
    "        utl.PltErr(None,None,Plot=False,\n",
    "                       title='png/scatter%s.png'%idime,\n",
    "                        ax=ax,\n",
    "                   xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                   xlim=(-2,2),ylim=(-2,2),\n",
    "                       )\n",
    "\n",
    "    @staticmethod\n",
    "    def ValidationMultiLabelClassification(loss, val_loss, model, X_train, X_test, y_train, y_test):\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "#                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/lossMultiLabelClassification.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/lossMultiLabelClassification.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred_test              = model.predict(X_test)        \n",
    "        y_pred_train             = model.predict(X_train)\n",
    "        \n",
    "        threshold                = 0.5 #--- hard-coded threshold\n",
    "        binary_predictions_test  = (y_pred_test > threshold).astype(int)\n",
    "        binary_predictions_train = (y_pred_train > threshold).astype(int)\n",
    "        binary_actual_test       = (y_test > threshold).astype(int)\n",
    "        binary_actual_train      = (y_train > threshold).astype(int)\n",
    "\n",
    "        \n",
    "        \n",
    "        #--- Compute the multilabel confusion matrix\n",
    "        conf_matrix = multilabel_confusion_matrix( binary_actual_test, binary_predictions_test )\n",
    "        ndime       = conf_matrix.shape[ 1 ] * conf_matrix.shape[ 2 ]\n",
    "        conf_matrix = conf_matrix.reshape((conf_matrix.shape[0],ndime))\n",
    "        np.savetxt('png/confusionMultiLabelClassification.txt',np.c_[conf_matrix])\n",
    "        \n",
    "        \n",
    "        #--- predict displacements\n",
    "        #--- reshape y_pred\n",
    "        \n",
    "            \n",
    "        \n",
    "#         disps_predictions_test = np.concatenate([list(map(lambda x: self.GetDispsFromBinaryMaps( x ) , binary_predictions_test ))])\n",
    "#         disps_actual_test      = np.concatenate([list(map(lambda x: self.GetDispsFromBinaryMaps( x ) , binary_actual_test ))])\n",
    "        \n",
    "# #         #--- plot predictions\n",
    "# #         y_pred_test  = model.predict(X_test)        \n",
    "# #         y_pred_train = model.predict(X_train)        \n",
    "#         for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "#             ax = utl.PltErr(None,None,Plot=False)\n",
    "#             #\n",
    "#             utl.PltErr(disps_actual_test[:,idime],disps_predictions_test[:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "# #             utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "# #                        attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "# #                        ax=ax,\n",
    "# #                        Plot = False,\n",
    "\n",
    "# #                       )\n",
    "#             #\n",
    "#             utl.PltErr(None,None,Plot=False,\n",
    "#                            title='png/scatter%s.png'%idime,\n",
    "#                             ax=ax,\n",
    "#                        xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                        xlim=(-3,3),ylim=(-3,3),\n",
    "#                            )\n",
    "\n",
    "    def GetDispsFromBinaryMaps( self, binaryMap ):\n",
    "        binaryMapReshaped = binaryMap.reshape((self.nbinx, self.nbiny, self.nbinz ))\n",
    "        filtr = binaryMapReshaped == 1\n",
    "        return np.c_[self.yv[filtr],self.xv[filtr],self.zv[filtr]]\n",
    "\n",
    "        \n",
    "    def PrintOvito( self, filtr, model ):\n",
    "        #--- save in ovito\n",
    "        X          = np.c_[self.descriptors[filtr]]\n",
    "        X          = NeuralNetwork.Zscore( X )\n",
    "        X_reshaped =  X.reshape((X.shape[0],self.shape[0],self.shape[1],self.shape[2],1))\n",
    "        y_pred     = model.predict( X_reshaped )\n",
    "        with open('original.xyz','w') as fp:\n",
    "            utl.PrintOvito(self.perAtomData.iloc[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "        with open('test.xyz','w') as fp:\n",
    "            xyz = self.perAtomData.iloc[filtr]['id type x y z'.split()]\n",
    "            cordc = pd.DataFrame(np.c_[xyz,y_pred[:,:3]],columns='id type x y z ux uy uz'.split())\n",
    "            utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "                \n",
    "\n",
    "    def ConvNetworkMixedInput(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels: pixel map\n",
    "        shape_vector_input = 3\n",
    "        \n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ] - shape_vector_input\n",
    "        pixel_map_input        =  keras.Input(shape=shape)\n",
    "        vector_input           =  keras.Input(shape=(shape_vector_input,))\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(pixel_map_input)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "        x       = layers.Flatten()(x)\n",
    "            \n",
    "        #--- concatenate flattened map with vector\n",
    "        combined = keras.layers.concatenate( [ x, vector_input ] )\n",
    "        \n",
    "        #--- output layer\n",
    "        outputs = layers.Dense( ndime )( combined ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=[pixel_map_input,vector_input], outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        model.summary()\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        nn = X_train.shape[ 1 ]\n",
    "        X_train_pixels = X_train[:,0:nn-shape_vector_input]\n",
    "        X_test_pixels  = X_test[:,0:nn-shape_vector_input]\n",
    "        assert    X_train_pixels.shape[ 1 ] ==    shape[0] * shape[1] * shape[2]\n",
    "        X_train_vector = X_train[:,nn-shape_vector_input:nn]\n",
    "        X_test_vector  = X_test[:,nn-shape_vector_input:nn]\n",
    "        assert    X_train_vector.shape[ 1 ] ==   shape_vector_input\n",
    "        \n",
    "    \n",
    "        X_train_pixels =  X_train_pixels.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_pixels  =  X_test_pixels.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        \n",
    "        model.fit( [X_train_pixels,X_train_vector], y_train, \n",
    "                   validation_data      = ( [X_test_pixels,X_test_vector], y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetRegressorMixedInput_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), ([X_train_pixels,X_train_vector], [X_test_pixels,X_test_vector])\n",
    "    \n",
    "    def ConvNetwork(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime )( x ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetRegressor_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "    def ConvNetworkMultiLabelClassifier(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  'relu' #self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation='sigmoid' )( x ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"binary_crossentropy\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetMultiLabelClassifier_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "    def ConvNetworkClassifier(self,y,\n",
    "                               random_state=1\n",
    "                               ):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        \n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        if self.verbose:\n",
    "            print('X.shape:=',X.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- set model parameters\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss=[\"binary_crossentropy\",\"sparse_categorical_crossentropy\"][1],\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#                                                     monitor=\"accuracy\",\n",
    "#                                                     save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetClassifier_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = model #keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def Duplicate(X, new_size = 100 ):\n",
    "        m = m0 = X.shape[ 0 ]\n",
    "#        n = X.shape[ 1 ]\n",
    "        augmented_x = np.copy( X )\n",
    "\n",
    "        while m <= new_size:\n",
    "            augmented_x = np.concatenate([augmented_x,X],axis = 0)\n",
    "            #\n",
    "            m = augmented_x.shape[ 0 ]\n",
    "\n",
    "        assert m > new_size\n",
    "\n",
    "        return augmented_x[:new_size]\n",
    "\n",
    "    @staticmethod    \n",
    "    def AddGaussianNoise(X,scale = 0.1):\n",
    "\n",
    "        epsilon_x = np.random.normal(scale=scale,size=X.size).reshape(X.shape)\n",
    "        X += epsilon_x\n",
    "        \n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, irun, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "                    disp           = np.c_[self.perAtomData[ irun ].iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.Positions[ irun ].T,self.Descriptors[ irun ][atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, 'disp = %s'%disp, attr_list='x y z mass'.split())\n",
    "                    \n",
    "    @staticmethod\n",
    "    def Zscore( X, **kwargs ):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        \n",
    "        if 'save_model' in kwargs:\n",
    "            pickle.dump( scaler, open( kwargs[ 'save_model' ], 'wb' ) )\n",
    "        return scaler.transform( X )\n",
    "\n",
    "#     def SaveConf(self,fout):\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[self.perAtomData],header=' '.join(list(self.perAtomData.keys())))\n",
    "\n",
    "#     def Test(self,y,\n",
    "#                                    random_state=1\n",
    "#                                    ):\n",
    "#             '''\n",
    "#             Convolutional neural network.\n",
    "\n",
    "#             Parameters\n",
    "#             ----------\n",
    "#             X_train : array-like training x input\n",
    "\n",
    "#             y_train : array-like, training y input\n",
    "\n",
    "#             X_test : array-like test x input\n",
    "\n",
    "#             y_test : array-like, training y input\n",
    "\n",
    "#             Return\n",
    "#             ---------- ( , loss,  )\n",
    "#             best_model : cnn object, best trained model based on on the validation loss\n",
    "\n",
    "#             loss : array-like, mse loss\n",
    "\n",
    "#             val_loss : array-like, validation loss\n",
    "\n",
    "#             '''\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('dim(y)=',y.shape)\n",
    "\n",
    "#             ndime  = y.shape[1] #--- dimension of the target vector\n",
    "\n",
    "\n",
    "#             #---------------\n",
    "#             #--- zscore X\n",
    "#             #---------------        \n",
    "#             X      = np.c_[self.descriptors ]\n",
    "#             scaler = StandardScaler()\n",
    "#             scaler.fit(X)\n",
    "#             X      = scaler.transform( X )\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('X.shape:=',X.shape)\n",
    "\n",
    "\n",
    "\n",
    "#             #-----------------------\n",
    "#             #--- train-test split\n",
    "#             #-----------------------\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "#                                                                 random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "#             #---- set model parameters\n",
    "#             shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "#             kernel_size   =  self.kernel_size \n",
    "#             epochs        =  self.max_iter[0]\n",
    "#             activation    =  self.activation\n",
    "#             padding       = 'same'\n",
    "#             filters       =  self.n_channels\n",
    "#             learning_rate = self.learning_rate_init[0]\n",
    "#             #\n",
    "#             ndime         =  y_train.shape[1]\n",
    "#             n_train       =  X_train.shape[0]\n",
    "#             n_test        =  X_test.shape[0]\n",
    "#             assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "#             inputs        =  keras.Input(shape=shape)\n",
    "#             #\n",
    "#     #         pdb.set_trace()\n",
    "#             #------------------------------\n",
    "#             #--- The network architecture\n",
    "#             #------------------------------\n",
    "#             model     = keras.Sequential([\n",
    "#                 layers.Dense(self.hidden_layer_size, activation=\"relu\"),\n",
    "#     #             layers.Dense(self.hidden_layer_size), #activation=\"relu\"),\n",
    "#                 layers.Dense(2, activation=\"softmax\")\n",
    "#                 ])\n",
    "#             optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "\n",
    "#             model.compile( optimizer=\"rmsprop\",\n",
    "#                            loss=\"sparse_categorical_crossentropy\",\n",
    "#                            metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "#             #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "#             X_train_reshaped =  X_train \n",
    "#             X_test_reshaped  =  X_test\n",
    "#             model.fit( X_train_reshaped, y_train, \n",
    "#                        validation_data      = ( X_test_reshaped, y_test ),\n",
    "#     #                     callbacks=callbacks,\n",
    "#                         epochs              = epochs, \n",
    "#                         verbose             = self.verbose, \n",
    "#                         shuffle             = False, \n",
    "#     #                     batch_size     = 128,\n",
    "#                         use_multiprocessing = True,\n",
    "#                         workers             = 4,\n",
    "#                      )        \n",
    "\n",
    "\n",
    "#             #--- save best model\n",
    "#             !mkdir best_model\n",
    "#     #         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#     #                                                    monitor=\"val_loss\",\n",
    "#     #                                                   save_freq=10,\n",
    "#     #                                                     save_best_only=True)]\n",
    "\n",
    "\n",
    "#             #--- validation loss\n",
    "#             loss       = model.history.history['loss']\n",
    "#             val_loss   = model.history.history['val_loss']\n",
    "#             best_model = model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "\n",
    "#             !mkdir png\n",
    "#             utl.PltErr(range(len(loss)), loss,\n",
    "#                        yscale='log',\n",
    "#                        xstr='epoch',ystr='loss',\n",
    "#                        title='png/loss_classification.png',\n",
    "#                       )\n",
    "\n",
    "#     #         pdb.set_trace()\n",
    "#             #--- confusion matrix\n",
    "#             cm = confusion_matrix(y_test, model.predict_classes(X_test),\n",
    "#                              labels=[0, 1]\n",
    "#                             )\n",
    "#             print('cm=',cm)\n",
    "#             np.savetxt('png/confusion.txt',np.c_[cm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c303869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Catalogs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8fc70",
   "metadata": {},
   "source": [
    "## main(): classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def main():\n",
    " \n",
    "    if not eval(confParser['neural net classification']['classification']):\n",
    "        return\n",
    "    \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes   = eval(confParser['neural net classification']['hidden_layer_sizes']),\n",
    "                        learning_rate_init   = eval(confParser['neural net classification']['learning_rate_init']),\n",
    "                        n_iter_no_change     = eval(confParser['neural net classification']['n_iter_no_change']),\n",
    "                        tol                  = eval(confParser['neural net classification']['tol']),\n",
    "                        max_iter             = eval(confParser['neural net classification']['max_iter']),\n",
    "                        alpha                = eval(confParser['neural net classification']['alpha']),\n",
    "                        hidden_layer_size    = eval(confParser['neural net classification']['hidden_layer_size']),\n",
    "                        fully_connected      = eval(confParser['neural net classification']['fully_connected']),\n",
    "                        implementation       = eval(confParser['neural net classification']['implementation']),\n",
    "                        cnn                  = eval(confParser['neural net classification']['cnn']),\n",
    "                        n_channels           = eval(confParser['neural net classification']['n_channels']),\n",
    "                        kernel_size          = eval(confParser['neural net classification']['kernel_size']),\n",
    "                        activation           = eval(confParser['neural net classification']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net classification']['number_hidden_layers']),\n",
    "                        n_train              = eval(confParser['neural net classification']['n_train']),\n",
    "                        best_model           = 'best_model',\n",
    "                        verbose              = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse2nd( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net classification']['nruns']))\n",
    "\n",
    "    nn.Combine2nd() #--- concat. descriptors\n",
    "\n",
    "    #--- classifier\n",
    "    nn.TrainClassifier()\n",
    "#        nn.Test(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    \n",
    "    \n",
    "    return nn\n",
    "\n",
    "#model_clf = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0db348",
   "metadata": {},
   "source": [
    "## main(): regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e01971ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " def main():\n",
    " \n",
    "    if not eval(confParser['neural net regression']['regression']):\n",
    "        return\n",
    "\n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes   = eval(confParser['neural net regression']['hidden_layer_sizes']),\n",
    "                        learning_rate_init   = eval(confParser['neural net regression']['learning_rate_init']),\n",
    "                        n_iter_no_change     = eval(confParser['neural net regression']['n_iter_no_change']),\n",
    "                        tol                  = eval(confParser['neural net regression']['tol']),\n",
    "                        max_iter             = eval(confParser['neural net regression']['max_iter']),\n",
    "                        alpha                = eval(confParser['neural net regression']['alpha']),\n",
    "                        hidden_layer_size    = eval(confParser['neural net regression']['hidden_layer_size']),\n",
    "                        fully_connected      = eval(confParser['neural net regression']['fully_connected']),\n",
    "                        implementation       = eval(confParser['neural net regression']['implementation']),\n",
    "                        cnn                  = eval(confParser['neural net regression']['cnn']),\n",
    "                        n_channels           = eval(confParser['neural net regression']['n_channels']),\n",
    "                        kernel_size          = eval(confParser['neural net regression']['kernel_size']),\n",
    "                        activation           = eval(confParser['neural net regression']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net regression']['number_hidden_layers']),\n",
    "                        n_train              = eval(confParser['neural net regression']['n_train']),\n",
    "                        du                   = eval(confParser['neural net regression']['du']),\n",
    "                        umax                 = eval(confParser['neural net regression']['umax']),\n",
    "                        best_model           = 'best_model',\n",
    "                        verbose              = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse2nd( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net regression']['nruns']))\n",
    "\n",
    "    nn.Combine2nd() #--- concat. descriptors\n",
    "\n",
    "    nn.TrainRegressorTransitionPaths()\n",
    "    nn.TrainRegressorBarriers()\n",
    "    \n",
    "    return nn\n",
    "\n",
    "#model_regr = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aefa4",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f1a5a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "    #--- ann\n",
    "    number_hidden_layers  = dict(zip(range(4),[1]))\n",
    "    hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "    n_channels            = dict(zip(range(4),[1]))\n",
    "    activations           = dict(zip(range(20),['relu']))\n",
    "#     string[ inums ] = \"\\t\\'5\\':\\'neuralNet/20x20/ann/classifier/layer%s/channel%s/activation%s/layer_size%s\\',\\n\" % (key_n,key_c,key_a,key_h) #--- change job name\n",
    "    \n",
    "    #--- cnn\n",
    "#     number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "#     hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "#     n_channels            = dict(zip(range(4),[8,16,32,64]))\n",
    "#     activations           = dict(zip(range(20),['linear']))\n",
    "\n",
    "    runs = range(8)\n",
    "    \n",
    "    legend = utl.Legends()\n",
    "    legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "    symbols = utl.Symbols()\n",
    "    \n",
    "    nphi = len(number_hidden_layers)\n",
    "    #---\n",
    "    count = 0\n",
    "    ax = utl.PltErr(None, None, Plot=False )\n",
    "    for key_n in number_hidden_layers:\n",
    "        number_hidden_layer = number_hidden_layers[key_n]\n",
    "#         if number_hidden_layer != 2:\n",
    "#             continue\n",
    "        for key_c in n_channels:\n",
    "            n_channel = n_channels[key_c]\n",
    "#             if n_channel != 16:\n",
    "#                 continue\n",
    "            for key_a in activations:\n",
    "                activation = activations[key_a]\n",
    "                for key_h in hidden_layer_size:\n",
    "                    nsize = hidden_layer_size[key_h]\n",
    "\n",
    "        #---\t\n",
    "#                    path = 'neuralNet/20x20/cnn/classifier/layer%s/channel%s/activation%s/layer_size%s'%(key_n,key_c,key_a,key_h) #--- change job name\n",
    "                    path = 'neuralNet/ni/interestitials/test2nd' #--- change job name\n",
    "                    fp = ['confusion.txt', 'val_loss_classification.txt','loss.txt'][ 2 ]\n",
    "                    for irun in runs:\n",
    "                        try:\n",
    "                            data = np.loadtxt('%s/Run%s/png/%s'%(path,irun,fp))\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        if fp == 'confusion.txt':\n",
    "                            accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "                            accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "                            print(data)\n",
    "                            utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                        else:\n",
    "                            epoch = data[:,0]\n",
    "                            loss = data[:,1]\n",
    "                            val_loss = data[:,2]\n",
    "\n",
    "                            utl.PltErr(epoch, loss,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=10,\n",
    "                                    label='train:%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                            utl.PltErr(epoch, val_loss,\n",
    "                               attrs=symbols.GetAttrs(count=(count+1)%7,nevery=10,\n",
    "                                    label='test:%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                    count += 1\n",
    "    ax = utl.PltErr(None, None,\n",
    "                        yscale='log',xscale='log',\n",
    "                       xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "                    ax=ax,\n",
    "                    legend=legend.Get(),\n",
    "                       title='png/training_loss.png',\n",
    "                   )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a3b1136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm=np.loadtxt('neuralNet/ni/interestitials/test2nd/Run0/png/confusionMultiLabelClassification.txt').astype(int)\n",
    "# falseNegative = list(map(lambda x: 1.0*x[0]/(x[0]+x[1]), cm))\n",
    "# truePositive  = list(map(lambda x: 1.0*x[3]/(x[2]+x[3]), cm))\n",
    "# filtr  = cm[:,3] > 0\n",
    "# cm[filtr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b74daa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend = utl.Legends()\n",
    "# legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "# symbols = utl.Symbols()\n",
    "\n",
    "# fp = ['confusion.txt', 'val_loss_classification.txt'][0]\n",
    "# data = np.loadtxt('neuralNet/ni/kmc/inactive/Run0/png/%s'%(fp))\n",
    "# ax = utl.PltErr(None, None, Plot=False )\n",
    "# if fp == 'confusion.txt':\n",
    "#     accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "#     accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "#     print(data)\n",
    "#     utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "#        attrs=symbols.GetAttrs(count=0,nevery=800,\n",
    "#             ), \n",
    "#                Plot=False,\n",
    "#                ax=ax,\n",
    "#                )\n",
    "# else:\n",
    "#     epoch = data[:,0]\n",
    "#     loss = data[:,1]\n",
    "#     val_loss = data[:,2]\n",
    "\n",
    "#     utl.PltErr(epoch, val_loss,\n",
    "#        attrs=symbols.GetAttrs(count=0,nevery=10,\n",
    "#             ), \n",
    "#                Plot=False,\n",
    "#                ax=ax,\n",
    "#                )\n",
    "    \n",
    "# ax = utl.PltErr(None, None,\n",
    "# yscale='log',xscale='log',\n",
    "# xstr='epoch',ystr='validation loss',\n",
    "# #                     ylim=(1e-1,1e1),\n",
    "# ax=ax,\n",
    "# # legend=legend.Get(),\n",
    "# title='png/training_loss.png',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506974a",
   "metadata": {},
   "source": [
    "## test example: 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1be92045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.725966 1.725967]]\n",
      "(3, 441)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# y=np.c_[[1.725966,1.725967],\n",
    "#             [-1.725966,1.725967],\n",
    "#             [-1.725966,-1.725967],\n",
    "#             [1.725966,-1.725967],\n",
    "#            ].T\n",
    "\n",
    "# X=np.concatenate([list(map(lambda x:np.load('png/descriptor%s.npy'%x).flatten(),range(4)))],axis=1)\n",
    "\n",
    "# #--- zscore\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_transfrmd = scaler.transform( X )\n",
    "\n",
    "# X_train_transfrmd, X_test_transfrmd, y_train, y_test = train_test_split(X_transfrmd, y, test_size=0.25)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# print(X_train_transfrmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69377834",
   "metadata": {},
   "source": [
    "### fully connected in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c56d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79024675\n",
      "Iteration 2, loss = 4.79153813\n",
      "Iteration 3, loss = 0.48272480\n",
      "Iteration 4, loss = 0.84242732\n",
      "Iteration 5, loss = 1.20200108\n",
      "Iteration 6, loss = 0.50029766\n",
      "Iteration 7, loss = 0.08083888\n",
      "Iteration 8, loss = 0.31471365\n",
      "Iteration 9, loss = 0.39602049\n",
      "Iteration 10, loss = 0.14417737\n",
      "Iteration 11, loss = 0.05911270\n",
      "Iteration 12, loss = 0.17784119\n",
      "Iteration 13, loss = 0.18843745\n",
      "Iteration 14, loss = 0.08671426\n",
      "Iteration 15, loss = 0.05304450\n",
      "Iteration 16, loss = 0.09624741\n",
      "Iteration 17, loss = 0.09671026\n",
      "Iteration 18, loss = 0.05631733\n",
      "Iteration 19, loss = 0.05017827\n",
      "Iteration 20, loss = 0.06458879\n",
      "Iteration 21, loss = 0.05694448\n",
      "Iteration 22, loss = 0.04181389\n",
      "Iteration 23, loss = 0.04398522\n",
      "Iteration 24, loss = 0.04448364\n",
      "Iteration 25, loss = 0.03786413\n",
      "Iteration 26, loss = 0.03483561\n",
      "Iteration 27, loss = 0.03725800\n",
      "Iteration 28, loss = 0.03546887\n",
      "Iteration 29, loss = 0.03089711\n",
      "Iteration 30, loss = 0.03086940\n",
      "Iteration 31, loss = 0.03225031\n",
      "Iteration 32, loss = 0.02917275\n",
      "Iteration 33, loss = 0.02726652\n",
      "Iteration 34, loss = 0.02892336\n",
      "Iteration 35, loss = 0.02808117\n",
      "Iteration 36, loss = 0.02537011\n",
      "Iteration 37, loss = 0.02600391\n",
      "Iteration 38, loss = 0.02698854\n",
      "Iteration 39, loss = 0.02494826\n",
      "Iteration 40, loss = 0.02394280\n",
      "Iteration 41, loss = 0.02572275\n",
      "Iteration 42, loss = 0.02497078\n",
      "Iteration 43, loss = 0.02293285\n",
      "Iteration 44, loss = 0.02413425\n",
      "Iteration 45, loss = 0.02455046\n",
      "Iteration 46, loss = 0.02270986\n",
      "Iteration 47, loss = 0.02347172\n",
      "Iteration 48, loss = 0.02360856\n",
      "Iteration 49, loss = 0.02255866\n",
      "Iteration 50, loss = 0.02314975\n",
      "Iteration 51, loss = 0.02309027\n",
      "Iteration 52, loss = 0.02259666\n",
      "Iteration 53, loss = 0.02288285\n",
      "Iteration 54, loss = 0.02297684\n",
      "Iteration 55, loss = 0.02300910\n",
      "Iteration 56, loss = 0.02306715\n",
      "Iteration 57, loss = 0.02287899\n",
      "Iteration 58, loss = 0.02262910\n",
      "Iteration 59, loss = 0.02261209\n",
      "Iteration 60, loss = 0.02282631\n",
      "Iteration 61, loss = 0.02271234\n",
      "Iteration 62, loss = 0.02245436\n",
      "Iteration 63, loss = 0.02261107\n",
      "Iteration 64, loss = 0.02257859\n",
      "Iteration 65, loss = 0.02275319\n",
      "Iteration 66, loss = 0.02301587\n",
      "Iteration 67, loss = 0.02290518\n",
      "Iteration 68, loss = 0.02263656\n",
      "Iteration 69, loss = 0.02244420\n",
      "Iteration 70, loss = 0.02264114\n",
      "Iteration 71, loss = 0.02285952\n",
      "Iteration 72, loss = 0.02284724\n",
      "Iteration 73, loss = 0.02254051\n",
      "Iteration 74, loss = 0.02253781\n",
      "Iteration 75, loss = 0.02259026\n",
      "Iteration 76, loss = 0.02266804\n",
      "Iteration 77, loss = 0.02250421\n",
      "Iteration 78, loss = 0.02246337\n",
      "Iteration 79, loss = 0.02244526\n",
      "Iteration 80, loss = 0.02255226\n",
      "Iteration 81, loss = 0.02250348\n",
      "Iteration 82, loss = 0.02240397\n",
      "Iteration 83, loss = 0.02242926\n",
      "Iteration 84, loss = 0.02245178\n",
      "Iteration 85, loss = 0.02249455\n",
      "Iteration 86, loss = 0.02250251\n",
      "Iteration 87, loss = 0.02240619\n",
      "Iteration 88, loss = 0.02238247\n",
      "Iteration 89, loss = 0.02239953\n",
      "Iteration 90, loss = 0.02242186\n",
      "Iteration 91, loss = 0.02243013\n",
      "Iteration 92, loss = 0.02237696\n",
      "Iteration 93, loss = 0.02237238\n",
      "Iteration 94, loss = 0.02236637\n",
      "Iteration 95, loss = 0.02241898\n",
      "Iteration 96, loss = 0.02244555\n",
      "Iteration 97, loss = 0.02243013\n",
      "Iteration 98, loss = 0.02236881\n",
      "Iteration 99, loss = 0.02236044\n",
      "Iteration 100, loss = 0.02237842\n",
      "mkdir: png: File exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# #        pdb.set_trace()\n",
    "# #--- tune parameters\n",
    "\n",
    "# #--- train\n",
    "# mlp = MLPRegressor(random_state=1,\n",
    "#                     verbose=True,\n",
    "#                    n_iter_no_change=100000,\n",
    "#                     max_iter=100,#00,\n",
    "#                    hidden_layer_sizes=(1000,1000),\n",
    "# #                    shuffle=False,\n",
    "# #                     alpha=1e-1,\n",
    "\n",
    "#                   )\n",
    "# mlp.fit(X_train_transfrmd,y_train)\n",
    "\n",
    "# #--- validate\n",
    "# !mkdir png\n",
    "# utl.PltErr(range(len(mlp.loss_curve_)), mlp.loss_curve_,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            yscale='log',xscale='log',\n",
    "# #           xlim=(1,self.max_iter[0]),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )\n",
    "\n",
    "# # #         pdb.set_trace()\n",
    "# y_pred =mlp.predict(X_test_transfrmd)        \n",
    "# y_pred_train = mlp.predict(X_train_transfrmd)        \n",
    "# for idime, xstr in zip(range(2),'ux uy'.split()):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     #\n",
    "#     utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(None,None,Plot=False,\n",
    "#                    title='png/scatter%s.png'%idime,\n",
    "#                     ax=ax,\n",
    "#                xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                xlim=(-3,3),ylim=(-3,3),\n",
    "#                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.best_loss_, mlp.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=mlp.predict(X_test_transfrmd)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(2):\n",
    "#     utl.PltErr(range(data.descriptors[0,:].shape[0]),data.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n",
    "# utl.PltErr(range(data.descriptors[100,:].shape[0]),data.descriptors[100,:],\n",
    "#           attrs={'fmt':'-','color':'C0'},\n",
    "#            xscale='log',yscale='log',\n",
    "#            ax=ax,\n",
    "#            Plot=False,\n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d061978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     random_state=1)\n",
    "# regr = MLPRegressor(verbose=False,\n",
    "#                     random_state=1, \n",
    "# #                     learning_rate='adaptive',\n",
    "# #                    early_stopping=True, \n",
    "#                      n_iter_no_change=1, \n",
    "#                     tol=1e-2,\n",
    "#                      max_iter=10000000,\n",
    "# #                     solver='sgd',\n",
    "#                    ).fit(X_train, y_train)\n",
    "# regr.tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eecba",
   "metadata": {},
   "source": [
    "### fully connected in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--- The network architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512), #activation=\"relu\"),\n",
    "# #     layers.Dense(1000), #activation=\"relu\"),\n",
    "#     layers.Dense(2) #, activation=\"relu\")\n",
    "#     ])\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- Preparing the image data\n",
    "# # train_images = train_images.reshape((60000, 28 * 28))\n",
    "# # train_images = train_images.astype(\"float32\") / 255\n",
    "# # test_images = test_images.reshape((10000, 28 * 28))\n",
    "# # test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# model.fit(X_train_transfrmd, y_train, \n",
    "#             validation_data=(X_test_transfrmd, y_test),\n",
    "\n",
    "#           epochs=100, verbose=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,100),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262922c9",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f22b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.random.set_random_seed(812)\n",
    "\n",
    "# shape=(300,300,1)\n",
    "# kernel_size = (3,3)\n",
    "# epochs = 1000\n",
    "# activation = ['linear','sigmoid','relu'][0]\n",
    "# padding='same'\n",
    "# filters = 1\n",
    "# #\n",
    "# ndime = y_train.shape[1]\n",
    "# n_train = X_train_transfrmd.shape[0]\n",
    "# n_test = X_test_transfrmd.shape[0]\n",
    "# assert shape[0]*shape[1]*shape[2] == X_train_transfrmd.shape[1]\n",
    "# inputs = keras.Input(shape=shape)\n",
    "# #\n",
    "# x = layers.Conv2D(filters=filters, kernel_size=kernel_size,activation=activation,padding=padding)(inputs)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=2*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=4*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=8*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "\n",
    "# #--- The network architecture\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,epsilon=1e-08)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- save best model \n",
    "# callbacks=[keras.callbacks.ModelCheckpoint( filepath='png/convnet_from_scratch.keras',  \n",
    "#                                            monitor=\"val_loss\",\n",
    "#                                            save_freq=10,\n",
    "#                                             save_best_only=True)]\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# X_train_reshaped = X_train_transfrmd.reshape((n_train,shape[0],shape[1],1))\n",
    "# X_test_reshaped = X_test_transfrmd.reshape((n_test,shape[0],shape[1],1))\n",
    "# model.fit(X_train_reshaped, y_train, \n",
    "#             validation_data=(X_test_reshaped, y_test),\n",
    "#             #callbacks=callbacks,\n",
    "#           epochs=epochs, verbose=False, shuffle=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,epochs),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = keras.models.load_model(\"png/convnet_from_scratch.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=best_model.predict(X_test_reshaped)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf166dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (ux,uy), y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab01950",
   "metadata": {},
   "source": [
    "# gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df2cd7",
   "metadata": {},
   "source": [
    "# fixed output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "bf4ac8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evlist_dir = '%s/EVLIST_DIR'%confParser['input files']['input_path']\n",
    "events_dir = '%s/SPEC_EVENTS_DIR'%confParser['input files']['input_path']\n",
    "lib_path   = confParser['input files']['lib_path'].split()[0] #'../../HeaDef/postprocess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "f7da0b5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: junk.xyz: No such file or directory\n",
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_135_1_0.xyz\n",
      "output disp:1.5545878410339355 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.020234107971191406 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>-3.551225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>-0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.007376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1  0.000000  0.000000  3.520380\n",
       "1   2     1  0.000000  3.520380  0.000000\n",
       "2   3     1  0.000000 -0.010411 -3.551225\n",
       "3   4     1  0.000000 -3.551225 -0.010411\n",
       "4   5     1 -3.537112 -0.007376 -0.007376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_136_1_0.xyz\n",
      "output disp:1.2717750072479248 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.00922703742980957 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.551225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>-0.007376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1  0.000000  0.000000  3.520380\n",
       "1   2     1  3.520380  0.000000  0.000000\n",
       "2   3     1 -0.010411  0.000000 -3.551225\n",
       "3   4     1 -3.551225  0.000000 -0.010411\n",
       "4   5     1 -0.007376 -3.537112 -0.007376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_140_1_0.xyz\n",
      "output disp:1.4401099681854248 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.009196758270263672 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.551225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>-0.007376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1 -3.520380  0.000000  0.000000\n",
       "1   2     1  0.000000  0.000000  3.520380\n",
       "2   3     1  3.551225  0.000000 -0.010411\n",
       "3   4     1  0.010411  0.000000 -3.551225\n",
       "4   5     1  0.007376 -3.537112 -0.007376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_155_1_0.xyz\n",
      "output disp:1.4787251949310303 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.01181173324584961 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.551225</td>\n",
       "      <td>-0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>-3.551225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>-0.007376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1  0.000000 -3.520380  0.000000\n",
       "1   2     1  0.000000  0.000000  3.520380\n",
       "2   3     1  0.000000  3.551225 -0.010411\n",
       "3   4     1  0.000000  0.010411 -3.551225\n",
       "4   5     1 -3.537112  0.007376 -0.007376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_233_1_0.xyz\n",
      "output disp:1.3822648525238037 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.01116180419921875 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1  0.000000  3.520380  0.000000\n",
       "1   2     1  3.520380  0.000000  0.000000\n",
       "2   3     1 -0.010411 -3.551225  0.000000\n",
       "3   4     1 -3.551225 -0.010411  0.000000\n",
       "4   5     1 -0.007376 -0.007376 -3.537112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_234_1_0.xyz\n",
      "output disp:1.2746798992156982 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.009464025497436523 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>3.551225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>0.007376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1  0.000000  0.000000 -3.520380\n",
       "1   2     1  0.000000  3.520380  0.000000\n",
       "2   3     1  0.000000 -0.010411  3.551225\n",
       "3   4     1  0.000000 -3.551225  0.010411\n",
       "4   5     1 -3.537112 -0.007376  0.007376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_235_1_0.xyz\n",
      "output disp:1.2668020725250244 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.009237051010131836 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.551225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>0.007376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1  0.000000  0.000000 -3.520380\n",
       "1   2     1  3.520380  0.000000  0.000000\n",
       "2   3     1 -0.010411  0.000000  3.551225\n",
       "3   4     1 -3.551225  0.000000  0.010411\n",
       "4   5     1 -0.007376 -3.537112  0.007376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_236_1_0.xyz\n",
      "output disp:1.3856010437011719 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.008900165557861328 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.551225</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1 -3.520380  0.000000  0.000000\n",
       "1   2     1  0.000000  3.520380  0.000000\n",
       "2   3     1  3.551225 -0.010411  0.000000\n",
       "3   4     1  0.010411 -3.551225  0.000000\n",
       "4   5     1  0.007376 -0.007376 -3.537112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_239_1_0.xyz\n",
      "output disp:1.3074212074279785 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.009708881378173828 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.551225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>0.007376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1 -3.520380  0.000000  0.000000\n",
       "1   2     1  0.000000  0.000000 -3.520380\n",
       "2   3     1  3.551225  0.000000  0.010411\n",
       "3   4     1  0.010411  0.000000  3.551225\n",
       "4   5     1  0.007376 -3.537112  0.007376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_252_1_0.xyz\n",
      "output disp:1.278195858001709 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.006929874420166016 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1  0.000000 -3.520380  0.000000\n",
       "1   2     1  3.520380  0.000000  0.000000\n",
       "2   3     1 -0.010411  3.551225  0.000000\n",
       "3   4     1 -3.551225  0.010411  0.000000\n",
       "4   5     1 -0.007376  0.007376 -3.537112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_254_1_0.xyz\n",
      "output disp:1.3055899143218994 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.009290933609008789 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.520380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.551225</td>\n",
       "      <td>0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>3.551225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.007376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1  0.000000 -3.520380  0.000000\n",
       "1   2     1  0.000000  0.000000 -3.520380\n",
       "2   3     1  0.000000  3.551225  0.010411\n",
       "3   4     1  0.000000  0.010411  3.551225\n",
       "4   5     1 -3.537112  0.007376  0.007376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :../simulations/ni/pure/test/Run0/SPEC_EVENTS_DIR/spec_event_256_1_0.xyz\n",
      "output disp:1.2979350090026855 s\n",
      "parsing junk.xyz\n",
      "elapsed time 0.009804010391235352 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.551225</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type         x         y         z\n",
       "0   1     1 -3.520380  0.000000  0.000000\n",
       "1   2     1  0.000000 -3.520380  0.000000\n",
       "2   3     1  3.551225  0.010411  0.000000\n",
       "3   4     1  0.010411  3.551225  0.000000\n",
       "4   5     1  0.007376  0.007376 -3.537112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def ParseEvList_dir():\n",
    "    files = os.listdir(evlist_dir)\n",
    "    events={}\n",
    "    for sfile in files:\n",
    "        try:\n",
    "            kmc_step = int(sfile.split('_')[-1])\n",
    "    #        print(kmc_step)\n",
    "            filee=open('%s/%s'%(evlist_dir,sfile)) #--- open file\n",
    "            events[kmc_step] = pd.read_csv(filee,delim_whitespace=True).iloc[1:]#delimiter='')\n",
    "        except:\n",
    "            continue\n",
    "    return events\n",
    "\n",
    "def ModifyCatalog(  ):\n",
    "    '''\n",
    "    Return a dataframe including per-atom energy and defect type \n",
    "    '''        \n",
    "    kmc_step     = 1\n",
    "\n",
    "    #--- discard refined == False\n",
    "    filtr = catalog[ kmc_step ].refined == 'T'\n",
    "    catalog[ kmc_step ] = catalog[ kmc_step ][ filtr ]\n",
    "\n",
    "    #--- displacements\n",
    "    fout = 'transition_paths.json'\n",
    "    os.system('rm %s'%fout)\n",
    "    catalog[ kmc_step ].apply(lambda x:GetDispForEvents(x,fout),axis=1)\n",
    "\n",
    "    #--- modify catalog\n",
    "#     self.catalog[ kmc_step ]['refined'] = 1 #--- add column: 1\n",
    "#     self.catalog[ kmc_step ][ 'DirX DirY DirZ'.split() ] = np.c_[ list( disps_events ) ] #--- add columns: ux, uy, uz\n",
    "#     self.catalog[ kmc_step ].reset_index(drop = True, inplace=True) #--- reset index\n",
    "\n",
    "#     #--- add atom indices\n",
    "#     AtomIds     = np.c_[self.catalog[ kmc_step ].AtomId].astype(int).flatten() #--- add atom index\n",
    "#     AtomIndices = EnergyBarrier.GetDataFrameIndex(self.perAtomData, key='id', val=AtomIds)\n",
    "#     self.catalog[ kmc_step ]['AtomIndex'] = AtomIndices\n",
    "\n",
    "def GetDispForEvents( item, fout ):\n",
    "    #--- parse spec_event file including the diffusion path\n",
    "    try:\n",
    "        diffusion_path_dict = ParseSpecEvents_dir( '%s/spec_event_%s_%s_0'\\\n",
    "                                                                %( events_dir, item.AtomId, item.Spec_id ) ) \n",
    "        diffusion_path_xyz = Displacement( '%s/spec_event_%s_%s_0.xyz'\\\n",
    "                                                                 %( events_dir, item.AtomId, item.Spec_id ), 'junk.xyz' ) \n",
    "        assert diffusion_path_dict[ 'active_atom_label' ] == int( item.AtomId )\n",
    "        assert diffusion_path_dict[ 'Spec_eventId' ]      == int( item.Spec_id )\n",
    "        assert diffusion_path_dict[ 'Original_eventId' ]  == int( item.eventId )\n",
    "        assert diffusion_path_dict[ 'event_label' ][ 0 ]  == int( item.IniTopoId ) and\\\n",
    "               diffusion_path_dict[ 'event_label' ][ 1 ]  == int( item.SadTopoId ) and\\\n",
    "               diffusion_path_dict[ 'event_label' ][ 2 ]  == int( item.FinTopoId ) \n",
    "\n",
    "        #--- save as json\n",
    "        with open(fout,'a') as fp:\n",
    "            rwjs = utl.ReadWriteJson(append=True)\n",
    "            rwjs.Write( [diffusion_path_xyz.to_dict()], fp )\n",
    "        \n",
    "        return diffusion_path_dict[ 'delr_main_atom' ]\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        return [np.nan, np.nan, np.nan ]\n",
    "\n",
    "def ParseSpecEvents_dir(fp):\n",
    "    '''\n",
    "    return energy barriers associated with hopping events\n",
    "    '''\n",
    "    with open( fp ) as filee: #'%s/%s'%(self.events_dir,sfile)) #--- open file\n",
    "        xstrs             = filee.readlines()\n",
    "        Spec_eventId      = int(xstrs[0].split()[-1]) #--- specific event id\n",
    "        Original_eventId  = int(xstrs[1].split()[-1]) #--- Original eventId\n",
    "        Refinement_step   = int(xstrs[2].split()[-1]) #--- Original eventId\n",
    "        event_label       = list(map(int,xstrs[3].split()[-1:-4:-1])) #--- Original eventId\n",
    "        energy_barrier    = float(xstrs[4].split()[-1]) #--- energy\n",
    "        delr_main_atom    = list(map(float,xstrs[12].split()[-1:-4:-1]))                 \n",
    "        active_atom_label = int(xstrs[15].split()[-1])\n",
    "\n",
    "    event_label.reverse()\n",
    "    delr_main_atom.reverse()\n",
    "    return {'Spec_eventId':Spec_eventId, 'Original_eventId':Original_eventId, 'Refinement_step':Refinement_step,\\\n",
    "            'event_label':event_label,   'energy_barrier':energy_barrier,     'delr_main_atom':delr_main_atom,\\\n",
    "            'active_atom_label':active_atom_label}\n",
    "        \n",
    "def Displacement(fp, fout,verbose=True):\n",
    "    '''\n",
    "    Return total displacements \n",
    "    '''\n",
    "    !rm $fout\n",
    "#    pdb.set_trace()\n",
    "    #--- fetch parameters\n",
    "\n",
    "    #--- call ovito\n",
    "    t0 = time.time()\n",
    "    if verbose:\n",
    "        print('input :%s'%fp)\n",
    "    os.system('ovitos %s/OvitosCna.py %s %s 1 7 %s'%(lib_path,fp,fout,'header.txt'))\n",
    "    if verbose:\n",
    "        print('output disp:%s s'%(time.time()-t0))\n",
    "\n",
    "    #--- parse disp files\n",
    "    if verbose:\n",
    "        print('parsing %s'%fout)\n",
    "    t0 = time.time()\n",
    "    lmpDisp = lp.ReadDumpFile( fout )\n",
    "    lmpDisp.GetCords( ncount = sys.maxsize )\n",
    "    if verbose:\n",
    "        print('elapsed time %s s'%(time.time()-t0))\n",
    "        display(lmpDisp.coord_atoms_broken[0].head())\n",
    "    \n",
    "    dispSad = lmpDisp.coord_atoms_broken[1]['x y z'.split()] - lmpDisp.coord_atoms_broken[0]['x y z'.split()]\n",
    "    dispFin = lmpDisp.coord_atoms_broken[2]['x y z'.split()] - lmpDisp.coord_atoms_broken[0]['x y z'.split()]\n",
    "    idType_xyz = lmpDisp.coord_atoms_broken[0]['id type x y z'.split()]\n",
    "    df = pd.DataFrame(np.c_[idType_xyz, dispSad,dispFin],columns='id type x y z ux_sad uy_sad uz_sad ux_fin uy_fin uz_fin'.split())\n",
    "    \n",
    "    return df\n",
    "            \n",
    "catalog          = ParseEvList_dir()\n",
    "ModifyCatalog()\n",
    "#catalog[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "33ef0500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>ux_sad</th>\n",
       "      <th>uy_sad</th>\n",
       "      <th>uz_sad</th>\n",
       "      <th>ux_fin</th>\n",
       "      <th>uy_fin</th>\n",
       "      <th>uz_fin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>2.710000e-06</td>\n",
       "      <td>-0.066493</td>\n",
       "      <td>-0.010883</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.016851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.520380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.066401</td>\n",
       "      <td>-4.377000e-05</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.010880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>-4.112000e-05</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.007821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.551225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010411</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>7.000000e-07</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>-0.007829</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-3.537112</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.014014</td>\n",
       "      <td>-6.602020e-02</td>\n",
       "      <td>-0.013971</td>\n",
       "      <td>-0.003582</td>\n",
       "      <td>-0.014026</td>\n",
       "      <td>-0.003578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>3.537112</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.013940</td>\n",
       "      <td>6.597610e-02</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.003577</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>-0.003579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.760190</td>\n",
       "      <td>1.760190</td>\n",
       "      <td>-0.043298</td>\n",
       "      <td>-1.720990e-01</td>\n",
       "      <td>0.033284</td>\n",
       "      <td>-0.011148</td>\n",
       "      <td>-0.001658</td>\n",
       "      <td>-0.011207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.760190</td>\n",
       "      <td>1.760190</td>\n",
       "      <td>-0.043249</td>\n",
       "      <td>1.720758e-01</td>\n",
       "      <td>0.033277</td>\n",
       "      <td>-0.011146</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>-0.011208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.760190</td>\n",
       "      <td>-1.760190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033322</td>\n",
       "      <td>-1.721280e-01</td>\n",
       "      <td>-0.043224</td>\n",
       "      <td>-0.011204</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>-0.011144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.760190</td>\n",
       "      <td>1.760190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033366</td>\n",
       "      <td>1.720518e-01</td>\n",
       "      <td>-0.043227</td>\n",
       "      <td>-0.011202</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>-0.011145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.788934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.760190</td>\n",
       "      <td>0.085131</td>\n",
       "      <td>-3.650000e-06</td>\n",
       "      <td>-0.037046</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.011859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.760190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.788934</td>\n",
       "      <td>-0.036965</td>\n",
       "      <td>-4.737000e-05</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>-0.011856</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.018865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.775532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.775532</td>\n",
       "      <td>0.031540</td>\n",
       "      <td>-1.655000e-05</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.005562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.776922</td>\n",
       "      <td>-1.767566</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>0.032770</td>\n",
       "      <td>-6.134400e-03</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>-0.003474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.776922</td>\n",
       "      <td>1.767566</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>6.112800e-03</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>-0.005891</td>\n",
       "      <td>-0.003474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-1.767566</td>\n",
       "      <td>-1.776922</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>-6.120900e-03</td>\n",
       "      <td>0.032892</td>\n",
       "      <td>-0.003475</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.006092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>1.767566</td>\n",
       "      <td>-1.776922</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>6.049300e-03</td>\n",
       "      <td>0.032891</td>\n",
       "      <td>-0.003473</td>\n",
       "      <td>-0.005894</td>\n",
       "      <td>0.006091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875098</td>\n",
       "      <td>-2.736000e-05</td>\n",
       "      <td>0.875087</td>\n",
       "      <td>1.747429</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.747427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  type         x         y         z    ux_sad        uy_sad  \\\n",
       "0    1.0   1.0  0.000000  0.000000  3.520380  0.026960  2.710000e-06   \n",
       "1    2.0   1.0  3.520380  0.000000  0.000000 -0.066401 -4.377000e-05   \n",
       "2    3.0   1.0 -0.010411  0.000000 -3.551225  0.009176 -4.112000e-05   \n",
       "3    4.0   1.0 -3.551225  0.000000 -0.010411  0.012597  7.000000e-07   \n",
       "4    5.0   1.0 -0.007376 -3.537112 -0.007376 -0.014014 -6.602020e-02   \n",
       "5    6.0   1.0 -0.007376  3.537112 -0.007376 -0.013940  6.597610e-02   \n",
       "6    7.0   1.0  0.000000 -1.760190  1.760190 -0.043298 -1.720990e-01   \n",
       "7    8.0   1.0  0.000000  1.760190  1.760190 -0.043249  1.720758e-01   \n",
       "8    9.0   1.0  1.760190 -1.760190  0.000000  0.033322 -1.721280e-01   \n",
       "9   10.0   1.0  1.760190  1.760190  0.000000  0.033366  1.720518e-01   \n",
       "10  11.0   1.0 -1.788934  0.000000  1.760190  0.085131 -3.650000e-06   \n",
       "11  12.0   1.0  1.760190  0.000000 -1.788934 -0.036965 -4.737000e-05   \n",
       "12  13.0   1.0 -1.775532  0.000000 -1.775532  0.031540 -1.655000e-05   \n",
       "13  14.0   1.0 -1.776922 -1.767566 -0.007376  0.032770 -6.134400e-03   \n",
       "14  15.0   1.0 -1.776922  1.767566 -0.007376  0.032813  6.112800e-03   \n",
       "15  16.0   1.0 -0.007376 -1.767566 -1.776922  0.010617 -6.120900e-03   \n",
       "16  17.0   1.0 -0.007376  1.767566 -1.776922  0.010655  6.049300e-03   \n",
       "17  18.0   1.0  0.000000  0.000000  0.000000  0.875098 -2.736000e-05   \n",
       "\n",
       "      uz_sad    ux_fin    uy_fin    uz_fin  \n",
       "0  -0.066493 -0.010883 -0.000002  0.016851  \n",
       "1   0.027027  0.016856 -0.000005 -0.010880  \n",
       "2   0.012709 -0.000283 -0.000004 -0.007821  \n",
       "3   0.009154 -0.007829 -0.000001 -0.000284  \n",
       "4  -0.013971 -0.003582 -0.014026 -0.003578  \n",
       "5  -0.013986 -0.003577  0.014020 -0.003579  \n",
       "6   0.033284 -0.011148 -0.001658 -0.011207  \n",
       "7   0.033277 -0.011146  0.001653 -0.011208  \n",
       "8  -0.043224 -0.011204 -0.001661 -0.011144  \n",
       "9  -0.043227 -0.011202  0.001653 -0.011145  \n",
       "10 -0.037046  0.018860 -0.000002 -0.011859  \n",
       "11  0.085215 -0.011856 -0.000005  0.018865  \n",
       "12  0.031594  0.005559 -0.000003  0.005562  \n",
       "13  0.010623  0.006084  0.005887 -0.003474  \n",
       "14  0.010625  0.006087 -0.005891 -0.003474  \n",
       "15  0.032892 -0.003475  0.005886  0.006092  \n",
       "16  0.032891 -0.003473 -0.005894  0.006091  \n",
       "17  0.875087  1.747429 -0.000003  1.747427  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwjs = utl.ReadWriteJson()\n",
    "transition_paths = rwjs.Read( 'transition_paths.json' )\n",
    "pd.DataFrame(transition_paths[ 1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "889f1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm 'ovito.xyz'\n",
    "for indx, item in enumerate( transition_paths ):\n",
    "    cordc = pd.DataFrame(item)\n",
    "    with open('ovito.xyz','a') as fp: \n",
    "        utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list='id type x y z ux_fin uy_fin uz_fin'.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "be072f45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data_tensor.shape: torch.Size([12, 18, 3])\n",
      "Epoch 0, Total Loss: 237.8274688720703\n",
      "Epoch 100, Total Loss: 62.24557876586914\n",
      "Epoch 200, Total Loss: 30.588550567626953\n",
      "Epoch 300, Total Loss: 22.478500366210938\n",
      "Epoch 400, Total Loss: 20.71580696105957\n",
      "Epoch 500, Total Loss: 20.318330764770508\n",
      "Epoch 600, Total Loss: 20.150463104248047\n",
      "Epoch 700, Total Loss: 20.016510009765625\n",
      "Epoch 800, Total Loss: 19.88688850402832\n",
      "Epoch 900, Total Loss: 19.759933471679688\n",
      "Epoch 1000, Total Loss: 19.63687515258789\n",
      "Epoch 1100, Total Loss: 19.517292022705078\n",
      "Epoch 1200, Total Loss: 19.400585174560547\n",
      "Epoch 1300, Total Loss: 19.289968490600586\n",
      "Epoch 1400, Total Loss: 19.18628692626953\n",
      "Epoch 1500, Total Loss: 19.085704803466797\n",
      "Epoch 1600, Total Loss: 18.98798179626465\n",
      "Epoch 1700, Total Loss: 18.897235870361328\n",
      "Epoch 1800, Total Loss: 18.813186645507812\n",
      "Epoch 1900, Total Loss: 18.735177993774414\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class GraphNeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dims, activation):\n",
    "        super(GraphNeuralNet, self).__init__()\n",
    "        self.output_dims = output_dims\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "        self.fc_out = nn.ModuleList([nn.Linear(hidden_dims[-1], dim) for dim in output_dims])\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, adj_matrices):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation(hidden_layer(x))\n",
    "        outputs = []\n",
    "        for adj_matrix in adj_matrices:\n",
    "            hidden = torch.matmul(adj_matrix, x)\n",
    "            for fc_out in self.fc_out:\n",
    "                outputs.append(fc_out(hidden))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def compute_adjacency_matrices(input_data, rcut):\n",
    "    adj_matrices = []\n",
    "    \n",
    "    for positions in input_data:\n",
    "        num_atoms = positions.shape[0]\n",
    "        adj_matrix = torch.zeros((num_atoms, num_atoms), dtype=torch.float)\n",
    "        \n",
    "        for i in range(num_atoms):\n",
    "            for j in range(i + 1, num_atoms):\n",
    "                distance = torch.norm(positions[i] - positions[j])\n",
    "                if distance <= rcut:\n",
    "                    adj_matrix[i, j] = 1\n",
    "                    adj_matrix[j, i] = 1\n",
    "            assert adj_matrix[i,:].sum() > 0, 'dangling node : increase the cutoff!'\n",
    "        adj_matrices.append(adj_matrix)\n",
    "    \n",
    "    #--- assert no \n",
    "    return adj_matrices\n",
    "\n",
    "\n",
    "def augment_data(input_data, target_displacements, noise_std):\n",
    "    augmented_input_data = []\n",
    "    augmented_target_displacements = []\n",
    "\n",
    "    for data, target in zip(input_data, target_displacements):\n",
    "        # Add Gaussian noise to input data\n",
    "        noisy_data = data + torch.randn_like(data) * noise_std\n",
    "        augmented_input_data.append(noisy_data)\n",
    "\n",
    "        # Add Gaussian noise to target displacements\n",
    "        noisy_target = target + torch.randn_like(target) * noise_std\n",
    "        augmented_target_displacements.append(noisy_target)\n",
    "\n",
    "    return augmented_input_data, augmented_target_displacements\n",
    "\n",
    "def standardize_data(data, mean, std):\n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_dim = eval(confParser['gnn']['input_dim']) #3  # Dimensionality of atom positions (e.g., x, y, z coordinates)\n",
    "hidden_dim = eval(confParser['gnn']['hidden_dim']) #[64]  # Dimensionality of hidden layers\n",
    "output_dims = eval(confParser['gnn']['output_dims']) #[3]  # Dimensionality of displacement vectors for each snapshot\n",
    "activation = eval(confParser['gnn']['activation']) #nn.ReLU() #nn.Identity()) #F.relu)\n",
    "lr = eval(confParser['gnn']['lr'])# 1.0e-4\n",
    "ntrain = eval(confParser['gnn']['ntrain'])#100\n",
    "num_epochs = eval(confParser['gnn']['num_epochs'])#20000\n",
    "noise_std   = eval(confParser['gnn']['noise_std'])#0.1\n",
    "\n",
    "num_snapshots = len( transition_paths )\n",
    "snapshots     = range(num_snapshots)\n",
    "\n",
    "model = GraphNeuralNet(input_dim, hidden_dim, output_dims,activation) #\n",
    "\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Example training data\n",
    "num_atoms = [ len(transition_paths[ i ]['id']) for i in snapshots ]\n",
    "input_data = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "\n",
    "\n",
    "# Example target data (displacement vectors for each snapshot and each path)\n",
    "target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots for dim in output_dims]\n",
    "\n",
    "\n",
    "# Augment the dataset to have order 100 snapshots\n",
    "augmented_input_data = []\n",
    "augmented_target_displacements = []\n",
    "input_data_tensor = torch.stack(input_data)\n",
    "ntrain_initial = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "    augmented_input, augmented_target = augment_data(input_data, target_displacements, noise_std)\n",
    "    augmented_input_data.extend(augmented_input)\n",
    "    augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "adj_matrices = compute_adjacency_matrices(augmented_input_data, rcut=3.0) #[torch.randint(0, 2, (num_atoms[i], num_atoms[i])).float() for i in range(num_snapshots)]  # Random adjacency matrices for each snapshot\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate input data along a new dimension to form a single tensor\n",
    "input_data_tensor = torch.stack(augmented_input_data)\n",
    "print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "# Standardize the augmented input data\n",
    "mean = input_data_tensor.mean(dim=(0, 1))\n",
    "std = input_data_tensor.std(dim=(0, 1))\n",
    "standardized_input_data = [standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "\n",
    "\n",
    "# Convert input data to tensors\n",
    "#input_data_tensor = torch.stack(augmented_input_data)\n",
    "target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "\n",
    "# Training loop\n",
    "total_loss_hist = []\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    predicted_displacements = model(input_data_tensor, adj_matrices)\n",
    "#    predicted_displacements_tensor = torch.stack( predicted_displacements )\n",
    "    losses = []\n",
    "    for indx, i in enumerate(snapshots):\n",
    "        snapshot_losses = [criterion(pred, augmented_target_displacements[indx]) for pred in predicted_displacements[indx]]\n",
    "        losses.extend(snapshot_losses)\n",
    "#    loss = criterion(predicted_displacements_tensor, target_displacements_tensor)\n",
    "    total_loss = sum(losses)\n",
    "    total_loss.backward()\n",
    "#    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss_hist += [total_loss.detach().numpy()]\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Total Loss: {total_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "afde5af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: png: File exists\r\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir png\n",
    "utl.PltErr(range(num_epochs),total_loss_hist,\n",
    "          xscale='log',yscale='log',\n",
    "           title='png/loss.png'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "457c17b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_prediction(model, input_data, adj_matrices):\n",
    "    with torch.no_grad():\n",
    "        predicted_displacements = model(input_data, adj_matrices)\n",
    "    return predicted_displacements\n",
    "\n",
    "ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "\n",
    "    \n",
    "# Example usage\n",
    "for i_snapshot,_ in enumerate(snapshots):\n",
    "#i_snapshot = 0\n",
    "# num_atoms = len(transition_paths[ i_snapshot ]['id'])\n",
    "#input_data = torch.rand(num_atoms, input_dim)  # Input positions of atoms\n",
    "    inputt = input_data[i_snapshot] #torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i_snapshot ])['x y z'.split()]] ).float()   # Arbitrary positions of atoms for each snapshot\n",
    "\n",
    "    #adj_matrix = torch.ones(num_atoms, num_atoms)  # Adjacency matrix for the snapshot\n",
    "    adj_matrix = adj_matrices[ i_snapshot ]\n",
    "\n",
    "    predicted_displacements = make_prediction(model, inputt, adj_matrix)\n",
    "\n",
    "    \n",
    "    u_pred = torch.stack(predicted_displacements)\n",
    "    u_act  = target_displacements[i_snapshot]\n",
    "\n",
    "    colors='black red green'.split()\n",
    "    for idime in range(3):\n",
    "        utl.PltErr(u_act[:,idime],u_pred[:,idime],\n",
    "               attrs={'fmt':'x','color':colors[idime]},\n",
    "              ax=ax, Plot=False,\n",
    "              )\n",
    "        \n",
    "utl.PltErr( None,None,\n",
    "           Plot=False,\n",
    "ax=ax,\n",
    "        xlim=(-2,2),ylim=(-2,2),\n",
    "           title='png/disp.png'\n",
    "     )\n",
    "# Print predicted displacement vectors for each path\n",
    "#predicted_displacements, target_displacements[i_snapshot]\n",
    "# for i, paths in enumerate(predicted_displacements):\n",
    "#     print(f\"Predicted displacements for path {i + 1}:\")\n",
    "#     for j, displacement in enumerate(paths):\n",
    "#         print(f\"Path {i + 1}, Dimension {j + 1}: {displacement}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
