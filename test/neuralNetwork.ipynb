{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#set-parameters\" data-toc-modified-id=\"set-parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>set parameters</a></span></li><li><span><a href=\"#Parse-Lammps-dump-file\" data-toc-modified-id=\"Parse-Lammps-dump-file-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Parse Lammps dump file</a></span></li><li><span><a href=\"#Energy\" data-toc-modified-id=\"Energy-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Energy</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>main()</a></span></li></ul></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Train NN</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['parameters', 'flags', 'MsdAnalysis', 'SroAnalysis', 'input files', 'EnergyBarrier', 'neural net', 'Atomic Radius']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(confParser['input files']['lib_path'])\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f9488",
   "metadata": {},
   "source": [
    "# set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc53f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- set dynamic parameters\n",
    "temp = confParser['parameters']['temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        descriptors = {}\n",
    "        self.perAtomData = {}\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                descriptors[irun]    = np.load('%s/Run%s/descriptors.npy'%(path,irun))\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "                if self.verbose:\n",
    "                    traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        \n",
    "        #--- same configurations\n",
    "        self.descriptors = descriptors[self.nruns[0]]\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystaliine atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        \n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- filter descriptors\n",
    "        filtr[atom_ids] = True\n",
    "        self.descriptors = self.descriptors[filtr]\n",
    "        \n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "                                 \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "    @staticmethod\n",
    "    def zscore(slist):\n",
    "        tmp = np.copy(slist)\n",
    "        print(np.mean(tmp),np.std(tmp))\n",
    "        tmp -= np.mean(tmp)\n",
    "        tmp /= np.std(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def TrainClassifier(self,y,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        #--- train-test split\n",
    "        X = np.c_[self.descriptors]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        #--- tune parameters\n",
    "        param_grid = {\n",
    "                        'hidden_layer_sizes':[(100,100)],\n",
    "        #                 'activation' : ['tanh', 'relu'],\n",
    "                         'learning_rate_init':[1e-4],\n",
    "        #                'alpha':[1e-4,1e-3,1e-2], #--- regularization \n",
    "        #               'learning_rate' : ['invscaling', 'adaptive'],\n",
    "\n",
    "                     } \n",
    "\n",
    "        #--- train\n",
    "        mlp = MLPClassifier(random_state=random_state)\n",
    "        clf = GridSearchCV(mlp, param_grid)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        #--- validate\n",
    "        !mkdir png\n",
    "        utl.PltErr(range(len(clf.best_estimator_.loss_curve_)), clf.best_estimator_.loss_curve_,\n",
    "                   yscale='log',\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "\n",
    "\n",
    "        #--- confusion matrix\n",
    "        cm = confusion_matrix(y_test, clf.predict(X_test),\n",
    "                         labels=[0, 1]\n",
    "                        )\n",
    "        print('cm=',cm)\n",
    "\n",
    "    def TrainRegressor(self,stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    "                       filtr = None,\n",
    "                       ):\n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        #--- train-test split\n",
    "        X = np.c_[self.descriptors[filtr]]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "#        pdb.set_trace()\n",
    "        #--- tune parameters\n",
    "        param_grid = {\n",
    "                        'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    " #                        'activation' : ['tanh', 'relu'],\n",
    "                         'learning_rate_init':self.learning_rate_init,\n",
    "        #                'alpha':[1e-4,1e-3,1e-2], #--- regularization \n",
    "        #               'learning_rate' : ['invscaling', 'adaptive'],\n",
    "\n",
    "                     } \n",
    "\n",
    "        #--- train\n",
    "        mlp = MLPRegressor(random_state=random_state,verbose=self.verbose)\n",
    "        clf = GridSearchCV(mlp, param_grid)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        #--- validate\n",
    "        !mkdir png\n",
    "        utl.PltErr(range(len(clf.best_estimator_.loss_curve_)), clf.best_estimator_.loss_curve_,\n",
    "                   yscale='log',\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "\n",
    "#         pdb.set_trace()\n",
    "        y_pred = clf.best_estimator_.predict(X_test)        \n",
    "        y_pred_train = clf.best_estimator_.predict(X_train)        \n",
    "        for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "            ax = utl.PltErr(None,None,Plot=False)\n",
    "            #\n",
    "#             utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "            #\n",
    "            utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                       attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(None,None,Plot=False,\n",
    "                           title='png/scatter%s.png'%idime,\n",
    "                            ax=ax,\n",
    "                       xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "                       xlim=(-2,2),ylim=(-2,2),\n",
    "                           )\n",
    "            \n",
    "        if printOvito:\n",
    "            X_train, X_test, _, _ = train_test_split(self.perAtomData[filtr]['id type x y z'.split()], y, stratify=stratify,\n",
    "                                                    random_state=random_state)\n",
    "#            pdb.set_trace()\n",
    "            with open('original.xyz','w') as fp:\n",
    "                utl.PrintOvito(self.perAtomData[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('train.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_train,y_pred_train],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2123a",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>ux</th>\n",
       "      <th>uy</th>\n",
       "      <th>uz</th>\n",
       "      <th>energy_barrier</th>\n",
       "      <th>defect_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11573.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.385145</td>\n",
       "      <td>14.492855</td>\n",
       "      <td>2.124000</td>\n",
       "      <td>1.726816</td>\n",
       "      <td>-1.726792e+00</td>\n",
       "      <td>7.152557e-07</td>\n",
       "      <td>0.996834</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9426.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.882855</td>\n",
       "      <td>14.492855</td>\n",
       "      <td>2.124000</td>\n",
       "      <td>-1.726812</td>\n",
       "      <td>-1.726816e+00</td>\n",
       "      <td>-4.768372e-06</td>\n",
       "      <td>0.996806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15694.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.385145</td>\n",
       "      <td>10.995145</td>\n",
       "      <td>2.124000</td>\n",
       "      <td>1.726835</td>\n",
       "      <td>1.726784e+00</td>\n",
       "      <td>-6.914139e-06</td>\n",
       "      <td>0.996819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7235.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.134001</td>\n",
       "      <td>14.492855</td>\n",
       "      <td>0.375145</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-1.725982e+00</td>\n",
       "      <td>1.725976e+00</td>\n",
       "      <td>0.996802</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17966.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.385145</td>\n",
       "      <td>12.744001</td>\n",
       "      <td>3.872855</td>\n",
       "      <td>1.726807</td>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>-1.726816e+00</td>\n",
       "      <td>0.996822</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7637.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.882855</td>\n",
       "      <td>10.995145</td>\n",
       "      <td>2.124000</td>\n",
       "      <td>-1.726803</td>\n",
       "      <td>1.726815e+00</td>\n",
       "      <td>-6.675720e-06</td>\n",
       "      <td>0.996819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6456.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.134001</td>\n",
       "      <td>10.995145</td>\n",
       "      <td>0.375145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.726811e+00</td>\n",
       "      <td>1.726811e+00</td>\n",
       "      <td>0.996820</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.882855</td>\n",
       "      <td>12.744001</td>\n",
       "      <td>3.872855</td>\n",
       "      <td>-1.726814</td>\n",
       "      <td>3.814697e-06</td>\n",
       "      <td>-1.726806e+00</td>\n",
       "      <td>0.996820</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1282.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.134001</td>\n",
       "      <td>14.492855</td>\n",
       "      <td>3.872855</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-1.726806e+00</td>\n",
       "      <td>-1.726816e+00</td>\n",
       "      <td>0.996807</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.385145</td>\n",
       "      <td>12.744001</td>\n",
       "      <td>0.375145</td>\n",
       "      <td>1.726788</td>\n",
       "      <td>-3.814697e-06</td>\n",
       "      <td>1.726823e+00</td>\n",
       "      <td>0.996844</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.204029</td>\n",
       "      <td>42.834000</td>\n",
       "      <td>9.203984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.603905</td>\n",
       "      <td>58.764084</td>\n",
       "      <td>7.433964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.673992</td>\n",
       "      <td>23.363981</td>\n",
       "      <td>33.984009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  type          x          y          z        ux            uy  \\\n",
       "0   11573.0   1.0  23.385145  14.492855   2.124000  1.726816 -1.726792e+00   \n",
       "1    9426.0   1.0  26.882855  14.492855   2.124000 -1.726812 -1.726816e+00   \n",
       "2   15694.0   1.0  23.385145  10.995145   2.124000  1.726835  1.726784e+00   \n",
       "3    7235.0   1.0  25.134001  14.492855   0.375145 -0.000006 -1.725982e+00   \n",
       "4   17966.0   1.0  23.385145  12.744001   3.872855  1.726807  9.536743e-07   \n",
       "5    7637.0   1.0  26.882855  10.995145   2.124000 -1.726803  1.726815e+00   \n",
       "6    6456.0   1.0  25.134001  10.995145   0.375145  0.000000  1.726811e+00   \n",
       "7     600.0   1.0  26.882855  12.744001   3.872855 -1.726814  3.814697e-06   \n",
       "8    1282.0   1.0  25.134001  14.492855   3.872855  0.000002 -1.726806e+00   \n",
       "9    9020.0   1.0  23.385145  12.744001   0.375145  1.726788 -3.814697e-06   \n",
       "10      1.0   1.0   9.204029  42.834000   9.203984  0.000000  0.000000e+00   \n",
       "11      2.0   1.0  44.603905  58.764084   7.433964  0.000000  0.000000e+00   \n",
       "12      3.0   1.0  28.673992  23.363981  33.984009  0.000000  0.000000e+00   \n",
       "\n",
       "              uz  energy_barrier  defect_label  \n",
       "0   7.152557e-07        0.996834           1.0  \n",
       "1  -4.768372e-06        0.996806           1.0  \n",
       "2  -6.914139e-06        0.996819           1.0  \n",
       "3   1.725976e+00        0.996802           1.0  \n",
       "4  -1.726816e+00        0.996822           1.0  \n",
       "5  -6.675720e-06        0.996819           1.0  \n",
       "6   1.726811e+00        0.996820           1.0  \n",
       "7  -1.726806e+00        0.996820           1.0  \n",
       "8  -1.726816e+00        0.996807           1.0  \n",
       "9   1.726823e+00        0.996844           1.0  \n",
       "10  0.000000e+00             inf           0.0  \n",
       "11  0.000000e+00             inf           0.0  \n",
       "12  0.000000e+00             inf           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim(y)= (19649, 3)\n",
      "Iteration 1, loss = 20.31239674\n",
      "Iteration 2, loss = 0.04239722\n",
      "Iteration 3, loss = 0.00147534\n",
      "Iteration 4, loss = 0.00136278\n",
      "Iteration 5, loss = 0.00142207\n",
      "Iteration 6, loss = 0.00131453\n",
      "Iteration 7, loss = 0.00129030\n",
      "Iteration 8, loss = 0.00127515\n",
      "Iteration 9, loss = 0.00124831\n",
      "Iteration 10, loss = 0.00122926\n",
      "Iteration 11, loss = 0.00120159\n",
      "Iteration 12, loss = 0.00119914\n",
      "Iteration 13, loss = 0.00115853\n",
      "Iteration 14, loss = 0.00114088\n",
      "Iteration 15, loss = 0.00112657\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 20.31820970\n",
      "Iteration 2, loss = 0.04300857\n",
      "Iteration 3, loss = 0.00152525\n",
      "Iteration 4, loss = 0.00140589\n",
      "Iteration 5, loss = 0.00148190\n",
      "Iteration 6, loss = 0.00134328\n",
      "Iteration 7, loss = 0.00130807\n",
      "Iteration 8, loss = 0.00127899\n",
      "Iteration 9, loss = 0.00125348\n",
      "Iteration 10, loss = 0.00123539\n",
      "Iteration 11, loss = 0.00120815\n",
      "Iteration 12, loss = 0.00126931\n",
      "Iteration 13, loss = 0.00117617\n",
      "Iteration 14, loss = 0.00115459\n",
      "Iteration 15, loss = 0.00114388\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 20.31845709\n",
      "Iteration 2, loss = 0.04258409\n",
      "Iteration 3, loss = 0.00131856\n",
      "Iteration 4, loss = 0.00121306\n",
      "Iteration 5, loss = 0.00129708\n",
      "Iteration 6, loss = 0.00116931\n",
      "Iteration 7, loss = 0.00114234\n",
      "Iteration 8, loss = 0.00111979\n",
      "Iteration 9, loss = 0.00110539\n",
      "Iteration 10, loss = 0.00108996\n",
      "Iteration 11, loss = 0.00107475\n",
      "Iteration 12, loss = 0.00111530\n",
      "Iteration 13, loss = 0.00105256\n",
      "Iteration 14, loss = 0.00104001\n",
      "Iteration 15, loss = 0.00103493\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 20.31802566\n",
      "Iteration 2, loss = 0.04233070\n",
      "Iteration 3, loss = 0.00121252\n",
      "Iteration 4, loss = 0.00108576\n",
      "Iteration 5, loss = 0.00114742\n",
      "Iteration 6, loss = 0.00101139\n",
      "Iteration 7, loss = 0.00097573\n",
      "Iteration 8, loss = 0.00094395\n",
      "Iteration 9, loss = 0.00091881\n",
      "Iteration 10, loss = 0.00089266\n",
      "Iteration 11, loss = 0.00086557\n",
      "Iteration 12, loss = 0.00089687\n",
      "Iteration 13, loss = 0.00083371\n",
      "Iteration 14, loss = 0.00081103\n",
      "Iteration 15, loss = 0.00079703\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 20.31678957\n",
      "Iteration 2, loss = 0.04228148\n",
      "Iteration 3, loss = 0.00128140\n",
      "Iteration 4, loss = 0.00117771\n",
      "Iteration 5, loss = 0.00124758\n",
      "Iteration 6, loss = 0.00114318\n",
      "Iteration 7, loss = 0.00112063\n",
      "Iteration 8, loss = 0.00110525\n",
      "Iteration 9, loss = 0.00108907\n",
      "Iteration 10, loss = 0.00107417\n",
      "Iteration 11, loss = 0.00105428\n",
      "Iteration 12, loss = 0.00109184\n",
      "Iteration 13, loss = 0.00103842\n",
      "Iteration 14, loss = 0.00102213\n",
      "Iteration 15, loss = 0.00101645\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 124.32469139\n",
      "Iteration 2, loss = 5.39274832\n",
      "Iteration 3, loss = 0.01896602\n",
      "Iteration 4, loss = 0.00137987\n",
      "Iteration 5, loss = 0.00134743\n",
      "Iteration 6, loss = 0.00134472\n",
      "Iteration 7, loss = 0.00134216\n",
      "Iteration 8, loss = 0.00133971\n",
      "Iteration 9, loss = 0.00133716\n",
      "Iteration 10, loss = 0.00133466\n",
      "Iteration 11, loss = 0.00133189\n",
      "Iteration 12, loss = 0.00132882\n",
      "Iteration 13, loss = 0.00132647\n",
      "Iteration 14, loss = 0.00132363\n",
      "Iteration 15, loss = 0.00131974\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 124.32779597\n",
      "Iteration 2, loss = 5.39497412\n",
      "Iteration 3, loss = 0.01919432\n",
      "Iteration 4, loss = 0.00149763\n",
      "Iteration 5, loss = 0.00146632\n",
      "Iteration 6, loss = 0.00146208\n",
      "Iteration 7, loss = 0.00145931\n",
      "Iteration 8, loss = 0.00145479\n",
      "Iteration 9, loss = 0.00145150\n",
      "Iteration 10, loss = 0.00144818\n",
      "Iteration 11, loss = 0.00144340\n",
      "Iteration 12, loss = 0.00143952\n",
      "Iteration 13, loss = 0.00143606\n",
      "Iteration 14, loss = 0.00143139\n",
      "Iteration 15, loss = 0.00142725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 124.32965972\n",
      "Iteration 2, loss = 5.39470229\n",
      "Iteration 3, loss = 0.01894597\n",
      "Iteration 4, loss = 0.00127067\n",
      "Iteration 5, loss = 0.00123947\n",
      "Iteration 6, loss = 0.00123714\n",
      "Iteration 7, loss = 0.00123473\n",
      "Iteration 8, loss = 0.00123166\n",
      "Iteration 9, loss = 0.00122968\n",
      "Iteration 10, loss = 0.00122769\n",
      "Iteration 11, loss = 0.00122372\n",
      "Iteration 12, loss = 0.00122133\n",
      "Iteration 13, loss = 0.00121867\n",
      "Iteration 14, loss = 0.00121596\n",
      "Iteration 15, loss = 0.00121285\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 124.32925305\n",
      "Iteration 2, loss = 5.39111232\n",
      "Iteration 3, loss = 0.01878625\n",
      "Iteration 4, loss = 0.00121409\n",
      "Iteration 5, loss = 0.00118059\n",
      "Iteration 6, loss = 0.00117633\n",
      "Iteration 7, loss = 0.00117260\n",
      "Iteration 8, loss = 0.00116845\n",
      "Iteration 9, loss = 0.00116460\n",
      "Iteration 10, loss = 0.00116103\n",
      "Iteration 11, loss = 0.00115584\n",
      "Iteration 12, loss = 0.00115204\n",
      "Iteration 13, loss = 0.00114751\n",
      "Iteration 14, loss = 0.00114301\n",
      "Iteration 15, loss = 0.00113833\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 124.33112061\n",
      "Iteration 2, loss = 5.39200448\n",
      "Iteration 3, loss = 0.01879703\n",
      "Iteration 4, loss = 0.00122616\n",
      "Iteration 5, loss = 0.00119374\n",
      "Iteration 6, loss = 0.00119195\n",
      "Iteration 7, loss = 0.00118989\n",
      "Iteration 8, loss = 0.00118694\n",
      "Iteration 9, loss = 0.00118500\n",
      "Iteration 10, loss = 0.00118284\n",
      "Iteration 11, loss = 0.00117951\n",
      "Iteration 12, loss = 0.00117721\n",
      "Iteration 13, loss = 0.00117510\n",
      "Iteration 14, loss = 0.00117318\n",
      "Iteration 15, loss = 0.00117079\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 278.66339024\n",
      "Iteration 2, loss = 229.78275649\n",
      "Iteration 3, loss = 188.07939845\n",
      "Iteration 4, loss = 152.74583289\n",
      "Iteration 5, loss = 123.00359629\n",
      "Iteration 6, loss = 98.14515739\n",
      "Iteration 7, loss = 77.53182207\n",
      "Iteration 8, loss = 60.58932150\n",
      "Iteration 9, loss = 46.80243006\n",
      "Iteration 10, loss = 35.70695546\n",
      "Iteration 11, loss = 26.88537533\n",
      "Iteration 12, loss = 19.96359338\n",
      "Iteration 13, loss = 14.60870023\n",
      "Iteration 14, loss = 10.52788776\n",
      "Iteration 15, loss = 7.46694960\n",
      "Iteration 16, loss = 5.20898909\n",
      "Iteration 17, loss = 3.57201816\n",
      "Iteration 18, loss = 2.40660338\n",
      "Iteration 19, loss = 1.59216777\n",
      "Iteration 20, loss = 1.03386365\n",
      "Iteration 21, loss = 0.65867882\n",
      "Iteration 22, loss = 0.41158528\n",
      "Iteration 23, loss = 0.25221306\n",
      "Iteration 24, loss = 0.15158207\n",
      "Iteration 25, loss = 0.08941219\n",
      "Iteration 26, loss = 0.05184478\n",
      "Iteration 27, loss = 0.02966081\n",
      "Iteration 28, loss = 0.01685758\n",
      "Iteration 29, loss = 0.00964643\n",
      "Iteration 30, loss = 0.00568063\n",
      "Iteration 31, loss = 0.00355449\n",
      "Iteration 32, loss = 0.00244347\n",
      "Iteration 33, loss = 0.00187807\n",
      "Iteration 34, loss = 0.00159759\n",
      "Iteration 35, loss = 0.00146200\n",
      "Iteration 36, loss = 0.00139847\n",
      "Iteration 37, loss = 0.00136935\n",
      "Iteration 38, loss = 0.00135637\n",
      "Iteration 39, loss = 0.00135064\n",
      "Iteration 40, loss = 0.00134801\n",
      "Iteration 41, loss = 0.00134675\n",
      "Iteration 42, loss = 0.00134609\n",
      "Iteration 43, loss = 0.00134554\n",
      "Iteration 44, loss = 0.00134509\n",
      "Iteration 45, loss = 0.00134472\n",
      "Iteration 46, loss = 0.00134430\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 278.65890763\n",
      "Iteration 2, loss = 229.78027254\n",
      "Iteration 3, loss = 188.07790463\n",
      "Iteration 4, loss = 152.74515986\n",
      "Iteration 5, loss = 123.00327030\n",
      "Iteration 6, loss = 98.14526100\n",
      "Iteration 7, loss = 77.53204980\n",
      "Iteration 8, loss = 60.58982768\n",
      "Iteration 9, loss = 46.80298026\n",
      "Iteration 10, loss = 35.70743135\n",
      "Iteration 11, loss = 26.88593710\n",
      "Iteration 12, loss = 19.96406679\n",
      "Iteration 13, loss = 14.60918111\n",
      "Iteration 14, loss = 10.52828104\n",
      "Iteration 15, loss = 7.46729717\n",
      "Iteration 16, loss = 5.20926560\n",
      "Iteration 17, loss = 3.57230891\n",
      "Iteration 18, loss = 2.40676854\n",
      "Iteration 19, loss = 1.59231904\n",
      "Iteration 20, loss = 1.03399994\n",
      "Iteration 21, loss = 0.65878943\n",
      "Iteration 22, loss = 0.41169727\n",
      "Iteration 23, loss = 0.25232478\n",
      "Iteration 24, loss = 0.15169241\n",
      "Iteration 25, loss = 0.08952407\n",
      "Iteration 26, loss = 0.05196249\n",
      "Iteration 27, loss = 0.02977532\n",
      "Iteration 28, loss = 0.01697421\n",
      "Iteration 29, loss = 0.00976221\n",
      "Iteration 30, loss = 0.00579696\n",
      "Iteration 31, loss = 0.00367048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.00255902\n",
      "Iteration 33, loss = 0.00199330\n",
      "Iteration 34, loss = 0.00171307\n",
      "Iteration 35, loss = 0.00157769\n",
      "Iteration 36, loss = 0.00151419\n",
      "Iteration 37, loss = 0.00148517\n",
      "Iteration 38, loss = 0.00147206\n",
      "Iteration 39, loss = 0.00146638\n",
      "Iteration 40, loss = 0.00146376\n"
     ]
    }
   ],
   "source": [
    " def main():\n",
    "        \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes = eval(confParser['neural net']['hidden_layer_sizes']),\n",
    "                        learning_rate_init = eval(confParser['neural net']['learning_rate_init']),\n",
    "                        verbose=True\n",
    "    \n",
    "    )\n",
    "    nn.Parse(path=confParser['neural net']['input_path'],\n",
    "             nruns=eval(confParser['neural net']['nruns']))\n",
    "    nn.Combine()\n",
    "#     tmp = nn.df_combined.set_index('id')\n",
    "    display(nn.perAtomData.iloc[:13])\n",
    "    #    \n",
    "#    nn.PCA()\n",
    "#    nn.Spectra()\n",
    "#    nn.TrainClassifier(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    filtr = nn.perAtomData.defect_label >= 0.0 #== 1.0\n",
    "    nn.TrainRegressor( stratify=np.c_[nn.perAtomData.defect_label].astype(int),\n",
    "                        y=np.c_[nn.perAtomData[filtr]['ux uy uz'.split()]],\n",
    "                      printOvito = True,\n",
    "                      filtr=filtr,\n",
    "                     )\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(11):\n",
    "#     utl.PltErr(range(nn.descriptors[0,:].shape[0]),nn.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a8977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystalDefect",
   "language": "python",
   "name": "crystaldefect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "476.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
