{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>main()</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#test-example:-2d\" data-toc-modified-id=\"test-example:-2d-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>test example: 2d</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-connected-in-sklearn\" data-toc-modified-id=\"fully-connected-in-sklearn-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>fully connected in sklearn</a></span></li><li><span><a href=\"#fully-connected-in-keras\" data-toc-modified-id=\"fully-connected-in-keras-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>fully connected in keras</a></span></li><li><span><a href=\"#cnn\" data-toc-modified-id=\"cnn-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>cnn</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['flags', 'input files', 'EnergyBarrier', 'neural net', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "#\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "from scipy.stats import gaussian_kde\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            if irun == 0:\n",
    "                #--- same configurations!\n",
    "                self.descriptors  = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['data']]\n",
    "                self.shape        = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['shape']].flatten()\n",
    "                self.positions    = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz .'%(path,irun))\n",
    "            try:\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                #--- displacement data\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "#         pdb.set_trace()\n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        atom_ids.sort()\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "        descriptors_center_atoms = self.descriptors[atom_ids]\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystaliine atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        descriptors_crystalline = self.descriptors[filtr]\n",
    "\n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- merge descriptors\n",
    "        self.descriptors = np.concatenate([descriptors_center_atoms,descriptors_crystalline],axis=0)\n",
    "\n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "                                 \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "    @staticmethod\n",
    "    def zscore(slist):\n",
    "        tmp = np.copy(slist)\n",
    "        print(np.mean(tmp),np.std(tmp))\n",
    "        tmp -= np.mean(tmp)\n",
    "        tmp /= np.std(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def SklearnMLP(self,X_train,y_train):\n",
    "        #-----------------------\n",
    "        #--- parameter grid\n",
    "        #-----------------------\n",
    "        param_grid = {\n",
    "                        'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                         #'activation' : ['tanh', 'relu'],\n",
    "                         'learning_rate_init':self.learning_rate_init,\n",
    "                        'alpha':self.alpha, #--- regularization \n",
    "                         #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                        'n_iter_no_change':self.n_iter_no_change,\n",
    "                        'tol':self.tol,\n",
    "                        'max_iter':self.max_iter,\n",
    "                     } \n",
    "        mlp   =  MLPClassifier(random_state=random_state,verbose=self.verbose)\n",
    "        clf  =  GridSearchCV(mlp, param_grid)\n",
    "        clf.fit(X_train,y_train)\n",
    "        model =  clf.best_estimator_\n",
    "        loss  =  model.loss_curve_\n",
    "        val_loss = loss\n",
    "        return (model, loss, val_loss)\n",
    "\n",
    "    def KerasANN(self, X_train, y_train,X_test, y_test, ndime):\n",
    "\n",
    "#         model     = keras.Sequential([ #--- The network architecture\n",
    "#             layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "#             layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "#             layers.Dense(ndime, activation='softmax')\n",
    "#             ])\n",
    "        \n",
    "        shape         =  (self.shape[0]*self.shape[1]*self.shape[2],)\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Dense(   self.hidden_layer_size, activation=self.activation\n",
    "                                       )(inputs)\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.Dense( self.hidden_layer_size, activation=self.activation\n",
    "                                     )(x)\n",
    "        #--- output layer\n",
    "#         x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=self.activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        \n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "        model.compile( optimizer=optimizer,\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"accuracy\"]\n",
    "                     )\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"accuracy\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        model.fit( X_train, y_train, \n",
    "           validation_data      = ( X_test, y_test ),\n",
    "            callbacks           = callbacks,\n",
    "            epochs              = self.max_iter[0], \n",
    "            verbose             = self.verbose, \n",
    "            shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "         )        \n",
    "        loss      = model.history.history['loss']\n",
    "        val_loss  = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        return (best_model, loss, val_loss)\n",
    "                             \n",
    "    def TrainClassifier(self,y,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        ndime = 2 #--- binary classification\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "\n",
    "        #--- train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                (model, loss, val_loss) = self.SklearnMLP(X_train,y_train)\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                (model, loss, val_loss) = self.KerasANN(X_train, y_train,X_test, y_test, ndime)\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkClassifier( y )\n",
    "                    \n",
    "        #--- save loss data\n",
    "        !mkdir png\n",
    "        np.savetxt('png/val_loss_classification.txt',\n",
    "                   np.c_[range(len(loss)),loss,val_loss],\n",
    "                   header='epoch loss val_loss')\n",
    "\n",
    "        #--- confusion matrix\n",
    "        predict_x = model.predict(X_test) \n",
    "        classes_x = np.argmax(predict_x,axis=1)\n",
    "        cm = confusion_matrix(y_test, classes_x,\n",
    "                         labels=[0, 1]\n",
    "                        )\n",
    "        np.savetxt('png/confusion.txt',np.c_[cm])\n",
    "\n",
    "        \n",
    "\n",
    "    def TrainRegressor(self,stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    "                       filtr = None,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "\n",
    "        ndime  = y.shape[1] #--- dimension of the target vector\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors[filtr]]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                #-----------------------\n",
    "                #--- parameter grid\n",
    "                #-----------------------\n",
    "                param_grid = {\n",
    "                                'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                                 #'activation' : ['tanh', 'relu'],\n",
    "                                 'learning_rate_init':self.learning_rate_init,\n",
    "                                'alpha':self.alpha, #--- regularization \n",
    "                                 #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                                'n_iter_no_change':self.n_iter_no_change,\n",
    "                                'tol':self.tol,\n",
    "                                'max_iter':self.max_iter,\n",
    "                             } \n",
    "                mlp   =  MLPRegressor(random_state=random_state,verbose=self.verbose) #--- mlp regressor\n",
    "                regr  =  GridSearchCV(mlp, param_grid)\n",
    "                regr.fit(X_train,y_train)\n",
    "                model =  regr.best_estimator_\n",
    "                loss  =  model.loss_curve_\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                model     = keras.Sequential([ #--- The network architecture\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(ndime, activation=self.activation)\n",
    "                    ])\n",
    "                optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4) #--- compilation step\n",
    "                model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "                               loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "                               metrics=[\"mse\"]\n",
    "                             )\n",
    "                model.fit(X_train, y_train, #--- “Fitting”\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          epochs=self.max_iter[0], verbose=self.verbose)#, batch_size=128)\n",
    "                loss      = model.history.history['loss']\n",
    "                val_loss  = model.history.history['val_loss']\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetwork(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred       = model.predict(X_test)        \n",
    "        y_pred_train = model.predict(X_train)        \n",
    "        for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "            ax = utl.PltErr(None,None,Plot=False)\n",
    "            #\n",
    "            utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "                       attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                       attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(None,None,Plot=False,\n",
    "                           title='png/scatter%s.png'%idime,\n",
    "                            ax=ax,\n",
    "                       xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "                       xlim=(-2,2),ylim=(-2,2),\n",
    "                           )\n",
    "        \n",
    "        #--- save in ovito\n",
    "        if printOvito:\n",
    "            X_train, X_test, _, _ = train_test_split(self.perAtomData[filtr]['id type x y z'.split()], y, stratify=stratify,\n",
    "                                                    random_state=random_state)\n",
    "#            pdb.set_trace()\n",
    "            with open('original.xyz','w') as fp:\n",
    "                utl.PrintOvito(self.perAtomData[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('train.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_train,y_pred_train],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('test.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_test,y_pred],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "                \n",
    "\n",
    "    def ConvNetwork(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "                                                   monitor=\"loss\",\n",
    "                                                  save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    def ConvNetworkClassifier(self,y,\n",
    "                               random_state=1\n",
    "                               ):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        \n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        if self.verbose:\n",
    "            print('X.shape:=',X.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- set model parameters\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss=\"binary_crossentropy\",#\"sparse_categorical_crossentropy\",\n",
    "                       metrics   =  [\"accuracy\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"accuracy\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "                    disp           = np.c_[self.perAtomData.iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.positions.T,self.descriptors[atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, 'disp = %s'%disp, attr_list='x y z mass'.split())\n",
    "#     def SaveConf(self,fout):\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[self.perAtomData],header=' '.join(list(self.perAtomData.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bb593d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Combine',\n",
       " 'ConvNetwork',\n",
       " 'ConvNetworkClassifier',\n",
       " 'GetCenterAtom',\n",
       " 'KerasANN',\n",
       " 'PCA',\n",
       " 'Parse',\n",
       " 'PrintDensityMap',\n",
       " 'SklearnMLP',\n",
       " 'Spectra',\n",
       " 'TrainClassifier',\n",
       " 'TrainRegressor',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'zscore']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(NeuralNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8fc70",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating descriptors ...\n",
      "mkdir: best_model: File exists\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f832f908f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f832f908f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f832f908f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "31/32 [============================>.] - ETA: 0s - loss: 1.7118 - accuracy: 0.7863WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f831bd3fe60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f831bd3fe60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f831bd3fe60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 2s 28ms/step - loss: 1.6896 - accuracy: 0.7891 - val_loss: 1.1999 - val_accuracy: 0.8187\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 1.1091 - accuracy: 0.8496 - val_loss: 0.9263 - val_accuracy: 0.8801\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.8671 - accuracy: 0.8877 - val_loss: 0.5848 - val_accuracy: 0.9094\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6717 - accuracy: 0.9160 - val_loss: 0.4038 - val_accuracy: 0.9269\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.4784 - accuracy: 0.9238 - val_loss: 0.4237 - val_accuracy: 0.9386\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.4799 - accuracy: 0.9316 - val_loss: 0.4184 - val_accuracy: 0.9415\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.4390 - accuracy: 0.9355 - val_loss: 0.3171 - val_accuracy: 0.9415\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.3902 - accuracy: 0.9424 - val_loss: 0.3058 - val_accuracy: 0.9503\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.3222 - accuracy: 0.9453 - val_loss: 0.2633 - val_accuracy: 0.9532\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.2859 - accuracy: 0.9512 - val_loss: 0.2625 - val_accuracy: 0.9532\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.2791 - accuracy: 0.9521 - val_loss: 0.2609 - val_accuracy: 0.9591\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.2570 - accuracy: 0.9521 - val_loss: 0.2588 - val_accuracy: 0.9591\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.2446 - accuracy: 0.9541 - val_loss: 0.2615 - val_accuracy: 0.9532\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.2189 - accuracy: 0.9551 - val_loss: 0.2600 - val_accuracy: 0.9532\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.2129 - accuracy: 0.9570 - val_loss: 0.2858 - val_accuracy: 0.9591\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.2126 - accuracy: 0.9590 - val_loss: 0.2788 - val_accuracy: 0.9591\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.2102 - accuracy: 0.9600 - val_loss: 0.2548 - val_accuracy: 0.9591\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.2087 - accuracy: 0.9609 - val_loss: 0.2538 - val_accuracy: 0.9591\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1973 - accuracy: 0.9619 - val_loss: 0.2541 - val_accuracy: 0.9591\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1828 - accuracy: 0.9639 - val_loss: 0.2524 - val_accuracy: 0.9591\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.1778 - accuracy: 0.9648 - val_loss: 0.2520 - val_accuracy: 0.9620\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1687 - accuracy: 0.9658 - val_loss: 0.2512 - val_accuracy: 0.9620\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1770 - accuracy: 0.9668 - val_loss: 0.2497 - val_accuracy: 0.9620\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1524 - accuracy: 0.9668 - val_loss: 0.2513 - val_accuracy: 0.9620\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.1507 - accuracy: 0.9668 - val_loss: 0.2508 - val_accuracy: 0.9649\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.1582 - accuracy: 0.9668 - val_loss: 0.2876 - val_accuracy: 0.9678\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1478 - accuracy: 0.9648 - val_loss: 0.2854 - val_accuracy: 0.9649\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1471 - accuracy: 0.9648 - val_loss: 0.2496 - val_accuracy: 0.9649\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1478 - accuracy: 0.9658 - val_loss: 0.2853 - val_accuracy: 0.9678\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1361 - accuracy: 0.9629 - val_loss: 0.2854 - val_accuracy: 0.9649\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1354 - accuracy: 0.9619 - val_loss: 0.2885 - val_accuracy: 0.9649\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1444 - accuracy: 0.9619 - val_loss: 0.2914 - val_accuracy: 0.9649\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1217 - accuracy: 0.9619 - val_loss: 0.2918 - val_accuracy: 0.9649\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1215 - accuracy: 0.9629 - val_loss: 0.2925 - val_accuracy: 0.9649\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.1200 - accuracy: 0.9619 - val_loss: 0.2909 - val_accuracy: 0.9649\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1390 - accuracy: 0.9639 - val_loss: 0.2897 - val_accuracy: 0.9649\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1031 - accuracy: 0.9639 - val_loss: 0.2898 - val_accuracy: 0.9649\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0923 - accuracy: 0.9619 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0916 - accuracy: 0.9629 - val_loss: 0.2906 - val_accuracy: 0.9620\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0903 - accuracy: 0.9629 - val_loss: 0.2912 - val_accuracy: 0.9591\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0882 - accuracy: 0.9629 - val_loss: 0.2909 - val_accuracy: 0.9591\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0897 - accuracy: 0.9629 - val_loss: 0.2903 - val_accuracy: 0.9591\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0973 - accuracy: 0.9619 - val_loss: 0.2903 - val_accuracy: 0.9591\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0778 - accuracy: 0.9619 - val_loss: 0.2904 - val_accuracy: 0.9591\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0784 - accuracy: 0.9619 - val_loss: 0.2908 - val_accuracy: 0.9591\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0906 - accuracy: 0.9619 - val_loss: 0.2903 - val_accuracy: 0.9591\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0779 - accuracy: 0.9629 - val_loss: 0.2908 - val_accuracy: 0.9591\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1149 - accuracy: 0.9629 - val_loss: 0.2921 - val_accuracy: 0.9591\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0775 - accuracy: 0.9629 - val_loss: 0.2925 - val_accuracy: 0.9591\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1092 - accuracy: 0.9629 - val_loss: 0.2908 - val_accuracy: 0.9591\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0773 - accuracy: 0.9639 - val_loss: 0.2908 - val_accuracy: 0.9591\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0881 - accuracy: 0.9639 - val_loss: 0.2879 - val_accuracy: 0.9591\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0881 - accuracy: 0.9639 - val_loss: 0.2881 - val_accuracy: 0.9591\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0772 - accuracy: 0.9639 - val_loss: 0.2906 - val_accuracy: 0.9591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.1013 - accuracy: 0.9639 - val_loss: 0.2881 - val_accuracy: 0.9591\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0884 - accuracy: 0.9639 - val_loss: 0.2879 - val_accuracy: 0.9591\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0869 - accuracy: 0.9639 - val_loss: 0.2881 - val_accuracy: 0.9591\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0769 - accuracy: 0.9639 - val_loss: 0.2883 - val_accuracy: 0.9591\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0885 - accuracy: 0.9639 - val_loss: 0.2875 - val_accuracy: 0.9591\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0871 - accuracy: 0.9639 - val_loss: 0.2878 - val_accuracy: 0.9591\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0767 - accuracy: 0.9639 - val_loss: 0.2883 - val_accuracy: 0.9591\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0883 - accuracy: 0.9639 - val_loss: 0.2902 - val_accuracy: 0.9591\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0885 - accuracy: 0.9639 - val_loss: 0.2902 - val_accuracy: 0.9591\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.1095 - accuracy: 0.9639 - val_loss: 0.2887 - val_accuracy: 0.9561\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0764 - accuracy: 0.9639 - val_loss: 0.2889 - val_accuracy: 0.9561\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0762 - accuracy: 0.9639 - val_loss: 0.2897 - val_accuracy: 0.9561\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0939 - accuracy: 0.9629 - val_loss: 0.2890 - val_accuracy: 0.9561\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0758 - accuracy: 0.9629 - val_loss: 0.2890 - val_accuracy: 0.9561\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0935 - accuracy: 0.9629 - val_loss: 0.2892 - val_accuracy: 0.9561\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0883 - accuracy: 0.9629 - val_loss: 0.2891 - val_accuracy: 0.9561\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.0875 - accuracy: 0.9629 - val_loss: 0.2906 - val_accuracy: 0.9561\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0759 - accuracy: 0.9629 - val_loss: 0.2908 - val_accuracy: 0.9561\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0835 - accuracy: 0.9639 - val_loss: 0.2902 - val_accuracy: 0.9561\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0759 - accuracy: 0.9639 - val_loss: 0.2902 - val_accuracy: 0.9561\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0759 - accuracy: 0.9639 - val_loss: 0.2905 - val_accuracy: 0.9561\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0864 - accuracy: 0.9629 - val_loss: 0.2894 - val_accuracy: 0.9591\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0758 - accuracy: 0.9629 - val_loss: 0.2897 - val_accuracy: 0.9591\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0756 - accuracy: 0.9629 - val_loss: 0.2905 - val_accuracy: 0.9591\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0850 - accuracy: 0.9619 - val_loss: 0.2886 - val_accuracy: 0.9591\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1283 - accuracy: 0.9639 - val_loss: 0.2890 - val_accuracy: 0.9591\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0870 - accuracy: 0.9639 - val_loss: 0.2889 - val_accuracy: 0.9591\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0752 - accuracy: 0.9639 - val_loss: 0.2893 - val_accuracy: 0.9591\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0749 - accuracy: 0.9639 - val_loss: 0.2905 - val_accuracy: 0.9591\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0985 - accuracy: 0.9619 - val_loss: 0.2889 - val_accuracy: 0.9561\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0746 - accuracy: 0.9629 - val_loss: 0.2895 - val_accuracy: 0.9561\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0967 - accuracy: 0.9619 - val_loss: 0.2885 - val_accuracy: 0.9591\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0849 - accuracy: 0.9639 - val_loss: 0.2881 - val_accuracy: 0.9561\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0744 - accuracy: 0.9648 - val_loss: 0.2887 - val_accuracy: 0.9561\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0741 - accuracy: 0.9639 - val_loss: 0.2859 - val_accuracy: 0.9561\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0977 - accuracy: 0.9609 - val_loss: 0.2840 - val_accuracy: 0.9591\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0737 - accuracy: 0.9629 - val_loss: 0.2849 - val_accuracy: 0.9561\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1167 - accuracy: 0.9619 - val_loss: 0.3207 - val_accuracy: 0.9591\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0844 - accuracy: 0.9629 - val_loss: 0.3166 - val_accuracy: 0.9561\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0734 - accuracy: 0.9629 - val_loss: 0.2833 - val_accuracy: 0.9561\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0844 - accuracy: 0.9629 - val_loss: 0.3165 - val_accuracy: 0.9591\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0813 - accuracy: 0.9629 - val_loss: 0.3187 - val_accuracy: 0.9591\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0732 - accuracy: 0.9639 - val_loss: 0.3179 - val_accuracy: 0.9591\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0730 - accuracy: 0.9639 - val_loss: 0.3129 - val_accuracy: 0.9591\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0953 - accuracy: 0.9639 - val_loss: 0.3201 - val_accuracy: 0.9591\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0728 - accuracy: 0.9629 - val_loss: 0.3201 - val_accuracy: 0.9591\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0728 - accuracy: 0.9629 - val_loss: 0.3204 - val_accuracy: 0.9591\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0727 - accuracy: 0.9648 - val_loss: 0.3192 - val_accuracy: 0.9561\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.1164 - accuracy: 0.9639 - val_loss: 0.3154 - val_accuracy: 0.9591\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0847 - accuracy: 0.9639 - val_loss: 0.3158 - val_accuracy: 0.9591\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0726 - accuracy: 0.9648 - val_loss: 0.3160 - val_accuracy: 0.9591\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0726 - accuracy: 0.9648 - val_loss: 0.3168 - val_accuracy: 0.9591\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0725 - accuracy: 0.9658 - val_loss: 0.3174 - val_accuracy: 0.9591\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0724 - accuracy: 0.9648 - val_loss: 0.3169 - val_accuracy: 0.9591\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1068 - accuracy: 0.9648 - val_loss: 0.3179 - val_accuracy: 0.9561\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0714 - accuracy: 0.9648 - val_loss: 0.3180 - val_accuracy: 0.9561\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0713 - accuracy: 0.9648 - val_loss: 0.3187 - val_accuracy: 0.9561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0958 - accuracy: 0.9639 - val_loss: 0.3181 - val_accuracy: 0.9561\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0820 - accuracy: 0.9668 - val_loss: 0.2797 - val_accuracy: 0.9591\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0705 - accuracy: 0.9668 - val_loss: 0.2799 - val_accuracy: 0.9591\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0932 - accuracy: 0.9658 - val_loss: 0.2760 - val_accuracy: 0.9591\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0705 - accuracy: 0.9639 - val_loss: 0.2760 - val_accuracy: 0.9591\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0705 - accuracy: 0.9658 - val_loss: 0.2760 - val_accuracy: 0.9620\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0703 - accuracy: 0.9658 - val_loss: 0.2781 - val_accuracy: 0.9591\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0919 - accuracy: 0.9639 - val_loss: 0.2764 - val_accuracy: 0.9620\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0689 - accuracy: 0.9648 - val_loss: 0.2766 - val_accuracy: 0.9620\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0688 - accuracy: 0.9648 - val_loss: 0.3107 - val_accuracy: 0.9620\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0687 - accuracy: 0.9658 - val_loss: 0.3377 - val_accuracy: 0.9591\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0685 - accuracy: 0.9658 - val_loss: 0.3357 - val_accuracy: 0.9591\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0904 - accuracy: 0.9648 - val_loss: 0.3060 - val_accuracy: 0.9591\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0686 - accuracy: 0.9648 - val_loss: 0.3092 - val_accuracy: 0.9591\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0868 - accuracy: 0.9639 - val_loss: 0.3114 - val_accuracy: 0.9620\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0686 - accuracy: 0.9639 - val_loss: 0.3117 - val_accuracy: 0.9620\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0686 - accuracy: 0.9639 - val_loss: 0.3130 - val_accuracy: 0.9620\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0679 - accuracy: 0.9639 - val_loss: 0.3473 - val_accuracy: 0.9620\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0679 - accuracy: 0.9648 - val_loss: 0.3490 - val_accuracy: 0.9620\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0768 - accuracy: 0.9639 - val_loss: 0.3106 - val_accuracy: 0.9620\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0685 - accuracy: 0.9639 - val_loss: 0.3112 - val_accuracy: 0.9620\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0685 - accuracy: 0.9639 - val_loss: 0.3117 - val_accuracy: 0.9620\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0678 - accuracy: 0.9658 - val_loss: 0.3116 - val_accuracy: 0.9591\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0671 - accuracy: 0.9668 - val_loss: 0.3132 - val_accuracy: 0.9591\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0780 - accuracy: 0.9648 - val_loss: 0.3123 - val_accuracy: 0.9591\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0784 - accuracy: 0.9658 - val_loss: 0.3076 - val_accuracy: 0.9620\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0671 - accuracy: 0.9658 - val_loss: 0.3108 - val_accuracy: 0.9620\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.0671 - accuracy: 0.9658 - val_loss: 0.3118 - val_accuracy: 0.9620\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0671 - accuracy: 0.9658 - val_loss: 0.3137 - val_accuracy: 0.9620\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0664 - accuracy: 0.9668 - val_loss: 0.3166 - val_accuracy: 0.9620\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0755 - accuracy: 0.9668 - val_loss: 0.3137 - val_accuracy: 0.9620\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0779 - accuracy: 0.9658 - val_loss: 0.3122 - val_accuracy: 0.9620\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3121 - val_accuracy: 0.9620\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 168/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3124 - val_accuracy: 0.9620\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3104 - val_accuracy: 0.9620\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3104 - val_accuracy: 0.9620\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3104 - val_accuracy: 0.9620\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3104 - val_accuracy: 0.9620\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3104 - val_accuracy: 0.9620\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9620\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0670 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0657 - accuracy: 0.9658 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0636 - accuracy: 0.9668 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3083 - val_accuracy: 0.9620\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 280/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0630 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0609 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0589 - accuracy: 0.9658 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 336/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9620\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9668 - val_loss: 0.3043 - val_accuracy: 0.9620\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0562 - accuracy: 0.9678 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 392/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.3003 - val_accuracy: 0.9620\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2983 - val_accuracy: 0.9620\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2983 - val_accuracy: 0.9620\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0555 - accuracy: 0.9658 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0555 - accuracy: 0.9668 - val_loss: 0.2982 - val_accuracy: 0.9620\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 448/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2962 - val_accuracy: 0.9620\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0528 - accuracy: 0.9678 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0528 - accuracy: 0.9688 - val_loss: 0.2941 - val_accuracy: 0.9620\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 504/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2942 - val_accuracy: 0.9620\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 560/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 616/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0508 - accuracy: 0.9707 - val_loss: 0.2943 - val_accuracy: 0.9620\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0501 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9620\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9620\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9620\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0487 - accuracy: 0.9707 - val_loss: 0.2902 - val_accuracy: 0.9649\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0474 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0460 - accuracy: 0.9717 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 728/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9707 - val_loss: 0.2882 - val_accuracy: 0.9649\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0454 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0440 - accuracy: 0.9697 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 784/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9707 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0440 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9649\n",
      "mkdir: png: File exists\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f831be30560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f831be30560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f831be30560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "11/11 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    " def main():\n",
    " \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes = eval(confParser['neural net']['hidden_layer_sizes']),\n",
    "                        learning_rate_init = eval(confParser['neural net']['learning_rate_init']),\n",
    "                        n_iter_no_change   = eval(confParser['neural net']['n_iter_no_change']),\n",
    "                        tol                = eval(confParser['neural net']['tol']),\n",
    "                        max_iter           = eval(confParser['neural net']['max_iter']),\n",
    "                        alpha              = eval(confParser['neural net']['alpha']),\n",
    "                        hidden_layer_size  = eval(confParser['neural net']['hidden_layer_size']),\n",
    "                        fully_connected    = eval(confParser['neural net']['fully_connected']),\n",
    "                        implementation     = eval(confParser['neural net']['implementation']),\n",
    "                        cnn                = eval(confParser['neural net']['cnn']),\n",
    "                        n_channels         = eval(confParser['neural net']['n_channels']),\n",
    "                        kernel_size        = eval(confParser['neural net']['kernel_size']),\n",
    "                        activation         = eval(confParser['neural net']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net']['number_hidden_layers']),\n",
    "                        verbose            = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net']['nruns']))\n",
    "\n",
    "    nn.Combine() #--- concat. descriptors\n",
    "    \n",
    "#     tmp = nn.df_combined.set_index('id')\n",
    "#    display(nn.perAtomData.iloc[:13])\n",
    "#    nn.PrintDensityMap(6,'density6.xyz')\n",
    "#    nn.PCA()\n",
    "#    nn.Spectra()\n",
    "\n",
    "\n",
    "    #--- classifier\n",
    "    if eval(confParser['neural net']['classification']):\n",
    "        nn.TrainClassifier(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    \n",
    "    \n",
    "    #--- filter data\n",
    "    train_type = int(eval(confParser['neural net']['train_type']))\n",
    "    \n",
    "    filtr      = {\n",
    "                     0: nn.perAtomData.defect_label == 1.0, #--- only non-crystalline atoms\n",
    "                     1: np.ones(len(nn.perAtomData),dtype=bool), #--- every atom\n",
    "                    }[train_type]\n",
    "    stratify   = {\n",
    "                    0:None,\n",
    "                    1:np.c_[nn.perAtomData.defect_label].astype(int), #--- ensure same ratio in test and training\n",
    "                    }[train_type]\n",
    "\n",
    "\n",
    "    \n",
    "    #--- train regressor\n",
    "    if eval(confParser['neural net']['regression']):\n",
    "\n",
    "        nn.TrainRegressor(  stratify=stratify,\n",
    "                            y=np.c_[nn.perAtomData[filtr]['ux uy uz'.split()]],\n",
    "                            printOvito = True,\n",
    "                            filtr=filtr,\n",
    "                         )\n",
    "    return nn\n",
    "\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aefa4",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1a5a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "    #--- ann\n",
    "#     number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "#     hidden_layer_size     = dict(zip(range(4),[10,100,1000,10000]))\n",
    "#     n_channels            = dict(zip(range(4),[1]))\n",
    "#     activations           = dict(zip(range(20),['linear']))\n",
    "#     string[ inums ] = \"\\t\\'5\\':\\'neuralNet/20x20/ann/classifier/layer%s/channel%s/activation%s/layer_size%s\\',\\n\" % (key_n,key_c,key_a,key_h) #--- change job name\n",
    "    \n",
    "    #--- cnn\n",
    "    number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "    hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "    n_channels            = dict(zip(range(4),[8,16,32,64]))\n",
    "    activations           = dict(zip(range(20),['linear']))\n",
    "\n",
    "    runs = [0,1,2]\n",
    "    \n",
    "    legend = utl.Legends()\n",
    "    legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "    symbols = utl.Symbols()\n",
    "    \n",
    "    nphi = len(number_hidden_layers)\n",
    "    #---\n",
    "    count = 0\n",
    "    ax = utl.PltErr(None, None, Plot=False )\n",
    "    for key_n in number_hidden_layers:\n",
    "        number_hidden_layer = number_hidden_layers[key_n]\n",
    "#         if number_hidden_layer != 2:\n",
    "#             continue\n",
    "        for key_c in n_channels:\n",
    "            n_channel = n_channels[key_c]\n",
    "#             if n_channel != 16:\n",
    "#                 continue\n",
    "            for key_a in activations:\n",
    "                activation = activations[key_a]\n",
    "                for key_h in hidden_layer_size:\n",
    "                    nsize = hidden_layer_size[key_h]\n",
    "\n",
    "        #---\t\n",
    "                    path = 'neuralNet/20x20/cnn/classifier/layer%s/channel%s/activation%s/layer_size%s'%(key_n,key_c,key_a,key_h) #--- change job name\n",
    "#                     path = 'neuralNet/ni/keras/20x20/ann/classifier' #--- change job name\n",
    "                    fp = ['confusion.txt', 'val_loss_classification.txt'][1]\n",
    "                    for irun in runs:\n",
    "                        try:\n",
    "                            data = np.loadtxt('%s/Run%s/png/%s'%(path,irun,fp))\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        if fp == 'confusion.txt':\n",
    "                            accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "                            accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "                            print(data)\n",
    "                            utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                        else:\n",
    "                            epoch = data[:,0]\n",
    "                            loss = data[:,1]\n",
    "                            val_loss = data[:,2]\n",
    "\n",
    "                            utl.PltErr(epoch, val_loss,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                    count += 1\n",
    "    ax = utl.PltErr(None, None,\n",
    "                        yscale='log',xscale='log',\n",
    "                       xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "                    ax=ax,\n",
    "                    legend=legend.Get(),\n",
    "                       title='png/training_loss.png',\n",
    "                   )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b569fca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[328.  12.]\n",
      " [  0.   2.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# legend = utl.Legends()\n",
    "# legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "# symbols = utl.Symbols()\n",
    "\n",
    "# fp = ['confusion.txt', 'val_loss_classification.txt'][0]\n",
    "# data = np.loadtxt('png/%s'%(fp))\n",
    "# ax = utl.PltErr(None, None, Plot=False )\n",
    "# if fp == 'confusion.txt':\n",
    "#     accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "#     accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "#     print(data)\n",
    "#     utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "#        attrs=symbols.GetAttrs(count=0,nevery=800,\n",
    "#             ), \n",
    "#                Plot=False,\n",
    "#                ax=ax,\n",
    "#                )\n",
    "# else:\n",
    "#     epoch = data[:,0]\n",
    "#     loss = data[:,1]\n",
    "#     val_loss = data[:,2]\n",
    "\n",
    "#     utl.PltErr(epoch, val_loss,\n",
    "#        attrs=symbols.GetAttrs(count=0,nevery=10,\n",
    "#             ), \n",
    "#                Plot=False,\n",
    "#                ax=ax,\n",
    "#                )\n",
    "    \n",
    "# ax = utl.PltErr(None, None,\n",
    "# yscale='log',xscale='log',\n",
    "# xstr='epoch',ystr='validation loss',\n",
    "# #                     ylim=(1e-1,1e1),\n",
    "# ax=ax,\n",
    "# # legend=legend.Get(),\n",
    "# title='png/training_loss.png',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506974a",
   "metadata": {},
   "source": [
    "## test example: 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be92045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# y=np.c_[[1.725966,1.725967],\n",
    "#             [-1.725966,1.725967],\n",
    "#             [-1.725966,-1.725967],\n",
    "#             [1.725966,-1.725967],\n",
    "#            ].T\n",
    "\n",
    "# X=np.concatenate([list(map(lambda x:np.load('png/descriptor%s.npy'%x).flatten(),range(4)))],axis=1)\n",
    "\n",
    "# #--- zscore\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_transfrmd = scaler.transform( X )\n",
    "\n",
    "# X_train_transfrmd, X_test_transfrmd, y_train, y_test = train_test_split(X_transfrmd, y, test_size=0.25)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# print(X_train_transfrmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69377834",
   "metadata": {},
   "source": [
    "### fully connected in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #        pdb.set_trace()\n",
    "# #--- tune parameters\n",
    "\n",
    "# #--- train\n",
    "# mlp = MLPRegressor(random_state=1,\n",
    "# #                    verbose=True,\n",
    "#                    n_iter_no_change=100000,\n",
    "#                     max_iter=10000,\n",
    "#                    hidden_layer_sizes=(1000,1000),\n",
    "# #                    shuffle=False,\n",
    "# #                     alpha=1e-1,\n",
    "\n",
    "#                   )\n",
    "# mlp.fit(X_train_transfrmd,y_train)\n",
    "\n",
    "# #--- validate\n",
    "# !mkdir png\n",
    "# utl.PltErr(range(len(mlp.loss_curve_)), mlp.loss_curve_,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            yscale='log',xscale='log',\n",
    "# #           xlim=(1,self.max_iter[0]),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )\n",
    "\n",
    "# # #         pdb.set_trace()\n",
    "# y_pred =mlp.predict(X_test_transfrmd)        \n",
    "# y_pred_train = mlp.predict(X_train_transfrmd)        \n",
    "# for idime, xstr in zip(range(2),'ux uy'.split()):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     #\n",
    "#     utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(None,None,Plot=False,\n",
    "#                    title='png/scatter%s.png'%idime,\n",
    "#                     ax=ax,\n",
    "#                xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                xlim=(-3,3),ylim=(-3,3),\n",
    "#                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.best_loss_, mlp.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=mlp.predict(X_test_transfrmd)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(2):\n",
    "#     utl.PltErr(range(data.descriptors[0,:].shape[0]),data.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n",
    "# utl.PltErr(range(data.descriptors[100,:].shape[0]),data.descriptors[100,:],\n",
    "#           attrs={'fmt':'-','color':'C0'},\n",
    "#            xscale='log',yscale='log',\n",
    "#            ax=ax,\n",
    "#            Plot=False,\n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d061978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     random_state=1)\n",
    "# regr = MLPRegressor(verbose=False,\n",
    "#                     random_state=1, \n",
    "# #                     learning_rate='adaptive',\n",
    "# #                    early_stopping=True, \n",
    "#                      n_iter_no_change=1, \n",
    "#                     tol=1e-2,\n",
    "#                      max_iter=10000000,\n",
    "# #                     solver='sgd',\n",
    "#                    ).fit(X_train, y_train)\n",
    "# regr.tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eecba",
   "metadata": {},
   "source": [
    "### fully connected in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--- The network architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512), #activation=\"relu\"),\n",
    "# #     layers.Dense(1000), #activation=\"relu\"),\n",
    "#     layers.Dense(2) #, activation=\"relu\")\n",
    "#     ])\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- Preparing the image data\n",
    "# # train_images = train_images.reshape((60000, 28 * 28))\n",
    "# # train_images = train_images.astype(\"float32\") / 255\n",
    "# # test_images = test_images.reshape((10000, 28 * 28))\n",
    "# # test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# model.fit(X_train_transfrmd, y_train, \n",
    "#             validation_data=(X_test_transfrmd, y_test),\n",
    "\n",
    "#           epochs=100, verbose=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,100),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262922c9",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f22b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.random.set_random_seed(812)\n",
    "\n",
    "# shape=(300,300,1)\n",
    "# kernel_size = (3,3)\n",
    "# epochs = 1000\n",
    "# activation = ['linear','sigmoid','relu'][0]\n",
    "# padding='same'\n",
    "# filters = 1\n",
    "# #\n",
    "# ndime = y_train.shape[1]\n",
    "# n_train = X_train_transfrmd.shape[0]\n",
    "# n_test = X_test_transfrmd.shape[0]\n",
    "# assert shape[0]*shape[1]*shape[2] == X_train_transfrmd.shape[1]\n",
    "# inputs = keras.Input(shape=shape)\n",
    "# #\n",
    "# x = layers.Conv2D(filters=filters, kernel_size=kernel_size,activation=activation,padding=padding)(inputs)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=2*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=4*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=8*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "\n",
    "# #--- The network architecture\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,epsilon=1e-08)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- save best model \n",
    "# callbacks=[keras.callbacks.ModelCheckpoint( filepath='png/convnet_from_scratch.keras',  \n",
    "#                                            monitor=\"val_loss\",\n",
    "#                                            save_freq=10,\n",
    "#                                             save_best_only=True)]\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# X_train_reshaped = X_train_transfrmd.reshape((n_train,shape[0],shape[1],1))\n",
    "# X_test_reshaped = X_test_transfrmd.reshape((n_test,shape[0],shape[1],1))\n",
    "# model.fit(X_train_reshaped, y_train, \n",
    "#             validation_data=(X_test_reshaped, y_test),\n",
    "#             #callbacks=callbacks,\n",
    "#           epochs=epochs, verbose=False, shuffle=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,epochs),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = keras.models.load_model(\"png/convnet_from_scratch.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=best_model.predict(X_test_reshaped)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf166dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (ux,uy), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e9080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "453.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
