{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>main()</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#test-example:-2d\" data-toc-modified-id=\"test-example:-2d-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>test example: 2d</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-connected-in-sklearn\" data-toc-modified-id=\"fully-connected-in-sklearn-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>fully connected in sklearn</a></span></li><li><span><a href=\"#fully-connected-in-keras\" data-toc-modified-id=\"fully-connected-in-keras-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>fully connected in keras</a></span></li><li><span><a href=\"#cnn\" data-toc-modified-id=\"cnn-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>cnn</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['flags', 'input files', 'EnergyBarrier', 'neural net', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "#\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "from scipy.stats import gaussian_kde\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                #--- same configurations!\n",
    "                self.descriptors  = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['data']]\n",
    "                self.shape        = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['shape']].flatten()\n",
    "                self.positions    = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['xyz']]\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                #--- displacement data\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz .'%(path,irun))\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "#         pdb.set_trace()\n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        atom_ids.sort()\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "        descriptors_center_atoms = self.descriptors[atom_ids]\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystaliine atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        descriptors_crystalline = self.descriptors[filtr]\n",
    "\n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- merge descriptors\n",
    "        self.descriptors = np.concatenate([descriptors_center_atoms,descriptors_crystalline],axis=0)\n",
    "\n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "                                 \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "    @staticmethod\n",
    "    def zscore(slist):\n",
    "        tmp = np.copy(slist)\n",
    "        print(np.mean(tmp),np.std(tmp))\n",
    "        tmp -= np.mean(tmp)\n",
    "        tmp /= np.std(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def SklearnMLP(self,X_train,y_train):\n",
    "        #-----------------------\n",
    "        #--- parameter grid\n",
    "        #-----------------------\n",
    "        param_grid = {\n",
    "                        'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                         #'activation' : ['tanh', 'relu'],\n",
    "                         'learning_rate_init':self.learning_rate_init,\n",
    "                        'alpha':self.alpha, #--- regularization \n",
    "                         #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                        'n_iter_no_change':self.n_iter_no_change,\n",
    "                        'tol':self.tol,\n",
    "                        'max_iter':self.max_iter,\n",
    "                     } \n",
    "        mlp   =  MLPClassifier(random_state=random_state,verbose=self.verbose)\n",
    "        clf  =  GridSearchCV(mlp, param_grid)\n",
    "        clf.fit(X_train,y_train)\n",
    "        model =  clf.best_estimator_\n",
    "        loss  =  model.loss_curve_\n",
    "        val_loss = loss\n",
    "        return (model, loss, val_loss)\n",
    "\n",
    "    def KerasANN(self, X_train, y_train,X_test, y_test, ndime):\n",
    "\n",
    "        model     = keras.Sequential([ #--- The network architecture\n",
    "            layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "            layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "            layers.Dense(ndime, activation='softmax')\n",
    "            ])\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "        model.compile( optimizer=optimizer,\n",
    "                       loss=\"binary_crossentropy\",#\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"accuracy\"]\n",
    "                     )\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"accuracy\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        model.fit( X_train, y_train, \n",
    "           validation_data      = ( X_test, y_test ),\n",
    "            callbacks           = callbacks,\n",
    "            epochs              = self.max_iter[0], \n",
    "            verbose             = self.verbose, \n",
    "            shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "         )        \n",
    "        loss      = model.history.history['loss']\n",
    "        val_loss  = model.history.history['val_loss']\n",
    "        #--- best model ??\n",
    "        return (model, loss, val_loss)\n",
    "                             \n",
    "    def TrainClassifier(self,y,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        ndime = 2 #--- binary classification\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "\n",
    "        #--- train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                (model, loss, val_loss) = self.SklearnMLP(X_train,y_train)\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                (model, loss, val_loss) = self.KerasANN(X_train, y_train,X_test, y_test, ndime)\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkClassifier( y )\n",
    "                    \n",
    "        #--- save loss data\n",
    "        !mkdir png\n",
    "        np.savetxt('png/val_loss_classification.txt',\n",
    "                   np.c_[range(len(loss)),loss,val_loss],\n",
    "                   header='epoch loss val_loss')\n",
    "\n",
    "        #--- confusion matrix\n",
    "        predict_x = model.predict(X_test) \n",
    "        classes_x = np.argmax(predict_x,axis=1)\n",
    "        cm = confusion_matrix(y_test, classes_x,\n",
    "                         labels=[0, 1]\n",
    "                        )\n",
    "        np.savetxt('png/confusion.txt',np.c_[cm])\n",
    "\n",
    "        \n",
    "\n",
    "    def TrainRegressor(self,stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    "                       filtr = None,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "\n",
    "        ndime  = y.shape[1] #--- dimension of the target vector\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors[filtr]]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                #-----------------------\n",
    "                #--- parameter grid\n",
    "                #-----------------------\n",
    "                param_grid = {\n",
    "                                'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                                 #'activation' : ['tanh', 'relu'],\n",
    "                                 'learning_rate_init':self.learning_rate_init,\n",
    "                                'alpha':self.alpha, #--- regularization \n",
    "                                 #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                                'n_iter_no_change':self.n_iter_no_change,\n",
    "                                'tol':self.tol,\n",
    "                                'max_iter':self.max_iter,\n",
    "                             } \n",
    "                mlp   =  MLPRegressor(random_state=random_state,verbose=self.verbose) #--- mlp regressor\n",
    "                regr  =  GridSearchCV(mlp, param_grid)\n",
    "                regr.fit(X_train,y_train)\n",
    "                model =  regr.best_estimator_\n",
    "                loss  =  model.loss_curve_\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                model     = keras.Sequential([ #--- The network architecture\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(ndime, activation=self.activation)\n",
    "                    ])\n",
    "                optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4) #--- compilation step\n",
    "                model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "                               loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "                               metrics=[\"mse\"]\n",
    "                             )\n",
    "                model.fit(X_train, y_train, #--- “Fitting”\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          epochs=self.max_iter[0], verbose=self.verbose)#, batch_size=128)\n",
    "                loss      = model.history.history['loss']\n",
    "                val_loss  = model.history.history['val_loss']\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetwork(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred       = model.predict(X_test)        \n",
    "        y_pred_train = model.predict(X_train)        \n",
    "        for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "            ax = utl.PltErr(None,None,Plot=False)\n",
    "            #\n",
    "            utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "                       attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                       attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(None,None,Plot=False,\n",
    "                           title='png/scatter%s.png'%idime,\n",
    "                            ax=ax,\n",
    "                       xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "                       xlim=(-2,2),ylim=(-2,2),\n",
    "                           )\n",
    "        \n",
    "        #--- save in ovito\n",
    "        if printOvito:\n",
    "            X_train, X_test, _, _ = train_test_split(self.perAtomData[filtr]['id type x y z'.split()], y, stratify=stratify,\n",
    "                                                    random_state=random_state)\n",
    "#            pdb.set_trace()\n",
    "            with open('original.xyz','w') as fp:\n",
    "                utl.PrintOvito(self.perAtomData[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('train.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_train,y_pred_train],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('test.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_test,y_pred],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "                \n",
    "\n",
    "    def ConvNetwork(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "                                                   monitor=\"loss\",\n",
    "                                                  save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    def ConvNetworkClassifier(self,y,\n",
    "                               random_state=1\n",
    "                               ):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        \n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        if self.verbose:\n",
    "            print('X.shape:=',X.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- set model parameters\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation='softmax')(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss=\"binary_crossentropy\",#\"sparse_categorical_crossentropy\",\n",
    "                       metrics   =  [\"accuracy\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"accuracy\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "                    disp           = np.c_[self.perAtomData.iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.positions.T,self.descriptors[atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, 'disp = %s'%disp, attr_list='x y z mass'.split())\n",
    "#     def SaveConf(self,fout):\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[self.perAtomData],header=' '.join(list(self.perAtomData.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8fc70",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating descriptors ...\n",
      "dim(y)= (1362, 1)\n",
      "X.shape:= (1362, 1331)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 11, 11, 11, 1)]   0         \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 11, 11, 11, 1)     28        \n",
      "                                                                 \n",
      " average_pooling3d_4 (Averag  (None, 5, 5, 5, 1)       0         \n",
      " ePooling3D)                                                     \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 5, 5, 5, 2)        56        \n",
      "                                                                 \n",
      " average_pooling3d_5 (Averag  (None, 2, 2, 2, 2)       0         \n",
      " ePooling3D)                                                     \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 2, 2, 2, 4)        220       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337\n",
      "Trainable params: 337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "cnn model summary: None\n",
      "mkdir: best_model: File exists\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa75f63bb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa75f63bb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa75f63bb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 9/32 [=======>......................] - ETA: 0s - loss: 0.6925 - accuracy: 0.0000e+00WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa76015bef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa76015bef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa76015bef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa764157dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa764157dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa764157dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/32 [===============>..............] - ETA: 1s - loss: 0.6919 - accuracy: 0.0035WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa767695c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa767695c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa767695c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa758133440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa758133440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa758133440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.0020WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa75f62fb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa75f62fb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa75f62fb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 5s 125ms/step - loss: 0.6916 - accuracy: 0.0020 - val_loss: 0.6914 - val_accuracy: 0.0029\n",
      "Epoch 2/10\n",
      "17/32 [==============>...............] - ETA: 0s - loss: 0.6914 - accuracy: 0.0037WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa7641739e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa7641739e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa7641739e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa75b188050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa75b188050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa75b188050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 113ms/step - loss: 0.6911 - accuracy: 0.0020 - val_loss: 0.6909 - val_accuracy: 0.0029\n",
      "Epoch 3/10\n",
      "15/32 [=============>................] - ETA: 0s - loss: 0.6908 - accuracy: 0.0021  WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa75cf3bd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa75cf3bd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fa75cf3bd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa758cd6440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa758cd6440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fa758cd6440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6906 - accuracy: 0.0020 - val_loss: 0.6904 - val_accuracy: 0.0029\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.6900 - accuracy: 0.0020 - val_loss: 0.6899 - val_accuracy: 0.0029\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.6895 - accuracy: 0.0020 - val_loss: 0.6894 - val_accuracy: 0.0029\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6890 - accuracy: 0.0020 - val_loss: 0.6889 - val_accuracy: 0.0029\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.6885 - accuracy: 0.0020 - val_loss: 0.6884 - val_accuracy: 0.0029\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.6880 - accuracy: 0.0020 - val_loss: 0.6879 - val_accuracy: 0.0029\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.6875 - accuracy: 0.0020 - val_loss: 0.6874 - val_accuracy: 0.0029\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.6870 - accuracy: 0.0020 - val_loss: 0.6869 - val_accuracy: 0.0029\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa76725b710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa76725b710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa76725b710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "11/11 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    " def main():\n",
    " \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes = eval(confParser['neural net']['hidden_layer_sizes']),\n",
    "                        learning_rate_init = eval(confParser['neural net']['learning_rate_init']),\n",
    "                        n_iter_no_change   = eval(confParser['neural net']['n_iter_no_change']),\n",
    "                        tol                = eval(confParser['neural net']['tol']),\n",
    "                        max_iter           = eval(confParser['neural net']['max_iter']),\n",
    "                        alpha              = eval(confParser['neural net']['alpha']),\n",
    "                        hidden_layer_size  = eval(confParser['neural net']['hidden_layer_size']),\n",
    "                        fully_connected    = eval(confParser['neural net']['fully_connected']),\n",
    "                        implementation     = eval(confParser['neural net']['implementation']),\n",
    "                        cnn                = eval(confParser['neural net']['cnn']),\n",
    "                        n_channels         = eval(confParser['neural net']['n_channels']),\n",
    "                        kernel_size        = eval(confParser['neural net']['kernel_size']),\n",
    "                        activation         = eval(confParser['neural net']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net']['number_hidden_layers']),\n",
    "                        verbose            = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net']['nruns']))\n",
    "\n",
    "    nn.Combine() #--- concat. descriptors\n",
    "    \n",
    "#     tmp = nn.df_combined.set_index('id')\n",
    "#    display(nn.perAtomData.iloc[:13])\n",
    "#    nn.PrintDensityMap(6,'density6.xyz')\n",
    "#    nn.PCA()\n",
    "#    nn.Spectra()\n",
    "\n",
    "\n",
    "    #--- classifier\n",
    "    if eval(confParser['neural net']['classification']):\n",
    "        nn.TrainClassifier(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    \n",
    "    \n",
    "    #--- filter data\n",
    "    train_type = int(eval(confParser['neural net']['train_type']))\n",
    "    \n",
    "    filtr      = {\n",
    "                     0: nn.perAtomData.defect_label == 1.0, #--- only non-crystalline atoms\n",
    "                     1: np.ones(len(nn.perAtomData),dtype=bool), #--- every atom\n",
    "                    }[train_type]\n",
    "    stratify   = {\n",
    "                    0:None,\n",
    "                    1:np.c_[nn.perAtomData.defect_label].astype(int), #--- ensure same ratio in test and training\n",
    "                    }[train_type]\n",
    "\n",
    "\n",
    "    \n",
    "    #--- train regressor\n",
    "    if eval(confParser['neural net']['regression']):\n",
    "\n",
    "        nn.TrainRegressor(  stratify=stratify,\n",
    "                            y=np.c_[nn.perAtomData[filtr]['ux uy uz'.split()]],\n",
    "                            printOvito = True,\n",
    "                            filtr=filtr,\n",
    "                         )\n",
    "    return nn\n",
    "\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aefa4",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f1a5a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "    n_channels  = dict(zip(range(4),[8,16,32,64]))\n",
    "    activations = dict(zip(range(20),['linear','relu']))\n",
    "    runs = [0,1,2]\n",
    "    \n",
    "    legend = utl.Legends()\n",
    "    legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "    symbols = utl.Symbols()\n",
    "    \n",
    "    nphi = len(number_hidden_layers)\n",
    "    #---\n",
    "    count = 0\n",
    "    ax = utl.PltErr(None, None, Plot=False )\n",
    "    for key_n in number_hidden_layers:\n",
    "        number_hidden_layer = number_hidden_layers[key_n]\n",
    "#         if number_hidden_layer != 2:\n",
    "#             continue\n",
    "        for key_c in n_channels:\n",
    "            n_channel = n_channels[key_c]\n",
    "#             if n_channel != 16:\n",
    "#                 continue\n",
    "            for key_a in activations:\n",
    "                activation = activations[key_a]\n",
    "\n",
    "        #---\t\n",
    "                path = 'neuralNet/ni/keras/20x20/cnn/classification3rd/layer%s/channel%s/activation%s'%(key_n,key_c,key_a) #--- change job name\n",
    "#                path = 'neuralNet/ni/keras/20x20/cnn/classification2nd' #--- change job name\n",
    "                fp = 'confusion.txt' #val_loss_classification.txt\n",
    "                for irun in runs:\n",
    "                    try:\n",
    "                        data = np.loadtxt('%s/Run%s/png/%s'%(path,irun,fp))\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "                    if fp == 'confusion.txt':\n",
    "                        accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "                        accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "                        \n",
    "                        utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                   Plot=False,\n",
    "                                   ax=ax,\n",
    "                                   )\n",
    "                    else:\n",
    "                        epoch = data[:,0]\n",
    "                        loss = data[:,1]\n",
    "                        val_loss = data[:,2]\n",
    "\n",
    "                        utl.PltErr(epoch, val_loss,\n",
    "                           attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                   Plot=False,\n",
    "                                   ax=ax,\n",
    "                                   )\n",
    "                count += 1\n",
    "    ax = utl.PltErr(None, None,\n",
    "#                        yscale='log',xscale='log',\n",
    "                       xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "                    ax=ax,\n",
    "                    legend=legend.Get(),\n",
    "                       title='png/training_loss.png',\n",
    "                   )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506974a",
   "metadata": {},
   "source": [
    "## test example: 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be92045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# y=np.c_[[1.725966,1.725967],\n",
    "#             [-1.725966,1.725967],\n",
    "#             [-1.725966,-1.725967],\n",
    "#             [1.725966,-1.725967],\n",
    "#            ].T\n",
    "\n",
    "# X=np.concatenate([list(map(lambda x:np.load('png/descriptor%s.npy'%x).flatten(),range(4)))],axis=1)\n",
    "\n",
    "# #--- zscore\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_transfrmd = scaler.transform( X )\n",
    "\n",
    "# X_train_transfrmd, X_test_transfrmd, y_train, y_test = train_test_split(X_transfrmd, y, test_size=0.25)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# print(X_train_transfrmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69377834",
   "metadata": {},
   "source": [
    "### fully connected in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #        pdb.set_trace()\n",
    "# #--- tune parameters\n",
    "\n",
    "# #--- train\n",
    "# mlp = MLPRegressor(random_state=1,\n",
    "# #                    verbose=True,\n",
    "#                    n_iter_no_change=100000,\n",
    "#                     max_iter=10000,\n",
    "#                    hidden_layer_sizes=(1000,1000),\n",
    "# #                    shuffle=False,\n",
    "# #                     alpha=1e-1,\n",
    "\n",
    "#                   )\n",
    "# mlp.fit(X_train_transfrmd,y_train)\n",
    "\n",
    "# #--- validate\n",
    "# !mkdir png\n",
    "# utl.PltErr(range(len(mlp.loss_curve_)), mlp.loss_curve_,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            yscale='log',xscale='log',\n",
    "# #           xlim=(1,self.max_iter[0]),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )\n",
    "\n",
    "# # #         pdb.set_trace()\n",
    "# y_pred =mlp.predict(X_test_transfrmd)        \n",
    "# y_pred_train = mlp.predict(X_train_transfrmd)        \n",
    "# for idime, xstr in zip(range(2),'ux uy'.split()):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     #\n",
    "#     utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(None,None,Plot=False,\n",
    "#                    title='png/scatter%s.png'%idime,\n",
    "#                     ax=ax,\n",
    "#                xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                xlim=(-3,3),ylim=(-3,3),\n",
    "#                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.best_loss_, mlp.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=mlp.predict(X_test_transfrmd)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(2):\n",
    "#     utl.PltErr(range(data.descriptors[0,:].shape[0]),data.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n",
    "# utl.PltErr(range(data.descriptors[100,:].shape[0]),data.descriptors[100,:],\n",
    "#           attrs={'fmt':'-','color':'C0'},\n",
    "#            xscale='log',yscale='log',\n",
    "#            ax=ax,\n",
    "#            Plot=False,\n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d061978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     random_state=1)\n",
    "# regr = MLPRegressor(verbose=False,\n",
    "#                     random_state=1, \n",
    "# #                     learning_rate='adaptive',\n",
    "# #                    early_stopping=True, \n",
    "#                      n_iter_no_change=1, \n",
    "#                     tol=1e-2,\n",
    "#                      max_iter=10000000,\n",
    "# #                     solver='sgd',\n",
    "#                    ).fit(X_train, y_train)\n",
    "# regr.tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eecba",
   "metadata": {},
   "source": [
    "### fully connected in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--- The network architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512), #activation=\"relu\"),\n",
    "# #     layers.Dense(1000), #activation=\"relu\"),\n",
    "#     layers.Dense(2) #, activation=\"relu\")\n",
    "#     ])\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- Preparing the image data\n",
    "# # train_images = train_images.reshape((60000, 28 * 28))\n",
    "# # train_images = train_images.astype(\"float32\") / 255\n",
    "# # test_images = test_images.reshape((10000, 28 * 28))\n",
    "# # test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# model.fit(X_train_transfrmd, y_train, \n",
    "#             validation_data=(X_test_transfrmd, y_test),\n",
    "\n",
    "#           epochs=100, verbose=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,100),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262922c9",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f22b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.random.set_random_seed(812)\n",
    "\n",
    "# shape=(300,300,1)\n",
    "# kernel_size = (3,3)\n",
    "# epochs = 1000\n",
    "# activation = ['linear','sigmoid','relu'][0]\n",
    "# padding='same'\n",
    "# filters = 1\n",
    "# #\n",
    "# ndime = y_train.shape[1]\n",
    "# n_train = X_train_transfrmd.shape[0]\n",
    "# n_test = X_test_transfrmd.shape[0]\n",
    "# assert shape[0]*shape[1]*shape[2] == X_train_transfrmd.shape[1]\n",
    "# inputs = keras.Input(shape=shape)\n",
    "# #\n",
    "# x = layers.Conv2D(filters=filters, kernel_size=kernel_size,activation=activation,padding=padding)(inputs)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=2*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=4*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=8*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "\n",
    "# #--- The network architecture\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,epsilon=1e-08)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- save best model \n",
    "# callbacks=[keras.callbacks.ModelCheckpoint( filepath='png/convnet_from_scratch.keras',  \n",
    "#                                            monitor=\"val_loss\",\n",
    "#                                            save_freq=10,\n",
    "#                                             save_best_only=True)]\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# X_train_reshaped = X_train_transfrmd.reshape((n_train,shape[0],shape[1],1))\n",
    "# X_test_reshaped = X_test_transfrmd.reshape((n_test,shape[0],shape[1],1))\n",
    "# model.fit(X_train_reshaped, y_train, \n",
    "#             validation_data=(X_test_reshaped, y_test),\n",
    "#             #callbacks=callbacks,\n",
    "#           epochs=epochs, verbose=False, shuffle=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,epochs),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = keras.models.load_model(\"png/convnet_from_scratch.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=best_model.predict(X_test_reshaped)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf166dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (ux,uy), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e9080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "453.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
