{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>main()</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#test-example:-2d\" data-toc-modified-id=\"test-example:-2d-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>test example: 2d</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-connected-in-sklearn\" data-toc-modified-id=\"fully-connected-in-sklearn-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>fully connected in sklearn</a></span></li><li><span><a href=\"#fully-connected-in-keras\" data-toc-modified-id=\"fully-connected-in-keras-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>fully connected in keras</a></span></li><li><span><a href=\"#cnn\" data-toc-modified-id=\"cnn-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>cnn</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['flags', 'input files', 'EnergyBarrier', 'neural net', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "#\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "from scipy.stats import gaussian_kde\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            if irun == 0:\n",
    "                #--- same configurations!\n",
    "                self.descriptors  = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['data']]\n",
    "                self.shape        = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['shape']].flatten()\n",
    "                self.positions    = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz .'%(path,irun))\n",
    "            try:\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                #--- displacement data\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "#         pdb.set_trace()\n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        atom_ids.sort()\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "        descriptors_center_atoms = self.descriptors[atom_ids]\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystaliine atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        descriptors_crystalline = self.descriptors[filtr]\n",
    "\n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- merge descriptors\n",
    "        self.descriptors = np.concatenate([descriptors_center_atoms,descriptors_crystalline],axis=0)\n",
    "\n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "                                 \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "    @staticmethod\n",
    "    def zscore(slist):\n",
    "        tmp = np.copy(slist)\n",
    "        print(np.mean(tmp),np.std(tmp))\n",
    "        tmp -= np.mean(tmp)\n",
    "        tmp /= np.std(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def SklearnMLP(self,X_train,y_train):\n",
    "        #-----------------------\n",
    "        #--- parameter grid\n",
    "        #-----------------------\n",
    "#         param_grid = {\n",
    "#                         'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "#                          #'activation' : ['tanh', 'relu'],\n",
    "#                          'learning_rate_init':self.learning_rate_init,\n",
    "# #                         'alpha':self.alpha, #--- regularization \n",
    "#                          #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "#                         'n_iter_no_change':self.n_iter_no_change,\n",
    "# #                        'tol':self.tol,\n",
    "#                         'max_iter':self.max_iter,\n",
    "#                      } \n",
    "        mlp   =  MLPClassifier(random_state=1,\n",
    "                               hidden_layer_sizes = self.hidden_layer_sizes[0],\n",
    "                               learning_rate_init = self.learning_rate_init[0],\n",
    "                               n_iter_no_change   = self.n_iter_no_change[0],\n",
    "                               max_iter           = self.max_iter[0],\n",
    "                               verbose=self.verbose)\n",
    "#         clf  =  GridSearchCV(mlp, param_grid)\n",
    "#        clf.fit(X_train,y_train)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        model =  mlp #clf.best_estimator_\n",
    "        loss  =  model.loss_curve_\n",
    "        val_loss = loss\n",
    "        return (model, loss, val_loss)\n",
    "\n",
    "    def KerasANN(self, X_train, y_train,X_test, y_test, ndime):\n",
    "\n",
    "        model     = keras.Sequential([ #--- The network architecture\n",
    "                                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                #                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                                    layers.Dense(ndime, activation='softmax')\n",
    "                                    ])\n",
    "        \n",
    "#         shape         =  (self.shape[0]*self.shape[1]*self.shape[2],)\n",
    "#         inputs        =  keras.Input(shape=shape)\n",
    "#         #------------------------------\n",
    "#         #--- The network architecture\n",
    "#         #------------------------------\n",
    "#         x             =  layers.Dense(   self.hidden_layer_size, activation=self.activation\n",
    "#                                        )(inputs)\n",
    "#         for i in range( self.number_hidden_layers ):\n",
    "#             x       = layers.Dense( self.hidden_layer_size, activation=self.activation\n",
    "#                                      )(x)\n",
    "#         #--- output layer\n",
    "# #         x       = layers.Flatten()(x)\n",
    "#         outputs = layers.Dense( ndime, activation=self.activation)(x)\n",
    "#         model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        \n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "        model.compile( optimizer=optimizer,\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"mse\"]\n",
    "                     )\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"mse\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        model.fit( X_train, y_train, \n",
    "           validation_data      = ( X_test, y_test ),\n",
    "            callbacks           = callbacks,\n",
    "            epochs              = self.max_iter[0], \n",
    "            verbose             = self.verbose, \n",
    "            shuffle             = False, \n",
    "#             batch_size     = 32,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "         )        \n",
    "        loss      = model.history.history['loss']\n",
    "        val_loss  = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        return (best_model, loss, val_loss)\n",
    "                             \n",
    "    def TrainClassifier(self,y,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        ndime = 2 #--- binary classification\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "\n",
    "        #--- train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                (model, loss, val_loss) = self.SklearnMLP(X_train,y_train)\n",
    "                classes_x = model.predict(X_test) \n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                (model, loss, val_loss) = self.KerasANN(X_train, y_train,X_test, y_test, ndime)\n",
    "                predict_x = model.predict(X_test) \n",
    "                classes_x = np.argmax(predict_x,axis=1)\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkClassifier( y )\n",
    "            predict_x = model.predict(X_test) \n",
    "            classes_x = np.argmax(predict_x,axis=1)\n",
    "                    \n",
    "        #--- save loss data\n",
    "        !mkdir png\n",
    "        np.savetxt('png/val_loss_classification.txt',\n",
    "                   np.c_[range(len(loss)),loss,val_loss],\n",
    "                   header='epoch loss val_loss')\n",
    "\n",
    "        #--- confusion matrix\n",
    "        cm = confusion_matrix(y_test, classes_x,\n",
    "                         labels=[0, 1]\n",
    "                        )\n",
    "        np.savetxt('png/confusion.txt',np.c_[cm])\n",
    "\n",
    "        \n",
    "\n",
    "    def TrainRegressor(self,stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    "                       filtr = None,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "\n",
    "        ndime  = y.shape[1] #--- dimension of the target vector\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors[filtr]]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                #-----------------------\n",
    "                #--- parameter grid\n",
    "                #-----------------------\n",
    "                param_grid = {\n",
    "                                'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                                 #'activation' : ['tanh', 'relu'],\n",
    "                                 'learning_rate_init':self.learning_rate_init,\n",
    "                                'alpha':self.alpha, #--- regularization \n",
    "                                 #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                                'n_iter_no_change':self.n_iter_no_change,\n",
    "                                'tol':self.tol,\n",
    "                                'max_iter':self.max_iter,\n",
    "                             } \n",
    "                mlp   =  MLPRegressor(random_state=random_state,verbose=self.verbose) #--- mlp regressor\n",
    "                regr  =  GridSearchCV(mlp, param_grid)\n",
    "                regr.fit(X_train,y_train)\n",
    "                model =  regr.best_estimator_\n",
    "                loss  =  model.loss_curve_\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                model     = keras.Sequential([ #--- The network architecture\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(ndime, activation=self.activation)\n",
    "                    ])\n",
    "                optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4) #--- compilation step\n",
    "                model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "                               loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "                               metrics=[\"mse\"]\n",
    "                             )\n",
    "                model.fit(X_train, y_train, #--- “Fitting”\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          epochs=self.max_iter[0], verbose=self.verbose)#, batch_size=128)\n",
    "                loss      = model.history.history['loss']\n",
    "                val_loss  = model.history.history['val_loss']\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetwork(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred       = model.predict(X_test)        \n",
    "        y_pred_train = model.predict(X_train)        \n",
    "        for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "            ax = utl.PltErr(None,None,Plot=False)\n",
    "            #\n",
    "            utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "                       attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                       attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                       ax=ax,\n",
    "                       Plot = False,\n",
    "\n",
    "                      )\n",
    "            #\n",
    "            utl.PltErr(None,None,Plot=False,\n",
    "                           title='png/scatter%s.png'%idime,\n",
    "                            ax=ax,\n",
    "                       xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "                       xlim=(-2,2),ylim=(-2,2),\n",
    "                           )\n",
    "        \n",
    "        #--- save in ovito\n",
    "        if printOvito:\n",
    "            X_train, X_test, _, _ = train_test_split(self.perAtomData[filtr]['id type x y z'.split()], y, stratify=stratify,\n",
    "                                                    random_state=random_state)\n",
    "#            pdb.set_trace()\n",
    "            with open('original.xyz','w') as fp:\n",
    "                utl.PrintOvito(self.perAtomData[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('train.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_train,y_pred_train],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "            with open('test.xyz','w') as fp:\n",
    "                cordc = pd.DataFrame(np.c_[X_test,y_pred],columns='id type x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "                \n",
    "\n",
    "    def ConvNetwork(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "                                                   monitor=\"loss\",\n",
    "                                                  save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    def ConvNetworkClassifier(self,y,\n",
    "                               random_state=1\n",
    "                               ):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        \n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        if self.verbose:\n",
    "            print('X.shape:=',X.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- set model parameters\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss=\"binary_crossentropy\",#\"sparse_categorical_crossentropy\",\n",
    "                       metrics   =  [\"accuracy\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "                                                    monitor=\"accuracy\",\n",
    "                                                    save_freq=10,\n",
    "                                                    save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "                    disp           = np.c_[self.perAtomData.iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.positions.T,self.descriptors[atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, 'disp = %s'%disp, attr_list='x y z mass'.split())\n",
    "#     def SaveConf(self,fout):\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[self.perAtomData],header=' '.join(list(self.perAtomData.keys())))\n",
    "\n",
    "#     def Test(self,y,\n",
    "#                                    random_state=1\n",
    "#                                    ):\n",
    "#             '''\n",
    "#             Convolutional neural network.\n",
    "\n",
    "#             Parameters\n",
    "#             ----------\n",
    "#             X_train : array-like training x input\n",
    "\n",
    "#             y_train : array-like, training y input\n",
    "\n",
    "#             X_test : array-like test x input\n",
    "\n",
    "#             y_test : array-like, training y input\n",
    "\n",
    "#             Return\n",
    "#             ---------- ( , loss,  )\n",
    "#             best_model : cnn object, best trained model based on on the validation loss\n",
    "\n",
    "#             loss : array-like, mse loss\n",
    "\n",
    "#             val_loss : array-like, validation loss\n",
    "\n",
    "#             '''\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('dim(y)=',y.shape)\n",
    "\n",
    "#             ndime  = y.shape[1] #--- dimension of the target vector\n",
    "\n",
    "\n",
    "#             #---------------\n",
    "#             #--- zscore X\n",
    "#             #---------------        \n",
    "#             X      = np.c_[self.descriptors ]\n",
    "#             scaler = StandardScaler()\n",
    "#             scaler.fit(X)\n",
    "#             X      = scaler.transform( X )\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('X.shape:=',X.shape)\n",
    "\n",
    "\n",
    "\n",
    "#             #-----------------------\n",
    "#             #--- train-test split\n",
    "#             #-----------------------\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "#                                                                 random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "#             #---- set model parameters\n",
    "#             shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "#             kernel_size   =  self.kernel_size \n",
    "#             epochs        =  self.max_iter[0]\n",
    "#             activation    =  self.activation\n",
    "#             padding       = 'same'\n",
    "#             filters       =  self.n_channels\n",
    "#             learning_rate = self.learning_rate_init[0]\n",
    "#             #\n",
    "#             ndime         =  y_train.shape[1]\n",
    "#             n_train       =  X_train.shape[0]\n",
    "#             n_test        =  X_test.shape[0]\n",
    "#             assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "#             inputs        =  keras.Input(shape=shape)\n",
    "#             #\n",
    "#     #         pdb.set_trace()\n",
    "#             #------------------------------\n",
    "#             #--- The network architecture\n",
    "#             #------------------------------\n",
    "#             model     = keras.Sequential([\n",
    "#                 layers.Dense(self.hidden_layer_size, activation=\"relu\"),\n",
    "#     #             layers.Dense(self.hidden_layer_size), #activation=\"relu\"),\n",
    "#                 layers.Dense(2, activation=\"softmax\")\n",
    "#                 ])\n",
    "#             optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "\n",
    "#             model.compile( optimizer=\"rmsprop\",\n",
    "#                            loss=\"sparse_categorical_crossentropy\",\n",
    "#                            metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "#             #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "#             X_train_reshaped =  X_train \n",
    "#             X_test_reshaped  =  X_test\n",
    "#             model.fit( X_train_reshaped, y_train, \n",
    "#                        validation_data      = ( X_test_reshaped, y_test ),\n",
    "#     #                     callbacks=callbacks,\n",
    "#                         epochs              = epochs, \n",
    "#                         verbose             = self.verbose, \n",
    "#                         shuffle             = False, \n",
    "#     #                     batch_size     = 128,\n",
    "#                         use_multiprocessing = True,\n",
    "#                         workers             = 4,\n",
    "#                      )        \n",
    "\n",
    "\n",
    "#             #--- save best model\n",
    "#             !mkdir best_model\n",
    "#     #         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#     #                                                    monitor=\"val_loss\",\n",
    "#     #                                                   save_freq=10,\n",
    "#     #                                                     save_best_only=True)]\n",
    "\n",
    "\n",
    "#             #--- validation loss\n",
    "#             loss       = model.history.history['loss']\n",
    "#             val_loss   = model.history.history['val_loss']\n",
    "#             best_model = model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "\n",
    "#             !mkdir png\n",
    "#             utl.PltErr(range(len(loss)), loss,\n",
    "#                        yscale='log',\n",
    "#                        xstr='epoch',ystr='loss',\n",
    "#                        title='png/loss_classification.png',\n",
    "#                       )\n",
    "\n",
    "#     #         pdb.set_trace()\n",
    "#             #--- confusion matrix\n",
    "#             cm = confusion_matrix(y_test, model.predict_classes(X_test),\n",
    "#                              labels=[0, 1]\n",
    "#                             )\n",
    "#             print('cm=',cm)\n",
    "#             np.savetxt('png/confusion.txt',np.c_[cm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "628ad42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Combine',\n",
       " 'ConvNetwork',\n",
       " 'ConvNetworkClassifier',\n",
       " 'GetCenterAtom',\n",
       " 'KerasANN',\n",
       " 'PCA',\n",
       " 'Parse',\n",
       " 'PrintDensityMap',\n",
       " 'SklearnMLP',\n",
       " 'Spectra',\n",
       " 'TrainClassifier',\n",
       " 'TrainRegressor',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'zscore']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(NeuralNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8fc70",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating descriptors ...\n",
      "mkdir: best_model: File exists\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f961628c3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f961628c3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f961628c3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 1/32 [..............................] - ETA: 17s - loss: 0.6944 - mse: 0.2522WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9608e6d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9608e6d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9608e6d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9606cbf050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9606cbf050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9606cbf050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/32 [========>.....................] - ETA: 1s - loss: 0.7395 - mse: 0.2605 WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9606cbf9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9606cbf9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9606cbf9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f960e4e9830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f960e4e9830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f960e4e9830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/32 [=================>............] - ETA: 0s - loss: 0.7222 - mse: 0.2586WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9605f499e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9605f499e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9605f499e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.7519 - mse: 0.2591 - val_loss: 0.7847 - val_mse: 0.2572\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7194 - mse: 0.2589 - val_loss: 0.7566 - val_mse: 0.2572\n",
      "Epoch 3/10\n",
      "11/32 [=========>....................] - ETA: 0s - loss: 0.6611 - mse: 0.2600WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9605f5a200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9605f5a200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f9605f5a200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9605caed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9605caed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f9605caed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/convnetClassifier_from_scratch.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 44ms/step - loss: 0.6924 - mse: 0.2587 - val_loss: 0.7280 - val_mse: 0.2573\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6676 - mse: 0.2592 - val_loss: 0.6977 - val_mse: 0.2577\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6425 - mse: 0.2597 - val_loss: 0.6652 - val_mse: 0.2583\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6177 - mse: 0.2604 - val_loss: 0.6335 - val_mse: 0.2592\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5936 - mse: 0.2612 - val_loss: 0.6014 - val_mse: 0.2602\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5702 - mse: 0.2623 - val_loss: 0.5685 - val_mse: 0.2614\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5476 - mse: 0.2636 - val_loss: 0.5400 - val_mse: 0.2623\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5257 - mse: 0.2652 - val_loss: 0.5222 - val_mse: 0.2646\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9606ceb8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9606ceb8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9606ceb8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "mkdir: png: File exists\n"
     ]
    }
   ],
   "source": [
    " def main():\n",
    " \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes = eval(confParser['neural net']['hidden_layer_sizes']),\n",
    "                        learning_rate_init = eval(confParser['neural net']['learning_rate_init']),\n",
    "                        n_iter_no_change   = eval(confParser['neural net']['n_iter_no_change']),\n",
    "                        tol                = eval(confParser['neural net']['tol']),\n",
    "                        max_iter           = eval(confParser['neural net']['max_iter']),\n",
    "                        alpha              = eval(confParser['neural net']['alpha']),\n",
    "                        hidden_layer_size  = eval(confParser['neural net']['hidden_layer_size']),\n",
    "                        fully_connected    = eval(confParser['neural net']['fully_connected']),\n",
    "                        implementation     = eval(confParser['neural net']['implementation']),\n",
    "                        cnn                = eval(confParser['neural net']['cnn']),\n",
    "                        n_channels         = eval(confParser['neural net']['n_channels']),\n",
    "                        kernel_size        = eval(confParser['neural net']['kernel_size']),\n",
    "                        activation         = eval(confParser['neural net']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net']['number_hidden_layers']),\n",
    "                        verbose            = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net']['nruns']))\n",
    "\n",
    "    nn.Combine() #--- concat. descriptors\n",
    "    \n",
    "#     tmp = nn.df_combined.set_index('id')\n",
    "#    display(nn.perAtomData.iloc[:13])\n",
    "#    nn.PrintDensityMap(6,'density6.xyz')\n",
    "#    nn.PCA()\n",
    "#    nn.Spectra()\n",
    "\n",
    "\n",
    "    #--- classifier\n",
    "    if eval(confParser['neural net']['classification']):\n",
    "        nn.TrainClassifier(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "#        nn.Test(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    \n",
    "    \n",
    "    #--- filter data\n",
    "    train_type = int(eval(confParser['neural net']['train_type']))\n",
    "    \n",
    "    filtr      = {\n",
    "                     0: nn.perAtomData.defect_label == 1.0, #--- only non-crystalline atoms\n",
    "                     1: np.ones(len(nn.perAtomData),dtype=bool), #--- every atom\n",
    "                    }[train_type]\n",
    "    stratify   = {\n",
    "                    0:None,\n",
    "                    1:np.c_[nn.perAtomData.defect_label].astype(int), #--- ensure same ratio in test and training\n",
    "                    }[train_type]\n",
    "\n",
    "\n",
    "    \n",
    "    #--- train regressor\n",
    "    if eval(confParser['neural net']['regression']):\n",
    "\n",
    "        nn.TrainRegressor(  stratify=stratify,\n",
    "                            y=np.c_[nn.perAtomData[filtr]['ux uy uz'.split()]],\n",
    "                            printOvito = True,\n",
    "                            filtr=filtr,\n",
    "                         )\n",
    "    return nn\n",
    "\n",
    "!rm -r png;mkdir png\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aefa4",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b74daa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[279.  61.]\n",
      " [  1.   1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend = utl.Legends()\n",
    "legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "symbols = utl.Symbols()\n",
    "\n",
    "fp = ['confusion.txt', 'val_loss_classification.txt'][0]\n",
    "data = np.loadtxt('png/%s'%(fp))\n",
    "ax = utl.PltErr(None, None, Plot=False )\n",
    "if fp == 'confusion.txt':\n",
    "    accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "    accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "    print(data)\n",
    "    utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "       attrs=symbols.GetAttrs(count=0,nevery=800,\n",
    "            ), \n",
    "               Plot=False,\n",
    "               ax=ax,\n",
    "               )\n",
    "else:\n",
    "    epoch = data[:,0]\n",
    "    loss = data[:,1]\n",
    "    val_loss = data[:,2]\n",
    "\n",
    "    utl.PltErr(epoch, val_loss,\n",
    "       attrs=symbols.GetAttrs(count=0,nevery=10,\n",
    "            ), \n",
    "               Plot=False,\n",
    "               ax=ax,\n",
    "               )\n",
    "    \n",
    "ax = utl.PltErr(None, None,\n",
    "yscale='log',xscale='log',\n",
    "xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "ax=ax,\n",
    "# legend=legend.Get(),\n",
    "title='png/training_loss.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1a5a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "    #--- ann\n",
    "#     number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "#     hidden_layer_size     = dict(zip(range(4),[10,100,1000,10000]))\n",
    "#     n_channels            = dict(zip(range(4),[1]))\n",
    "#     activations           = dict(zip(range(20),['linear']))\n",
    "#     string[ inums ] = \"\\t\\'5\\':\\'neuralNet/20x20/ann/classifier/layer%s/channel%s/activation%s/layer_size%s\\',\\n\" % (key_n,key_c,key_a,key_h) #--- change job name\n",
    "    \n",
    "    #--- cnn\n",
    "    number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "    hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "    n_channels            = dict(zip(range(4),[8,16,32,64]))\n",
    "    activations           = dict(zip(range(20),['linear']))\n",
    "\n",
    "    runs = [0,1,2]\n",
    "    \n",
    "    legend = utl.Legends()\n",
    "    legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "    symbols = utl.Symbols()\n",
    "    \n",
    "    nphi = len(number_hidden_layers)\n",
    "    #---\n",
    "    count = 0\n",
    "    ax = utl.PltErr(None, None, Plot=False )\n",
    "    for key_n in number_hidden_layers:\n",
    "        number_hidden_layer = number_hidden_layers[key_n]\n",
    "#         if number_hidden_layer != 2:\n",
    "#             continue\n",
    "        for key_c in n_channels:\n",
    "            n_channel = n_channels[key_c]\n",
    "#             if n_channel != 16:\n",
    "#                 continue\n",
    "            for key_a in activations:\n",
    "                activation = activations[key_a]\n",
    "                for key_h in hidden_layer_size:\n",
    "                    nsize = hidden_layer_size[key_h]\n",
    "\n",
    "        #---\t\n",
    "                    path = 'neuralNet/20x20/cnn/classifier/layer%s/channel%s/activation%s/layer_size%s'%(key_n,key_c,key_a,key_h) #--- change job name\n",
    "#                     path = 'neuralNet/ni/keras/20x20/ann/classifier' #--- change job name\n",
    "                    fp = ['confusion.txt', 'val_loss_classification.txt'][1]\n",
    "                    for irun in runs:\n",
    "                        try:\n",
    "                            data = np.loadtxt('%s/Run%s/png/%s'%(path,irun,fp))\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        if fp == 'confusion.txt':\n",
    "                            accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "                            accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "                            print(data)\n",
    "                            utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                        else:\n",
    "                            epoch = data[:,0]\n",
    "                            loss = data[:,1]\n",
    "                            val_loss = data[:,2]\n",
    "\n",
    "                            utl.PltErr(epoch, val_loss,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                    count += 1\n",
    "    ax = utl.PltErr(None, None,\n",
    "                        yscale='log',xscale='log',\n",
    "                       xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "                    ax=ax,\n",
    "                    legend=legend.Get(),\n",
    "                       title='png/training_loss.png',\n",
    "                   )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506974a",
   "metadata": {},
   "source": [
    "## test example: 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1be92045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.725966 1.725967]]\n",
      "(3, 441)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y=np.c_[[1.725966,1.725967],\n",
    "            [-1.725966,1.725967],\n",
    "            [-1.725966,-1.725967],\n",
    "            [1.725966,-1.725967],\n",
    "           ].T\n",
    "\n",
    "X=np.concatenate([list(map(lambda x:np.load('png/descriptor%s.npy'%x).flatten(),range(4)))],axis=1)\n",
    "\n",
    "#--- zscore\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_transfrmd = scaler.transform( X )\n",
    "\n",
    "X_train_transfrmd, X_test_transfrmd, y_train, y_test = train_test_split(X_transfrmd, y, test_size=0.25)\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "print(X_train_transfrmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69377834",
   "metadata": {},
   "source": [
    "### fully connected in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c56d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79024675\n",
      "Iteration 2, loss = 4.79153813\n",
      "Iteration 3, loss = 0.48272480\n",
      "Iteration 4, loss = 0.84242732\n",
      "Iteration 5, loss = 1.20200108\n",
      "Iteration 6, loss = 0.50029766\n",
      "Iteration 7, loss = 0.08083888\n",
      "Iteration 8, loss = 0.31471365\n",
      "Iteration 9, loss = 0.39602049\n",
      "Iteration 10, loss = 0.14417737\n",
      "Iteration 11, loss = 0.05911270\n",
      "Iteration 12, loss = 0.17784119\n",
      "Iteration 13, loss = 0.18843745\n",
      "Iteration 14, loss = 0.08671426\n",
      "Iteration 15, loss = 0.05304450\n",
      "Iteration 16, loss = 0.09624741\n",
      "Iteration 17, loss = 0.09671026\n",
      "Iteration 18, loss = 0.05631733\n",
      "Iteration 19, loss = 0.05017827\n",
      "Iteration 20, loss = 0.06458879\n",
      "Iteration 21, loss = 0.05694448\n",
      "Iteration 22, loss = 0.04181389\n",
      "Iteration 23, loss = 0.04398522\n",
      "Iteration 24, loss = 0.04448364\n",
      "Iteration 25, loss = 0.03786413\n",
      "Iteration 26, loss = 0.03483561\n",
      "Iteration 27, loss = 0.03725800\n",
      "Iteration 28, loss = 0.03546887\n",
      "Iteration 29, loss = 0.03089711\n",
      "Iteration 30, loss = 0.03086940\n",
      "Iteration 31, loss = 0.03225031\n",
      "Iteration 32, loss = 0.02917275\n",
      "Iteration 33, loss = 0.02726652\n",
      "Iteration 34, loss = 0.02892336\n",
      "Iteration 35, loss = 0.02808117\n",
      "Iteration 36, loss = 0.02537011\n",
      "Iteration 37, loss = 0.02600391\n",
      "Iteration 38, loss = 0.02698854\n",
      "Iteration 39, loss = 0.02494826\n",
      "Iteration 40, loss = 0.02394280\n",
      "Iteration 41, loss = 0.02572275\n",
      "Iteration 42, loss = 0.02497078\n",
      "Iteration 43, loss = 0.02293285\n",
      "Iteration 44, loss = 0.02413425\n",
      "Iteration 45, loss = 0.02455046\n",
      "Iteration 46, loss = 0.02270986\n",
      "Iteration 47, loss = 0.02347172\n",
      "Iteration 48, loss = 0.02360856\n",
      "Iteration 49, loss = 0.02255866\n",
      "Iteration 50, loss = 0.02314975\n",
      "Iteration 51, loss = 0.02309027\n",
      "Iteration 52, loss = 0.02259666\n",
      "Iteration 53, loss = 0.02288285\n",
      "Iteration 54, loss = 0.02297684\n",
      "Iteration 55, loss = 0.02300910\n",
      "Iteration 56, loss = 0.02306715\n",
      "Iteration 57, loss = 0.02287899\n",
      "Iteration 58, loss = 0.02262910\n",
      "Iteration 59, loss = 0.02261209\n",
      "Iteration 60, loss = 0.02282631\n",
      "Iteration 61, loss = 0.02271234\n",
      "Iteration 62, loss = 0.02245436\n",
      "Iteration 63, loss = 0.02261107\n",
      "Iteration 64, loss = 0.02257859\n",
      "Iteration 65, loss = 0.02275319\n",
      "Iteration 66, loss = 0.02301587\n",
      "Iteration 67, loss = 0.02290518\n",
      "Iteration 68, loss = 0.02263656\n",
      "Iteration 69, loss = 0.02244420\n",
      "Iteration 70, loss = 0.02264114\n",
      "Iteration 71, loss = 0.02285952\n",
      "Iteration 72, loss = 0.02284724\n",
      "Iteration 73, loss = 0.02254051\n",
      "Iteration 74, loss = 0.02253781\n",
      "Iteration 75, loss = 0.02259026\n",
      "Iteration 76, loss = 0.02266804\n",
      "Iteration 77, loss = 0.02250421\n",
      "Iteration 78, loss = 0.02246337\n",
      "Iteration 79, loss = 0.02244526\n",
      "Iteration 80, loss = 0.02255226\n",
      "Iteration 81, loss = 0.02250348\n",
      "Iteration 82, loss = 0.02240397\n",
      "Iteration 83, loss = 0.02242926\n",
      "Iteration 84, loss = 0.02245178\n",
      "Iteration 85, loss = 0.02249455\n",
      "Iteration 86, loss = 0.02250251\n",
      "Iteration 87, loss = 0.02240619\n",
      "Iteration 88, loss = 0.02238247\n",
      "Iteration 89, loss = 0.02239953\n",
      "Iteration 90, loss = 0.02242186\n",
      "Iteration 91, loss = 0.02243013\n",
      "Iteration 92, loss = 0.02237696\n",
      "Iteration 93, loss = 0.02237238\n",
      "Iteration 94, loss = 0.02236637\n",
      "Iteration 95, loss = 0.02241898\n",
      "Iteration 96, loss = 0.02244555\n",
      "Iteration 97, loss = 0.02243013\n",
      "Iteration 98, loss = 0.02236881\n",
      "Iteration 99, loss = 0.02236044\n",
      "Iteration 100, loss = 0.02237842\n",
      "mkdir: png: File exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# #        pdb.set_trace()\n",
    "# #--- tune parameters\n",
    "\n",
    "# #--- train\n",
    "# mlp = MLPRegressor(random_state=1,\n",
    "#                     verbose=True,\n",
    "#                    n_iter_no_change=100000,\n",
    "#                     max_iter=100,#00,\n",
    "#                    hidden_layer_sizes=(1000,1000),\n",
    "# #                    shuffle=False,\n",
    "# #                     alpha=1e-1,\n",
    "\n",
    "#                   )\n",
    "# mlp.fit(X_train_transfrmd,y_train)\n",
    "\n",
    "# #--- validate\n",
    "# !mkdir png\n",
    "# utl.PltErr(range(len(mlp.loss_curve_)), mlp.loss_curve_,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            yscale='log',xscale='log',\n",
    "# #           xlim=(1,self.max_iter[0]),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )\n",
    "\n",
    "# # #         pdb.set_trace()\n",
    "# y_pred =mlp.predict(X_test_transfrmd)        \n",
    "# y_pred_train = mlp.predict(X_train_transfrmd)        \n",
    "# for idime, xstr in zip(range(2),'ux uy'.split()):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     #\n",
    "#     utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(None,None,Plot=False,\n",
    "#                    title='png/scatter%s.png'%idime,\n",
    "#                     ax=ax,\n",
    "#                xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                xlim=(-3,3),ylim=(-3,3),\n",
    "#                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.best_loss_, mlp.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=mlp.predict(X_test_transfrmd)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(2):\n",
    "#     utl.PltErr(range(data.descriptors[0,:].shape[0]),data.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n",
    "# utl.PltErr(range(data.descriptors[100,:].shape[0]),data.descriptors[100,:],\n",
    "#           attrs={'fmt':'-','color':'C0'},\n",
    "#            xscale='log',yscale='log',\n",
    "#            ax=ax,\n",
    "#            Plot=False,\n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d061978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     random_state=1)\n",
    "# regr = MLPRegressor(verbose=False,\n",
    "#                     random_state=1, \n",
    "# #                     learning_rate='adaptive',\n",
    "# #                    early_stopping=True, \n",
    "#                      n_iter_no_change=1, \n",
    "#                     tol=1e-2,\n",
    "#                      max_iter=10000000,\n",
    "# #                     solver='sgd',\n",
    "#                    ).fit(X_train, y_train)\n",
    "# regr.tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eecba",
   "metadata": {},
   "source": [
    "### fully connected in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--- The network architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512), #activation=\"relu\"),\n",
    "# #     layers.Dense(1000), #activation=\"relu\"),\n",
    "#     layers.Dense(2) #, activation=\"relu\")\n",
    "#     ])\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- Preparing the image data\n",
    "# # train_images = train_images.reshape((60000, 28 * 28))\n",
    "# # train_images = train_images.astype(\"float32\") / 255\n",
    "# # test_images = test_images.reshape((10000, 28 * 28))\n",
    "# # test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# model.fit(X_train_transfrmd, y_train, \n",
    "#             validation_data=(X_test_transfrmd, y_test),\n",
    "\n",
    "#           epochs=100, verbose=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,100),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262922c9",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f22b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.random.set_random_seed(812)\n",
    "\n",
    "# shape=(300,300,1)\n",
    "# kernel_size = (3,3)\n",
    "# epochs = 1000\n",
    "# activation = ['linear','sigmoid','relu'][0]\n",
    "# padding='same'\n",
    "# filters = 1\n",
    "# #\n",
    "# ndime = y_train.shape[1]\n",
    "# n_train = X_train_transfrmd.shape[0]\n",
    "# n_test = X_test_transfrmd.shape[0]\n",
    "# assert shape[0]*shape[1]*shape[2] == X_train_transfrmd.shape[1]\n",
    "# inputs = keras.Input(shape=shape)\n",
    "# #\n",
    "# x = layers.Conv2D(filters=filters, kernel_size=kernel_size,activation=activation,padding=padding)(inputs)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=2*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=4*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=8*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "\n",
    "# #--- The network architecture\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,epsilon=1e-08)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- save best model \n",
    "# callbacks=[keras.callbacks.ModelCheckpoint( filepath='png/convnet_from_scratch.keras',  \n",
    "#                                            monitor=\"val_loss\",\n",
    "#                                            save_freq=10,\n",
    "#                                             save_best_only=True)]\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# X_train_reshaped = X_train_transfrmd.reshape((n_train,shape[0],shape[1],1))\n",
    "# X_test_reshaped = X_test_transfrmd.reshape((n_test,shape[0],shape[1],1))\n",
    "# model.fit(X_train_reshaped, y_train, \n",
    "#             validation_data=(X_test_reshaped, y_test),\n",
    "#             #callbacks=callbacks,\n",
    "#           epochs=epochs, verbose=False, shuffle=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,epochs),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = keras.models.load_model(\"png/convnet_from_scratch.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=best_model.predict(X_test_reshaped)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf166dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (ux,uy), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e9080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "453.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
