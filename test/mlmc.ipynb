{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6665ea1",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#MachineLeranedMC\" data-toc-modified-id=\"MachineLeranedMC-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MachineLeranedMC</a></span><ul class=\"toc-item\"><li><span><a href=\"#main()\" data-toc-modified-id=\"main()-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>main()</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0151ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from buildDescriptors.ipynb\n",
      "conf. file sections: ['flags', 'input files', 'descriptors', 'neural net', 'neural net classification', 'neural net regression', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from buildDescriptors.ipynb\n",
      "conf. file sections: ['flags', 'input files', 'descriptors', 'neural net', 'neural net classification', 'neural net regression', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import import_ipynb\n",
    "import configparser\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#--- user modules\n",
    "confParser = configparser.ConfigParser() #--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import buildDescriptors as bd\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n",
    "imp.reload(bd)\n",
    "\n",
    "if eval(confParser['flags']['RemoteMachine']):\n",
    "    import lammps\n",
    "\n",
    "#--- increase width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLeranedMC( bd.ParseConfiguration,\n",
    "                        bd.EnergyBarrier,\n",
    "                      ):\n",
    "    '''\n",
    "    Performs Machine Learned Monte Carlo Swaps\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 confParser, \n",
    "                 verbose = False\n",
    "                ):\n",
    "        \n",
    "#         bd.ParseConfiguration.__init__(self, confParser, verbose = verbose )\n",
    "        self.verbose     =  verbose \n",
    "        self.confParser  =  confParser\n",
    "        \n",
    "        self.save_output = 'saved_output'\n",
    "        !rm -r $self.save_output; mkdir $self.save_output\n",
    "        \n",
    "        #--- assign units\n",
    "        temperature                  = eval(self.confParser[ 'ml mc' ][ 'temperature' ] ) #--- kelvin\n",
    "        self.rate_constant_prefactor = 1.0e+13 #s^-1\n",
    "        self.kbt                     = 8.617e-05 #eV K-1\n",
    "        self.kbt                    *= temperature\n",
    "        \n",
    "    def Parse(self,fp):\n",
    "        '''\n",
    "        Parse lammps dump file\n",
    "        '''\n",
    "        t0           = time.time()\n",
    "        self.lmpData = lp.ReadDumpFile( '%s'%(fp) ) \n",
    "        self.lmpData.GetCords( ncount = sys.maxsize)\n",
    "        if self.verbose:\n",
    "            print('elapsed time=%s s'%(time.time()-t0))\n",
    "            print('time steps:',self.lmpData.coord_atoms_broken.keys())\n",
    "            display(self.lmpData.coord_atoms_broken[0].head())\n",
    "\n",
    "    \n",
    "    def Initialize( self ):\n",
    "        '''\n",
    "        Initialize variables\n",
    "        '''\n",
    "        self.lmpData0 = self.lmpData.coord_atoms_broken[0].copy()\n",
    "        \n",
    "        natom         = len( self.lmpData.coord_atoms_broken[0] )\n",
    "        ndime         = 3\n",
    "        self.disp     = np.zeros( natom * ndime ).reshape((natom,ndime))\n",
    "        self.tdisp    = np.zeros( natom * ndime ).reshape((natom,ndime))\n",
    " \n",
    "        self.mc_time  = 0.0\n",
    "                \n",
    "        self.box      = lp.Box(BoxBounds=self.lmpData.BoxBounds[0],AddMissing=np.array([0,0,0]))\n",
    "\n",
    "    def GetDescriptors( self ):\n",
    "        '''\n",
    "        Compute structural descriptors  \n",
    "        '''\n",
    "        \n",
    "        bd.EnergyBarrier.__init__( self,\n",
    "                                  None,#'%s/EVENTS_DIR'%self.confParser['input files']['input_path'],\n",
    "                                  None,#'%s/EVLIST_DIR'%self.confParser['input files']['input_path'],\n",
    "                                  self.lmpData,\n",
    "                                  None,# self.lmpDisp,\n",
    "                                   verbose    = self.verbose,\n",
    "                                   nconf      = 2, #--- only two events\n",
    "                                   confParser = self.confParser,\n",
    "                                   species    = confParser['input files']['species'].split(),\n",
    "                                   r_cut      = eval(self.confParser['descriptors']['r_cut']),\n",
    "                                   dr         = eval(self.confParser['descriptors']['dr']),\n",
    "                                   scale      = eval(self.confParser['descriptors']['scale']),\n",
    "                                   n_max      = 8,\n",
    "                                   l_max      = 6,\n",
    "                      )\n",
    "        \n",
    "        self.perAtomData = self.lmpDataa\n",
    "        self.SetDescriptors(\n",
    "                      #soap = False,\n",
    "                      #acsf = True,   \n",
    "                      gr = True,\n",
    "                     )\n",
    "        \n",
    "    def GetDefects( self, fp, scaler ):\n",
    "        '''\n",
    "        Classify Defects\n",
    "        '''\n",
    "        \n",
    "        #--- load ml model\n",
    "        model                = keras.models.load_model(fp)\n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        loaded_scaler        = pickle.load( open(scaler, 'rb' ) )\n",
    "        X                    = loaded_scaler.transform( np.c_[self.descriptors ] )\n",
    "\n",
    "        #--- predict classes\n",
    "        predict_x            = model.predict( X ) \n",
    "        self.predict_classes = np.argmax( predict_x, axis=1 )\n",
    "    \n",
    "    def DiscretizeTransitionPath( self ):\n",
    "         #--- hard-coded values\n",
    "        self.umax = 2.5 #--- to be modified\n",
    "        self.du   = 0.5\n",
    "        xlin = np.arange(-self.umax,+self.umax,self.du)\n",
    "        ylin = np.arange(-self.umax,+self.umax,self.du)\n",
    "        zlin = np.arange(-self.umax,+self.umax,self.du)\n",
    "        self.nbinx = len(xlin)-1\n",
    "        self.nbiny = len(ylin)-1\n",
    "        self.nbinz = len(zlin)-1\n",
    "        self.bins = (xlin, ylin, zlin)\n",
    "        self.ux, self.uy, self.uz = np.meshgrid( self.bins[1][:-1], self.bins[0][:-1], self.bins[2][:-1] )\n",
    "\n",
    "        \n",
    "    def GetDispsFromBinaryMaps( self, atomIndex, binaryMap ):\n",
    "        binaryMapReshaped = binaryMap.reshape((self.nbinx, self.nbiny, self.nbinz ))\n",
    "        filtr = binaryMapReshaped == 1\n",
    "        disps = np.c_[self.uy[filtr],self.ux[filtr],self.uz[filtr]]\n",
    "        nrows = disps.shape[ 0 ]\n",
    "        assert nrows > 0, 'no diffusion path!'\n",
    "        return np.c_[np.ones(nrows)*atomIndex,disps]\n",
    "    \n",
    "    def GetDisp( self, fp, scaler ):\n",
    "        '''\n",
    "        Predict Displacements\n",
    "        '''\n",
    "        \n",
    "        #--- load ml model\n",
    "        model               = keras.models.load_model(fp)\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        loaded_scaler       = pickle.load( open( scaler, 'rb' ) )\n",
    "        filtr               = self.predict_classes > 0\n",
    "        X                   = loaded_scaler.transform( np.c_[self.descriptors[ filtr ] ] )\n",
    "\n",
    "\n",
    "        #--- reshape X\n",
    "        shape               =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        n                   =  X.shape[ 0 ]\n",
    "        X_reshaped          =  X.reshape((n,shape[0],shape[1],shape[2],1))\n",
    "        \n",
    "        prediction          =  model.predict( X_reshaped )\n",
    "        threshold           = 0.5 #--- hard-coded threshold\n",
    "        binary_predictions  = (prediction > threshold).astype(int)\n",
    "\n",
    "        #---\n",
    "        atomIndices         = self.lmpDataa[ filtr ].index\n",
    "        self.predict_disp     = np.concatenate([list(map(lambda x: self.GetDispsFromBinaryMaps( x[0],x[1] ) , zip(atomIndices,binary_predictions) ))])\n",
    "        self.predict_disp     = self.predict_disp.reshape((self.predict_disp.shape[0],self.predict_disp.shape[2]))\n",
    "        \n",
    "\n",
    "\n",
    "    def GetBarrier( self, fp, scaler ):\n",
    "        '''\n",
    "        Predict Displacements\n",
    "        '''\n",
    "        \n",
    "        #--- load ml model\n",
    "        model               = keras.models.load_model(fp)\n",
    "\n",
    "\n",
    "        #--- setup input\n",
    "        atomIndices    = self.predict_disp[ :, 0 ].astype( int )\n",
    "\n",
    "        pixel_maps_input = np.c_[self.descriptors[ atomIndices ] ]\n",
    "        vectors_input    = self.predict_disp[ :, 1: ]\n",
    "        X                = np.c_[pixel_maps_input,vectors_input]\n",
    "\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        loaded_scaler       = pickle.load( open( scaler, 'rb' ) )\n",
    "        X                   = loaded_scaler.transform( X )\n",
    "\n",
    "\n",
    "        #--- reshape X\n",
    "        shape               =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels: pixel map\n",
    "        shape_vector_input  = vectors_input.shape[ 1 ]\n",
    "\n",
    "        mdime               = X.shape[ 1 ]\n",
    "        X_pixels            = X[:,0:mdime-shape_vector_input]\n",
    "        X_vector            = X[:,mdime-shape_vector_input:mdime]\n",
    "        n                   =  X.shape[ 0 ]\n",
    "        X_pixels            =  X_pixels.reshape((n,shape[0],shape[1],shape[2],1))\n",
    "\n",
    "        \n",
    "        self.predict_energy =  model.predict( [X_pixels,X_vector] )\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    def BuildCatalog( self): #, filtr ):\n",
    "        #--- center atoms\n",
    "        atomIndices    = self.predict_disp[ :, 0 ].astype( int )\n",
    "        atomIDs        = self.lmpDataa.iloc[ atomIndices ].id\n",
    "        atomTypes      = self.lmpDataa.iloc[ atomIndices ].type\n",
    "\n",
    "        rates = self.rate_constant_prefactor * np.exp(-self.predict_energy/self.kbt)\n",
    "        \n",
    "        self.catalog = pd.DataFrame( np.c_[atomIDs, atomIndices, self.predict_energy, rates, self.predict_disp[:,1:] ],\n",
    "                                     columns = 'AtomId AtomIndex barrier true_rate ux uy uz'.split()\n",
    "                                   )\n",
    "    def MCsampling( self ):\n",
    "        normalized_rates = np.cumsum( self.catalog.true_rate ) / self.catalog.true_rate.sum()\n",
    "        n                = len( normalized_rates )\n",
    "        x                = np.random.random()\n",
    "        self.event_indx  = np.arange( n )[ x < normalized_rates ][ 0 ]\n",
    "        \n",
    "        #--- advance time\n",
    "        inv_rate         = 1.0 / self.catalog.iloc[ self.event_indx ].true_rate\n",
    "        self.mc_time    += np.random.exponential( scale = inv_rate )\n",
    "\n",
    "    def UpdateDisp( self ):\n",
    "        self.disp[ : ]           = 0.0\n",
    "        atomIndex                = self.catalog.iloc[ self.event_indx ].AtomIndex.astype( int )\n",
    "        disps                    = self.catalog.iloc[ self.event_indx ]['ux uy uz'.split()]\n",
    "        self.disp[ atomIndex ]   = disps\n",
    "        self.tdisp[ atomIndex ] += disps\n",
    "        \n",
    "    def UpdateCords( self ):\n",
    "        coords  = np.c_[ self.lmpData.coord_atoms_broken[ 0 ]['x y z'.split()] ]\n",
    "        coords += self.disp        \n",
    "        \n",
    "        self.lmpData.coord_atoms_broken[0]['x y z'.split()] = coords\n",
    "        \n",
    "        #--- wrap coords\n",
    "        df      = self.lmpData.coord_atoms_broken[ 0 ]\n",
    "        atoms   = lp.Atoms(**df['id type x y z'.split() ].to_dict( orient = 'series' ) )\n",
    "        #  \n",
    "        wr      = lp.Wrap(atoms, self.box)\n",
    "        wr.WrapCoord()\n",
    "        #\n",
    "        self.lmpData.coord_atoms_broken[0] = pd.DataFrame(atoms.__dict__)\n",
    "\n",
    "    def Print( self, fout, itime, **kwargs ):\n",
    "        '''\n",
    "        save configurations in lammps/kart formats\n",
    "        '''\n",
    "        #-----------------------\n",
    "        #--- lammps format\n",
    "        #-----------------------\n",
    "        df    = self.lmpData.coord_atoms_broken[ 0 ]\n",
    "        atomm = lp.Atoms(**df.to_dict(orient='series'),ux=self.disp[:,0],uy=self.disp[:,1],uz=self.disp[:,2])\n",
    "        #\n",
    "        wd    = lp.WriteDumpFile(atomm, self.box )\n",
    "        with open('%s/%s.xyz'%(self.save_output,fout),'a') as fp:\n",
    "            wd.Write(fp,itime = itime,\n",
    "                     attrs=['id', 'type', 'x', 'y', 'z','ux','uy','uz'],\n",
    "                     fmt='%i %i %4.3e %4.3e %4.3e %4.3e %4.3e %4.3e')\n",
    "            \n",
    "        #-----------------------\n",
    "        #--- k-art format\n",
    "        #-----------------------\n",
    "        AtomIndices = kwargs[ 'AtomIndices' ] if 'AtomIndices' in kwargs else df.index\n",
    "        with open('%s/%s'%(self.save_output,fout),'a') as fp:\n",
    "            #--- half step\n",
    "            if itime > 0:\n",
    "                fp.write('%s\\n'%df.iloc[AtomIndices].shape[0])\n",
    "                fp.write(\"Lattice=\\\" %s \\\" Time=%e  Step=%s  Energy=0.0  Barrier=%e\\n\"\\\n",
    "                         %(' '.join(map(str,self.box.CellVector.flatten())),self.mc_time,itime-0.5,self.catalog.iloc[ self.event_indx ].barrier)\n",
    "                        )\n",
    "                for item in np.c_[ df.iloc[AtomIndices] ]:\n",
    "                    fp.write('Ni %e %e %e %d\\n'%(item[2],item[3],item[4],item[0]))\n",
    "            #\n",
    "            #--- full step\n",
    "            fp.write('%s\\n'%df.iloc[AtomIndices].shape[0])\n",
    "            fp.write(\"Lattice=\\\" %s \\\" Time=%e  Step=%s  Energy=0.0  Barrier=%e\\n\"\\\n",
    "                     %(' '.join(map(str,self.box.CellVector.flatten())),self.mc_time,itime,0.0)\n",
    "                    )\n",
    "            for item in np.c_[ df.iloc[AtomIndices] ]:\n",
    "                fp.write('Ni %e %e %e %d\\n'%(item[2],item[3],item[4],item[0]))\n",
    "\n",
    "    def PrintMSD( self, fout, itime ):\n",
    "        with open('%s/%s'%(self.save_output,fout),'a') as fp:\n",
    "            if itime == 0:\n",
    "                fp.write('#  Elapsed Time    Sqr Displ.      Sqr Displ.     Sqr Displ.  KMC step\\n')\n",
    "                fp.write('#  ************    ***Total***       Atom Ni        Atom NiV  ********\\n')\n",
    "            fp.write('0.00000000E+00      0.0000000      0.0000000      0.0000000         %d\\n'%itime)\n",
    "\n",
    "                \n",
    "    def PrintCatalog( self, fout, itime ):\n",
    "        rwj = utl.ReadWriteJson()\n",
    "        with open('%s/%s'%(self.save_output,fout),'a') as fp:\n",
    "            rwj.Write([ self.catalog.to_dict( orient = 'list' ) ], fp,\n",
    "                      mc_time = [ self.mc_time ],\n",
    "                      mc_step = [ itime ],\n",
    "                     )\n",
    "            \n",
    "        #--- save ovito\n",
    "        indices = self.catalog.AtomIndex.astype( int )\n",
    "        df      = self.lmpData.coord_atoms_broken[ 0 ].iloc[ indices ]\n",
    "        disps   = np.c_[self.catalog[ 'ux uy uz'.split() ]]\n",
    "        atomm   = lp.Atoms(**df.to_dict(orient='series'),DisplacementX=disps[:,0],DisplacementY=disps[:,1],DisplacementZ=disps[:,2])\n",
    "        #\n",
    "        wd      = lp.WriteDumpFile(atomm, self.box )\n",
    "        with open('%s/%s'%(self.save_output,'catalog_ovito.xyz'),'a') as fp:\n",
    "            wd.Write(fp,itime = itime,\n",
    "                     attrs=['id', 'type', 'x', 'y', 'z','DisplacementX','DisplacementY','DisplacementZ'],\n",
    "                     fmt='%i %i %4.3e %4.3e %4.3e %4.3e %4.3e %4.3e')\n",
    "            \n",
    "            \n",
    "#         for AtomIndex in self.catalog.AtomIndex.astype( int ):\n",
    "#             fout = '%s/catalog_descriptors_atomIndx%s.xyz'%(self.save_output,AtomIndex)\n",
    "#             self.PrintDensityMap(AtomIndex, fout)\n",
    "        \n",
    "    @staticmethod    \n",
    "    def AddGaussianNoise(X,scale = 0.1):\n",
    "\n",
    "        epsilon_x = np.random.normal(scale=scale,size=X.size).reshape(X.shape)\n",
    "        X += epsilon_x\n",
    "\n",
    "    @staticmethod\n",
    "    def Zscore( X ):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        return scaler.transform( X )\n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "#                     disp           = np.c_[self.perAtomData.iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.positions.T,self.descriptors[atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, ' ', attr_list='x y z mass'.split())\n",
    "    \n",
    "    def Lammps( self ):\n",
    "        '''\n",
    "        run minimization in lammps\n",
    "        \n",
    "        version built at: /mnt/home/kkarimi/Project/git/lammps-2Aug2023/src\n",
    "        \n",
    "        follow instructions on 'https://docs.lammps.org/Python_head.html'\n",
    "        '''\n",
    "        \n",
    "        #--- lammps data file\n",
    "        df               = self.lmpData.coord_atoms_broken[ 0 ]\n",
    "        atom             = lp.Atoms(**df['id type x y z'.split() ].to_dict( orient = 'series' ) )\n",
    "        mass             = dict(zip(set(df.type),np.ones(len(set(df.type)))))\n",
    "        wd               = lp.WriteDataFile(atom, self.box, mass) #--- modify!!\n",
    "        fout             = 'lammps.dat'\n",
    "        wd.Write( fout )\n",
    "\n",
    "            \n",
    "        #--- run lammps\n",
    "        MEAM_library_DIR = '/mnt/home/kkarimi/Project/git/lammps-27May2021/src/../potentials'\n",
    "        INC              = '/mnt/home/kkarimi/Project/git/crystalDefect/simulations/lmpScripts'\n",
    "        args             = \"-var OUT_PATH . -var PathEam %s -var INC %s -var buff 0.0 \\\n",
    "                            -var nevery 1000 -var ParseData 1 -var DataFile %s -var ntype 3 -var cutoff 3.54\\\n",
    "                            -var DumpFile dumpMin.xyz -var WriteData data_minimized.dat\"%(MEAM_library_DIR,INC,fout)\n",
    "        lmp              = lammps.lammps( cmdargs = args.split() )\n",
    "        lmp.file( \"%s/in.minimization_constant_volume\"%INC )\n",
    "        \n",
    "        #--- update coords\n",
    "        rd               = lp.ReadDumpFile('data_minimized.dat')\n",
    "        rd.ReadData()\n",
    "        cords            = np.c_[rd.coord_atoms_broken[0]['x y z'.split()]]\n",
    "        self.lmpData.coord_atoms_broken[0]['x y z'.split()] = cords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38b8c5",
   "metadata": {},
   "source": [
    "# MachineLeranedMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65031dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fout = 'junk.json'\n",
    "# data={'eng':[1966,1974],'bra':[1970,1994]}\n",
    "# df=pd.DataFrame(data)\n",
    "# rwj = utl.ReadWriteJson()\n",
    "# rwj.Write([df.to_dict(orient='list')],fout,\n",
    "#          itime=[10],\n",
    "#          )\n",
    "# #help(utl.ReadWriteJson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731564e2",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba922c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dump.xyz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-35278ffbfadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#--- parse atom positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmlmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfParser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ml mc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfParser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ml mc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dump_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#--- initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ff548f2a07e4>\u001b[0m in \u001b[0;36mParse\u001b[0;34m(self, fp)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmpData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadDumpFile\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmpData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetCords\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mncount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'elapsed time=%s s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Tmp/txt/git/HeaDef/postprocess/LammpsPostProcess.py\u001b[0m in \u001b[0;36mGetCords\u001b[0;34m(self, ncount, sort, columns)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetCords\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mslist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dump.xyz'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    mc_steps = eval(confParser['ml mc']['mc_steps'])\n",
    "\n",
    "\n",
    "\n",
    "    mlmc     = MachineLeranedMC(confParser,\n",
    "    #                           verbose = True\n",
    "                             )\n",
    "\n",
    "    #--- parse atom positions\n",
    "    mlmc.Parse('%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['dump_file']))\n",
    "\n",
    "    #--- initialization\n",
    "    mlmc.Initialize()\n",
    "    mlmc.Print(    'allconf',        itime = 0 )\n",
    "    mlmc.Print(    'allconf_defect', itime = 0 )        \n",
    "    mlmc.PrintMSD( 'Diffusion.dat',  itime = 0 )\n",
    "    mlmc.DiscretizeTransitionPath()\n",
    "    \n",
    "    #--- mc loop\n",
    "    for mc_istep in range( mc_steps ):\n",
    "        print('mc_istep=',mc_istep)\n",
    "        \n",
    "        #--- build descriptors\n",
    "        mlmc.GetDescriptors()\n",
    "\n",
    "        #--- identify defects\n",
    "        mlmc.GetDefects(fp     = '%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['classifier_load']),\n",
    "                        scaler = '%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['classifier_scaler'])\n",
    "                       )\n",
    "\n",
    "        #--- predict diffusion paths \n",
    "        mlmc.GetDisp(fp        = '%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['regressor_load']),\n",
    "                     scaler    = '%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['regressor_scaler'])\n",
    "\n",
    "                    )\n",
    "\n",
    "        #--- predict energy \n",
    "        mlmc.GetBarrier(fp     = '%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['regressor_barrier']),\n",
    "                        scaler = '%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['regressor_en_scaler'])\n",
    "\n",
    "                    )\n",
    "\n",
    "        #--- build catalog\n",
    "        mlmc.BuildCatalog() # filtr = mlmc.atomTypes == 1 ) #--- only include atomType = 1\n",
    "        mlmc.PrintCatalog( 'catalog.json', itime = mc_istep )\n",
    "        \n",
    "        #--- mc sampling\n",
    "        mlmc.MCsampling()\n",
    "\n",
    "        #--- update disp\n",
    "        mlmc.UpdateDisp()\n",
    "\n",
    "        #--- save output\n",
    "        mlmc.Print( 'allconf', itime = mc_istep + 1 )\n",
    "        #\n",
    "        mlmc.Print( 'allconf_defect', itime = mc_istep + 1,\n",
    "                   AtomIndices = list(set(mlmc.catalog.AtomIndex.astype(int)))\n",
    "                  )        \n",
    "        mlmc.PrintMSD( 'Diffusion.dat', itime = mc_istep + 1 )\n",
    "\n",
    "        #--- update coord\n",
    "        mlmc.UpdateCords()\n",
    "\n",
    "        #--- minimize via lammps\n",
    "        mlmc.Lammps()\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "497.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
