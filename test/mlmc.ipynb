{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0151ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from buildDescriptors.ipynb\n",
      "conf. file sections: ['flags', 'input files', 'EnergyBarrier', 'neural net', 'ml mc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'buildDescriptors' from 'buildDescriptors.ipynb'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import configparser\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import pdb\n",
    "#--- tensorflow\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #--- rm warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#tf.get_logger().setLevel('INFO')\n",
    "# tf.autograph.set_verbosity(1)\n",
    "# import logging\n",
    "# tf.get_logger().setLevel(logging.ERROR)\n",
    "#\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#--- user modules\n",
    "confParser = configparser.ConfigParser() #--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import buildDescriptors as bd\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n",
    "imp.reload(bd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97901398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1966, 1970)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(sdict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38b8c5",
   "metadata": {},
   "source": [
    "# MachineLeranedMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "396a30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLeranedMC( bd.ParseConfiguration,\n",
    "                        bd.EnergyBarrier,\n",
    "                      ):\n",
    "    '''\n",
    "    Performs Machine Learned Monte Carlo Swaps\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 confParser, \n",
    "                 verbose = False\n",
    "                ):\n",
    "        \n",
    "#         bd.ParseConfiguration.__init__(self, confParser, verbose = verbose )\n",
    "        self.verbose     =  verbose \n",
    "        self.confParser  =  confParser\n",
    "        \n",
    "        self.save_output = 'saved_output'\n",
    "        !rm -r $self.save_output; mkdir $self.save_output\n",
    "        \n",
    "    def Parse(self,fp):\n",
    "        t0 = time.time()\n",
    "        self.lmpData = lp.ReadDumpFile( '%s'%(fp) ) \n",
    "        self.lmpData.GetCords( ncount = sys.maxsize)\n",
    "        if self.verbose:\n",
    "            print('elapsed time=%s s'%(time.time()-t0))\n",
    "            print('time steps:',self.lmpData.coord_atoms_broken.keys())\n",
    "            display(self.lmpData.coord_atoms_broken[0].head())\n",
    "\n",
    "    \n",
    "    def Initialize( self ):\n",
    "        \n",
    "        self.lmpData0 = self.lmpData.coord_atoms_broken[0].copy()\n",
    "        \n",
    "        natom         = len( self.lmpData.coord_atoms_broken[0] )\n",
    "        ndime         = 3\n",
    "        self.disp     = np.zeros( natom * ndime ).reshape((natom,ndime))\n",
    "        self.tdisp    = np.zeros( natom * ndime ).reshape((natom,ndime))\n",
    " \n",
    "        self.mc_time  = 0.0\n",
    "                \n",
    "        self.box      = lp.Box(BoxBounds=self.lmpData.BoxBounds[0],AddMissing=np.array([0,0,0]))\n",
    "\n",
    "    def GetDescriptors( self ):\n",
    "        '''\n",
    "        Compute structural descriptors \n",
    "        '''\n",
    "        \n",
    "        bd.EnergyBarrier.__init__( self,\n",
    "                                  None,#'%s/EVENTS_DIR'%self.confParser['input files']['input_path'],\n",
    "                                  None,#'%s/EVLIST_DIR'%self.confParser['input files']['input_path'],\n",
    "                                  self.lmpData,\n",
    "                                  None,# self.lmpDisp,\n",
    "                                   verbose    = self.verbose,\n",
    "                                   nconf      = 2, #--- only two events\n",
    "                                   confParser = self.confParser,\n",
    "                                   species    = ['Ni'], #'Ni Co Cr'.split()\n",
    "                                   r_cut      = eval(self.confParser['EnergyBarrier']['r_cut']),\n",
    "                                   dr         = eval(self.confParser['EnergyBarrier']['dr']),\n",
    "                                   scale      = eval(self.confParser['EnergyBarrier']['scale']),\n",
    "                                   n_max      = 8,\n",
    "                                   l_max      = 6,\n",
    "\n",
    "                      )\n",
    "        \n",
    "        self.perAtomData = self.lmpDataa\n",
    "        self.SetDescriptors(\n",
    "                      #soap = False,\n",
    "                      #acsf = True,   \n",
    "                      gr = True,\n",
    "                     )\n",
    "        \n",
    "    def GetDefects( self, fp ):\n",
    "        '''\n",
    "        Classify Defects\n",
    "        '''\n",
    "        \n",
    "        #--- load ml model\n",
    "        model = keras.models.load_model(fp)\n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "\n",
    "        #--- predict classes\n",
    "        predict_x = model.predict( X ) \n",
    "        self.predict_classes = np.argmax( predict_x, axis=1 )\n",
    "    \n",
    "    \n",
    "    def GetDisp( self, fp ):\n",
    "        '''\n",
    "        Predict Displacements\n",
    "        '''\n",
    "\n",
    "        #--- load ml model\n",
    "        model = keras.models.load_model(fp)\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        filtr  = self.predict_classes == 1\n",
    "        X      = np.c_[self.descriptors[ filtr ] ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "\n",
    "        #--- reshape X\n",
    "        shape      =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        n          =  X.shape[ 0 ]\n",
    "        X_reshaped =  X.reshape((n,shape[0],shape[1],shape[2],1))\n",
    "\n",
    "        self.predict_disp = model.predict( X_reshaped )\n",
    "        \n",
    "        #--- energy barriers\n",
    "        Energy = 1.0\n",
    "        self.predict_energy = np.ones(n)*Energy\n",
    "        \n",
    "        #--- center atoms\n",
    "        self.atomIDs     = self.lmpDataa[ filtr ].id\n",
    "        self.atomIndices = self.lmpDataa[ filtr ].index\n",
    "\n",
    "    \n",
    "    def BuildCatalog( self ):\n",
    "        rate_constant_prefactor = 1.0\n",
    "        kbt = 1.0\n",
    "        rates = rate_constant_prefactor * np.exp(-self.predict_energy/kbt)\n",
    "        \n",
    "        self.catalog = pd.DataFrame( np.c_[self.atomIDs, self.atomIndices, self.predict_energy, rates, self.predict_disp ],\n",
    "                                     columns = 'AtomId AtomIndex barrier true_rate dx dy dz'.split(),\n",
    "                                   )\n",
    "    def MCsampling( self ):\n",
    "        normalized_rates = np.cumsum( self.catalog.true_rate ) / self.catalog.true_rate.sum()\n",
    "        n                = len( normalized_rates )\n",
    "        x                = np.random.random()\n",
    "        self.event_indx  = np.arange( n )[ x < normalized_rates ][ 0 ]\n",
    "        \n",
    "        #--- advance time\n",
    "        inv_rate         = 1.0 / self.catalog.iloc[ self.event_indx ].true_rate\n",
    "        self.mc_time    += np.random.exponential( scale = inv_rate )\n",
    "\n",
    "    def UpdateDisp( self ):\n",
    "        self.disp[ : ]           = 0.0\n",
    "        atomIndex                = self.catalog.iloc[ self.event_indx ].AtomIndex.astype( int )\n",
    "        self.disp[ atomIndex ]   = self.predict_disp[ self.event_indx ]\n",
    "        self.tdisp[ atomIndex ] += self.predict_disp[ self.event_indx ]\n",
    "        \n",
    "    def UpdateCords( self ):\n",
    "        coords = np.c_[ self.lmpData.coord_atoms_broken[ 0 ]['x y z'.split()] ]\n",
    "        coords += self.disp\n",
    "        \n",
    "        #--- wrap coords ???\n",
    "        \n",
    "        \n",
    "        self.lmpData.coord_atoms_broken[0]['x y z'.split()] = coords\n",
    "\n",
    "    def Print( self, fout, itime ):\n",
    "        df = self.lmpData.coord_atoms_broken[ 0 ]\n",
    "        atomm = lp.Atoms(**df.to_dict(orient='series'),dx=self.disp[:,0],dy=self.disp[:,1],dz=self.disp[:,2])\n",
    "#         pdb.set_trace()\n",
    "        #\n",
    "        wd = lp.WriteDumpFile(atomm, self.box )\n",
    "        with open('%s/%s'%(self.save_output,fout),'a') as fp:\n",
    "            wd.Write(fp,itime = itime,\n",
    "                     attrs=['id', 'type', 'x', 'y', 'z','dx','dy','dz'],\n",
    "                     fmt='%i %i %4.3e %4.3e %4.3e %4.3e %4.3e %4.3e')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731564e2",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba922c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fdac38a4cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "43/43 [==============================] - 0s 6ms/step\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fdac38cc560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fdac38a4950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "43/43 [==============================] - 0s 5ms/step\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fdac38694d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fdac3a5f200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fdac54c6950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fdac3a5f9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fdac389fa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 109ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mc_steps = 10\n",
    "\n",
    "mlmc  =  MachineLeranedMC(confParser,\n",
    "#                           verbose = True\n",
    "                         )\n",
    "    \n",
    "#--- parse atom positions\n",
    "mlmc.Parse('%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['dump_file']))\n",
    "    \n",
    "#--- initialization\n",
    "mlmc.Initialize()\n",
    "#mlmc.Print( 'coords.xyz', itime = 0 )\n",
    "    \n",
    "for mc_istep in range( mc_steps ):\n",
    "    #--- build descriptors\n",
    "    mlmc.GetDescriptors()\n",
    "\n",
    "    #--- identify defects\n",
    "    mlmc.GetDefects('%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['classifier_load']))\n",
    "\n",
    "    #--- predict diffusion paths \n",
    "    mlmc.GetDisp('%s/%s'%(confParser['ml mc']['input_path'],confParser['ml mc']['regressor_load']))\n",
    "\n",
    "    #--- build catalog\n",
    "    mlmc.BuildCatalog()\n",
    "\n",
    "    #--- mc sampling\n",
    "    mlmc.MCsampling()\n",
    "\n",
    "    #--- update disp\n",
    "    mlmc.UpdateDisp()\n",
    "   \n",
    "    #--- save output\n",
    "    mlmc.Print( 'coords.xyz', itime = mc_istep )\n",
    "   \n",
    "    #--- update coord\n",
    "    mlmc.UpdateCords()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmc.lmpData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmc.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc079c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlmc.mc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(mlmc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
