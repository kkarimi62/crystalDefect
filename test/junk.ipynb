{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded12cf",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import-libs\" data-toc-modified-id=\"import-libs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>import libs</a></span></li><li><span><a href=\"#Train-NN\" data-toc-modified-id=\"Train-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#main():-classifier\" data-toc-modified-id=\"main():-classifier-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>main(): classifier</a></span></li><li><span><a href=\"#main():-regressor\" data-toc-modified-id=\"main():-regressor-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>main(): regressor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#test-example:-2d\" data-toc-modified-id=\"test-example:-2d-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>test example: 2d</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-connected-in-sklearn\" data-toc-modified-id=\"fully-connected-in-sklearn-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>fully connected in sklearn</a></span></li><li><span><a href=\"#fully-connected-in-keras\" data-toc-modified-id=\"fully-connected-in-keras-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>fully connected in keras</a></span></li><li><span><a href=\"#cnn\" data-toc-modified-id=\"cnn-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>cnn</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117638d",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf. file sections: ['flags', 'input files', 'descriptors', 'neural net', 'neural net classification', 'neural net regression', 'gnn', 'NeuralNets', 'ml mc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gnnEnv/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'LammpsPostProcess' from '../../HeaDef/postprocess/LammpsPostProcess.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "confParser = configparser.ConfigParser()\n",
    "\n",
    "#--- parse conf. file\n",
    "confParser.read('configuration.ini')\n",
    "print('conf. file sections:',confParser.sections())\n",
    "\n",
    "#--- system libs\n",
    "import os\n",
    "import sys\n",
    "list(map(lambda x:sys.path.append(x), confParser['input files']['lib_path'].split()))\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "if not eval(confParser['flags']['RemoteMachine']):\n",
    "    plt.rc('text', usetex=True)\n",
    "import pickle\n",
    "\n",
    "#--- ase\n",
    "from dscribe.descriptors import SOAP, ACSF\n",
    "import ase\n",
    "import ase.io\n",
    "import ase.build\n",
    "from ase.io import lammpsdata\n",
    "\n",
    "\n",
    "#--- sklearn\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "#--- tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# PyTorch geometric\n",
    "import torch_geometric\n",
    "import torch_geometric.data as geom_data\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# PL callbacks\n",
    "#from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch import Tensor\n",
    "\n",
    "#--- user modules\n",
    "import LammpsPostProcess as lp\n",
    "import utility as utl\n",
    "import imp\n",
    "imp.reload(utl)\n",
    "imp.reload(lp)\n",
    "\n",
    "#--- increase width\n",
    "#from IPython.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a2e60",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd8c31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, verbose=False,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        for key in kwargs:\n",
    "            setattr(self,key,kwargs[key])\n",
    "            \n",
    "            \n",
    "        !mkdir $self.best_model\n",
    "\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            if irun == 0:\n",
    "                #--- same configurations!\n",
    "                self.descriptors  = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['data']]\n",
    "                self.shape        = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['shape']].flatten()\n",
    "                self.positions    = np.c_[rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz .'%(path,irun))\n",
    "            try:\n",
    "                data = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                #--- displacement data\n",
    "                self.perAtomData[irun] = pd.DataFrame(np.c_[data],\n",
    "                columns='id\ttype\tx\ty\tz\tux\tuy\tuz\tenergy_barrier\tdefect_label'.split()\n",
    "                            )\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "\n",
    "#     def Junk(self,path,nruns):\n",
    "#         self.perAtomData = {}\n",
    "#         self.Descriptors = {}\n",
    "#         self.Shape       = {}\n",
    "#         self.Positions   = {}\n",
    "#         self.Catalogs    = {}\n",
    "#         #\n",
    "#         rwjs = utl.ReadWriteJson()\n",
    "#         for irun in range(nruns):\n",
    "#             try:\n",
    "# #                 data_json               = rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]\n",
    "# #                 self.Descriptors[irun]  = np.c_[data_json['data']]\n",
    "# #                 self.Shape[irun]        = np.c_[data_json['shape']].flatten()\n",
    "# #                 self.Positions[irun]    = np.c_[data_json['xyz']]\n",
    "#                 os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "#                 data                    = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "#                 self.perAtomData[irun]  = pd.DataFrame(np.c_[data],\n",
    "#                                                        columns ='id type x y z'.split()\n",
    "#                                                       )\n",
    "#                 self.Catalogs[irun]     = pd.read_csv('%s/Run%s/catalog.txt'%(path,irun))\n",
    "#             except:\n",
    "# #                 if self.verbose:\n",
    "# #                     traceback.print_exc()\n",
    "#                 continue\n",
    "                \n",
    "        \n",
    "#         self.nruns     = list(self.perAtomData.keys())\n",
    "#         self.nruns.sort()\n",
    "\n",
    "#         self.Descriptors[ 0 ] = pd.DataFrame(np.random.random(size=9876))\n",
    "#         #--- assert shape and positions are the same for all realizations\n",
    "# #         self.shape     = self.Shape[ self.nruns[ 0 ] ]\n",
    "# #         self.positions = self.Positions[ self.nruns[ 0 ] ]\n",
    "\n",
    "        \n",
    "        \n",
    "    def Parse2nd(self,path,nruns):\n",
    "        self.perAtomData = {}\n",
    "        self.Descriptors = {}\n",
    "        self.Shape       = {}\n",
    "        self.Positions   = {}\n",
    "        self.Catalogs    = {}\n",
    "        #\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                data_json               = rwjs.Read('%s/Run%s/descriptors.json'%(path,irun))[0]\n",
    "                self.Descriptors[irun]  = np.c_[data_json['data']]\n",
    "                self.Shape[irun]        = np.c_[data_json['shape']].flatten()\n",
    "                self.Positions[irun]    = np.c_[data_json['xyz']]\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                data                    = np.loadtxt('%s/Run%s/perAtomData.txt'%(path,irun))\n",
    "                self.perAtomData[irun]  = pd.DataFrame(np.c_[data],\n",
    "                                                       columns ='id type x y z'.split()\n",
    "                                                      )\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/catalog.txt'%(path,irun))\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns     = list(self.perAtomData.keys())\n",
    "        self.nruns.sort()\n",
    "\n",
    "        #--- assert shape and positions are the same for all realizations\n",
    "        self.shape     = self.Shape[ self.nruns[ 0 ] ]\n",
    "        self.positions = self.Positions[ self.nruns[ 0 ] ]\n",
    "        \n",
    "    def Combine(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "#         pdb.set_trace()\n",
    "        #--- center atoms\n",
    "        center_atom_indices = list(map(lambda x:NeuralNetwork.GetCenterAtom( self.perAtomData[x])[0],self.nruns))\n",
    "        sdict = dict(zip(center_atom_indices,self.nruns))\n",
    "        \n",
    "        atom_ids = list(sdict.keys())\n",
    "        atom_ids.sort()\n",
    "        #         center_atom_indices = list( set( center_atom_indices ) )\n",
    "        data = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[sdict[x]].iloc[ x ]],atom_ids)),axis=1).T\n",
    "#        descriptors_center_atoms = self.descriptors[atom_ids]\n",
    "        descriptors_center_atoms = np.c_[list(map(lambda x:self.Descriptors[sdict[x]][x], atom_ids))]\n",
    "    \n",
    "        #--- data frame\n",
    "#        print(data.shape)\n",
    "        irun = self.nruns[0]\n",
    "        df_combined = pd.DataFrame(data,columns=list(self.perAtomData[irun].keys()))\n",
    "    \n",
    "        #--- filter crystalline atoms\n",
    "        filtr = self.perAtomData[irun].defect_label == 0.0\n",
    "        df_crystalline = self.perAtomData[irun][filtr]\n",
    "        descriptors_crystalline = self.descriptors[filtr]\n",
    "\n",
    "        #--- merge\n",
    "        keys = list(df_combined.keys())\n",
    "        data_concat = np.concatenate([np.c_[df_combined[keys]],np.c_[df_crystalline[keys]]],axis=0) \n",
    "        self.perAtomData = pd.DataFrame(data_concat,\n",
    "                              columns=keys\n",
    "                             )\n",
    "\n",
    "        \n",
    "        #--- merge descriptors\n",
    "        self.descriptors = np.concatenate([descriptors_center_atoms,descriptors_crystalline],axis=0)\n",
    "\n",
    "        assert self.perAtomData.shape[ 0 ] == self.descriptors.shape[0], 'need more mc swaps: %s %s'\\\n",
    "        %(self.perAtomData.shape[ 0 ],self.descriptors.shape[0])\n",
    "                            \n",
    "    def Combine2nd(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('concatenating descriptors ...')\n",
    "            \n",
    "        irun = self.nruns[0]\n",
    "        keys = list( self.perAtomData[ irun ].keys() )\n",
    "\n",
    "        #--- center atoms\n",
    "        data_concat         = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[x]],self.nruns)),axis=0)\n",
    "        self.perAtomData    = pd.DataFrame(data_concat,\n",
    "                                 columns=keys\n",
    "                                )\n",
    "        self.descriptors    = np.concatenate(list(map(lambda x:self.Descriptors[x], self.nruns)))\n",
    "    \n",
    "#     def Junk2nd(self):\n",
    "        \n",
    "#         if self.verbose:\n",
    "#             print('concatenating descriptors ...')\n",
    "            \n",
    "#         irun = self.nruns[0]\n",
    "#         keys = list( self.perAtomData[ irun ].keys() )\n",
    "\n",
    "#         #--- center atoms\n",
    "#         data_concat         = np.concatenate(list(map(lambda x: np.c_[self.perAtomData[x]],self.nruns)),axis=0)\n",
    "#         self.perAtomData    = pd.DataFrame(data_concat,\n",
    "#                                  columns=keys\n",
    "#                                 )\n",
    "#         self.descriptors    = None #self.Descriptors[0]\n",
    "\n",
    "    def Parse3rd(self,path,nruns):\n",
    "\n",
    "        self.Catalogs    = {}\n",
    "        self.transition_paths = []\n",
    "        self.transition_paths_discretized = []\n",
    "        #\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                self.transition_paths.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths.json'%(path,irun)) )\n",
    "                self.transition_paths_discretized.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths_discretized.json'%(path,irun)) )\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/saved_output/catalog.txt'%(path,irun))\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns     = list(self.Catalogs.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "    def DataBuilder( self ):\n",
    "        \n",
    "        ntrain        = self.ntrain\n",
    "        num_snapshots = len( self.transition_paths )\n",
    "        snapshots     = range(num_snapshots)\n",
    "        input_data    = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "        # Example target data (displacement vectors for each snapshot and each path)\n",
    "        target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots]\n",
    "\n",
    "        # Augment the dataset to have order 100 snapshots\n",
    "        augmented_input_data = []\n",
    "        augmented_target_displacements = []\n",
    "        input_data_tensor = torch.stack(input_data)\n",
    "        ntrain_initial = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "        n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input, augmented_target = GraphNet.augment_data(input_data, target_displacements, self.noise_std)\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "        adj_matrices = torch.stack(GraphNet.compute_adjacency_matrices(augmented_input_data, rcut=3.0)) \n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data_tensor = torch.stack(augmented_input_data)\n",
    "#        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "        # Standardize the augmented input data\n",
    "        mean = input_data_tensor.mean(dim=(0, 1))\n",
    "        std = input_data_tensor.std(dim=(0, 1))\n",
    "        standardized_input_data = [GraphNet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "\n",
    "\n",
    "        # Convert input data to tensors\n",
    "        target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data)):\n",
    "            x = input_data_tensor[i]  # Node features\n",
    "            edge_index = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "            y = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "            # Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            graphs.append(data)\n",
    "            \n",
    "        # Create a single large graph by concatenating Data objects\n",
    "        large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "        # Define batch size and create DataLoader\n",
    "        batch_size = len(input_data)\n",
    "#        loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "        train_ratio = 0.8\n",
    "\n",
    "        # Define batch sizes for training and test dataloaders\n",
    "        train_batch_size = int(batch_size * train_ratio)\n",
    "\n",
    "        # Create DataLoader for training dataset\n",
    "        loader = DataLoader(large_graph, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Accessing batches in the DataLoader\n",
    "        loader_iter=iter(loader)\n",
    "        self.dataset_train = next(loader_iter)\n",
    "        self.dataset_test = next(loader_iter)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('dataset_train:',self.dataset_train)\n",
    "            print('dataset_test:',self.dataset_test)\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def GetCenterAtom(df):\n",
    "        disp_magnitude = df.ux**2+df.uy**2+df.uz**2\n",
    "        center_atom_indx = disp_magnitude.sort_values(ascending=False).index[0]\n",
    "        return center_atom_indx, int(df.iloc[ center_atom_indx ].id)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def zscore(slist):\n",
    "#         tmp = np.copy(slist)\n",
    "#         print(np.mean(tmp),np.std(tmp))\n",
    "#         tmp -= np.mean(tmp)\n",
    "#         tmp /= np.std(tmp)\n",
    "#         return tmp\n",
    "\n",
    "    def PCA(self,\n",
    "           n_components=2,\n",
    "            random_state = 1,\n",
    "           ):\n",
    "        #--- concat. data\n",
    "        X = self.descriptors\n",
    "        pca = PCA(n_components=n_components,random_state=random_state)\n",
    "        pca.fit(X)\n",
    "        X_transformed = pca.transform(X)\n",
    "\n",
    "        xdata = X_transformed[:,0]\n",
    "        ydata = X_transformed[:,1]\n",
    "        #\n",
    "        filtr_defects = self.perAtomData.defect_label == 0.0\n",
    "        #\n",
    "\n",
    "        legend = utl.Legends()\n",
    "        legend.Set(bbox_to_anchor=(1.1,.5, 0.5, 0.5))\n",
    "#         pdb.set_trace()\n",
    "        #ax = utl.PltErr(zscore(xdata)[filtr_defects],zscore(ydata)[filtr_defects],\n",
    "        ax = utl.PltErr(xdata[filtr_defects],ydata[filtr_defects],\n",
    "                  attrs={'fmt':'x','alpha':1,'label':'defect_free'},\n",
    "                        Plot = False,\n",
    "        #                 xlim=(-2,2),\n",
    "        #                 ylim=(-2,2),\n",
    "                  )\n",
    "\n",
    "        #utl.PltErr(zscore(xdata)[~filtr_defects],zscore(ydata)[~filtr_defects],\n",
    "        !mkdir png\n",
    "        utl.PltErr(xdata[~filtr_defects],ydata[~filtr_defects],\n",
    "                  attrs={'fmt':'.','color':'red','label':'defects'},\n",
    "                   ax=ax,\n",
    "                   xstr='pca_1',ystr='pca_2',\n",
    "                   legend = legend.Get(),\n",
    "                   title='png/pca.png'\n",
    "                  )\n",
    "    def Spectra(self,\n",
    "               nrows=100,\n",
    "               ):\n",
    "        assert nrows <= self.descriptors.shape[ 0 ]\n",
    "        !mkdir png\n",
    "        utl.PltBitmap(np.log10(np.abs(self.descriptors[:nrows,:])),\n",
    "                      xlabel=r'$\\mathrm{ndim}$',ylabel=r'$\\mathrm{natom}$',\n",
    "                      xlim=(0,self.descriptors.shape[1]),\n",
    "                      ylim=(0,nrows),\n",
    "                      colorbar=True,\n",
    "                      zscore=False,\n",
    "                      vminmax=(-3,3),\n",
    "                      title='png/feature_bitmap.png'\n",
    "                     )\n",
    "        \n",
    "    def SklearnMLP(self,X_train,y_train):\n",
    "        #-----------------------\n",
    "        #--- parameter grid\n",
    "        #-----------------------\n",
    "#         param_grid = {\n",
    "#                         'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "#                          #'activation' : ['tanh', 'relu'],\n",
    "#                          'learning_rate_init':self.learning_rate_init,\n",
    "# #                         'alpha':self.alpha, #--- regularization \n",
    "#                          #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "#                         'n_iter_no_change':self.n_iter_no_change,\n",
    "# #                        'tol':self.tol,\n",
    "#                         'max_iter':self.max_iter,\n",
    "#                      } \n",
    "        mlp   =  MLPClassifier(random_state=1,\n",
    "                               hidden_layer_sizes = self.hidden_layer_sizes[0],\n",
    "                               learning_rate_init = self.learning_rate_init[0],\n",
    "                               n_iter_no_change   = self.n_iter_no_change[0],\n",
    "                               max_iter           = self.max_iter[0],\n",
    "                               verbose=self.verbose)\n",
    "#         clf  =  GridSearchCV(mlp, param_grid)\n",
    "#        clf.fit(X_train,y_train)\n",
    "        mlp.fit(X_train,y_train)\n",
    "        model =  mlp #clf.best_estimator_\n",
    "        loss  =  model.loss_curve_\n",
    "        val_loss = loss\n",
    "        return (model, loss, val_loss)\n",
    "\n",
    "    def KerasANN(self, X_train, y_train,X_test, y_test, ndime):\n",
    "\n",
    "        model     = keras.Sequential([ #--- The network architecture\n",
    "                                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                #                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                                    layers.Dense(ndime, activation='softmax')\n",
    "                                    ])\n",
    "        \n",
    "#         shape         =  (self.shape[0]*self.shape[1]*self.shape[2],)\n",
    "#         inputs        =  keras.Input(shape=shape)\n",
    "#         #------------------------------\n",
    "#         #--- The network architecture\n",
    "#         #------------------------------\n",
    "#         x             =  layers.Dense(   self.hidden_layer_size, activation=self.activation\n",
    "#                                        )(inputs)\n",
    "#         for i in range( self.number_hidden_layers ):\n",
    "#             x       = layers.Dense( self.hidden_layer_size, activation=self.activation\n",
    "#                                      )(x)\n",
    "#         #--- output layer\n",
    "# #         x       = layers.Flatten()(x)\n",
    "#         outputs = layers.Dense( ndime, activation=self.activation)(x)\n",
    "#         model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        \n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "        model.compile( optimizer=optimizer,\n",
    "                       loss=\"sparse_categorical_crossentropy\",\n",
    "                       metrics=[\"mse\"]\n",
    "                     )\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#                                                     monitor=\"mse\",\n",
    "#                                                     save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        model.fit( X_train, y_train, \n",
    "           validation_data      = ( X_test, y_test ),\n",
    "#             callbacks           = callbacks,\n",
    "            epochs              = self.max_iter[0], \n",
    "            verbose             = self.verbose, \n",
    "            shuffle             = False, \n",
    "#             batch_size     = 32,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "         )    \n",
    "\n",
    "        model.save('best_model/convnetClassifier_from_scratch.tf')\n",
    "        loss      = model.history.history['loss']\n",
    "        val_loss  = model.history.history['val_loss']\n",
    "        best_model = model #keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        return (best_model, loss, val_loss)\n",
    "\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def MapClassIds( y ):\n",
    "        ndime         = len(set(y.flatten()))\n",
    "        class_ids     = list(set(y.flatten()))\n",
    "        class_ids.sort()\n",
    "        map_class_ids = dict(zip(class_ids,range(ndime)))        \n",
    "        return ndime, np.c_[list(map(lambda x:[map_class_ids[x]],y.flatten()))]\n",
    "    \n",
    "    @staticmethod\n",
    "    def GetSubSetCrystallineAtoms(X,y,n_train):\n",
    "        #--- data frame\n",
    "        df = pd.DataFrame( y, columns=['topoID'] )\n",
    "        #--- groups\n",
    "        sdict = df.groupby(by='topoID').groups\n",
    "        if sdict[ 0 ].shape[ 0 ] < n_train:\n",
    "            return X, y\n",
    "        indices = np.random.choice(sdict[ 0 ], size=n_train, replace=False)\n",
    "        sdict[ 0 ] = indices\n",
    "        indices_total = np.concatenate( list(map(lambda x:sdict[x],sdict)) )\n",
    "        return X[indices_total], y[ indices_total ]\n",
    "    \n",
    "    def GetLabels( self, irun ):\n",
    "        nsize                                  = self.Descriptors[ irun ].shape[ 0 ]\n",
    "        y_labels                               = np.zeros(nsize,dtype=int)\n",
    "        nonCrystallineAtomsIndices             = self.Catalogs[ irun ].AtomIndex\n",
    "        nonCrystallineAtomsTopoIds             = self.Catalogs[ irun ].IniTopoId.astype(int)\n",
    "        y_labels[ nonCrystallineAtomsIndices ] = nonCrystallineAtomsTopoIds\n",
    "        return y_labels.reshape( ( nsize, 1 ) )\n",
    "\n",
    "    \n",
    "    def TrainClassifier(self,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        #--- get labels\n",
    "        y_labels = np.concatenate( list( map(lambda x:self.GetLabels(x), self.nruns ) ) )\n",
    "        assert self.descriptors.shape[ 0 ] == y_labels.shape[ 0 ]\n",
    "        \n",
    "        #--- map topo ids to integers 0, 1 ... ndime\n",
    "        ndime, y = NeuralNetwork.MapClassIds( y_labels )\n",
    "\n",
    "        \n",
    "        X      = np.c_[self.descriptors]\n",
    "\n",
    "        #--- filter: only train a subset of crystalline atoms\n",
    "        X, y   = NeuralNetwork.GetSubSetCrystallineAtoms( X, y, self.n_train )\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/classifier.sav'%self.best_model )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.001 )\n",
    "\n",
    "\n",
    "        #--- exclude void\n",
    "#        filtr  = self.perAtomData.type==2\n",
    "#         X      = X[~filtr]\n",
    "#         y      = y[~filtr]\n",
    "\n",
    "        #--- sample from crystalline atoms\n",
    "        \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "#        train_size = self.n_train\n",
    "#        test_size  = int( self.n_train / 3 )\n",
    "        assert X.shape[0] >= self.n_train, 'increase nruns!' #train_size + train_size, 'increase nruns!'\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "#                                                               test_size=test_size, train_size=train_size,\n",
    "                                                              random_state=random_state)\n",
    "        if len(set(y_train.flatten())) < ndime:\n",
    "            'warning: not every class present in train set!'\n",
    "        if len(set(y_test.flatten()))  < ndime: \n",
    "            'warning: not every class present in test set!'\n",
    "        \n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                (model, loss, val_loss) = self.SklearnMLP(X_train,y_train)\n",
    "                classes_x = model.predict(X_test) \n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                (model, loss, val_loss) = self.KerasANN(X_train, y_train,X_test, y_test, ndime)\n",
    "                predict_x = model.predict(X_test) \n",
    "                classes_x = np.argmax(predict_x,axis=1)\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkClassifier( y )\n",
    "            predict_x = model.predict(X_test) \n",
    "            classes_x = np.argmax(predict_x,axis=1)\n",
    "                    \n",
    "        #--- save loss data\n",
    "        !mkdir png\n",
    "        np.savetxt('png/val_loss_classification.txt',\n",
    "                   np.c_[range(len(loss)),loss,val_loss],\n",
    "                   header='epoch loss val_loss')\n",
    "\n",
    "        #--- confusion matrix\n",
    "        cm = confusion_matrix(y_test, classes_x,\n",
    "                         labels=range(ndime)\n",
    "                        )\n",
    "        np.savetxt('png/confusion.txt',np.c_[cm])\n",
    "\n",
    "        \n",
    "    def PrintDescriptors(self,descriptors,y,fout):\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        rwjs.Write([{'descriptors':np.c_[descriptors],\n",
    "                     'target':np.c_[y],\n",
    "                     'shape_descriptor':self.shape}],fout)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def GetTopoIds( catalog, key ): \n",
    "        TopoIds = list( catalog.groupby( by = key ).groups.keys())\n",
    "        TopoIds.sort()\n",
    "        return TopoIds \n",
    "    \n",
    "    @staticmethod\n",
    "    def MapTopoIds( TopoIds ):\n",
    "        ndime         = len( TopoIds )\n",
    "        map_TopoIds = dict(zip(TopoIds,range(ndime)))        \n",
    "        return map_TopoIds\n",
    "\n",
    "    def GetTopoArrayIndex( self, IniTopoId, FinTopoId ):\n",
    "        mappedIniTopoId = self.mappedTopoIds[ IniTopoId ]\n",
    "        mappedFinTopoId = self.mappedTopoIds[ FinTopoId ]\n",
    "        assert mappedIniTopoId < self.n_unique_transition_paths and\\\n",
    "               mappedFinTopoId < self.n_unique_transition_paths \n",
    "        return mappedIniTopoId * self.n_unique_transition_paths * self.ndime + mappedFinTopoId * self.ndime\n",
    "\n",
    "    def GetTopoArrayIndex2nd( self, ux, uy, uz ):\n",
    "        aa = np.c_[[ux,uy,uz]].T\n",
    "        H, bin_edges = np.histogramdd(aa,bins=self.bins)        \n",
    "        assert H.sum() == 1.0\n",
    "        \n",
    "        return H.astype(int).flatten()\n",
    "        \n",
    "\n",
    "    def FillTargetMatrix( self, item ):\n",
    "#        pdb.set_trace()\n",
    "        ux = item.inifin_dr * item.DirX\n",
    "        uy = item.inifin_dr * item.DirY\n",
    "        uz = item.inifin_dr * item.DirZ\n",
    "        assert np.abs( ux ) < self.umax and\\\n",
    "                np.abs( uy ) < self.umax and\\\n",
    "                np.abs( uz ) < self.umax,'ux=%e, uy=%e, uz=%e increase self.umax!'%(ux,uy,uz)\n",
    "        irow                                   = int( item.AtomIndex )\n",
    "#        icol                                   = int( self.GetTopoArrayIndex( item.IniTopoId, item.FinTopoId ) )\n",
    "        H                                   = self.GetTopoArrayIndex2nd( ux, uy, uz )\n",
    "\n",
    "        self.y_targets[ irow ] += H           \n",
    "\n",
    "    def DiscretizeTransitionPath( self ):\n",
    "         #--- hard-coded values\n",
    "        xlin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        ylin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        zlin = np.arange(-self.umax,+self.umax+self.du,self.du)\n",
    "        self.nbinx = len(xlin)-1\n",
    "        self.nbiny = len(ylin)-1\n",
    "        self.nbinz = len(zlin)-1\n",
    "        self.bins = (xlin, ylin, zlin)\n",
    "        self.xv, self.yv, self.zv = np.meshgrid( self.bins[1][:-1], self.bins[0][:-1], self.bins[2][:-1] )\n",
    "\n",
    "#        print(yv[H==1],xv[H==1],zv[H==1])\n",
    "\n",
    "    def GetTargets( self, irun ):\n",
    "        #--- set-up y matrix\n",
    "#         IniTopoId                              = NeuralNetwork.GetTopoIds( self.Catalogs[ irun ], 'IniTopoId' )\n",
    "#         FinTopoId                              = NeuralNetwork.GetTopoIds( self.Catalogs[ irun ], 'FinTopoId' )\n",
    "#         TopoIds                                = list( set( FinTopoId + IniTopoId ) ) #--- transition path ids\n",
    "#         TopoIds.sort()\n",
    "#         self.mappedTopoIds                     = NeuralNetwork.MapTopoIds( TopoIds )\n",
    "        \n",
    "#         self.n_unique_transition_paths         = len( TopoIds )\n",
    "\n",
    "\n",
    "        nsize                                  = ( self.Descriptors[ irun ].shape[ 0 ], self.nbinx * self.nbiny * self.nbinz )\n",
    "        self.y_targets                         = np.zeros( nsize[ 0 ] * nsize[ 1 ], dtype=int ).reshape( nsize )\n",
    "        \n",
    "        #--- fill y matrix\n",
    "        self.Catalogs[ irun ].apply( lambda x: self.FillTargetMatrix( x ), axis = 1 )\n",
    "        \n",
    "        #--- assert self.y_targets is binary\n",
    "        assert set(self.y_targets.flatten()) == set(np.array([0,1])), 'decrease du!'\n",
    "        return self.y_targets\n",
    "        \n",
    "    def MaskCrystallineAtoms(self, irun ):\n",
    "        nsize                              = self.Descriptors[ irun ].shape[ 0 ]\n",
    "        mask                               = np.zeros(nsize,dtype=bool)\n",
    "        nonCrystallineAtomsIndices         = np.array( list( set( self.Catalogs[ irun ].AtomIndex ) ) )\n",
    "        mask[ nonCrystallineAtomsIndices ] = True\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def GetInputOutput( self, irun, indx ):\n",
    "        atomIndices     =  self.Catalogs[ irun ].AtomIndex\n",
    "        pixel_map_input =  self.Descriptors[ irun ][ atomIndices ]    \n",
    "        dr              =  np.c_[self.Catalogs[ irun ]['inifin_dr']].flatten()\n",
    "        dr_multi        = np.c_[ dr, dr, dr ]\n",
    "        vector_input    =  self.Catalogs[ irun ][ ' DirX      DirY      DirZ'.split() ] * dr_multi\n",
    "        output          =  self.Catalogs[ irun ][ 'barrier' ]\n",
    "        return [pixel_map_input, vector_input, output][ indx ]\n",
    "\n",
    "    def TrainRegressorBarriers(self,\n",
    "                       random_state=1,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #--- get transition path bitmap\n",
    "#        self.DiscretizeTransitionPath()\n",
    "#        self.ndime                                  = 4 #--- hard-coded: (ux,uy,uz,E)\n",
    "        pixel_maps_input = np.concatenate( list( map(lambda x:self.GetInputOutput(x,0), self.nruns ) ) )\n",
    "        vectors_input    = np.concatenate( list( map(lambda x:self.GetInputOutput(x,1), self.nruns ) ) )\n",
    "        scalar_output    = np.concatenate( list( map(lambda x:self.GetInputOutput(x,2), self.nruns ) ) )\n",
    "\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[pixel_maps_input,vectors_input]\n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/scaler_regression_barriers.sav'%self.best_model )\n",
    "        y      = np.c_[ scalar_output ]\n",
    "        \n",
    "        if X.shape[ 0 ] - self.n_train < 0 :  \n",
    "            X = NeuralNetwork.Duplicate(X, new_size = self.n_train )\n",
    "            y = NeuralNetwork.Duplicate(y, new_size = self.n_train )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.01 )\n",
    "        NeuralNetwork.AddGaussianNoise(y, scale = 0.01 )\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, #stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "\n",
    "                \n",
    "        (model, loss, val_loss), (X_train, X_test) = self.ConvNetworkMixedInput(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            \n",
    "            \n",
    "            #--- validation\n",
    "        NeuralNetwork.Validation(loss, val_loss, \n",
    "                                 model, \n",
    "                                 X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "    def TrainRegressorTransitionPaths(self,#stratify,y,\n",
    "                       random_state=1,\n",
    "                       printOvito = False,\n",
    " #                      filtr = None,\n",
    "                       ):\n",
    "        '''\n",
    "        Multi-layer Perceptron regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stratify : array-like, default=None\n",
    "        If not None, data is split in a stratified fashion, using this as\n",
    "        the class labels.\n",
    "        \n",
    "        y : array-like, target data\n",
    "        \n",
    "        random_state : initial seed, default=1\n",
    "        \n",
    "        printOvito : bool, default=False\n",
    "        \n",
    "        filtr : bool, default=False\n",
    "        if not None, data is filtered before calling train-test split\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #--- get transition path bitmaps\n",
    "        self.DiscretizeTransitionPath()\n",
    "#        self.ndime                                  = 4 #--- hard-coded: (ux,uy,uz,E)\n",
    "        y = np.concatenate( list( map(lambda x:self.GetTargets(x), self.nruns ) ) )\n",
    "\n",
    "        \n",
    "        #--- filtr crystalline atoms\n",
    "        filtr = np.concatenate( list( map(lambda x:self.MaskCrystallineAtoms(x), self.nruns ) ) )\n",
    "\n",
    "        y     = y[ filtr ]\n",
    "        \n",
    "#        pdb.set_trace()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "\n",
    "        ndime  = y.shape[1] #--- dimension of the target vector\n",
    "        \n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors[filtr]]\n",
    "        X      = NeuralNetwork.Zscore( X, save_model = '%s/scaler_regression.sav'%self.best_model )\n",
    "        \n",
    "        \n",
    "        if X.shape[ 0 ] - self.n_train < 0 :  \n",
    "            X = NeuralNetwork.Duplicate(X, new_size = self.n_train )\n",
    "            y = NeuralNetwork.Duplicate(y, new_size = self.n_train )\n",
    "\n",
    "        #--- add noise\n",
    "        NeuralNetwork.AddGaussianNoise(X, scale = 0.1 )\n",
    "#        NeuralNetwork.AddGaussianNoise(y, scale = 0.1 )\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, #stratify=stratify,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "\n",
    "        #-----------------------\n",
    "        #--- train model\n",
    "        #-----------------------\n",
    "        if self.fully_connected: #--- dense nn\n",
    "            if self.implementation == 'sklearn':\n",
    "                #-----------------------\n",
    "                #--- parameter grid\n",
    "                #-----------------------\n",
    "                param_grid = {\n",
    "                                'hidden_layer_sizes':self.hidden_layer_sizes,\n",
    "                                 #'activation' : ['tanh', 'relu'],\n",
    "                                 'learning_rate_init':self.learning_rate_init,\n",
    "                                'alpha':self.alpha, #--- regularization \n",
    "                                 #'learning_rate' : ['invscaling', 'adaptive'],\n",
    "                                'n_iter_no_change':self.n_iter_no_change,\n",
    "                                'tol':self.tol,\n",
    "                                'max_iter':self.max_iter,\n",
    "                             } \n",
    "                mlp   =  MLPRegressor(random_state=random_state,verbose=self.verbose) #--- mlp regressor\n",
    "                regr  =  GridSearchCV(mlp, param_grid)\n",
    "                regr.fit(X_train,y_train)\n",
    "                model =  regr.best_estimator_\n",
    "                loss  =  model.loss_curve_\n",
    "                \n",
    "            elif self.implementation == 'keras': #--- dense nn in keras\n",
    "                model     = keras.Sequential([ #--- The network architecture\n",
    "                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "#                    layers.Dense(self.hidden_layer_size, activation=self.activation),\n",
    "                    layers.Dense(ndime, activation='softmax')\n",
    "                    ])\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate_init) #--- compilation step\n",
    "                model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "                               loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "                               metrics=[\"mse\"]\n",
    "                             )\n",
    "                model.fit(X_train, y_train, #--- “Fitting”\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          epochs=self.max_iter[0], verbose=self.verbose, batch_size=1)\n",
    "                loss      = model.history.history['loss']\n",
    "                val_loss  = model.history.history['val_loss']\n",
    "                \n",
    "        elif self.cnn: #--- convolutional\n",
    "            \n",
    "            (model, loss, val_loss), (X_train, X_test) =\\\n",
    "            self.ConvNetworkMultiLabelClassifier(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            NeuralNetwork.ValidationMultiLabelClassification(loss, val_loss, #--- validation\n",
    "                                 model, \n",
    "                                 X_train, X_test, y_train, y_test)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "#             (model, loss, val_loss), (X_train, X_test) =\\\n",
    "#             self.ConvNetwork(X_train, y_train, X_test, y_test )\n",
    "            \n",
    "            \n",
    "            \n",
    "            #--- validation\n",
    "#             NeuralNetwork.Validation(loss, val_loss, \n",
    "#                                      model, \n",
    "#                                      X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        #--- save in ovito file\n",
    "#         if printOvito:\n",
    "#             m = self.descriptors.shape[ 0 ]\n",
    "#             indices = np.arange( m )[ filtr ]\n",
    "        \n",
    "#             if indices.shape[ 0 ] - self.n_train < 0 :  \n",
    "#                 indices = NeuralNetwork.Duplicate(indices, new_size = self.n_train )\n",
    "            \n",
    "#             indices_train, indices_test, _, _ = train_test_split(indices, indices, #stratify=stratify,\n",
    "#                                                                 random_state=random_state)\n",
    "#             self.PrintOvito( indices_test, model )\n",
    "\n",
    "    @staticmethod\n",
    "    def Validation(loss, val_loss, model, X_train, X_test, y_train, y_test):\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "#                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred_test  = model.predict(X_test)        \n",
    "        y_pred_train = model.predict(X_train)        \n",
    "#         for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "#             ax = utl.PltErr(None,None,Plot=False)\n",
    "#             #\n",
    "#             utl.PltErr(y_test[:,idime],y_pred_test[:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                        attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(None,None,Plot=False,\n",
    "#                            title='png/scatter%s.png'%idime,\n",
    "#                             ax=ax,\n",
    "#                        xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                        xlim=(-2,2),ylim=(-2,2),\n",
    "#                            )\n",
    "\n",
    "        #--- energy\n",
    "        idime = 0 #3\n",
    "        xstr  = 'energy'\n",
    "        ax = utl.PltErr(None,None,Plot=False)\n",
    "        #\n",
    "        utl.PltErr(y_test[:,idime],y_pred_test[:,idime],\n",
    "                   attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "                   ax=ax,\n",
    "                   Plot = False,\n",
    "\n",
    "                  )\n",
    "        utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "                   attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "                   ax=ax,\n",
    "                   Plot = False,\n",
    "\n",
    "                  )\n",
    "        #\n",
    "        utl.PltErr(None,None,Plot=False,\n",
    "                       title='png/scatter%s.png'%idime,\n",
    "                        ax=ax,\n",
    "                   xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                   xlim=(-2,2),ylim=(-2,2),\n",
    "                       )\n",
    "\n",
    "    @staticmethod\n",
    "    def ValidationMultiLabelClassification(loss, val_loss, model, X_train, X_test, y_train, y_test):\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        !mkdir png         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "                   attrs={'fmt':'-'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(loss)), loss,\n",
    "                   attrs={'fmt':'-'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "#                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/lossMultiLabelClassification.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/lossMultiLabelClassification.txt',np.c_[range(len(loss)),loss,val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        \n",
    "        #--- plot predictions\n",
    "        y_pred_test              = model.predict(X_test)        \n",
    "        y_pred_train             = model.predict(X_train)\n",
    "        \n",
    "        threshold                = 0.5 #--- hard-coded threshold\n",
    "        binary_predictions_test  = (y_pred_test > threshold).astype(int)\n",
    "        binary_predictions_train = (y_pred_train > threshold).astype(int)\n",
    "        binary_actual_test       = (y_test > threshold).astype(int)\n",
    "        binary_actual_train      = (y_train > threshold).astype(int)\n",
    "\n",
    "        \n",
    "        \n",
    "        #--- Compute the multilabel confusion matrix\n",
    "        conf_matrix = multilabel_confusion_matrix( binary_actual_test, binary_predictions_test )\n",
    "        ndime       = conf_matrix.shape[ 1 ] * conf_matrix.shape[ 2 ]\n",
    "        conf_matrix = conf_matrix.reshape((conf_matrix.shape[0],ndime))\n",
    "        np.savetxt('png/confusionMultiLabelClassification.txt',np.c_[conf_matrix])\n",
    "        \n",
    "        \n",
    "        #--- predict displacements\n",
    "        #--- reshape y_pred\n",
    "        \n",
    "            \n",
    "        \n",
    "#         disps_predictions_test = np.concatenate([list(map(lambda x: self.GetDispsFromBinaryMaps( x ) , binary_predictions_test ))])\n",
    "#         disps_actual_test      = np.concatenate([list(map(lambda x: self.GetDispsFromBinaryMaps( x ) , binary_actual_test ))])\n",
    "        \n",
    "# #         #--- plot predictions\n",
    "# #         y_pred_test  = model.predict(X_test)        \n",
    "# #         y_pred_train = model.predict(X_train)        \n",
    "#         for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "#             ax = utl.PltErr(None,None,Plot=False)\n",
    "#             #\n",
    "#             utl.PltErr(disps_actual_test[:,idime],disps_predictions_test[:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "\n",
    "#                       )\n",
    "#             #\n",
    "# #             utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "# #                        attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "# #                        ax=ax,\n",
    "# #                        Plot = False,\n",
    "\n",
    "# #                       )\n",
    "#             #\n",
    "#             utl.PltErr(None,None,Plot=False,\n",
    "#                            title='png/scatter%s.png'%idime,\n",
    "#                             ax=ax,\n",
    "#                        xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                        xlim=(-3,3),ylim=(-3,3),\n",
    "#                            )\n",
    "\n",
    "    def GetDispsFromBinaryMaps( self, binaryMap ):\n",
    "        binaryMapReshaped = binaryMap.reshape((self.nbinx, self.nbiny, self.nbinz ))\n",
    "        filtr = binaryMapReshaped == 1\n",
    "        return np.c_[self.yv[filtr],self.xv[filtr],self.zv[filtr]]\n",
    "\n",
    "        \n",
    "    def PrintOvito( self, filtr, model ):\n",
    "        #--- save in ovito\n",
    "        X          = np.c_[self.descriptors[filtr]]\n",
    "        X          = NeuralNetwork.Zscore( X )\n",
    "        X_reshaped =  X.reshape((X.shape[0],self.shape[0],self.shape[1],self.shape[2],1))\n",
    "        y_pred     = model.predict( X_reshaped )\n",
    "        with open('original.xyz','w') as fp:\n",
    "            utl.PrintOvito(self.perAtomData.iloc[filtr], fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "        with open('test.xyz','w') as fp:\n",
    "            xyz = self.perAtomData.iloc[filtr]['id type x y z'.split()]\n",
    "            cordc = pd.DataFrame(np.c_[xyz,y_pred[:,:3]],columns='id type x y z ux uy uz'.split())\n",
    "            utl.PrintOvito(cordc, fp, '0', attr_list='id type x y z ux uy uz'.split())\n",
    "                \n",
    "\n",
    "    def ConvNetworkMixedInput(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels: pixel map\n",
    "        shape_vector_input = 3\n",
    "        \n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ] - shape_vector_input\n",
    "        pixel_map_input        =  keras.Input(shape=shape)\n",
    "        vector_input           =  keras.Input(shape=(shape_vector_input,))\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(pixel_map_input)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "        x       = layers.Flatten()(x)\n",
    "            \n",
    "        #--- concatenate flattened map with vector\n",
    "        combined = keras.layers.concatenate( [ x, vector_input ] )\n",
    "        \n",
    "        #--- output layer\n",
    "        outputs = layers.Dense( ndime )( combined ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=[pixel_map_input,vector_input], outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        model.summary()\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        nn = X_train.shape[ 1 ]\n",
    "        X_train_pixels = X_train[:,0:nn-shape_vector_input]\n",
    "        X_test_pixels  = X_test[:,0:nn-shape_vector_input]\n",
    "        assert    X_train_pixels.shape[ 1 ] ==    shape[0] * shape[1] * shape[2]\n",
    "        X_train_vector = X_train[:,nn-shape_vector_input:nn]\n",
    "        X_test_vector  = X_test[:,nn-shape_vector_input:nn]\n",
    "        assert    X_train_vector.shape[ 1 ] ==   shape_vector_input\n",
    "        \n",
    "    \n",
    "        X_train_pixels =  X_train_pixels.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_pixels  =  X_test_pixels.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        \n",
    "        model.fit( [X_train_pixels,X_train_vector], y_train, \n",
    "                   validation_data      = ( [X_test_pixels,X_test_vector], y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetRegressorMixedInput_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), ([X_train_pixels,X_train_vector], [X_test_pixels,X_test_vector])\n",
    "    \n",
    "    def ConvNetwork(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime )( x ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetRegressor_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "    def ConvNetworkMultiLabelClassifier(self,X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "#         tf.random.set_random_seed(812)\n",
    "\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  'relu' #self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "        #\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation='sigmoid' )( x ) #, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"binary_crossentropy\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnet_from_scratch.tf',  \n",
    "#                                                    monitor=\"loss\",\n",
    "#                                                   save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "#                    callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                    batch_size          = 1,\n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetMultiLabelClassifier_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model =model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "    def ConvNetworkClassifier(self,y,\n",
    "                               random_state=1\n",
    "                               ):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like training x input\n",
    "        \n",
    "        y_train : array-like, training y input\n",
    "        \n",
    "        X_test : array-like test x input\n",
    "        \n",
    "        y_test : array-like, training y input\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "        \n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('dim(y)=',y.shape)\n",
    "        \n",
    "\n",
    "        #---------------\n",
    "        #--- zscore X\n",
    "        #---------------        \n",
    "        X      = np.c_[self.descriptors ]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X      = scaler.transform( X )\n",
    "    \n",
    "        if self.verbose:\n",
    "            print('X.shape:=',X.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #-----------------------\n",
    "        #--- train-test split\n",
    "        #-----------------------\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- set model parameters\n",
    "        shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "        kernel_size   =  self.kernel_size \n",
    "        epochs        =  self.max_iter[0]\n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        learning_rate = self.learning_rate_init[0]\n",
    "        #\n",
    "        ndime         =  y_train.shape[1]\n",
    "        n_train       =  X_train.shape[0]\n",
    "        n_test        =  X_test.shape[0]\n",
    "        assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "            \n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:',model.summary())\n",
    "\n",
    "        #--- The compilation step\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss=[\"binary_crossentropy\",\"sparse_categorical_crossentropy\"][1],\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        #--- save best model\n",
    "        !mkdir best_model\n",
    "#         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#                                                     monitor=\"accuracy\",\n",
    "#                                                     save_freq=10,\n",
    "#                                                     save_best_only=True)]\n",
    "\n",
    "        #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "        X_train_reshaped =  X_train.reshape((n_train,shape[0],shape[1],shape[2],1))\n",
    "        X_test_reshaped  =  X_test.reshape((n_test,shape[0],shape[1],shape[2],1))\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   callbacks            = callbacks,\n",
    "                    epochs              = epochs, \n",
    "                    verbose             = self.verbose, \n",
    "                    shuffle             = False, \n",
    "#                     batch_size     = 128,\n",
    "#                     use_multiprocessing = True,\n",
    "#                     workers             = 4,\n",
    "                 )\n",
    "\n",
    "        #--- validation loss\n",
    "        model.save('best_model/convnetClassifier_from_scratch.tf')\n",
    "        loss       = model.history.history['loss']\n",
    "        val_loss   = model.history.history['val_loss']\n",
    "        best_model = model #keras.models.load_model(\"best_model/convnetClassifier_from_scratch.tf\")\n",
    "\n",
    "        \n",
    "        return ( best_model, loss, val_loss ), (X_train_reshaped, X_test_reshaped)\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def Duplicate(X, new_size = 100 ):\n",
    "        m = m0 = X.shape[ 0 ]\n",
    "#        n = X.shape[ 1 ]\n",
    "        augmented_x = np.copy( X )\n",
    "\n",
    "        while m <= new_size:\n",
    "            augmented_x = np.concatenate([augmented_x,X],axis = 0)\n",
    "            #\n",
    "            m = augmented_x.shape[ 0 ]\n",
    "\n",
    "        assert m > new_size\n",
    "\n",
    "        return augmented_x[:new_size]\n",
    "\n",
    "    @staticmethod    \n",
    "    def AddGaussianNoise(X,scale = 0.1):\n",
    "\n",
    "        epsilon_x = np.random.normal(scale=scale,size=X.size).reshape(X.shape)\n",
    "        X += epsilon_x\n",
    "        \n",
    "    \n",
    "    def PrintDensityMap(self, atomIndx, irun, fout):\n",
    "        with open(fout,'w') as fp:\n",
    "                    disp           = np.c_[self.perAtomData[ irun ].iloc[atomIndx]['ux uy uz'.split()]].flatten()\n",
    "                    df             = pd.DataFrame(np.c_[self.Positions[ irun ].T,self.Descriptors[ irun ][atomIndx]],\n",
    "                                                  columns='x y z mass'.split())\n",
    "                    utl.PrintOvito(df, fp, 'disp = %s'%disp, attr_list='x y z mass'.split())\n",
    "                    \n",
    "    @staticmethod\n",
    "    def Zscore( X, **kwargs ):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        \n",
    "        if 'save_model' in kwargs:\n",
    "            pickle.dump( scaler, open( kwargs[ 'save_model' ], 'wb' ) )\n",
    "        return scaler.transform( X )\n",
    "\n",
    "#     def SaveConf(self,fout):\n",
    "#         with open(fout,'w') as fp:\n",
    "#             np.savetxt(fp,np.c_[self.perAtomData],header=' '.join(list(self.perAtomData.keys())))\n",
    "\n",
    "#     def Test(self,y,\n",
    "#                                    random_state=1\n",
    "#                                    ):\n",
    "#             '''\n",
    "#             Convolutional neural network.\n",
    "\n",
    "#             Parameters\n",
    "#             ----------\n",
    "#             X_train : array-like training x input\n",
    "\n",
    "#             y_train : array-like, training y input\n",
    "\n",
    "#             X_test : array-like test x input\n",
    "\n",
    "#             y_test : array-like, training y input\n",
    "\n",
    "#             Return\n",
    "#             ---------- ( , loss,  )\n",
    "#             best_model : cnn object, best trained model based on on the validation loss\n",
    "\n",
    "#             loss : array-like, mse loss\n",
    "\n",
    "#             val_loss : array-like, validation loss\n",
    "\n",
    "#             '''\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('dim(y)=',y.shape)\n",
    "\n",
    "#             ndime  = y.shape[1] #--- dimension of the target vector\n",
    "\n",
    "\n",
    "#             #---------------\n",
    "#             #--- zscore X\n",
    "#             #---------------        \n",
    "#             X      = np.c_[self.descriptors ]\n",
    "#             scaler = StandardScaler()\n",
    "#             scaler.fit(X)\n",
    "#             X      = scaler.transform( X )\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print('X.shape:=',X.shape)\n",
    "\n",
    "\n",
    "\n",
    "#             #-----------------------\n",
    "#             #--- train-test split\n",
    "#             #-----------------------\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "#                                                                 random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "#             #---- set model parameters\n",
    "#             shape         =  (self.shape[0],self.shape[1],self.shape[2],1) #--- rows, cols, thickness, channels\n",
    "#             kernel_size   =  self.kernel_size \n",
    "#             epochs        =  self.max_iter[0]\n",
    "#             activation    =  self.activation\n",
    "#             padding       = 'same'\n",
    "#             filters       =  self.n_channels\n",
    "#             learning_rate = self.learning_rate_init[0]\n",
    "#             #\n",
    "#             ndime         =  y_train.shape[1]\n",
    "#             n_train       =  X_train.shape[0]\n",
    "#             n_test        =  X_test.shape[0]\n",
    "#             assert        shape[0] * shape[1] * shape[2] == X_train.shape[ 1 ]\n",
    "#             inputs        =  keras.Input(shape=shape)\n",
    "#             #\n",
    "#     #         pdb.set_trace()\n",
    "#             #------------------------------\n",
    "#             #--- The network architecture\n",
    "#             #------------------------------\n",
    "#             model     = keras.Sequential([\n",
    "#                 layers.Dense(self.hidden_layer_size, activation=\"relu\"),\n",
    "#     #             layers.Dense(self.hidden_layer_size), #activation=\"relu\"),\n",
    "#                 layers.Dense(2, activation=\"softmax\")\n",
    "#                 ])\n",
    "#             optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate) #--- compilation step\n",
    "\n",
    "#             model.compile( optimizer=\"rmsprop\",\n",
    "#                            loss=\"sparse_categorical_crossentropy\",\n",
    "#                            metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "#             #--- “Fitting” the model X_train_transfrmd, y_train\n",
    "#             X_train_reshaped =  X_train \n",
    "#             X_test_reshaped  =  X_test\n",
    "#             model.fit( X_train_reshaped, y_train, \n",
    "#                        validation_data      = ( X_test_reshaped, y_test ),\n",
    "#     #                     callbacks=callbacks,\n",
    "#                         epochs              = epochs, \n",
    "#                         verbose             = self.verbose, \n",
    "#                         shuffle             = False, \n",
    "#     #                     batch_size     = 128,\n",
    "#                         use_multiprocessing = True,\n",
    "#                         workers             = 4,\n",
    "#                      )        \n",
    "\n",
    "\n",
    "#             #--- save best model\n",
    "#             !mkdir best_model\n",
    "#     #         callbacks=[keras.callbacks.ModelCheckpoint( filepath='best_model/convnetClassifier_from_scratch.tf',  \n",
    "#     #                                                    monitor=\"val_loss\",\n",
    "#     #                                                   save_freq=10,\n",
    "#     #                                                     save_best_only=True)]\n",
    "\n",
    "\n",
    "#             #--- validation loss\n",
    "#             loss       = model.history.history['loss']\n",
    "#             val_loss   = model.history.history['val_loss']\n",
    "#             best_model = model #keras.models.load_model(\"best_model/convnet_from_scratch.tf\")\n",
    "\n",
    "\n",
    "#             !mkdir png\n",
    "#             utl.PltErr(range(len(loss)), loss,\n",
    "#                        yscale='log',\n",
    "#                        xstr='epoch',ystr='loss',\n",
    "#                        title='png/loss_classification.png',\n",
    "#                       )\n",
    "\n",
    "#     #         pdb.set_trace()\n",
    "#             #--- confusion matrix\n",
    "#             cm = confusion_matrix(y_test, model.predict_classes(X_test),\n",
    "#                              labels=[0, 1]\n",
    "#                             )\n",
    "#             print('cm=',cm)\n",
    "#             np.savetxt('png/confusion.txt',np.c_[cm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c303869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Catalogs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8fc70",
   "metadata": {},
   "source": [
    "## main(): classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe6a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def main():\n",
    " \n",
    "    if not eval(confParser['neural net classification']['classification']):\n",
    "        return\n",
    "    \n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes   = eval(confParser['neural net classification']['hidden_layer_sizes']),\n",
    "                        learning_rate_init   = eval(confParser['neural net classification']['learning_rate_init']),\n",
    "                        n_iter_no_change     = eval(confParser['neural net classification']['n_iter_no_change']),\n",
    "                        tol                  = eval(confParser['neural net classification']['tol']),\n",
    "                        max_iter             = eval(confParser['neural net classification']['max_iter']),\n",
    "                        alpha                = eval(confParser['neural net classification']['alpha']),\n",
    "                        hidden_layer_size    = eval(confParser['neural net classification']['hidden_layer_size']),\n",
    "                        fully_connected      = eval(confParser['neural net classification']['fully_connected']),\n",
    "                        implementation       = eval(confParser['neural net classification']['implementation']),\n",
    "                        cnn                  = eval(confParser['neural net classification']['cnn']),\n",
    "                        n_channels           = eval(confParser['neural net classification']['n_channels']),\n",
    "                        kernel_size          = eval(confParser['neural net classification']['kernel_size']),\n",
    "                        activation           = eval(confParser['neural net classification']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net classification']['number_hidden_layers']),\n",
    "                        n_train              = eval(confParser['neural net classification']['n_train']),\n",
    "                        best_model           = 'best_model',\n",
    "                        verbose              = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse2nd( path  = confParser['neural net']['input_path'],\n",
    "              nruns = eval(confParser['neural net classification']['nruns']))\n",
    "\n",
    "    nn.Combine2nd() #--- concat. descriptors\n",
    "\n",
    "    #--- classifier\n",
    "    nn.TrainClassifier()\n",
    "#        nn.Test(np.c_[nn.perAtomData.defect_label].astype(int))\n",
    "    \n",
    "    \n",
    "    return nn\n",
    "\n",
    "#model_clf = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0db348",
   "metadata": {},
   "source": [
    "## main(): regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01971ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " def main():\n",
    " \n",
    "    if not eval(confParser['neural net regression']['regression']):\n",
    "        return\n",
    "\n",
    "    nn = NeuralNetwork(\n",
    "                        hidden_layer_sizes   = eval(confParser['neural net regression']['hidden_layer_sizes']),\n",
    "                        learning_rate_init   = eval(confParser['neural net regression']['learning_rate_init']),\n",
    "                        n_iter_no_change     = eval(confParser['neural net regression']['n_iter_no_change']),\n",
    "                        tol                  = eval(confParser['neural net regression']['tol']),\n",
    "                        max_iter             = eval(confParser['neural net regression']['max_iter']),\n",
    "                        alpha                = eval(confParser['neural net regression']['alpha']),\n",
    "                        hidden_layer_size    = eval(confParser['neural net regression']['hidden_layer_size']),\n",
    "                        fully_connected      = eval(confParser['neural net regression']['fully_connected']),\n",
    "                        implementation       = eval(confParser['neural net regression']['implementation']),\n",
    "                        cnn                  = eval(confParser['neural net regression']['cnn']),\n",
    "                        n_channels           = eval(confParser['neural net regression']['n_channels']),\n",
    "                        kernel_size          = eval(confParser['neural net regression']['kernel_size']),\n",
    "                        activation           = eval(confParser['neural net regression']['activation']),\n",
    "                        number_hidden_layers = eval(confParser['neural net regression']['number_hidden_layers']),\n",
    "                        n_train              = eval(confParser['neural net regression']['n_train']),\n",
    "                        du                   = eval(confParser['neural net regression']['du']),\n",
    "                        umax                 = eval(confParser['neural net regression']['umax']),\n",
    "                        best_model           = 'best_model',\n",
    "                        verbose              = True \n",
    "                    )\n",
    "    \n",
    "    nn.Parse2nd( path  = confParser['neural net']['input_path'],\n",
    "                 nruns = eval(confParser['neural net regression']['nruns'])\n",
    "               )\n",
    "\n",
    "    nn.Combine2nd() #--- concat. descriptors\n",
    "\n",
    "    nn.TrainRegressorTransitionPaths()\n",
    "    nn.TrainRegressorBarriers()\n",
    "    \n",
    "    return nn\n",
    "\n",
    "#model_regr = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aefa4",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1a5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if eval(confParser['flags']['RemoteMachine']):\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "    #--- ann\n",
    "    number_hidden_layers  = dict(zip(range(4),[1]))\n",
    "    hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "    n_channels            = dict(zip(range(4),[1]))\n",
    "    activations           = dict(zip(range(20),['relu']))\n",
    "#     string[ inums ] = \"\\t\\'5\\':\\'neuralNet/20x20/ann/classifier/layer%s/channel%s/activation%s/layer_size%s\\',\\n\" % (key_n,key_c,key_a,key_h) #--- change job name\n",
    "    \n",
    "    #--- cnn\n",
    "#     number_hidden_layers  = dict(zip(range(4),[1,2,3]))\n",
    "#     hidden_layer_size     = dict(zip(range(4),[1]))\n",
    "#     n_channels            = dict(zip(range(4),[8,16,32,64]))\n",
    "#     activations           = dict(zip(range(20),['linear']))\n",
    "\n",
    "    runs = range(8)\n",
    "    \n",
    "    legend = utl.Legends()\n",
    "    legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "    symbols = utl.Symbols()\n",
    "    \n",
    "    nphi = len(number_hidden_layers)\n",
    "    #---\n",
    "    count = 0\n",
    "    ax = utl.PltErr(None, None, Plot=False )\n",
    "    for key_n in number_hidden_layers:\n",
    "        number_hidden_layer = number_hidden_layers[key_n]\n",
    "#         if number_hidden_layer != 2:\n",
    "#             continue\n",
    "        for key_c in n_channels:\n",
    "            n_channel = n_channels[key_c]\n",
    "#             if n_channel != 16:\n",
    "#                 continue\n",
    "            for key_a in activations:\n",
    "                activation = activations[key_a]\n",
    "                for key_h in hidden_layer_size:\n",
    "                    nsize = hidden_layer_size[key_h]\n",
    "\n",
    "        #---\t\n",
    "#                    path = 'neuralNet/20x20/cnn/classifier/layer%s/channel%s/activation%s/layer_size%s'%(key_n,key_c,key_a,key_h) #--- change job name\n",
    "                    path = 'neuralNet/ni/interestitials/test2nd' #--- change job name\n",
    "                    fp = ['confusion.txt', 'val_loss_classification.txt','loss.txt'][ 2 ]\n",
    "                    for irun in runs:\n",
    "                        try:\n",
    "                            data = np.loadtxt('%s/Run%s/png/%s'%(path,irun,fp))\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        if fp == 'confusion.txt':\n",
    "                            accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "                            accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "                            print(data)\n",
    "                            utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=800,\n",
    "                                    label='%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                        else:\n",
    "                            epoch = data[:,0]\n",
    "                            loss = data[:,1]\n",
    "                            val_loss = data[:,2]\n",
    "\n",
    "                            utl.PltErr(epoch, loss,\n",
    "                               attrs=symbols.GetAttrs(count=count%7,nevery=10,\n",
    "                                    label='train:%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                            utl.PltErr(epoch, val_loss,\n",
    "                               attrs=symbols.GetAttrs(count=(count+1)%7,nevery=10,\n",
    "                                    label='test:%s layers, %s channels, act. %s'%(number_hidden_layer,n_channel,activation)), \n",
    "                                       Plot=False,\n",
    "                                       ax=ax,\n",
    "                                       )\n",
    "                    count += 1\n",
    "    ax = utl.PltErr(None, None,\n",
    "                        yscale='log',xscale='log',\n",
    "                       xstr='epoch',ystr='validation loss',\n",
    "#                     ylim=(1e-1,1e1),\n",
    "                    ax=ax,\n",
    "                    legend=legend.Get(),\n",
    "                       title='png/training_loss.png',\n",
    "                   )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6dc865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm=np.loadtxt('neuralNet/ni/interestitials/test2nd/Run0/png/confusionMultiLabelClassification.txt').astype(int)\n",
    "# falseNegative = list(map(lambda x: 1.0*x[0]/(x[0]+x[1]), cm))\n",
    "# truePositive  = list(map(lambda x: 1.0*x[3]/(x[2]+x[3]), cm))\n",
    "# filtr  = cm[:,3] > 0\n",
    "# cm[filtr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74daa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend = utl.Legends()\n",
    "# legend.Set(fontsize=14,bbox_to_anchor=(1.5, 0.3, 0.5, 0.5))\n",
    "# symbols = utl.Symbols()\n",
    "\n",
    "# fp = ['confusion.txt', 'val_loss_classification.txt'][0]\n",
    "# data = np.loadtxt('neuralNet/ni/kmc/inactive/Run0/png/%s'%(fp))\n",
    "# ax = utl.PltErr(None, None, Plot=False )\n",
    "# if fp == 'confusion.txt':\n",
    "#     accuracy_crystals = data[0,0]/np.sum(data[0,:])\n",
    "#     accuracy_defects = data[1,1]/np.sum(data[1,:])\n",
    "#     print(data)\n",
    "#     utl.PltErr(accuracy_crystals, accuracy_defects,\n",
    "#        attrs=symbols.GetAttrs(count=0,nevery=800,\n",
    "#             ), \n",
    "#                Plot=False,\n",
    "#                ax=ax,\n",
    "#                )\n",
    "# else:\n",
    "#     epoch = data[:,0]\n",
    "#     loss = data[:,1]\n",
    "#     val_loss = data[:,2]\n",
    "\n",
    "#     utl.PltErr(epoch, val_loss,\n",
    "#        attrs=symbols.GetAttrs(count=0,nevery=10,\n",
    "#             ), \n",
    "#                Plot=False,\n",
    "#                ax=ax,\n",
    "#                )\n",
    "    \n",
    "# ax = utl.PltErr(None, None,\n",
    "# yscale='log',xscale='log',\n",
    "# xstr='epoch',ystr='validation loss',\n",
    "# #                     ylim=(1e-1,1e1),\n",
    "# ax=ax,\n",
    "# # legend=legend.Get(),\n",
    "# title='png/training_loss.png',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506974a",
   "metadata": {},
   "source": [
    "## test example: 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be92045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# y=np.c_[[1.725966,1.725967],\n",
    "#             [-1.725966,1.725967],\n",
    "#             [-1.725966,-1.725967],\n",
    "#             [1.725966,-1.725967],\n",
    "#            ].T\n",
    "\n",
    "# X=np.concatenate([list(map(lambda x:np.load('png/descriptor%s.npy'%x).flatten(),range(4)))],axis=1)\n",
    "\n",
    "# #--- zscore\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_transfrmd = scaler.transform( X )\n",
    "\n",
    "# X_train_transfrmd, X_test_transfrmd, y_train, y_test = train_test_split(X_transfrmd, y, test_size=0.25)\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "# print(X_train_transfrmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69377834",
   "metadata": {},
   "source": [
    "### fully connected in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c56d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #        pdb.set_trace()\n",
    "# #--- tune parameters\n",
    "\n",
    "# #--- train\n",
    "# mlp = MLPRegressor(random_state=1,\n",
    "#                     verbose=True,\n",
    "#                    n_iter_no_change=100000,\n",
    "#                     max_iter=100,#00,\n",
    "#                    hidden_layer_sizes=(1000,1000),\n",
    "# #                    shuffle=False,\n",
    "# #                     alpha=1e-1,\n",
    "\n",
    "#                   )\n",
    "# mlp.fit(X_train_transfrmd,y_train)\n",
    "\n",
    "# #--- validate\n",
    "# !mkdir png\n",
    "# utl.PltErr(range(len(mlp.loss_curve_)), mlp.loss_curve_,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            yscale='log',xscale='log',\n",
    "# #           xlim=(1,self.max_iter[0]),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )\n",
    "\n",
    "# # #         pdb.set_trace()\n",
    "# y_pred =mlp.predict(X_test_transfrmd)        \n",
    "# y_pred_train = mlp.predict(X_train_transfrmd)        \n",
    "# for idime, xstr in zip(range(2),'ux uy'.split()):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     #\n",
    "#     utl.PltErr(y_test[:,idime],y_pred[:,idime],\n",
    "#                attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(y_train[:,idime],y_pred_train[:,idime],\n",
    "#                attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                ax=ax,\n",
    "#                Plot = False,\n",
    "\n",
    "#               )\n",
    "#     #\n",
    "#     utl.PltErr(None,None,Plot=False,\n",
    "#                    title='png/scatter%s.png'%idime,\n",
    "#                     ax=ax,\n",
    "#                xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                xlim=(-3,3),ylim=(-3,3),\n",
    "#                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e1353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.best_loss_, mlp.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157c537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=mlp.predict(X_test_transfrmd)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a952ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce616c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = utl.PltErr(None,None,Plot=False)\n",
    "\n",
    "# for i in range(2):\n",
    "#     utl.PltErr(range(data.descriptors[0,:].shape[0]),data.descriptors[i,:],\n",
    "#               attrs={'fmt':'-'},#,'color':'C0'},\n",
    "#                xscale='log',yscale='log',\n",
    "#                ax=ax,\n",
    "#                Plot=False,\n",
    "#               )\n",
    "\n",
    "# utl.PltErr(range(data.descriptors[100,:].shape[0]),data.descriptors[100,:],\n",
    "#           attrs={'fmt':'-','color':'C0'},\n",
    "#            xscale='log',yscale='log',\n",
    "#            ax=ax,\n",
    "#            Plot=False,\n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5598bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Spectra(nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d061978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     random_state=1)\n",
    "# regr = MLPRegressor(verbose=False,\n",
    "#                     random_state=1, \n",
    "# #                     learning_rate='adaptive',\n",
    "# #                    early_stopping=True, \n",
    "#                      n_iter_no_change=1, \n",
    "#                     tol=1e-2,\n",
    "#                      max_iter=10000000,\n",
    "# #                     solver='sgd',\n",
    "#                    ).fit(X_train, y_train)\n",
    "# regr.tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eecba",
   "metadata": {},
   "source": [
    "### fully connected in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a27a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--- The network architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512), #activation=\"relu\"),\n",
    "# #     layers.Dense(1000), #activation=\"relu\"),\n",
    "#     layers.Dense(2) #, activation=\"relu\")\n",
    "#     ])\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-4)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- Preparing the image data\n",
    "# # train_images = train_images.reshape((60000, 28 * 28))\n",
    "# # train_images = train_images.astype(\"float32\") / 255\n",
    "# # test_images = test_images.reshape((10000, 28 * 28))\n",
    "# # test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# model.fit(X_train_transfrmd, y_train, \n",
    "#             validation_data=(X_test_transfrmd, y_test),\n",
    "\n",
    "#           epochs=100, verbose=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,100),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262922c9",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70f22b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.random.set_random_seed(812)\n",
    "\n",
    "# shape=(300,300,1)\n",
    "# kernel_size = (3,3)\n",
    "# epochs = 1000\n",
    "# activation = ['linear','sigmoid','relu'][0]\n",
    "# padding='same'\n",
    "# filters = 1\n",
    "# #\n",
    "# ndime = y_train.shape[1]\n",
    "# n_train = X_train_transfrmd.shape[0]\n",
    "# n_test = X_test_transfrmd.shape[0]\n",
    "# assert shape[0]*shape[1]*shape[2] == X_train_transfrmd.shape[1]\n",
    "# inputs = keras.Input(shape=shape)\n",
    "# #\n",
    "# x = layers.Conv2D(filters=filters, kernel_size=kernel_size,activation=activation,padding=padding)(inputs)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=2*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=4*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# # x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "# # x = layers.Conv2D(filters=8*filters, kernel_size=kernel_size,activation=activation,padding=padding)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense( ndime, activation=activation)(x)\n",
    "\n",
    "# #--- The network architecture\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# #--- The compilation step\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,epsilon=1e-08)\n",
    "# model.compile( optimizer=optimizer,#\"rmsprop\",\n",
    "#                loss=\"mean_squared_error\",#\"sparse_categorical_crossentropy\",\n",
    "#                metrics=[\"mse\"]\n",
    "#              )\n",
    "\n",
    "# #--- save best model \n",
    "# callbacks=[keras.callbacks.ModelCheckpoint( filepath='png/convnet_from_scratch.keras',  \n",
    "#                                            monitor=\"val_loss\",\n",
    "#                                            save_freq=10,\n",
    "#                                             save_best_only=True)]\n",
    "\n",
    "# #--- “Fitting” the model X_train_transfrmd,y_train\n",
    "# X_train_reshaped = X_train_transfrmd.reshape((n_train,shape[0],shape[1],1))\n",
    "# X_test_reshaped = X_test_transfrmd.reshape((n_test,shape[0],shape[1],1))\n",
    "# model.fit(X_train_reshaped, y_train, \n",
    "#             validation_data=(X_test_reshaped, y_test),\n",
    "#             #callbacks=callbacks,\n",
    "#           epochs=epochs, verbose=False, shuffle=False)#, batch_size=128)\n",
    "\n",
    "# loss = model.history.history['loss']\n",
    "# val_loss = model.history.history['val_loss']\n",
    "# #--- validate\n",
    "\n",
    "# ax = utl.PltErr(range(len(val_loss)), val_loss,\n",
    "#            attrs={'fmt':'-'}, Plot=False,\n",
    "#           )\n",
    "# utl.PltErr(range(len(loss)), loss,\n",
    "#            attrs={'fmt':'-'},\n",
    "#            ax=ax,\n",
    "#            yscale='log',xscale='log',\n",
    "#            xlim=(1,epochs),\n",
    "#            xstr='epoch',ystr='loss',\n",
    "#            title='png/loss.png',\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "673ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = keras.models.load_model(\"png/convnet_from_scratch.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fa9c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ux,uy=best_model.predict(X_test_reshaped)[0]\n",
    "# ax=utl.PltErr([0,ux],[0,uy],\n",
    "#               Plot=False\n",
    "#           )\n",
    "# utl.PltErr([0,y_test[0][0]],[0,y_test[0][1]],\n",
    "#            xlim=(-3,3),ylim=(-3,3),\n",
    "#             ax=ax\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaf166dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (ux,uy), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e1c0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rd = lp.ReadDumpFile( '%s/lammps_data.dat'%confParser['input files']['input_path'] )\n",
    "# rd.ReadData()\n",
    "# # box = \n",
    "# natoms = rd.coord_atoms_broken[ 0 ].shape[0]\n",
    "# atom_indices = ' '.join(map(str,range(natoms)))\n",
    "\n",
    "# fp = '%s/lammps_data.dat'%confParser['input files']['input_path']\n",
    "# fout = 'neighbor_list.xyz'\n",
    "# cutoff = 3.0\n",
    "# lib_path = confParser['input files']['lib_path'].split()[0]\n",
    "# #--- neighbor list\n",
    "# os.system('ovitos %s/OvitosCna.py %s %s 1 6 %s %s'%(lib_path,fp,fout,cutoff,atom_indices))\n",
    "\n",
    "\n",
    "# nl = lp.ReadDumpFile(fout)\n",
    "# nl.GetCords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dab4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GetIndex(dff, key, vals ):\n",
    "# #    dff = rd.coord_atoms_broken[ 0 ]\n",
    "#     dff['index'] = range(natoms)\n",
    "#     indices = dff.set_index(key, drop = True, append=False, inplace= False).loc[vals]['index']\n",
    "#     return np.c_[indices].flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e3578bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# from scipy.sparse import lil_matrix\n",
    "\n",
    "# #--- adj matrix\n",
    "\n",
    "# df_xyz = rd.coord_atoms_broken[ 0 ]\n",
    "# df = nl.coord_atoms_broken[0]\n",
    "# df\n",
    "# center_ids = df.groupby(by='id').groups\n",
    "\n",
    "# #--- sparse\n",
    "# # Adj_mat = sparse_mat(natoms,natoms)\n",
    "# Adj_mat_total = lil_matrix((natoms, natoms),dtype=int)\n",
    "\n",
    "# for center_id in center_ids:\n",
    "#     center_indx = GetIndex(df_xyz,'id',[center_id])[ 0 ]\n",
    "#     neibor_ids  = df['J'].iloc[ center_ids[ center_id ] ].astype( int )\n",
    "#     neibor_indices = GetIndex(df_xyz,'id',np.c_[neibor_ids].flatten())\n",
    "#     Adj_mat_total[center_indx, neibor_indices ] = 1\n",
    "# #     if Adj_mat_total[center_indx].sum() != 12:\n",
    "# #         print('center_indx=%s'%center_indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f771e15",
   "metadata": {},
   "source": [
    "# neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d17a84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNets:\n",
    "\n",
    "    def __init__(self,confParser,verbose=True):\n",
    "        self.ntrain               = eval(confParser['NeuralNets']['ntrain'])    \n",
    "        self.noise_std            = eval(confParser['NeuralNets']['noise_std'])\n",
    "        self.verbose              = verbose\n",
    "        self.kernel_size          =  (3,3,3)\n",
    "        self.max_iter             =  eval(confParser['NeuralNets']['max_iter'])\n",
    "        self.activation           =  eval(confParser['NeuralNets']['activation'])\n",
    "        self.n_channels           = 32\n",
    "        self.learning_rate        = eval(confParser['NeuralNets']['learning_rate'])\n",
    "        self.number_hidden_layers = eval(confParser['NeuralNets']['number_hidden_layers'])\n",
    "            \n",
    "    def Parse(self,path,nruns):\n",
    "\n",
    "        self.Catalogs    = {}\n",
    "        self.transition_paths = []\n",
    "        self.transition_paths_atoms = []\n",
    "        #\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                self.transition_paths.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths_discretized.json'%(path,irun)) )\n",
    "                self.transition_paths_atoms.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths.json'%(path,irun)) )\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/saved_output/catalog.txt'%(path,irun))\n",
    "            except:\n",
    "#                 if self.verbose:\n",
    "#                     traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns     = list(self.Catalogs.keys())\n",
    "        self.nruns.sort()\n",
    "        \n",
    "        self.shape = tuple(np.loadtxt('%s/Run%s/saved_output/shape.txt'%(path,0)).astype(int))\n",
    "        \n",
    "        \n",
    "    def DataBuilder( self ):\n",
    "        \n",
    "        ntrain        = self.ntrain\n",
    "        num_snapshots = len( self.transition_paths )\n",
    "        snapshots     = range(num_snapshots)\n",
    "        input_data    = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['rho'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "        # Example target data (displacement vectors for each snapshot and each path)\n",
    "        target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots]\n",
    "\n",
    "        # Augment the dataset to have order 100 snapshots\n",
    "        augmented_input_data = []\n",
    "        augmented_target_displacements = []\n",
    "        input_data_tensor = torch.stack(input_data)\n",
    "        ntrain_initial = input_data_tensor.shape[0]\n",
    "        n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input, augmented_target = NeuralNets.augment_data(input_data, target_displacements, self.noise_std)\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data_tensor = torch.stack(augmented_input_data)\n",
    "#        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "        # Standardize the augmented input data\n",
    "        mean = input_data_tensor.mean(dim=(0))\n",
    "        std = input_data_tensor.std(dim=(0))\n",
    "        standardized_input_data = ( input_data_tensor - mean ) / std\n",
    "        assert torch.all(standardized_input_data.mean(dim=(0)).abs() < 1.0e-6 )\n",
    "        assert torch.all((standardized_input_data.std(dim=(0)) - 1.0).abs() < 1.0e-6 )\n",
    "\n",
    "\n",
    "        # Convert input data to tensors\n",
    "        target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "        input_data_tensor           = standardized_input_data #torch.stack(standardized_input_data)\n",
    "\n",
    "\n",
    "        X = input_data_tensor\n",
    "        y = target_displacements_tensor\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                               test_size=test_size, train_size=train_size,\n",
    "                                                              random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "        # Define batch sizes for training and test dataloaders\n",
    "        self.dataset_train = {}\n",
    "        self.dataset_test = {}\n",
    "        self.dataset_train['x'] = X_train\n",
    "        self.dataset_train['y'] = y_train\n",
    "        self.dataset_test['x']  = X_test\n",
    "        self.dataset_test['y']  = y_test\n",
    "\n",
    "\n",
    "        if self.verbose:\n",
    "            print('dataset_train:',self.dataset_train['x'].shape)\n",
    "            print('dataset_test:',self.dataset_test['x'].shape)\n",
    "            \n",
    "    def CreateModel(self):\n",
    "        shape         =  (self.shape[0], self.shape[1], self.shape[2], 1)  # Bitmap size 24x24x24 with 1 channel\n",
    "        ndime         = 3\n",
    "        kernel_size   =  self.kernel_size \n",
    "        activation    =  self.activation\n",
    "        padding       = 'same'\n",
    "        filters       =  self.n_channels\n",
    "        inputs        =  keras.Input(shape=shape)\n",
    "\n",
    "        #------------------------------\n",
    "        #--- The network architecture\n",
    "        #------------------------------\n",
    "        x             =  layers.Conv3D(   filters     =  filters, \n",
    "                                          kernel_size =  kernel_size,\n",
    "                                          activation  =  activation,\n",
    "                                          padding     =  padding\n",
    "                                       )(inputs)\n",
    "        filters       *=  2\n",
    "        for i in range( self.number_hidden_layers ):\n",
    "            x       = layers.AveragePooling3D( pool_size = 2 )( x )\n",
    "            x       = layers.Conv3D( filters       =  filters, \n",
    "                                     kernel_size   =  kernel_size,\n",
    "                                     activation    =  activation,\n",
    "                                     padding       =  padding\n",
    "                                     )(x)\n",
    "            filters *= 2\n",
    "\n",
    "        #--- output layer\n",
    "        x       = layers.Flatten()(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = layers.Dense( 256, activation=activation )( x )\n",
    "        x = layers.Dense( 512, activation=activation )( x )\n",
    "        x = layers.Dense( shape[0] * shape[1] * shape[2] * ndime )( x )\n",
    "        outputs = layers.Reshape((shape[0], shape[1], shape[2], ndime))(x)\n",
    "        model   = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:', model.summary())\n",
    "            \n",
    "            \n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = self.learning_rate )\n",
    "        model.compile( optimizer =  optimizer,\n",
    "                       loss      =  \"mean_squared_error\",\n",
    "                       metrics   =  [\"mse\"]\n",
    "                     )\n",
    "\n",
    "        return model\n",
    "            \n",
    "\n",
    "\n",
    "    def autoencoder_3d(self):\n",
    "        input_shape         =  (self.shape[0], self.shape[1], self.shape[2], 1)  # Bitmap size 24x24x24 with 1 channel\n",
    "        ndime         = 3\n",
    "\n",
    "        # Encoder\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "        x = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "        x = layers.MaxPooling3D((2, 2, 2), padding='same')(x)\n",
    "        encoded = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = layers.UpSampling3D((2, 2, 2))(x)\n",
    "        decoded = layers.Conv3D(3, (3, 3, 3), activation='linear', padding='same')(x)\n",
    "\n",
    "        # Autoencoder model\n",
    "        autoencoder = keras.Model(inputs, decoded)\n",
    "        optimizer = tf.keras.optimizers.Adam( learning_rate = self.learning_rate )\n",
    "        autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "        if self.verbose:\n",
    "            print('cnn model summary:', autoencoder.summary())\n",
    "        return autoencoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Training(self):\n",
    "        '''\n",
    "        Convolutional neural network.\n",
    "\n",
    "        Return\n",
    "        ---------- ( , loss,  )\n",
    "        best_model : cnn object, best trained model based on on the validation loss\n",
    "\n",
    "        loss : array-like, mse loss\n",
    "\n",
    "        val_loss : array-like, validation loss\n",
    "\n",
    "        '''\n",
    "\n",
    "        model = self.autoencoder_3d() #CreateModel()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #\n",
    "        shape         = self.shape\n",
    "        assert        shape[0] * shape[1] * shape[2] == self.dataset_train['x'].shape[1]\n",
    "        ndime         = self.dataset_train['y'].shape[2]\n",
    "        n_train       =  self.dataset_train['x'].shape[0]\n",
    "        n_test        =  self.dataset_test['x'].shape[0]\n",
    "        #\n",
    "\n",
    "\n",
    "        #--- Fitting the model\n",
    "        X_train_reshaped =  self.dataset_train['x'].reshape((n_train, shape[0], shape[1], shape[2], 1)).numpy()\n",
    "        X_test_reshaped  =  self.dataset_test['x'].reshape((n_test, shape[0], shape[1], shape[2], 1)).numpy()\n",
    "        y_train = self.dataset_train['y'].reshape((n_train,shape[0],shape[1],shape[2],ndime)).numpy()\n",
    "        y_test  = self.dataset_test['y'].reshape((n_test,shape[0],shape[1],shape[2],ndime)).numpy()\n",
    "        if self.verbose:\n",
    "            print('y_train.shape:',y_train.shape)\n",
    "\n",
    "\n",
    "        model.fit( X_train_reshaped, y_train, \n",
    "                   validation_data      = ( X_test_reshaped, y_test ),\n",
    "                   epochs              = self.max_iter, \n",
    "                   verbose             = self.verbose, \n",
    "                   shuffle             = False,\n",
    "                  batch_size           = 128\n",
    "                 )\n",
    "\n",
    "        #--- Save the model\n",
    "        os.system('mkdir best_model')\n",
    "        model.save('best_model/convnetRegressor_from_scratch.tf')\n",
    "        self.loss       = model.history.history['loss']\n",
    "        self.val_loss   = model.history.history['val_loss']\n",
    "        self.best_model = model\n",
    "        \n",
    "        #--- save reshaped dataset\n",
    "        self.dataset_train['x_reshaped'] =  X_train_reshaped\n",
    "        self.dataset_train['y_reshaped'] =  y_train\n",
    "        self.dataset_test['x_reshaped']  =  X_test_reshaped\n",
    "        self.dataset_test['y_reshaped'] =   y_test\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_data(input_data, target_displacements, noise_std):\n",
    "        augmented_input_data = []\n",
    "        augmented_target_displacements = []\n",
    "\n",
    "        for data, target in zip(input_data, target_displacements):\n",
    "            # Add Gaussian noise to input data\n",
    "            noisy_data = data + torch.randn_like(data) * noise_std\n",
    "            augmented_input_data.append(noisy_data)\n",
    "\n",
    "            # Add Gaussian noise to target displacements\n",
    "            noisy_target = target + torch.randn_like(target) * noise_std\n",
    "            augmented_target_displacements.append(noisy_target)\n",
    "\n",
    "        return augmented_input_data, augmented_target_displacements\n",
    "    \n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def standardize_data(data, mean, std):\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    \n",
    "    \n",
    "    def Validation(self):\n",
    "        #-----------------------\n",
    "        #--- validation\n",
    "        #-----------------------\n",
    "        os.system('mkdir png')         #--- plot validation loss \n",
    "        ax = utl.PltErr(range(len(self.val_loss)), self.val_loss,\n",
    "                   attrs={'fmt':'-','color':'red'}, Plot=False,\n",
    "                  )\n",
    "        utl.PltErr(range(len(self.loss)), self.loss,\n",
    "                   attrs={'fmt':'-','color':'C0'},\n",
    "                   ax=ax,\n",
    "                   yscale='log',xscale='log',\n",
    "#                   xlim=(1,self.max_iter[0]),\n",
    "                   xstr='epoch',ystr='loss',\n",
    "                   title='png/loss.png',\n",
    "                  )\n",
    "        \n",
    "        np.savetxt('png/loss.txt',np.c_[range(len(self.loss)),self.loss,self.val_loss],header='epoch loss val_loss')\n",
    "        \n",
    "        \n",
    "        #--- plot actual vs. prediction\n",
    "        y_pred_test  = self.best_model.predict(self.dataset_test['x_reshaped'])        \n",
    "        y_pred_train = self.best_model.predict(self.dataset_train['x_reshaped'])  \n",
    "        \n",
    "        grid_pts = np.c_[pd.DataFrame(self.transition_paths[0])['x y z'.split()]]\n",
    "        os.system('rm png/training.xyz png/actual_train.xyz png/actual_test.xyz png/test.xyz')\n",
    "        for indx, disps_map in enumerate( y_pred_train ):\n",
    "            with open('png/training.xyz','a') as fp:\n",
    "                udisp = disps_map.reshape((self.shape[0]*self.shape[1]*self.shape[2],3))\n",
    "                cordc = pd.DataFrame(np.c_[grid_pts,udisp],columns='x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "\n",
    "\n",
    "            with open('png/actual_train.xyz','a') as fp:\n",
    "                udisp = self.dataset_train['y'][indx]\n",
    "                cordc = pd.DataFrame(np.c_[grid_pts,udisp],columns='x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "\n",
    "        for indx, disps_map in enumerate( y_pred_test ):\n",
    "            with open('png/actual_test.xyz','a') as fp:\n",
    "                udisp = self.dataset_test['y'][indx]\n",
    "                cordc = pd.DataFrame(np.c_[grid_pts,udisp],columns='x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "\n",
    "            with open('png/test.xyz','a') as fp:\n",
    "                udisp = disps_map.reshape((self.shape[0]*self.shape[1]*self.shape[2],3))\n",
    "                cordc = pd.DataFrame(np.c_[grid_pts,udisp],columns='x y z ux uy uz'.split())\n",
    "                utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "\n",
    "            \n",
    "        \n",
    "        #--- find disp at query points\n",
    "#         self.Mesh()\n",
    "#         udisp_pred_train = []\n",
    "#         udisp_actual_train = []\n",
    "#         !rm png/training.xyz\n",
    "#         for indx, disps_map in enumerate( y_pred_train ): #--- loop over maps\n",
    "#             query_points = np.c_[pd.DataFrame(self.transition_paths_atoms[ indx ])['x y z'.split()]] #--- query points from atom-based data\n",
    "#             udisp = list( map(lambda x: disps_map[self.GetIndex( x )].flatten(),query_points) )\n",
    "#             with open('png/query.xyz','a') as fp:\n",
    "#                 cordc = pd.DataFrame(np.c_[query_points,udisp],columns='x y z ux uy uz'.split())\n",
    "#                 utl.PrintOvito(cordc, fp, 'itime=%s'%indx, attr_list=['x', 'y', 'z','ux','uy','uz'])\n",
    "#             udisp_pred_train.extend(udisp) #--- extract disps from query points\n",
    "#             udisp_actual_train.extend(np.c_[pd.DataFrame(self.transition_paths_atoms[ indx ])['ux_fin    uy_fin    uz_fin'.split()]]) #--- actual disps\n",
    "\n",
    "#         #--- testing \n",
    "#         udisp_pred_test = []\n",
    "#         udisp_actual_test = []\n",
    "#         for indx, disps_map in enumerate( y_pred_test ):\n",
    "#             query_points = np.c_[pd.DataFrame(self.transition_paths_atoms[ indx ])['x y z'.split()]]\n",
    "#             udisp_pred_test.extend(list( map(lambda x: disps_map[self.GetIndex( x )].flatten(),query_points) ))\n",
    "#             udisp_actual_test.extend(np.c_[pd.DataFrame(self.transition_paths_atoms[ indx ])['ux_fin    uy_fin    uz_fin'.split()]])\n",
    "\n",
    "#         #--- plot\n",
    "#         for idime, xstr in zip(range(3),'ux uy uz'.split()):\n",
    "#             ax = utl.PltErr(None,None,Plot=False)\n",
    "#             #\n",
    "#             utl.PltErr(np.c_[udisp_actual_test][:,idime],np.c_[udisp_pred_test][:,idime],\n",
    "#                        attrs={'fmt':'x','color':'red','zorder':10,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(np.c_[udisp_actual_train][:,idime],np.c_[udisp_pred_train][:,idime],\n",
    "#                        attrs={'fmt':'.','color':'blue','zorder':1,'markersize':6},\n",
    "#                        ax=ax,\n",
    "#                        Plot = False,\n",
    "#                       )\n",
    "#             #\n",
    "#             utl.PltErr(None,None,Plot=False,\n",
    "#                            title='png/scatter%s.png'%idime,\n",
    "#                             ax=ax,\n",
    "#                        xstr='%s actual'%xstr,ystr='%s predicted'%xstr,\n",
    "#                        xlim=(-2,2),ylim=(-2,2),\n",
    "#                            )\n",
    "\n",
    "    def GetIndex( self, query_point ):\n",
    "        aa = np.c_[query_point].T\n",
    "        H, bin_edges = np.histogramdd(aa,bins=self.bins)        \n",
    "        assert H.sum() == 1.0        \n",
    "        return H.astype(bool)\n",
    "        \n",
    "    def Mesh(self):\n",
    "        xv = np.c_[pd.DataFrame(self.transition_paths[0]).x].flatten().reshape(self.shape)\n",
    "        yv = np.c_[pd.DataFrame(self.transition_paths[0]).y].flatten().reshape(self.shape)\n",
    "        zv = np.c_[pd.DataFrame(self.transition_paths[0]).z].flatten().reshape(self.shape)\n",
    "        xlin = xv[:,0,0]\n",
    "        ylin = yv[0,:,0]\n",
    "        zlin = zv[0,0,:]\n",
    "        dx = xlin[1]-xlin[0]\n",
    "        dy = ylin[1]-ylin[0]\n",
    "        dz = zlin[1]-zlin[0]\n",
    "        xlin = np.append(xlin,xlin[-1]+dx) \n",
    "        ylin = np.append(ylin,ylin[-1]+dy) \n",
    "        zlin = np.append(zlin,zlin[-1]+dz) \n",
    "        self.bins = [xlin,ylin,zlin]\n",
    "\n",
    "    @staticmethod\n",
    "    def IsGpuAvailable():\n",
    "        tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "       # Check if GPU is available\n",
    "        device_name = tf.test.gpu_device_name()\n",
    "        if device_name == '/device:GPU:0':\n",
    "            print('GPU device found:', device_name)\n",
    "        else:\n",
    "            print('GPU device not found')\n",
    "\n",
    "        # Check if TensorFlow is using GPU\n",
    "        if tf.config.list_physical_devices('GPU'):\n",
    "            print('TensorFlow is using GPU')\n",
    "        else:\n",
    "            print('TensorFlow is using CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3680c39",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d384052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nn = NeuralNets(confParser)\n",
    "    nn.Parse( path  = confParser['neural net']['input_path'],\n",
    "             nruns = eval(confParser['neural net regression']['nruns'])\n",
    "           )\n",
    "\n",
    "    nn.DataBuilder()\n",
    "    nn.Training()\n",
    "    nn.Validation()\n",
    "\n",
    "#main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a451788",
   "metadata": {},
   "source": [
    "# gnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2142613",
   "metadata": {},
   "source": [
    "## graph net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7f8e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        c_hidden,\n",
    "        c_out,\n",
    "        num_layers=1,\n",
    "        layer_name=\"GCN\",\n",
    "        dp_rate=0.1,\n",
    "        verbose=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"GNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of \"hidden\" graph layers\n",
    "            layer_name: String of the graph layer to use\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "            kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer_by_name = {\"linear\":geom_nn.Linear,\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}\n",
    "        gnn_layer         = gnn_layer_by_name[layer_name]\n",
    "        layers = []\n",
    "        in_channels       = c_in\n",
    "        out_channels      = c_hidden\n",
    "        for l_idx in range(num_layers-1):\n",
    "            layers       += [\n",
    "            gnn_layer(in_channels=in_channels, \n",
    "                                           out_channels=out_channels, \n",
    "                                           **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate),\n",
    "            ]\n",
    "            in_channels       = c_hidden\n",
    "        layers            += [gnn_layer(in_channels=in_channels, \n",
    "                                                         out_channels=c_out, \n",
    "                                                         **kwargs)]\n",
    "        self.layers        = nn.ModuleList(layers)\n",
    "\n",
    "        if verbose:\n",
    "            for indx, layer in enumerate( self.layers ):\n",
    "                 print('layer %s'%indx, layer )\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index ):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "                x    = layer(x, edge_index)\n",
    "    \n",
    "            else:\n",
    "                x          = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e36b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNet( GNNModel ):\n",
    "    def __init__(self,**kwargs):\n",
    "        for key in kwargs:\n",
    "            setattr(self, key, kwargs[key])\n",
    "\n",
    "        GNNModel.__init__(  self, \n",
    "                            c_in       = self.c_in,\n",
    "                            c_hidden   = self.c_hidden,\n",
    "                            c_out      = self.c_out,\n",
    "                            num_layers = self.num_layers,\n",
    "                            layer_name = 'linear',#\"GCN\",\n",
    "                            dp_rate    = 0.1,\n",
    "                        )\n",
    "    \n",
    "    def Parse(self,path,nruns):\n",
    "\n",
    "        self.Catalogs    = {}\n",
    "        self.transition_paths = []\n",
    "        self.dumpFiles = []\n",
    "        #\n",
    "        if self.verbose:\n",
    "            print('parsing %s'%path)\n",
    "        rwjs = utl.ReadWriteJson()\n",
    "        for irun in range(nruns):\n",
    "            try:\n",
    "                self.transition_paths.extend( rwjs.Read('%s/Run%s/saved_output/transition_paths.json'%(path,irun)) )\n",
    "                self.dumpFiles.append('%s/Run%s/dumpFile/dump.xyz'%(path,irun))\n",
    "                os.system('ln -s %s/Run%s/dumpFile/dump.xyz ./dump.%s.xyz'%(path,irun,irun))\n",
    "                self.Catalogs[irun]     = pd.read_csv('%s/Run%s/saved_output/catalog.txt'%(path,irun))\n",
    "            except:\n",
    "                if self.verbose:\n",
    "                    traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        self.nruns     = list(self.Catalogs.keys())\n",
    "        self.nruns.sort()\n",
    "                                        \n",
    "        \n",
    "    def DataBuilder2nd( self ):\n",
    "        graphs = []\n",
    "        x=[[],[]]\n",
    "        disp=[[],[]]\n",
    "#        nn=[[],[]]\n",
    "        \n",
    "        x[0]=list(np.linspace(0,1.0,7))\n",
    "        x[0].pop(2)\n",
    "        u=np.zeros(len(x[0]))\n",
    "        u[1]=1\n",
    "        disp[0].append(u)\n",
    "        print('mode0')\n",
    "        utl.PltErr(x[0],u)\n",
    "        n=len(x[0])\n",
    "        adj_mat = torch.zeros((n, n), dtype=torch.float)\n",
    "        adj_mat[0,5]=1\n",
    "        adj_mat[0,1]=1\n",
    "        adj_mat[1,0]=1\n",
    "        adj_mat[2,3]=1\n",
    "        adj_mat[3,2]=1\n",
    "        adj_mat[3,4]=1\n",
    "        adj_mat[4,3]=1\n",
    "        adj_mat[4,5]=1\n",
    "        adj_mat[5,4]=1\n",
    "        adj_mat[5,0]=1\n",
    "        print(adj_mat)\n",
    "        u=np.zeros(len(x[0]))\n",
    "        u[2]=-1\n",
    "        disp[0].append(u)\n",
    "        print('mode1')\n",
    "        utl.PltErr(x[0],u)\n",
    "        \n",
    "\n",
    "        x[1]=list(np.linspace(0,1.0,7))\n",
    "        x[1].pop(3)\n",
    "        u=np.zeros(len(x[0]))\n",
    "        u[2]=1\n",
    "        disp[1].append(u)\n",
    "        utl.PltErr(x[1],u)\n",
    "        n=len(x[1])\n",
    "        adj_mat2 = torch.zeros((n, n), dtype=torch.float)\n",
    "        adj_mat2[0,5]=1\n",
    "        adj_mat2[0,1]=1\n",
    "        adj_mat2[1,0]=1\n",
    "        adj_mat2[1,2]=1\n",
    "        adj_mat2[2,1]=1\n",
    "        adj_mat2[3,4]=1\n",
    "        adj_mat2[4,3]=1\n",
    "        adj_mat2[4,5]=1\n",
    "        adj_mat2[5,4]=1\n",
    "        adj_mat2[5,0]=1\n",
    "        print(adj_mat2)\n",
    "        u=np.zeros(len(x[1]))\n",
    "        u[3]=-1\n",
    "        disp[1].append(u)\n",
    "        utl.PltErr(x[1],u)\n",
    "        \n",
    "#         nn[0]=[2,1,1,2,2,2]\n",
    "#         nn[1]=[2,2,1,1,2,2]\n",
    "            \n",
    "        num_snapshots = 2\n",
    "        snapshots     = range(num_snapshots)\n",
    "        \n",
    "        adj_matrices = torch.stack([adj_mat,adj_mat2]) \n",
    "        \n",
    "        attrs=[[],[]]\n",
    "        attrs[0]=np.array([[1.0,1.0,1.0],[1.0,1.0,0.0],[0.0,1.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]])\n",
    "        attrs[1]=np.array([[1.0,1.0,1.0],[1.0,1.0,1.0],[1.0,1.0,0.0],[0.0,1.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]])\n",
    "\n",
    "        input_data    = [torch.from_numpy( np.c_[x[i],attrs[i]] ).float() for i in snapshots]  \n",
    " #       input_data_tensor           = torch.stack(input_data)\n",
    "\n",
    "        # Example target data (displacement vectors for each snapshot and each path)\n",
    "#        target_displacements = [torch.from_numpy( np.c_[u] ).float() for u in disp]\n",
    "        target_displacements = [torch.from_numpy( np.c_[disp[i]].T ).float() for i in snapshots]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate input data along a new dimension to form a single tensor\n",
    "#        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "        # Standardize the augmented input data\n",
    "#         mean = input_data_tensor.mean(dim=(0, 1))\n",
    "#         std = input_data_tensor.std(dim=(0, 1))\n",
    "        standardized_input_data = input_data #[GraphNet.standardize_data(data, mean, std) for data in input_data_tensor]\n",
    "\n",
    "\n",
    "        # Convert input data to tensors\n",
    "        target_displacements_tensor = torch.stack(target_displacements)\n",
    "        input_data_tensor           = torch.stack(standardized_input_data)\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data)):\n",
    "            x = input_data_tensor[i]  # Node features\n",
    "            edge_index = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "            y = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "            # Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            graphs.append(data)\n",
    "            \n",
    "        # Create a single large graph by concatenating Data objects\n",
    "        large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "        # Define batch size and create DataLoader\n",
    "        batch_size = len(input_data)\n",
    "#        loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "        train_ratio = 0.8\n",
    "\n",
    "        # Define batch sizes for training and test dataloaders\n",
    "        train_batch_size = int( np.max([1,int(batch_size * train_ratio)]) )\n",
    "\n",
    "        # Create DataLoader for training dataset\n",
    "        loader = DataLoader(large_graph, batch_size=train_batch_size, shuffle=False)\n",
    "\n",
    "        # Accessing batches in the DataLoader\n",
    "        loader_iter=iter(loader)\n",
    "        self.dataset_train = next(loader_iter)\n",
    "        if self.verbose:\n",
    "            print('dataset_train:',self.dataset_train)\n",
    "        self.dataset_test = next(loader_iter)\n",
    "        if self.verbose:\n",
    "            print('dataset_test:',self.dataset_test)\n",
    "\n",
    "\n",
    "    def DataBuilder( self ):\n",
    "        \n",
    "        ntrain        = 1 #self.ntrain\n",
    "        num_snapshots = len( self.transition_paths )\n",
    "        snapshots     = range(num_snapshots)\n",
    "        input_data    = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "#         input_data    = [torch.from_numpy( np.c_[pd.DataFrame(self.transition_paths[ i ])['x y z'.split()],\\\n",
    "#                                                  self.SetDescriptors( self.dumpFiles[i], acsf=True )] ).float() for i in snapshots]  \n",
    "#\n",
    "        # Example target data (displacement vectors for each snapshot and each path)\n",
    "        target_displacements = [torch.from_numpy(np.array(self.transition_paths[ i ]['diffusion_paths'])[:,:self.c_out]).float() for i in snapshots]\n",
    "\n",
    "#        assert dim == 36 for all nruns ????\n",
    "        \n",
    "        # Augment the dataset to have order 100 single graphs\n",
    "        augmented_input_data           = []\n",
    "        augmented_target_displacements = []\n",
    "        input_data_tensor              = torch.stack(input_data)\n",
    "        ntrain_initial                 = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "        n_repeat                       = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "        for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "            augmented_input, augmented_target = GraphNet.augment_data(input_data, target_displacements, self.noise_std)\n",
    "            augmented_input_data.extend(augmented_input)\n",
    "            augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "        adj_matrices_attrs      = self.compute_adjacency_matrices2nd(augmented_input_data, rcut=self.cutoff)\n",
    "        adj_matrices            = torch.stack(adj_matrices_attrs[ 0 ])\n",
    "        edge_attrs              = torch.stack(adj_matrices_attrs[ 1 ])\n",
    "#        adj_matrices      = torch.stack(self.compute_adjacency_matrices2nd(augmented_input_data, rcut=self.cutoff)) \n",
    "#        adj_matrices      = torch.stack(self.compute_adjacency_matrices(augmented_input_data, rcut=self.cutoff)) \n",
    "        \n",
    "        \n",
    "        #--- verify adj matrix????\n",
    "        self.PrintOvito(adjacency = adj_matrices[0])\n",
    "\n",
    "\n",
    "        # Concatenate input data along a new dimension to form a single tensor\n",
    "        input_data_tensor = torch.stack(augmented_input_data)\n",
    "#        print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "        # Standardize the augmented input data\n",
    "        mean              = input_data_tensor.mean(dim=(0, 1))\n",
    "        std               = input_data_tensor.std(dim=(0, 1))\n",
    "        standardized_input_data = [GraphNet.standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "        self.mean         = mean\n",
    "        self.std          = std\n",
    "        \n",
    "        # Standardize edge attributes\n",
    "        mean              = edge_attrs.mean(dim=(0, 1))\n",
    "        std               = edge_attrs.std(dim=(0, 1))\n",
    "        standardized_edge_attrs = [GraphNet.standardize_data(data, mean, std) for data in edge_attrs]\n",
    "\n",
    "\n",
    "        # Convert input data to tensors\n",
    "        target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "        input_data_tensor           = torch.stack(standardized_input_data)\n",
    "        edge_attrs_tensor           = torch.stack(standardized_edge_attrs)\n",
    "\n",
    "\n",
    "\n",
    "        # Concatenate nodes and edges for each graph\n",
    "        graphs = []\n",
    "        for i in range(len(input_data)):\n",
    "            x             = input_data_tensor[i]  # Node features\n",
    "            edge_index    = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "            edge_features = edge_attrs_tensor[ i ][ :, : self.edge_dim ]\n",
    "            y             = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "            # Create a Data object for each graph\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr = edge_features, y=y)\n",
    "            graphs.append(data)\n",
    "        \n",
    "        # Create a single large graph by concatenating Data objects\n",
    "        large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "        # Define batch size and create DataLoader\n",
    "        batch_size = len(input_data)\n",
    "#        loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Define the split ratio (e.g., 80% for training, 20% for testing)\n",
    "        train_ratio = 0.8\n",
    "\n",
    "        # Define batch sizes for training and test dataloaders\n",
    "        train_batch_size = int( np.max([1,int(batch_size * train_ratio)]) )\n",
    "\n",
    "        # Create DataLoader for training dataset\n",
    "        loader = DataLoader(large_graph, batch_size=train_batch_size, shuffle=False)\n",
    "\n",
    "        # Accessing batches in the DataLoader\n",
    "        loader_iter=iter(loader)\n",
    "        self.dataset_train = next(loader_iter)\n",
    "        if self.verbose:\n",
    "            print('dataset_train:',self.dataset_train)\n",
    "        self.dataset_test = next(loader_iter)\n",
    "        if self.verbose:\n",
    "            print('dataset_test:',self.dataset_test)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_adjacency_matrices(input_data, rcut):\n",
    "        adj_matrices = []\n",
    "\n",
    "        for positions in input_data:\n",
    "            num_atoms = positions.shape[0]\n",
    "            adj_matrix = torch.zeros((num_atoms, num_atoms), dtype=torch.float)\n",
    "\n",
    "            for i in range(num_atoms):\n",
    "                adj_matrix[i, i] = 1\n",
    "                for j in range(i + 1, num_atoms):\n",
    "                    distance = torch.norm(positions[i] - positions[j])\n",
    "                    if distance <= rcut:\n",
    "                        adj_matrix[i, j] = 1\n",
    "                        adj_matrix[j, i] = 1\n",
    "                assert adj_matrix[i,:].sum() > 0, 'dangling node : increase the cutoff!'\n",
    "            adj_matrices.append(adj_matrix)\n",
    "\n",
    "        #--- assert no \n",
    "        return adj_matrices\n",
    "\n",
    "    def SetDescriptors(self,fin,**kwargs):\n",
    "               \n",
    "\n",
    "        xyz = lp.ReadDumpFile(fin)\n",
    "        xyz.GetCords() \n",
    "\n",
    "        #--- convert to lammps data file\n",
    "        atom = lp.Atoms(**xyz.coord_atoms_broken[0].to_dict(orient='series'))\n",
    "        box        = lp.Box(BoxBounds=xyz.BoxBounds[0],AddMissing=np.array([0,0,0]))\n",
    "\n",
    "        wd = lp.WriteDataFile(atom, box, {1:1}) #--- modify!!\n",
    "        wd.Write('lammps.dat')\n",
    "        \n",
    "        \n",
    "        #--- load configuration\n",
    "        atoms = ase.io.read(\"lammps.dat\",format=\"lammps-data\",style='atomic')\n",
    "\n",
    "       #--- set atomic numbers for each species\n",
    "        junk = SOAP(\n",
    "             species=[\"Ni\"],#self.species,\n",
    "             periodic=True,\n",
    "             r_cut=self.cutoff,\n",
    "                 n_max=1,\n",
    "                 l_max=1,\n",
    "         )\n",
    "        types   = atoms.get_atomic_numbers()\n",
    "        numbers = list(map(lambda x:junk.index_to_atomic_number[x-1], types ) )\n",
    "        atoms.set_atomic_numbers(numbers)\n",
    "        numbers = atoms.get_atomic_numbers()\n",
    "#         #assert soap.check_atomic_numbers(atoms.get_atomic_numbers())\n",
    "\n",
    "        \n",
    "        #--- Setting up the SOAP descriptor\n",
    "        if 'soap' in kwargs and kwargs['soap']:\n",
    "            soap = SOAP(\n",
    "                species=self.species,\n",
    "                periodic=True,\n",
    "                r_cut=self.r_cut,\n",
    "                n_max=self.n_max,\n",
    "                l_max=self.l_max,\n",
    "            )\n",
    "           \n",
    "            #--- center atom is the last entry\n",
    "            self.descriptors = soap.create( atoms) #,centers=[atoms.get_number_of_atoms()-1])\n",
    "\n",
    "            #--- descriptor dimension\n",
    "            count = 0\n",
    "            nspecies = len(self.species)\n",
    "            for Z in range(nspecies):#atoms.get_atomic_numbers():\n",
    "                for Zprime in range(nspecies): #atoms.get_atomic_numbers():\n",
    "                    for l in range(self.l_max+1):\n",
    "                        for n in range(self.n_max):\n",
    "                            for nprime in range(self.n_max):\n",
    "                                if nprime >= n and Zprime >= Z:\n",
    "                                    count += 1\n",
    "            assert count == self.descriptors[0].shape[0], 'count = %s, soap.shape=%s'%(count,self.descriptors[0].shape[0])\n",
    "\n",
    "        #--- Setting up the parinello descriptor\n",
    "        if 'acsf' in kwargs and kwargs['acsf']:\n",
    "            dr = 0.1\n",
    "            eta_inv = 0.2\n",
    "            eta = 1/eta_inv\n",
    "            zeta = 2\n",
    "            lambdaa = 1 #-1\n",
    "            Rs = np.arange(0,self.cutoff,dr)\n",
    "            acsf = ACSF(\n",
    "            species=[\"Ni\"],\n",
    "            r_cut=self.cutoff,\n",
    "            g2_params= list(zip(np.ones(len(Rs))*eta,Rs)), #[[1, 1], [1, 2], [1, 3]],\n",
    "#            g4_params=[[eta, zeta, lambdaa]],\n",
    "            g4_params=[[eta, 1, 1], [eta, 2, 1], [eta, 1, -1], [eta, 2, -1]],\n",
    "        )\n",
    "\n",
    "            return acsf.create( atoms) #,centers=[atoms.get_number_of_atoms()-1])\n",
    "        \n",
    "    def BuildNeighborList( self, indx, atom_indices,cutoff ):\n",
    "        atom_indices = ' '.join(map(str,atom_indices))\n",
    "\n",
    "        fp = self.dumpFiles[ indx ] #'%s/lammps_data.dat'%confParser['input files']['input_path']\n",
    "        fout = 'neighbor_list.xyz'\n",
    "        os.system('rm %s'%fout)\n",
    "        lib_path = confParser['input files']['lib_path'].split()[0]\n",
    "        #--- neighbor list\n",
    "        os.system('ovitos %s/OvitosCna.py %s %s 1 6 %s %s'%(lib_path,fp,fout,cutoff,atom_indices))\n",
    "        nl = lp.ReadDumpFile(fout)\n",
    "        nl.GetCords()\n",
    "        return nl.coord_atoms_broken[0]\n",
    "\n",
    "    def GetIndxById( self, atom_ids, indx ):\n",
    "        df              = pd.DataFrame(self.transition_paths[ indx ])\n",
    "        df['indices']   = range(df.shape[0])\n",
    "        atom_indices    = utl.FilterDataFrame(df,key='id',val=atom_ids)['indices']\n",
    "        return np.c_[atom_indices].flatten()\n",
    "            \n",
    "    def compute_adjacency_matrices2nd(self,input_data, rcut):\n",
    "        adj_matrices       = []\n",
    "        edge_attrs         = []\n",
    "        for indx, positions in enumerate( input_data ):\n",
    "            num_atoms      = positions.shape[0]\n",
    "            adj_matrix     = torch.zeros((num_atoms, num_atoms), dtype=torch.float)\n",
    "            nl             = self.BuildNeighborList(indx,range(len(positions)),rcut) #--- neighbor list\n",
    "            #--- add \"index\" columns\n",
    "            nl['index_i']=self.GetIndxById( np.c_[nl.id].flatten(), indx )\n",
    "            nl['index_j']=self.GetIndxById( np.c_[nl.J].flatten(), indx )\n",
    "            groups         = nl.groupby(by='id').groups\n",
    "            atom_i_ids     = list(groups.keys())\n",
    "            atom_i_indices = self.GetIndxById( atom_i_ids, indx )\n",
    "            for i, atom_id in zip(atom_i_indices,atom_i_ids):\n",
    "#                adj_matrix[i, i] = 1\n",
    "                atom_j_ids       = nl.iloc[groups[ atom_id ]].J\n",
    "                atom_j_indices   = self.GetIndxById( atom_j_ids, indx )\n",
    "                for j, jatom_id in zip(atom_j_indices, atom_j_ids ): #[ atom_j_indices > i ]:\n",
    "                    if j < i :\n",
    "                        continue\n",
    "                    filtr = np.all([nl.id==atom_id,nl.J==jatom_id],axis=0)\n",
    "                    edge_features = nl.iloc[ filtr ][ ''.split() ]\n",
    "                    adj_matrix[i, j] = 1\n",
    "                    adj_matrix[j, i] = 1\n",
    "                assert adj_matrix[i,:].sum() > 0, 'dangling node : increase the cutoff!'\n",
    "#            pdb.set_trace()\n",
    "            #--- edge attributes\n",
    "            keys = 'DX  DY  DZ  PBC_SHIFT_X PBC_SHIFT_Y PBC_SHIFT_Z'.split()\n",
    "            indices = adj_matrix.nonzero().numpy()\n",
    "            nl_reindexed = nl.set_index(['index_i','index_j'],drop=False)\n",
    "            edge_attr = list(map(lambda x: list(nl_reindexed[keys].loc[tuple(x)]),indices))\n",
    "\n",
    "#            pdb.set_trace()\n",
    "            edge_attrs.append( torch.Tensor( edge_attr ) )\n",
    "            adj_matrices.append( adj_matrix )\n",
    "\n",
    "        #--- assert no \n",
    "        return adj_matrices, edge_attrs\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def augment_data(input_data, target_displacements, noise_std):\n",
    "        augmented_input_data = []\n",
    "        augmented_target_displacements = []\n",
    "\n",
    "        for data, target in zip(input_data, target_displacements):\n",
    "            # Add Gaussian noise to input data\n",
    "            noisy_data = data + torch.randn_like(data) * noise_std\n",
    "            augmented_input_data.append(noisy_data)\n",
    "\n",
    "            # Add Gaussian noise to target displacements\n",
    "            noisy_target = target + torch.randn_like(target) * noise_std\n",
    "            augmented_target_displacements.append(noisy_target)\n",
    "\n",
    "        return augmented_input_data, augmented_target_displacements\n",
    "\n",
    "    @staticmethod\n",
    "    def standardize_data(data, mean, std):\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_best_model(model, optimizer, epoch, loss, best_loss, path):\n",
    "        \"\"\"Save the best model.\"\"\"\n",
    "        if loss < best_loss:\n",
    "#             state = {\n",
    "#                 'epoch': epoch,\n",
    "#                 'model_state_dict': model.state_dict(),\n",
    "#                 'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                 'loss': loss,\n",
    "#             }\n",
    "#             torch.save(state, path)\n",
    "            torch.save(model, path)\n",
    "            print(f'Saved the best model with loss: {loss:4.3e}')\n",
    "            return loss\n",
    "        else:\n",
    "            return best_loss\n",
    "    \n",
    "    # Save checkpoint during training\n",
    "    @staticmethod\n",
    "    def save_checkpoint(model, filename):\n",
    "#         checkpoint = {\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': loss,\n",
    "#         }\n",
    "#        torch.save(checkpoint, filename)\n",
    "        torch.save(model.state_dict(), filename)\n",
    "\n",
    "\n",
    "    def PrintOvito(self, **kwargs ):\n",
    "        !rm 'ovito.xyz'\n",
    "        ndime = 3\n",
    "        for indx, item in enumerate( self.transition_paths ):\n",
    "#             pdb.set_trace()\n",
    "            cordc = pd.DataFrame(item)['id x y z'.split()]\n",
    "            diffusion_paths = np.array(item['diffusion_paths'])\n",
    "            nmode = int( diffusion_paths.shape[ 1 ] / ndime )\n",
    "            for imode in range(nmode):\n",
    "                diffusion_path = diffusion_paths[:,imode*ndime:(imode+1)*ndime]\n",
    "                df = pd.DataFrame(np.c_[cordc,diffusion_path],columns = 'id x y z ux uy uz'.split())\n",
    "                with open('ovito.xyz','a') as fp:\n",
    "                    utl.PrintOvito(df, fp, 'itime=%s'%indx, \n",
    "                                   attr_list='id x y z ux uy uz'.split())\n",
    "\n",
    "        l=33.64\n",
    "        if 'adjacency' in kwargs:\n",
    "            item = self.transition_paths[ 0 ]\n",
    "            cordc = pd.DataFrame(item)['id x y z'.split()]\n",
    "            natom = cordc.shape[ 0 ]\n",
    "            df = pd.DataFrame(np.c_[cordc.id,np.ones(natom),np.ones(natom),cordc['x y z'.split()]],\\\n",
    "                              columns = 'id junk0 junk1 x y z'.split())\n",
    "            adj_matrix = kwargs[ 'adjacency' ]\n",
    "            bonds = adj_matrix.nonzero()\n",
    "            bonds += 1\n",
    "            nbond = bonds.shape[ 0 ]\n",
    "            with open('lammps.data','w') as fout:\n",
    "                fout.write('# LAMMPS data file written by OVITO\\n%s atoms\\n%s bonds\\n1 atom types\\n1 bond types\\n%s %s xlo xhi\\n%s %s ylo yhi\\n%s %s zlo zhi\\n\\n'\\\n",
    "                           %(natom,nbond,0,l,0,l,0,l))\n",
    "                fout.write('Atoms # bond\\n\\n')\n",
    "                np.savetxt(fout,np.c_[df],'%d %d %d %e %e %e')\n",
    "        \n",
    "                fout.write('\\nBonds\\n\\n')\n",
    "                np.savetxt(fout,np.c_[np.arange(1,nbond+1), np.ones(nbond),bonds[:,0],bonds[:,1]],fmt='%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0cd67",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8b62ce99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "No GPUs available. Please check your CUDA installation.\n",
      "layer 0 Linear(4, 64, bias=True)\n",
      "layer 1 ReLU(inplace=True)\n",
      "layer 2 Dropout(p=0.1, inplace=False)\n",
      "layer 3 Linear(64, 2, bias=True)\n",
      "mode0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAEFCAYAAAChPiF8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAovElEQVR4nO3dfXBc9Xno8e+zerdsyy96t8FvyDbBlkJiAonj8OLENSC1tE2m09tkUnIb39ykJS/k9naS3ia0k+ntzA0hoWGIk6aZQm9pQm+gNuC4DZAaCG1MiW3A7Mo4cgyyVpJf5JWs933uH+ess5a10tnV7p6j3eczs3PQ7jm/80iHfXx+b+cnqooxxgRNyO8AjDFmOpacjDGBZMnJGBNIlpyMMYFkyckYE0iWnIwxgWTJaRoissvvGMzl7LoETy6viSWn6RXMl0BEOvyOIYsK4rrYNfHGklPhK6QvQqGwa+KBFNMI8draWl29evWs+/X19VFXV5f7gPJgYGCAmpoav8PIikK5LsV4TV566aV+VU3r4pVmHNU8tHr1ag4ePOh3GMYUHRE5ke4xVq0zxgSSJSdjTCB5Tk4i8kERuV9EDojIeRFREXk4k5OKyEoR+a6IdIvIqIh0ich9IrJ0hmPeJiLfF5FeERkRkbCI3CMiVZnEYIwJtnTanP4UaAMGgTeBjZmcUETWAS8A9cDjwOvAu4BPAztFZKuqnp5yzPXA00AZ8ChwErgF+DNgu4hsV9XRTOIJmhOnh/j2geM89nI3Q6MTVFeUcse1zXx821pWLa/2Ozxj8iadat1ngfXAYuC/z+GcD+AkprtU9Q5V/RNVvQX4GrAB+EryziJSAvwtsAD4oKr+F1X9n8D1wD8BW93Y5r1nwr3svO8Aj/zHSQZHJ1BgcHSCR/7jJDvvO8Az4V6/QzQmbzwnJ1V9RlU7dQ5jD9y7ph1AF/DNKR9/CRgCPiIiybcINwJXA/+mqv+cFE8c+GP3x0+IiGQaVxCcOD3EJx/+T4bHJ5mIX/onnogrw+OTfPLh/+TE6SGfIjQmv/LdIH6zu93vJpeLVDUGPI9zh3RD0ke3uNt9UwtT1eNABFgFrM16tHn07QPHGZ+Mz7jP+GSc7xz4RZ4iMsZf+U5OG9xtJMXnne52/RyPmXcee7n7sjumqSbiyg9ffitPERnjr3wnp8Sw2IEUnyfeXzLHYy4SkV0iclBEDvb19XkMM/+GRie87TfmbT9jAqY28T10X7POySv4EeKquhvYDbBly5bAztWprihl0EOCqi4v+EtmClO/qm5J54B83zkl7nJSTSxKvH9ujsfMO3dc20xpaOY2/dKQ8JvXrshTRMb4K9/JKexuU7UPtbjb5PalTI6Zdz6+bS1lJTNfjrKSEH+wbU2eIjLGX/lOTs+42x0icsm5RWQRzpilC8CLSR897W53Ti1MRNbiJK0TwPGsR5tHq5ZX88CH30FVWQlTb6BKBKrKSnjgw++wgZimaOQkOYlImYhsdMc1XaSqbwD7gdXAp6Ycdg9QDTykqsmDeX4CHAXeJyK/nnSOEPBX7o8PzmX8VVDcvKGefZ/ZxpraagRIjNxatbyafZ/Zxs0b6n2Nz5h88ty6KiJ3AHe4Pza623eLyPfc/+5X1c+7/70CJ6GcwElEyT6JM33lGyKy3d3vepwxUBHgi8k7q+qkiNyJcwf1qIg8CvwS2A5swRkb9TWvv0fQrVpeTXVFKe9tqeWh/3o9/+MHh3jqlR4aFlf6HZoxeZXOndPbgY+6r19z31ub9N4HvRTi3j1tAb6Hk5TuBtYBXwdumDqvzj3m34HrcObi7cCZrlID/DnwgUKZVwcQjyuRaIz1DYsA6GhrZnB0gmfDwR0GYUwueL5zUtUvA1/2uG8XkLLrSVVPAnd6Pbd7zGvAh9I5Zj46efYCI+Nx1jcsBOA965azrLqcvYe72bmpcZajjSkc9jyngAn3xAAu3jmVloS4dVMjPz7aywUbgGmKiCWngOnsHQSgxU1O4FTthscn+fFReyqBKR6WnAIm3BNj5dIqFlb8qsZ93epl1C+qYM+hbh8jMya/LDkFTCQaY0PSXRNASUi4vbWJZ8N9nB8Z9ykyY/LLklOAjE/GeaNv8JIqXUJ7azNjk3H+5dWoD5EZk3+WnAKkq3+I8UllQ+PCyz57x5VLWLGkij2HrWpnioMlpwCJRJ3G8PXT3DmJCO1tTTzX2c/ZobF8h2ZM3llyCpBwNEZIYF3d5XdOAB2tzUzElX2v9uQ5MmPyz5JTgER6YqyuraayrGTaz69pXsya2mrrtTNFwZJTgESiMdbXX16lSxAR2lubePH4aXpjI3mMzJj8s+QUECPjk3SdHmJ9Y+rkBM6AzLjCU0esamcKmyWngHijb5C4ctkYp6nWNyxiQ8Mi9lqvnSlwlpwCIhJ15tRNN4xgqvbWJn7WdZbuc8O5DssY31hyCohwzyDlJSFPT7psb2sG4Mkjp3IdljG+seQUEJFojLV11bM+RxxgTW01m1Ystl47U9AsOQVEuCc27eDLVDpamzn05oAtT24KVlEkJxHpEJHdAwOp1uX01+DoBG+dG2bDLD11yW5vbQJg72Gr2pl5oUZEdotIh9cDiiI5qeoeVd1VU5Nq6Tt/dUYvfcCcFyuXLuAdVy6xqp2ZLwZUdZeq7vF6QFEkp6C72FOXRnICZ8zT6z0xjvXGchGWMb6y5BQA4Z5BqspKWLm0Kq3jbtvchAjsOWRVO1N4LDkFQCQao6VhIaFZliOfqmFxJdevWcaew90UwLJ9xlzCklMAJC8Fla721maO9w1x9JRV7UxhseTks7NDY/TGRtNub0q4dVMjJSGxh9CZgmPJyWeJxvDZJvymsnxhBVuvqmWvVe1MgbHk5LOLyalh9jl1qbS3NnHyzDCH3gzmOC5jMmHJyWfhaIxFlaU0Lq7MuIxfu6aRshKxMU+moFhy8lkkOsiGhkWIpNdTl6ymqowb19fxxOFTxONWtTOFwZKTj1TV6anLsL0pWUdbMz3nRzh44mwWIjPGf5acfNQXG+XchfGMe+qSvf/qBirLQvYQOlMwLDn5KOw2hrfMoTE8obqilFs21vPkkVNMTMbnXJ4xfrPk5KPEOnXZuHMC5zEq/YNjvHj8TFbKM8ZPlpx8FOmJUbuwnOULK7JS3s0b66kuL7GqnSkIlpx8FJ7DtJXpVJaV8IG3NfDUKz2MTVjVzsxvlpx8Eo8rnVlOTuD02g0Mj/P8sf6slmtMvlly8slb54YZGpvMenLa1lLH4spSG5Bp5r20kpOIrBSR74pIt4iMikiXiNwnIks9Hn+TiKiH1xVTjptp3xfT+R2CorPX+1JQ6SgvDbFzUyP7X4syMj6Z1bKNyadSrzuKyDrgBaAeeBx4HXgX8Glgp4hsVdXTsxTTBdyT4rPNwG8Br6jqyWk+PwF8b5r335w1+AAK9zg9dS1ZvnMC5zEq3z/4Js+G+9i5qTHr5RuTD56TE/AATmK6S1XvT7wpIvcCnwW+AnxipgJUtQv48nSficg/uP/57RSHd6nqtMfOR5FojOaaShZXlmW97PesW86y6nL2HO625GTmLU/VOveuaQfOnc83p3z8JWAI+IiIzL4i5PTl1wK/CQwDf5dJGfNNuCc701amU1oS4rbNjTx9tJcLYxM5OYcxuea1zelmd7tfVS/po1bVGPA8sAC4IcM4PgpUAD9Q1XMp9lkiIh8TkS+IyKdEJNNz+W4yrhzrG8x6Y3iy9tZmhscn+dejvTk7hzG55DU5bXC3kRSfd7rb9RnG8XF3+60Z9mkD/gan+vjXwE9F5OcisjnDc/rmxOkhxibiOU1O161eRsPiCvZar52Zp7wmp8SCb6meZpZ4f0m6AYjIjTjJ7xVVfSHFbvcCW4E6YBFwHfAoTsJ6WkRWzFD+LhE5KCIH+/r60g0vJzJdCiodJSHhts1NPBvu4/zIeM7OY4xHtYnvofvaNdsBQRjnlAhyd6odVPVuVX1BVftVdVBVD6rqh4B/AmqBz89w7G5V3aKqW+rq6rIbeYbCPYOIwFX12R1GMFVHWzNjk3H2vxrN6XmM8aA/8T10Xym/7wlek1PizijVkrmJ9895LA8AEVkG/DZOQ/hD6RzretDdvi+DY30TicZYtWwBVeUlOT3PtVcsYcWSKptrZ+Ylr8kp7G5TtSm1uNtUbVKpJBrCvz9DQ/hMEvW0jHoJ/RKOxnIyvmkqEaG9rYnnOvs5OzSW8/MZk01ek9Mz7naHiFxyjIgswmkPugCkO1o70RA+6y1eCokeu+MZHp93oxOTdPUP5bS9KVlHazMTcWXfqz15OZ8x2eIpOanqG8B+YDXwqSkf34Nz5/KQqg4l3hSRjSKyMVWZIrINuJqZG8IRkVYRuWykooi04vTcATzs5fcIgl/0DzER15yNcZrqmubFrKmttrl2Zt5JZ4T4J3Gmr3xDRLYDR4HrccZARYAvTtn/qLtN9eT+WRvCXZ8DOkTkAHASGAU2AjuBEpwR5f+Q+vBgCffkvqcumYjQ0drEXz9zjN7YCPWLMl/lxZh88txb5949bcGZ33Y9cDewDvg6cIOHeXUXuROFP4i3hvDHgJ8Am3DaqO4C3gk8BfyGqu7SebSaZCQaozQkrKnNXzNZe1szcYWnjljVzswf6dw54U7IvdPjvinXOlLVs0CVx3Iew0lQBSHcM8ia2mrKS/M3imN9wyI2NCxiz6FuPvqe1Xk7rzFzEYRxTkWlszd3c+pm0tHWxMETZ+k+N5z3cxuTCUtOeXRhbIJfnrmQt/amZO2tzQA8cfhU3s9tTCYsOeXRsd5BVMnpnLpUVtdWs3lFDXtsQKaZJyw55dHFnjofqnUA7a1NHH5zgBOnh2bf2RifWXLKo0g0RkVpiCuXLfDl/Le3NgGw16p2Zh6w5JRHkeggV9UvpCSUsiMzp1YuXcA7Vy21AZlmXrDklEeRaMyXxvBk7a1NvN4T45i7wIIxQWXJKU8Ghsc5NTDiyzCCZLdvbkIE9hyyqp0JNktOedKZhwfMeVG/uJLr1yxjz+Fu5tHAelOELDnlSdhNTi0NuX3AnBcdbc0c7xvitVPn/Q7FmJQsOeVJZ3SQ6vISVizxNGsnp27d1ERJSKzXzgSaJac8SSwFJeJPT12yZdXlbL2qlj2HrGpngsuSU54EoacuWUdrE2+eHebQm6nWrDDGX5ac8qB/cJTTQ2O+TFtJZcc1jZSXhGzMkwksS055EHGnrQQpOdVUlfG+9XU8cfgU8bhV7UzwFEVyEpEOEdk9MOBPFSaxTt36Rv976pJ1tDXRc36EgyfO+h2KKXw1IrJbRDq8HlAUyUlV96jqrpqaVCtb5VY4OsjSBWXULazw5fypvP/qBirLrGpn8mLAfWrtHq8HFEVy8lskGmN9QzB66pJVV5SyfWMDT71yionJuN/hGHMJS045pqpEemK+PSZlNu2tTfQPjvHi8TN+h2LMJSw55dipgRFioxN5WUQzEzdvrKe6vMSqdiZwLDnlWCQgc+pSqSwrYcc1jex7tYexCavameCw5JRjF3vqAjCnLpX21iYGhsd57ljf7DsbkyeWnHIs3DNIw+IKliwo9zuUlLa11LG4spS99hgVEyCWnHIs0VMXZOWlIXZuamT/a1FGxif9DscYwJJTTsXj6qxTF/DkBM5jVAZHJ3g2bFU7EwyWnHLo5NkLjIzHA9sYnuzda5ezvLrclo4ygWHJKYcSS0H5/WheL0pLQty6uZEfH40yNDrhdzjGWHLKpURPXUt9cHvqknW0NjMyHufHr/f6HYoxlpxyKRwd5IplVVRXlPodiifXrV5Gw+IKG5BpAsGSUw5FemKsrw9+lS4hFBJu39zMT8J9nB8Z9zscU+QsOeXI+GSc4/2D86K9KVl7WxNjk3H2vxr1OxRT5Cw55UhX/xDjkzoveuqSXXvFElYsqbKqnfGdJaccCUeD9/RLL0SEjrZmnj/Wz5mhMb/DMUXMklOORHpilISEtXXVfoeStvbWJibiyr5XevwOxRSxtJKTiKwUke+KSLeIjIpIl4jcJyJL0yjjWRHRGV6VKY57m4h8X0R6RWRERMIico+I+L8Q3DTC0Rirli+gsqzE71DSdk3zYtbWVrPXBmQaH3nu4xaRdcALQD3wOPA68C7g08BOEdmqqqfTOPc9Kd6/bASgiFwPPA2UAY8CJ4FbgD8DtovIdlUdTePcOdcZHQzsA+ZmIyK0tzZx/zPH6D0/Qv3iaf+9MCan0hmA8wBOYrpLVe9PvCki9wKfBb4CfMJrYar6ZS/7iUgJ8LfAAuA3VPWf3fdDwPeB33bP/7+9njvXRsYn6To9REdbs9+hZKyjrZlvPH2MJ4+c4ve3rvE7HFOEPFXr3LumHUAX8M0pH38JGAI+IiK5aGC5Ebga+LdEYgJQ1Tjwx+6Pn5AAPaD7WO8gcWXe3jkBtDQsYmPjIluy3PjGa5vTze52v5sULlLVGPA8zp3NDV5PLCK/IyJ/IiKfE5FbRSTV0iS3uNt9Uz9Q1eNABFgFrPV67lybDw+Y86K9tYmDJ87SfW7Y71BMEfKanDa420iKzzvd7fo0zv0I8JfAV4EngV+KyAfzdO6cCkdjlJeEWLV8/vXUJWtvdaqlT9jdk/GB1+SUWPAt1aqUifeXeCjrcaADWAlUARtxktQS4B9FZGc2zy0iu0TkoIgc7OvLz7OKOqODrK2rpqxkfo/UWF1bzeYVNfYYFZMNtYnvofvaNdsBef/2qOrXVHWvqr6lqiOqGlbVLwB3u/H8ZZbPt1tVt6jqlrq6umwWnVI4wEtBpaujrYnDbw7Q1T/kdyhmfutPfA/d1+7ZDvCanBJ3J6mWzE28f85jedP5Ds4wgreLSPI3Ox/nzprYyDhvnRuedyPDU7k9UbU7YlU7k19ek1PY3aZq12lxt6nahWalqiNAzP0xubEm5+fOps7eQWD+TVtJZcWSKt65aqnNtTN55zU5PeNud7jjiy5y73K2AheAFzMNREQ2AEtxElR/0kdPu9upbVGIyFqcpHUCOJ7pubMp0hPsdeoy0dHaxOs9MTqjsdl3NiZLPCUnVX0D2A+sBj415eN7cO50HlLViw0TIrJRRDYm7ygia0Rk2dTyRaQOZ6AlwCOqmjxK/CfAUeB9IvLrSceEgL9yf3xQVdXL75JrkeggVWUlrFwayFk1GbltcxMisMd67UwepTNC/JM401e+ISLbcRLG9ThjoCLAF6fsf9TdJg+OvBF4UESew7nTOQNcCdyG03Z0kF8NrARAVSdF5E6cO6hHReRR4JfAdmALzhirr6Xxe+SUsxTUQkKhwIwJnbP6xZXcsGY5ew9389n3txCg8a6mgHnurXPvnrYA38NJSncD64CvAzd4nFf3Es74pgacaSd341TXjgB3AVtV9dw05/534DqcYQg7cKar1AB/DnwgSPPqwvNgnbpMdLQ1c7xviNdOnfc7FFMk0nq4taqeBO70uO9l/7yq6hHg99M5Z9KxrwEfyuTYfDkzNEZfbLQgk9POTY38r8dfYc+hU1zTnKrj1Jjsmd+jBAPm4rSVAhnjlGxZdTnvvaqWvYe7CUjznilwlpyyKNGbVUg9dcnaW5t48+wwPz95zu9QTBGw5JRF4WiMxZWlNCxONYd5fttxTSPlJSF7UoHJC0tOWRTpcR4wV6i9WTVVZbxvfR17D3cTj1vVzuSWJacsUVXC0RgtBVqlS+hoayJ6fpSfdZ3xOxRT4Cw5ZUlvbJSB4fGCbW9KeP/VDVSWWdXO5J4lpyyJzNOloNJVXVHK9o0NPHnkFBOT8dkPMCZDlpyyJNxTGE+/9KKjrYnTQ2O8eNyqdiZ3LDllSSQao3ZhBcsXFmZPXbKbNtRTXV5iTyowOWXJKUvC0cGiuGsCqCwrYcc1jTz1yinGJqxqZ3LDklMWxONKZ4HOqUulo62J8yMTPHcsP48+NsXHklMWvHVumAtjkwXzaF4v3ntVHTVVZew5ZL12JjcsOWVBsfTUJSsvDbHzmkb+5bUoI+OTfodjCpAlpywIF8g6delqb2ticHSCZ8O9fodiCpAlpyyI9MRorqlkUWWZ36Hk1bvXLmd5dblV7UxOWHLKgnB0sCAfkzKb0pIQt21u4sevRxkanZj9AGPSUBTJSUQ6RGT3wECqdTkzNzEZ542+wYKftpJKe2sTI+Nx/vVo1O9QTLDViMhuEenwekBRJCdV3aOqu2pqsv8ExxNnLjA2ES+qxvBk161eRsPiCptrZ2YzoKq7VHWP1wOKIjnl0sWloIqwWgcQCgm3b27mJ+E+BobH/Q7HFBBLTnMUjsYQgXV1xdVTl6yjrYmxyTj/8ppV7Uz2WHKao0g0xqplC6gqL/E7FN+8/YolrFxaZXPtTFZZcpqjSHSwaNubEkSE9tZmnjvWz5mhMb/DMQXCktMcjE5M8ov+oaJtb0rW0dbEZFzZ90qP36GYAmHJaQ6O9w0xGdeiv3MCeFvTYtbWVlvVzmSNJac5KMY5damICO1tzbz4i9P0nh/xOxxTACw5zUG4J0ZpSFhTW+13KIHQ0dqEKjx5xMY8mbmz5DQHkegga+uqKS+1PyNAS8MiNjYuYo8NyDRZYN+qOYgU2QPmvOhoa+alE2d569yw36GYec6SU4YujE3wyzMXinZOXSrtrU0APHHYGsbN3FhyylBndBCg4BfRTNeq5dW0rqyxuXZmziw5ZSjxgDkb43S5jtZmDr85QFf/kN+hmHnMklOGOqMxKkpDXLlsgd+hBM7tbtVur1XtzBxYcspQODpIS8NCSkLidyiB07ykii2rllrVzsyJJacMRXqsp24m7a1NvN4To9Ot/hqTrrSSk4isFJHviki3iIyKSJeI3CciSz0eXy0ivyci/1dEXheRIRGJichBEblbRMpTHKczvF5M53fIhoEL4/ScH7HkNIPbWpsICTbmyWSs1OuOIrIOeAGoBx4HXgfeBXwa2CkiW1X19CzFbAMeBs4AzwCPAUuBXwf+D/BbIrJdVaeb/3AC+N4077/p9XfIlkiv2xhuySml+kWVXL9mOXsPdfPZ97cgYtVfkx7PyQl4ACcx3aWq9yfeFJF7gc8CXwE+MUsZPcCHgR+o6sVna4jI54FngfcAnwK+Os2xXar65TTizZmLc+qsp25GHW3NfOGHR3i1+zybVmT/EcmmsHmq1rl3TTuALuCbUz7+EjAEfEREZpxkpqo/V9W/T05M7vsxfpWQbvISk58iPTEWVpTSXFPpdyiBtnNTI6UhsYZxkxGvbU43u9v9qhpP/sBNLM8DC4Ab5hBL4gHUqdYYWiIiHxORL4jIp0RkLueak3A0xvqGhVZVmcWy6nK2XlXL3sPdqKrf4Zh5xmty2uBuIyk+73S36+cQy8fc7b4Un7cBf4NTffxr4Kci8nMR2TyHc2bEnn7pXUdbM2+eHebnJ8/5HYqZZ7wmp0SDQaqF3xLvL8kkCBH5Q2An8HPgu9Psci+wFagDFgHXAY/iJKynRWTFDGXvcnsDD/b19WUS3iX6B0c5MzRmycmjHdc0UF4SslWBTW3ie+i+ds12gO/jnETkt4D7cBrLf1tVL1tfSFXvVtUXVLVfVQdV9aCqfgj4J6AW+Hyq8lV1t6puUdUtdXV1c4632JeCStfiyjJu3FDHE0e6icetalfE+hPfQ/e1e7YDvCanxJ1Rqi6XxPvnPJYHgIjcATwC9AI3qerxdI4HHnS370vzuIyF7emXaetoayZ6fpSfdZ3xOxQzj3hNTmF3m6pNqcXdpmqTuoyIfAj4ARAFblTV8CyHTCdRT8vboygj0RjLqsupXTjteFEzje0b66ksC7HH5tqZNHhNTs+42x0icskxIrIIpz3oAuBptLaI/B7wD0A3TmLqnOWQVBI9dunecWUs3BOjpd566tJRXVHK9qsbeOpIDxOT8dkPMAaPyUlV3wD2A6txBkkmuwfnzuUhVb34jAwR2SgiG6eWJSIfBf4O+CXwvtmqciLSKiJl072P03MHzqjznFNVOqOD1t6UgY7WJk4PjfHT47NNIjDGkc4I8U/iTF/5hohsB44C1+OMgYoAX5yy/1F3e/EWQ0RuxumNC+Hcjd05zR3IOVW9L+nnzwEdInIAOAmMAhtxevdKgG/j3IXl3KmBEWKjE9belIGbNtSzsKKUvYdOsa1l7h0TpvB5Tk6q+oaIbAH+HCcx3AacAr4O3KOqZz0Us4pf3a19LMU+J3B67xIeAxYDrcAtQCVwGngK+Laq/rPX32Gu7AFzmassK2HH2xp46pVT/MUdm2xRCDOrdO6cUNWTwJ0e973slkhVv8f0k3dnKucxnATlu8QwgvX1lpwy0d7WxP97+S0OdPax/eoGv8MxAWf/fKUhHI3RsLiCmgWXNYEZD957VR01VWU21854YskpDZ02bWVOyktD7Lymkf2v9jAyPul3OCbgLDl5NBlXOntj9gynOepoa2ZobJJnw71+h2ICzpKTRyfPXGBkPG7PcJqjG9Yuo3Zhuc21M7Oy5OTRxZ46u3Oak9KSELduauLHr0cZGk31dBxjLDl5luipu6p+oc+RzH8dbc2MjMf516NRv0MxAWbJyaNI7yBXLKuiuiKt0RdmGltWLaVxcaVV7cyMLDl5FOmxxvBsCYWE21ub+LdIHwPDlz0hxxjAkpMnYxNx3uizYQTZ1NHWzNhknP2v9vgdigkoS04edJ0eYiKuNm0li9pW1nDFsiobkGlSsuTkQdhtDG+xaStZIyK0tzbz3LF+zgyNzX6AKTqWnDzojMYoCQlr6/L2TLui0N7axGRceeoVu3syl7Pk5EE4GmP18gVUlpX4HUpBeVvTYtbWVbPXeu3MNCw5eRCxB8zlRKJq9+IvTtN7froV6E0xs+Q0i5HxSbpOD1lPXY50tDahCk8esbsncylLTrM41juIqq22kistDYvY2LiIPdZrZ6YoiuQkIh0isntgINWaoKlFbCmonOtoa+alE2d569yw36GY3KkRkd0i0uH1gKJITqq6R1V31dSkWnYvtXA0RnlJiNXLF+QgMgNOrx3AE7Z0VCEbUNVdqrrH6wFFkZzmItITY139QkpL7E+VK6uWV9O6ssbm2plL2DduFpHoIBsa7EkEudbR2syRtwbo6h+afWdTFCw5zSA2Ms5b54ZpsfamnLvdrdrttaqdcVlymkFn7yBgD5jLh+YlVWxZtdSqduYiS04zSDxgzgZg5kdHWzPhaOxiD6kpbpacZhCOxlhQXsKKJVV+h1IUbt3cSEhg7yGr2hlLTjOKRGO0NCwiFLpsfVCTA/WLKrlh7XL2Hj6FqvodjvGZJacZhHsGWW/PDM+rjrZmjvcP8Wr3eb9DMT6z5JTCmaEx+gdHrb0pz3Ze00hpSNhjvXZFz5JTCjZtxR9Lq8t5b0stew9Z1a7YWXJKIZGc7M4p/9pbm3nr3DAvnzzndyjGR5acUgj3xKipKqN+UYXfoRSdHdc0UF4SsofQFTlLTilEojHWNyxExHrq8m1xZRk3bajjiSPdxONWtStWlpymoapEorYUlJ/a25qJnh/lZ11n/A7F+MSS0zR6Y6MMDI9be5OP3n91PVVlJdZrV8QsOU0jsRSU3Tn5Z0F5KbdcXc9TR3qYmIz7HY7xgSWnadgwgmDoaG3m9NAYPz1+2u9QjA/SSk4islJEvisi3SIyKiJdInKfiCxNs5xl7nFdbjndbrkrc31uL8I9MWoXVrCsujzbRZs03LShjoUVpeyxuXZFqdTrjiKyDngBqAceB14H3gV8GtgpIltVddZ/4kRkuVvOeuBp4BFgI3AncLuIvFtVj+fi3DM5cXqIbx84zmMvdzM4OkGJwJ8+doSPb1vLquW2mKYfKstKeM+65fzw5bd44sgpLoxOUl1Ryh3XNuf1uiT/vzE0OuFLDMUYh3gdhSsiPwJ2AHep6v1J798LfBb4lqp+wkM53wJ2Afeq6t1J798FfB34karuzMW5t2zZogcPHrzs/WfCvXzy4f9kfDLORFLXdWlIKCsJ8cCH38HNG+pnK95k2TPhXv7bQy8xNnFpm1M+r0tQ/t+Y73GIyEuquiWdc3lKTu6dyzGgC1inqvGkzxYBpwAB6lU15XNWRWQh0AvEgSZVjSV9FgKOA6vccxzP5rlh+uR04vQQO+87wPD4ZMrjqspK2PeZbXYHlUdBuC5BiKFQ4sgkOXltc7rZ3e5PTg4AboJ5HlgA3DBLOTcAVcDzyYnJLScO/GjK+bJ57ml9+8BxxmfpDRqfjPOdA7/IpHiToSBclyDEUMxxeG1z2uBuIyk+78Spdq0HfjzHcnDLyfa5p/XYy92X3J5OZyKu/PDlt/iLOzalW7zJkNfr8vf/foIXc9Sbd6zPWVDVzxjmYxzZ+q54TU6JBd9SrUqZeH9JDsqZ07lFZBdOGxdXXnnlZZ8PjU6kKHbKfmPe9jPZ4fW6xBVacrQ6TuIZ8n7GMB/jSPFdqRWR5DaV3aq6e6ZyPPfWzVfuH2A3OG1OUz+vrihl0MMXobq84P9UgeL1uiysKOWB33tnTmLY9KUf+R7DfIwjxXelP1dtTom7k1RL5ibeP5eDcrJ17mndcW0zpbM8hrc0JPzmtSsyKd5kKAjXJQgxFHMcXpNT2N2uT/F5i7tN1S40l3Kyde5pfXzbWspmWc23rCTEH2xbk0nxJkNBuC5BiKGY4/CanJ5xtzvcLv+L3O78rcAF4MVZynkRGAa2uscllxPCadhOPl82zz2tVcureeDD76CqrOSyfxVKQ0JVWQkPfPgdNowgz4JwXYIQQzHH4Sk5qeobwH5gNfCpKR/fA1QDDyWPMxKRjSKycUo5g8BD7v5fnlLOH7rl/yh5hHgm507XzRvq2feZbfzuu65kYUUpIk79/XffdSX7PrPNBmD6JAjXJQgxFGsc6YwQnzqF5ChwPc44pAjwnuQpJCKiAKoqU8qZOn3lP4Crgd/AGaD5HjchZXzuVFKNEDfG5FYuB2Em7mC2AN/DSQx3A+twppzc4HVum7vfu4FvAFe55VwP/C3wzqmJKZvnNsbMH57vnAqB3TkZ44+c3jkZY0w+FdWdk4j0ASc87FoL9Oc4nHypIfXo+vmmUK5LMV6TVapal07BRZWcvBKRg+neggaViOxW1V1+x5ENhXJd7Jp4Y9W6wrfH7wDMZeyaeGDJqcCpqn0RAsauiTeWnKY342xp4xu7LsGTs2tibU7GmECyOydjTCBZcjLGBFJRJCc/19sz08vGNRGRZ0VEZ3hV5vJ3KCQi8kERuV9EDojIeffv93CGZWXl+1bwj3f0c709M70crEN4T4r37dnK3v0p0AYMAm/i/L+dtqxeW1Ut6BfOii4K/NGU9+9133/QYznfcvf/6pT373Lf3+f37zpfXlm8Js86/wv7/zvN9xfOEz5acJZZu8m9Dg/7dW1VtbB76/xcb89ML5vrEIrIs8CNOuWxPGZuROQmnIc8/r2qfjiN47J2baHw25z8XG/PTC/r6xCKyO+IyJ+IyOdE5FYRqcheuCYNWb22hZ6cMlknL5flmNz8LR8B/hL4KvAk8EsR+WBm4Zk5yOq1LfTk5Od6e2Z62fxbPg50ACtx7mw34iSpJcA/isjOjKM0mcjq96Tge+tM4VLVr015Kwx8QUS6gftxEtW+vAdmsqLQ75z8XG/PTC8ff8vv4AwjePvUVX5MTmX12hZ6cvJzvT0zvZz/LVV1BEh0XNiaXvmT1Wtb6MnJz/X2zPRyug6hW84GYClOgiqEJ2fOF1m9tgWdnNTH9fbM9LJ1TURkjYgsm1q+iNThrOQD8Iiq2ijxLBORMvearEt+P5NrO+N5CnkQJvi73p6ZXjauiYj8PvAg8BzOINgzwJXAbThtGweBD6jquZz/QgVARO4A7nB/bAR+DefvesB9r19VP+/uuxr4BXBCVVdPKScra0wChT99xU2+V+D8a3oKGMNZ5OA+YOk0+yoppkQAy3DWyjvhlnMK+C6w0u/fcb695npNgM046xgeAU4D4zgJ6gDwR0C537/jfHrh1Ah0hldX0r6rp76X6bWd6VXwd07GmPmpoNucjDHzlyUnY0wgWXIyxgSSJSdjTCBZcjLGBJIlJ2NMIFlyMsYEkiUnY0wgWXIyxgSSJSdjTCD9f2apQwgVX92hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 0.]])\n",
      "mode1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAEFCAYAAAChPiF8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo1UlEQVR4nO3dfXBcZ33o8e9v9WLJsiy/SLK0cWzH7yaJRMBJTE3Ii8F1Em1JKUyntzBtmOLhkja8hOntQKcQ7tCXuZcQSMmAoZQp6W1K02moncSYkoQ6CaGYQuwk9q4dx44TWyvJL/Jqrff93T/OWXkta6Wz0q7O7p7fZ2bn2GfPec5vdVY/Pec5z3MeUVWMMabYhPwOwBhjJmLJyRhTlCw5GWOKkiUnY0xRsuRkjClKlpyMMUXJktMERGS73zGYy9l5KT6FPCeWnCZWNr8EIhLxO4Y8KovzYufEG0tO5a+cfhHKhZ0TDyRIPcQbGxt1xYoVU27X3d1NU1NT4QOaBb29vTQ0NPgdRl6Uy3kJ4jn55S9/2aOqOZ28ymlHVYJWrFjBvn37/A7DmMARkeO57mOXdcaYomTJyRhTlDwnJxH5oIg8JCJ7ReS8iKiIPDKdg4rIUhH5roicFJFBETkmIg+KyMJJ9nmbiPxARLpEZEBEoiJyv4jUTicGY0xxy6XN6c+BdqAPeBNYP50Disgq4AWgGfghcAi4AfgksE1ENqvq6XH73Ag8DVQBjwEngNuAvwC2iMgWVR2cTjxmYsdPJ/n23qM8/quTJAdHqJtTyV3XhfnYTStZvrjO7/BMAORyWfdpYC0wH/ifMzjmwziJ6V5VvUtV/0xVbwO+CqwDvpy5sYhUAH8PzAU+qKr/Q1X/F3Aj8K/AZjc2kyfPRLvY9uBeHv2vE/QNjqBA3+AIj/7XCbY9uJdnol1+h2gCwHNyUtVnVPWwzqDvgVtr2gocA74x7u0vAEngIyKS+af5ZmAD8J+q+u8Z8aSAP3X/+3ERkenGZS46fjrJJx75b/qHRxlJXXqqR1JK//Aon3jkvzl+OulThCYoZrtB/FZ3ucdNLmNUNQE8j1ND2pTx1m3ucvf4wlT1KBADlgMr8x5tAH1771GGR1OTbjM8muI7e1+fpYhMUM12clrnLmNZ3j/sLtfOcB8zTY//6uRlNabxRlLKv/3qrVmKyATVbCendLfY3izvp9cvmOE+Y0Rku4jsE5F93d3dHsMMruTgiLfthrxtZ4yrMf176L6mHJNX9j3EVXUHsANg48aNwRmrM011cyrp85Cg6qrL/qtj8qtHVTfmssNs15zStZxsA4vS68/NcB8zTXddF6YyNPm9hcqQ8NvXXTFLEZmgmu3kFHWX2dqH1rjLzPal6exjpuljN62kqmLyr0VVRYg/uumqWYrIBNVsJ6dn3OVWEbnk2CJSj9Nn6QLwYsZbT7vLbeMLE5GVOEnrOHA079EG0PLFdTz84XdQW1XB+PpTZUiorarg4Q+/wzpimoIrSHISkSoRWe/2axqjqq8Be4AVwD3jdrsfqAO+r6qZnWh+ChwE3iMiv5VxjBDwN+5/vzmT/lfmUreua2b3p25iwdwqKkIylqTar2xg96du4tZ1zb7GZ4LBc6umiNwF3OX+t8VdvktEvuf+u0dVP+v++wqchHIcJxFl+gTO8JWvi8gWd7sbcfpAxYDPZ26sqqMicjdODeoxEXkMeAPYAmzE6Rv1Va+fw3izdOFckkOjfHTzCj5/59uIPPQcI6NqNSYza3KpOb0d+AP39ZvuupUZ6z7opRC39rQR+B5OUroPWAV8Ddg0flydu8/PgetxxuJtxRmu0gB8CXifjavLv+OnkwyNpFi7pB6ASHsrL73Zaz3DzazJZfjKF1VVJnmtyNj22Ph148o6oap3q2qrqlar6nJV/ZSqnp3k+K+q6odUtVFV56jqWlX9gqr25/KBjTexeAJgLDnd2RYGYNf+U77FZILFnudkJhTt7ANgzZJ5AFyxoJZ3Ll/IzpdO+hmWCRBLTmZCsa4EyxbNZW5GZ8tIWyuHOhMc6Ur4GJkJCktOZkKxzsTYJV3aHde2IgI7X7JLO1N4lpzMZQZHRnm9J8m6lnmXrG+eX8Omqxazc/9JrOeGKTRLTuYyr/ckGUnpZTUngI72Vo52Jzl4yi7tTGFZcjKXiXZeeqcu0+3XtFIREnbut4ZxU1iWnMxlDsf7qAgJK5su73C5qK6ad69uZJdd2pkCs+RkLhONJ7iqsY45lRUTvt/R1sqJM/289Ga2R2wZM3OWnMxlYvEE6ya4pEvbenUL1RUh6/NkCsqSk7lE/9Aob5y5MNb5ciINtVW8Z20TT+w/RWqKR/oaM12WnMwljnT1ocqkNSdwxtp1nh9g3/GsI46MmRFLTuYS0fSYupbJk9N7NyyhpirELrtrZwrEkpO5RCyeoLoyxPJFcyfdrm5OJVvWL+HJA6cYmWIqKWOmw5KTuUS0M8HqpnlUTvGoXnAu7Xr6hvj562dmITITNJaczCVi8QRrJ2kMz3TLumbqqivsrp0pCEtOZsz5gWFO9Q5M2d6UVlNVwdarW3jq5U6GRuzSzuRXIJKTiEREZEdvr3UanMxhtzF8qjt1mSLtrfT2D/P8kZ5ChWXKQ4OI7BCRiNcdApGcVHWnqm5vaMg29Z2Biw+Ym2hMXTbvXt1EQ22VXdqZqfSq6nZV3el1h0AkJ+NNLJ6grrqCKxbUet6nujLEtqtb2PNqnIHh0QJGZ4LGkpMZE+1MsHpJPaEpZvwdr6O9lb7BEZ6NdhcoMhNElpzMmMNdCdZ5vFOX6V0rF7O4rtoeo2LyypKTAaCnb5CevqGc2pvSKitC3H5tC08f7OLC0EgBojNBZMnJABenglrnsRvBeJG2MP3Do/zHwa58hmUCzJKTAZwJDSC3bgSZrl+xiCXz57DL7tqZPLHkZACIxvtoqK2iqX7OtPYPhYQ7rw3zbLSb8wPDeY7OBJElJwM4HTDXLalHJLc7dZki7a0MjabY80o8j5GZoLLkZFBVovEEa1tyv1OX6e1XLmDpwlp7jIrJC0tOhs7zAyQGRqbd3pQmInS0hXnucA9nk0N5is4ElSUnM+lUULmKtLcyklJ2v9I547JMsFlyMmPdCPKRnN7WOp+VjXU21s7MmCUnQyzeR1P9HBbWVc+4LBGhoz3Mi0dP05UYyEN0JqgsOZkpp4LKVaStlZTCUwfs0s5MnyWngEul1H36Zf6S05ol9axvqbdLOzMjlpwC7sTZCwwMp1g3w24E40Xaw+w7fpaT5/rzWq4JDktOAZe+U7cmjzUncKYsB3hi/6m8lmuCI6fkJCJLReS7InJSRAZF5JiIPCgiCz3uf4uIqIfXleP2m2zbF3P5DOZSh7ucp1+uac5vzWn54jraljZYh0wzbZVeNxSRVcALQDPwQ+AQcAPwSWCbiGxW1dNTFHMMuD/Le9cCHwBeVtUTE7x/HPjeBOvfnDJ4k1W0M8EVC2qpr6nKe9kdba385ZOHOH46yfLFdXkv35Q3z8kJeBgnMd2rqg+lV4rIA8CngS8DH5+sAFU9BnxxovdE5J/cf347y+7HVHXCfc30xeKJaT8mZSp3toX5yycPsWv/Ke65dXVBjmHKl6fLOrfWtBWn5vONcW9/AUgCHxGRaf15FJFG4LeBfuAfplOGyd3waIrXuvvyeqcu0xULatm4fKHdtTPT4rXN6VZ3uUdVL5mgTFUTwPPAXGDTNOP4A2AO8C+qei7LNgtE5KMi8jkRuUdEpnss4zrWk2R4VD1PojkdHW2tHOpMcKQrUbBjmPLkNTmtc5exLO8fdpdrpxnHx9zltybZph34O5zLx78FfiYivxaRa6d5zMCLxXOfCipXd7S1EhLY+ZLdtTO58Zqc0hO+ZZuVMr1+Qa4BiMjNOMnvZVV9IctmDwCbgSagHrgeeAwnYT0tIldMUv52EdknIvu6u212kEzReIKQwOo836nL1Fxfw41XLWbn/pOoasGOY4peY/r30H1tn2qHYujnlA5yR7YNVPU+VX1BVXtUtU9V96nqh4B/BRqBz06y7w5V3aiqG5uamvIbeYmLdSZYsbiOmqqKgh4n0h7maHeSV0+dL+hxTFHrSf8euq+sv+9pXpNTumaUbcrc9PpzHssDQEQWAb+D0xD+/Vz2dX3TXb5nGvsGXr6HrWSz7ZoWKkPCLuuQaXLgNTlF3WW2NqU17jJbm1Q26YbwH0zSED6Z9HWadaLJ0cDwKMdOJwvaGJ62qK6azasb2fmSXdoZ77wmp2fc5VYRuWQfEanHaQ+6AOTaWzvdED5lFS+L9B27o9PcP7Be6+4jpbC2QH2cxou0h3nzbD8vvZmt2dKYS3lKTqr6GrAHWAHcM+7t+3FqLt9X1WR6pYisF5H12coUkZuADUzeEI6ItInIZd2XRaQN584dwCNePoe5aGyeulm4rAPYevUSqitC1ufJeJZLD/FP4Axf+bqIbAEOAjfi9IGKAZ8ft/1Bd5ltOo8pG8JdnwEiIrIXOAEMAuuBbUAFTo/yf8q+u5lItLOPqgphRePsXBHPr6ni5nVNPLH/FJ+/YwOh0PRneTHB4PlunVt72ogzvu1G4D5gFfA1YJOHcXVj3IHCH8RbQ/jjwE+Ba3DaqO4F3gk8BbxfVberNWTkLBZPsKppHlUVs3fDtqOtlc7zA+w7fnbWjmlKVy41J9wBuXd73Dbrn0ZVPQvUeizncZwEZfIo2pngHcs9PUwib967YQk1Vc6l3Q1XLZrVY5vSUwz9nMws6xsc4a1z/aybhTt1mermVLJlwxKeevkUI6OpqXcwgWbJKYAO53G2lVxF2lrp6RvixaNnZv3YprRYcgqgsTt1s9SNINMt65qZN6fS7tqZKVlyCqBoZx81VSGuXDh31o9dU1XB+962hN2vdDI0Ypd2JjtLTgEUiydY01zv2+38SHsrvf3DPHfEBmKb7Cw5BdBsjanL5t2rm2iorWKXPUbFTMKSU8CcTQ7RlRjM+1RQuaiuDLHt6hb2vBpnYHjUtzhMcbPkFDAxH+/UZYq0h+kbHOHZqF3amYlZcgoYP+/UZdq0chGL66rZaVNHmSwsOQVMLN5H/ZxKWubX+BpHZUWIO65t5ScH4yQHR3yNxRQnS04BE40nWNtSj4j/A28j7WEGhlP85FCX36GYImTJKUBU1fc7dZk2Ll9Iy/wa65BpJmTJKUC6E4OcuzA862PqsgmFhDvbWvlptJvzA8N+h2OKjCWnAImm79T53BieqaOtlaHRFHteifsdiikylpwCZDbmqcvV269cwNKFtXZpZy4TiOQkIhER2dHbG+znV8c6Eyyuq6Zx3hy/QxkjIkTawzx/pIczySG/wzGF0yAiO0Qk4nWHQCQnVd2pqtsbGrLNbBUM0SJqDM/U0dbKSErZ/XKn36GYwul1n1q70+sOgUhOBlIp5XA84Xvny4m8rXU+K5vq2GUdMk0GS04B8da5fpJDo0VZcxIROtrC/OzoabrOD/gdjikSlpwC4nBXekxdcXQjGC/S1ooqPHnAnlRgHJacAiLa6dypW1OENSdw4lrfUm9TlpsxlpwCIhZP0NpQQ0PtZfOTFo1Ie5h9x89y8ly/36GYImDJKSCincV5py5TR1srAE9Y7clgySkQRlPKke6+orxTl2n54jraljbYY1QMYMkpEI6fTjI0kmJNc3E2hmeKtIXZ/2Yvx08n/Q7F+MySUwAUywPmvLjTvbSzhnFjySkAop19iMDqEqg5hRfUsnH5QhtrZyw5BUEsnmDZornMra70OxRPIu1hDnUmxmYmNsFkySkAinVMXTa3X9tCSGCnXdoFmiWnMjc4MsqxnmTR9gyfSHN9DZtWLmbX/pOoqt/hGJ9Ycipzr/ckGUlpSdWcADrawhztTvLqqfN+h2J8YsmpzEU7S+dOXaZt17RQGRJ22qzAgWXJqczF4gkqQ8LKxtK5rANYVFfNu9c02qVdgFlyKnPRzj6uaqyjurL0TnVHW5g3z/bz6xPn/A7F+CCnb6yILBWR74rISREZFJFjIvKgiCzMoYxnRUQneU0426OIvE1EfiAiXSIyICJREblfRGpz+QxBc7irtO7UZdp69RKqK0LWITOgPHd8EZFVwAtAM/BD4BBwA/BJYJuIbFbV0zkc+/4s6y+b/lVEbgSeBqqAx4ATwG3AXwBbRGSLqg7mcOxAuDA0whtnLvCB65b6Hcq0zK+p4uZ1Tezaf5LP37GBUMj/iUDN7MmlV97DOInpXlV9KL1SRB4APg18Gfi418JU9YtethORCuDvgbnA+1X13931IeAHwO+4x/9rr8cOiiNdfajCupbSam/KFGkP8+NX4/zi2BluXLnY73DMLPJ0WefWmrYCx4BvjHv7C0AS+IiI1OU1OsfNwAbgP9OJCUBVU8Cfuv/9uBTD/NpFJn2nrlQv6wDeu6GZ2qoKu7QLIK9tTre6yz1uUhijqgngeZyazSavBxaR3xWRPxORz4jI7SKSbb6i29zl7vFvqOpRIAYsB1Z6PXZQxOIJqitDLF9ciL8Zs2NudSW3bWjmyQOnGBlNTb2DKRtek9M6dxnL8v5hd7k2h2M/CvwV8BXgSeANEfngLB07EGLxPlY3zaOixNtqIm1hTieHePHoGb9DMbPIa3JKT/iWbVbK9PoFHsr6IRABlgK1wHqcJLUA+GcR2ZbPY4vIdhHZJyL7uru7PYRXPmJFOhVUrm5Z18S8OZX2pILS1pj+PXRf26faYdY7v6jqV1V1l6q+paoDqhpV1c8B97nx/FWej7dDVTeq6sampqZ8Fl3UevuHOdU7UNLtTWk1VRVsfdsSnnr5FEMjdmlXonrSv4fua8dUO3hNTunaSbYpc9Prz3ksbyLfwelG8HYRyfyNmo1jl53DYw+YK907dZki7WHOD4zw3JFg1X6DzGtyirrLbO06a9xltnahKanqAJB+gE9mC27Bj12OovHSv1OXafPqRhpqq2ysXYB4TU7PuMutbv+iMW4tZzNwAXhxuoGIyDpgIU6C6sl462l3Ob4tChFZiZO0jgNHp3vscnQ43kdddQVXLCiPDvTVlSFuv6aFH78aZ2B41O9wzCzwlJxU9TVgD7ACuGfc2/fj1HS+r6pjT6UXkfUisj5zQxG5SkQWjS9fRJpwOloCPKqqmb3EfwocBN4jIr+VsU8I+Bv3v99UGx16iWhngjVL6imn7l8dbWH6Bkd4NtrldyhmFuTSQ/wTOMNXvi4iW3ASxo04faBiwOfHbX/QXWb+dtwMfFNEnsOp6ZwBlgF34LQd7eNix0oAVHVURO7GqUE9JiKPAW8AW4CNOH2svprD5wiEWDzBezcs8TuMvNq0chGN86rZuf8U265p9TscU2Cek5OqviYiG4Ev4Vxi3QGcAr4G3K+qZz0U80uc/k3vBK4D5uNcxh3AGYryLVUdmuDYPxeR63FqaVuBepxLuS8Bf23j6i7V0zfI6eQQa8ugG0GmyooQd1zbyg/2nSA5OELdnNJ4JrqZnpzOrqqeAO72uO1l1xOqegD4w1yOmbHvq8CHprNv0MTSD5grk8bwTB1tYf7hZ8f5j4Nx3v/2K/wOxxRQ6T3kx0wpNnanrjy6EWTauHwhLfNrbKxdAFhyKkPReB8L5lbRVJ9tuGLpCoWEO9ta+Wm0m97+Yb/DMQVkyakMxdypoMrpTl2mSHuYodEUP3417ncopoAsOZUZVSXWmSjL9qa09qUNXLmo1sbalTlLTmWm8/wAicGRsrtTl0lE6GgL89yRHs4kL7u5a8qEJacyM/aAuebyawzPFGkLM5pSdr/c6XcopkAsOZWZWJmNqctmQ2s9K5vq7NKujFlyKjPRzj6a6+ewsK7a71AKSkSItIV58fXTdJ0f8DscUwCWnMpMuTxgzotIeyuq8OQB6/NUjiw5lZFUSkt6nrpcrW6uZ31LPTutQ2ZZsuRURk6cvcDAcKose4ZnE2kP88vjZ3nrXL/foZg8s+RURsphKqhcRdrCADyx3xrGy40lpzKSvlO3JkDJadniubQvbbCxdmXIklMZicb7WLqwlnkBe5RIR1uY/W/2cqwnOfXGpmRYciojh+PlPWwlmzvbnAfP7bJLu7JiyalMDI+meK27L1CXdGnhBbVcv2KhXdqVmUAkJxGJiMiO3t5s83KWvmM9SYZHtWymgspVR1uYQ52JsSmxTNFpEJEdIhLxukMgkpOq7lTV7Q0N2aa+K33lNhVUrm6/toWQYH2eilevqm5X1Z1edwhEcgqCWGeCkMCqpmDWnJrra9i0cjG7XjqJTcRTHiw5lYlYvI8VjXXUVFX4HYpvIu1hjvYkefXUeb9DMXlgyalMxOIJ1jYH85IubdvVLVSGxGYFLhOWnMrAwPAox04ny/oBc14srKvm3Wsa2bXfLu3KgSWnMnCkq4+UludUULmKtIV582w/vz5xzu9QzAxZcioD6WErQe1GkOl9Vy+huiJkl3ZlwJJTGYjF+6iuCLF8cZ3fofhufk0Vt6xr4okDJ0ml7NKulFlyKgOxeIKVTXVUVdjpBOeuXfz8IL84dsbvUMwM2Le5DEQ7g/OAOS+2bGimtqqCnTbWrqRZcipxiYFh3jrXH5hH83oxt7qSLRuaeepAJyOjKb/DMdNkyanEHe7qA4I7bCWbjrYwp5ND/Ozoab9DMdNkyanEpQe6WjeCS92yrol5cyrZZXftSpYlpxIX7eyjtqqCpQtr/Q6lqNRUVbD16iU89fIphkbs0q4UWXIqcbF4gjVL5hEKid+hFJ1IW5jzAyPsPdztdyhmGiw5lbho3O7UZbN5dSML5lbZQ+hKlCWnEnY2OUR3YtDam7Korgyx7eoW9rzSycDwqN/hmBzllJxEZKmIfFdETorIoIgcE5EHRWShx/3rROT3ReT/icghEUmKSEJE9onIfSIy4RzaIqKTvF7M5TOUk/SwlaAP+J1MpD1McmiUZ6NdfodicuR5mg4RWQW8ADQDPwQOATcAnwS2ichmVZ3qvu1NwCPAGeAZ4HFgIfBbwP8FPiAiW1R1YIJ9jwPfm2D9m14/Q7kZS04BmkQzVzdetYjGedXsfOkU265p9Tsck4Nc5hB6GCcx3auqD6VXisgDwKeBLwMfn6KMTuDDwL+o6lBGGZ8FngV+A7gH+MoE+x5T1S/mEG/Zi8YT1NdU0jK/xu9QilZlRYg7rm3lB/tOkBwcoS5g02aVMk+XdW6taStwDPjGuLe/ACSBj4jIpCNPVfXXqvqPmYnJXZ/gYkK6xUtMBmKdfaxbUo+I3ambTKQ9zMBwiv84GPc7FJMDr21Ot7rLPap6SacRN7E8D8wFNs0glmF3OZLl/QUi8lER+ZyI3CMiMzlWyVNV506dtTdN6Z3LFtIyv8Yeo1JivCande4yluX9w+5y7Qxi+ai73J3l/Xbg73AuH/8W+JmI/FpErp3BMUtWd2KQ3v5hu1PnQSgkdLS18p+xbnr7h6fewRQFr8kpPadStonf0usXTCcIEfljYBvwa+C7E2zyALAZaALqgeuBx3AS1tMicsUkZW937wbu6+4un8546amg1lhjuCcd7WGGRlPseaXT71CCqjH9e+i+tk+1g+/9nETkA8CDOI3lv6Oql/1pU9X7VPUFVe1R1T5V3aeqHwL+FWgEPputfFXdoaobVXVjU1NTgT7F7It22pi6XLQvbeDKRbXWIdM/PenfQ/e1Y6odvCandM0o26yU6fXnPJYHgIjcBTwKdAG3qOrRXPYHvuku35PjfiUvFk/QOK+axfPm+B1KSRARIm1hnjvSw5nk0NQ7GN95TU5Rd5mtTWmNu8zWJnUZEfkQ8C9AHLhZVaNT7DKR9HVa4J5PG4332bCVHHW0hRlNKU+9bLWnUuA1OT3jLreKyCX7iEg9TnvQBcBTb20R+X3gn4CTOInp8BS7ZJO+Y5drjaukpVLKERtTl7MNrfWsaqqzx6iUCE/JSVVfA/YAK3A6SWa6H6fm8n1VTaZXish6EVk/viwR+QPgH4A3gPdMdSknIm0iUjXRepw7d+D0Og+Mt871kxwateSUIxGhoy3Mi6+fpuv8RIMQTDHJpbvsJ3CGr3xdRLYAB4EbcfpAxYDPj9v+oLsc6yEoIrfi3I0L4dTG7p6gA+E5VX0w4/+fASIishc4AQwC63Hu7lUA38aphQWGTQU1fZH2Vr72k8M8eeAUf7j5Kr/DMZPwnJxU9TUR2Qh8CScx3AGcAr4G3K+qZz0Us5yLtbWPZtnmOM7du7THgflAG3AbUAOcBp4Cvq2q/+71M5SLi90IrOaUq9XN9Wxonc/O/Zacil1OA41U9QRwt8dtL6sSqer3mHjw7mTlPI6ToIwr1pkg3FDD/JrLrnaNBx1trfyfH0V561w/VyywJ4gWK9/7OZncxeJ9NmxlBiJtYQCesKmjipolpxIzMpriSLd1I5iJZYvn0r60wcbaFTlLTiXm+JkLDI2kLDnNUKQ9zIG3ejnWk5x6Y+MLS04lJmbDVvLizjbnwXO77NKuaFlyKjGxeB8isLrZuhHMRGtDLdevWGiXdkXMklOJicUTLF80l9rqCr9DKXmR9jDReGKs35gpLpacSkw0nrD+TXly+zWthAR2vWSXdsXIklMJGRwZ5fWepLU35UlT/RzetWoxu/afQlX9DseMY8mphBztTjKaUuvjlEeRtjBHe5K8cvK836GYcSw5lZCxMXVWc8qbbde0UBkSewhdEbLkVEJi8QSVIeGqxsA9vqpgFsyt5qY1jex86aRd2hUZS04lJNrZx1WNdVRX2mnLp462MG+d6+dXJ875HYrJYN/yEhKzqaAK4n1XL6G6MmQPoSsylpxKxIWhEd44c8Hamwpgfk0Vt6xt4okDJ0ml7NKuWFhyKhFHuvoAbExdgUTaw8TPD/KLY2f8DsW4LDmViLGpoOyyriC2bGimtqqCnTbWrmgEIjmJSEREdvT2ZpsTtPjF4gnmVIZYtmiu36GUpbnVlWzZ0MxTBzoZGU35HU45ahCRHSIS8bpDIJKTqu5U1e0NDdmm3St+0Xgfq5vnURG67AGjJk8i7WFOJ4f42dHTfodSjnpVdbuq7vS6QyCSUzmIdSasMbzAbl7bRP2cSnbaWLuiYMmpBPT2D9N5fsC6ERRYTVUF77t6Cbtf7mRoxC7t/GbJqQQctmErsybSHub8wAh7D3dPvbEpKEtOJeDiVFD2gLlCe/fqRhbMrbJLuyJgyakExDoT1FVX2DRGs6CqIsTt17Tw41fjDAyP+h1OoFlyKgFRd9jKBLMjmwLoaAuTHBrlmUNdfocSaJacSsDheJ+1N82iTSsX0zhvjj1GxWeWnIpcT98gp5NDNmxlFlWEhDuvbeEnh+L0DY74HU5gWXIqcumpoCw5za6O9jADwyl+cjDudyiBZcmpyKXv1K1tsTt1s+mdyxbS2lBjU0f5yJJTkYvFEyycW0XTvDl+hxIooZBw57Wt/DTWRW//sN/hBJIlpyIXi/exdondqfNDpD3M8Kiy55VOv0MJJEtORUxVnTF1NmzFF21LG1i2aC477a6dLyw5FbFTvQMkBkdsEk2fiAgdba08f6SHM8khv8MJHEtORSxqY+p8F2kPM5pSnnrZak+zzZJTEbvYjcDu1PllfUs9q5rqbKydDyw5FbFYvI8l8+ewYG6136EElogQaQ/z89fP0HV+wO9wAiWn5CQiS0XkuyJyUkQGReSYiDwoIgtzLGeRu98xt5yTbrlLC33sUhKLJ6zzZRHoaAujCk8csEu72SReZzkVkVXAC0Az8EPgEHADcCsQBTar6pTPNxWRxW45a4GngV8A64H3A13Au1T1aCGOvXHjRt23b9+E7x0/neTbe4/y+K9OkhwcoW5OJXddF+ZjN61k+eLZm2E3M46+wRGqKoTfvf7KWY/DXHT8dJL3f+N5zvcPo0pRfDeK5TvqNQ4R+aWqbszlOLkkpx8BW4F7VfWhjPUPAJ8GvqWqH/dQzreA7cADqnpfxvp7ga8BP1LVbYU4drbk9Ey0i0888t8Mj6YYyZi3rDIkVFWEePjD7+DWdc1TFT9jxRKHuSh9TgZHRsmc0i6o343pxlGw5OTWXI4Ax4BVqprKeK8eOAUI0KyqyUnKmYdTO0oBraqayHgvBBwFlrvHOJrPY8PEyen46STbHtxL/yTP7qmtqmD3p24q6F+nYonDXFQs56Qc4phOcvLa5nSru9yTmRwA3ATzPDAX2DRFOZuAWuD5zMTklpMCfjTuePk89oS+vfcow1NMBTQ8muI7e1+fTvElF4e5qFjOSVDjqPS43Tp3Gcvy/mGcy661wE9mWA5uOfk+9oQe/9XJS6qnExlJKf/48+O8WMApg4509zFVJXYkpfzbr97if991TcHiMBeV2nejWOLI13fUa3JKT/iWbVbK9PoFBShnRscWke04bVwsW7bssveTHp/Xk9LCPsP7sDvd+FSSQ/Z8odlSat+NYokjy3e0UUQy21R2qOqOycrxmpxKlvsD2AFOm9P49+vmVHp6oNi8OZU8/PvvzH+Armu+8CNPcdRVl/0pKxql9t0oljiyfEd7CtXmlK6dZJsyN73+XAHKydexJ3TXdWEqp5hFtzIk/PZ1V0yn+JKLw1xULOckqHF4TU5Rd7k2y/tr3GW2dqGZlJOvY0/oYzetpKpi8h9DVUWIP7rpqukUX3JxmIuK5ZwENQ6vyekZd7nVveU/xr2dvxm4ALw4RTkvAv3AZne/zHJCOA3bmcfL57EntHxxHQ9/+B3UVlVc9lehMiTUVlXw8IffUfDb98USh7moWM5JUOPwlJxU9TVgD7ACuGfc2/cDdcD3M/sZich6EVk/rpw+4Pvu9l8cV84fu+X/KLOH+HSOnatb1zWz+1M38Xs3LGPenEpEnOv337thGbs/ddOsdXwsljjMRcVyToIYx0yGrxwEbsTphxQDfiNzCImIKICqyrhyxg9f+S9gAxeHr/yGm5CmfexsJhu+YowpnEJ2wkzXYDYC38NJDPcBq3CGnGzykhzcck4D7wK+Dqx2y7kR+HvgneMTUz6PbYwpHZ5rTuXAak7G+KOgNSdjjJlNgao5iUg3cNzDpo1AT4HDmS0NZO9dX2rK5bwE8ZwsV9WmXAoOVHLySkT25VoFLVYiskNVt/sdRz6Uy3mxc+KNXdaVv51+B2AuY+fEA0tOZU5V7RehyNg58caS08QmHS1tfGPnpfgU7JxYm5MxpihZzckYU5QsORljilIgkpOf8+2ZieXjnIjIsyKik7xqCvkZyomIfFBEHhKRvSJy3v35PTLNsvLy+1b2j1WcZM67TwLbRGS68+09ijPf3t3AnSJy2Xx7ZmL5OicZ7s+y3p5p7N2fA+1AH/Amznc7Z3k9t6pa1i+cGV0U+JNx6x9w13/TYznfcrf/yrj197rrd/v9WUvllcdz8qzzFfb/M5X6C+cJH2twplm7xT0Pj/h1blW1vO/W+TnfnplYPuchFJFngZt13GN5zMyIyC04D3n8R1X9cA775e3cQvm3Ofk5356ZWN7nIRSR3xWRPxORz4jI7SIyJ3/hmhzk9dyWe3Kazjx5hSzHFOZn+SjwV8BXgCeBN0Tkg9MLz8xAXs9tuScnP+fbMxPL58/yh0AEWIpTs12Pk6QWAP8sItumHaWZjrz+npT93TpTvlT1q+NWRYHPichJ4CGcRLV71gMzeVHuNSc/59szE5uNn+V3cLoRvH38LD+moPJ6bss9Ofk5356ZWMF/lqo6AKRvXNhcWrMnr+e23JOTn/PtmYkVdB5Ct5x1wEKcBFUOT84sFXk9t2WdnNTH+fbMxPJ1TkTkKhFZNL58EWnCmckH4FFVtV7ieSYiVe45WZW5fjrndtLjlHMnTPB3vj0zsXycExH5Q+CbwHM4nWDPAMuAO3DaNvYB71PVcwX/QGVARO4C7nL/2wL8Js7Pda+7rkdVP+tuuwJ4HTiuqivGlZOXOSaB8h++4ibfK3H+mp4ChnAmOXgQWDjBtkqWIRHAIpy58o675ZwCvgss9fszltprpucEuBZnHsMDwGlgGCdB7QX+BKj2+zOW0gvnikAneR3L2HbF+HXTPbeTvcq+5mSMKU1l3eZkjCldlpyMMUXJkpMxpihZcjLGFCVLTsaYomTJyRhTlCw5GWOKkiUnY0xRsuRkjClKlpyMMUXp/wNHSqGJ+3Wn8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 0.]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_train: DataBatch(x=[6, 4], edge_index=[2, 10], y=[6, 2], batch=[6], ptr=[2])\n",
      "dataset_test: DataBatch(x=[6, 4], edge_index=[2, 10], y=[6, 2], batch=[6], ptr=[2])\n",
      "tensor([[0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1667, 1.0000, 1.0000, 1.0000],\n",
      "        [0.3333, 1.0000, 1.0000, 0.0000],\n",
      "        [0.6667, 0.0000, 1.0000, 1.0000],\n",
      "        [0.8333, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000]])\n",
      "tensor([[ 0.,  0.],\n",
      "        [ 0.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0., -1.],\n",
      "        [ 0.,  0.],\n",
      "        [ 0.,  0.]])\n",
      "mkdir: best_model: File exists\n",
      "Epoch 0, Training Loss: 1.577e-01, Validation Loss: 1.660e-01\n",
      "Saved the best model with loss: 1.577e-01\n",
      "Epoch 1000, Training Loss: 1.032e-02, Validation Loss: 1.173e-02\n",
      "Saved the best model with loss: 1.032e-02\n",
      "Epoch 2000, Training Loss: 1.768e-05, Validation Loss: 2.535e-04\n",
      "Saved the best model with loss: 1.768e-05\n",
      "Epoch 3000, Training Loss: 3.037e-06, Validation Loss: 2.021e-04\n",
      "Saved the best model with loss: 3.037e-06\n",
      "Epoch 4000, Training Loss: 2.044e-06, Validation Loss: 1.984e-04\n",
      "Saved the best model with loss: 2.044e-06\n",
      "Epoch 5000, Training Loss: 1.169e-06, Validation Loss: 1.939e-04\n",
      "Saved the best model with loss: 1.169e-06\n",
      "Epoch 6000, Training Loss: 4.898e-07, Validation Loss: 1.894e-04\n",
      "Saved the best model with loss: 4.898e-07\n",
      "Epoch 7000, Training Loss: 1.280e-07, Validation Loss: 1.857e-04\n",
      "Saved the best model with loss: 1.280e-07\n",
      "Epoch 8000, Training Loss: 1.866e-08, Validation Loss: 1.828e-04\n",
      "Saved the best model with loss: 1.866e-08\n",
      "Epoch 9000, Training Loss: 8.890e-10, Validation Loss: 1.811e-04\n",
      "Saved the best model with loss: 8.890e-10\n",
      "mkdir: png: File exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main(): \n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    \n",
    "    # Check if GPUs are available\n",
    "    if torch.cuda.is_available():\n",
    "        # Get the number of available GPUs\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"{num_gpus} GPU(s) available\")\n",
    "\n",
    "        # Assert that at least one GPU is allocated\n",
    "        assert num_gpus > 0, \"No GPUs available. Please check your CUDA installation.\"\n",
    "\n",
    "        # Print information about each GPU\n",
    "        for i in range(num_gpus):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            print(f\"GPU {i}: {gpu_name}\")\n",
    "    else:\n",
    "        print(\"No GPUs available. Please check your CUDA installation.\")\n",
    "\n",
    "    gnn = GraphNet(\n",
    "                     c_in       = 4,\n",
    "                     c_hidden   = 64,\n",
    "                     c_out      = 2,\n",
    "                     num_layers = 2,\n",
    "                     num_epochs = 10000,\n",
    "                     noise_std  = 0.0,\n",
    "                     lr         = 0.0001,\n",
    "        layer_name = \"GCN\",\n",
    "                     verbose    = True \n",
    "                ).to(device)  # Move model to GPU\n",
    "\n",
    "#    gnn.Parse( path  = confParser['gnn']['input_path'],\n",
    "#                 nruns = eval(confParser['gnn']['nruns']))\n",
    "    \n",
    "    #--- build dataset based on the input catalogs\n",
    "    gnn.DataBuilder2nd()\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(gnn.parameters(), lr=gnn.lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # training loop\n",
    "    training_loss_hist   = []\n",
    "    validation_loss_hist = []\n",
    "    best_loss = np.inf\n",
    "    print(gnn.dataset_test.x)\n",
    "    print(gnn.dataset_test.y)\n",
    "    !mkdir best_model\n",
    "    for epoch in range( gnn.num_epochs ):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_displacements = gnn(gnn.dataset_train.x.to(device), gnn.dataset_train.edge_index.to(device))\n",
    "        training_loss              = criterion(predicted_displacements, gnn.dataset_train.y.to(device))\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss_hist += [training_loss.detach().cpu().numpy()]  # Move loss back to CPU\n",
    "\n",
    "        #--- validation loss\n",
    "        gnn.eval()\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "                predicted_displacements = gnn(gnn.dataset_test.x.to(device), gnn.dataset_test.edge_index.to(device))\n",
    "                validation_loss         = criterion(predicted_displacements, gnn.dataset_test.y.to(device))\n",
    "\n",
    "                validation_loss_hist += [validation_loss.cpu().numpy()]  # Move loss back to CPU\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f'Epoch {epoch}, Training Loss: {training_loss.item():4.3e}, Validation Loss: {validation_loss.item():4.3e}')\n",
    "\n",
    "            # Update best_loss if validation loss improves and save the model\n",
    "            best_loss = GraphNet.save_best_model(gnn, optimizer, \n",
    "                                        epoch, training_loss.detach().cpu().numpy(), best_loss, \n",
    "                                        'best_model/best_model.pth')\n",
    "\n",
    "    #--- plot loss vs epoch\n",
    "    !mkdir png\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    utl.PltErr(range(gnn.num_epochs),training_loss_hist,\n",
    "               attrs={'fmt':'-','color':'C0'},\n",
    "               ax=ax,Plot=False\n",
    "          )\n",
    "    utl.PltErr(range(gnn.num_epochs),validation_loss_hist,\n",
    "               attrs={'fmt':'-','color':'red'},\n",
    "              xscale='log',yscale='log',\n",
    "               title='png/loss.png',\n",
    "               Plot=False,\n",
    "               ax=ax\n",
    "          )\n",
    "    return gnn.dataset_train, gnn.dataset_test\n",
    "\n",
    "\n",
    "data_train, data_test = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "65badb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "u_pred=\n",
      " [[ 2.35438347e-06 -1.37239695e-05]\n",
      " [ 9.99999523e-01 -4.54485416e-07]\n",
      " [-3.87430191e-07 -9.99999642e-01]\n",
      " [ 1.35451555e-05  2.40430236e-05]\n",
      " [-4.59253788e-05  5.27277589e-05]\n",
      " [ 3.04132700e-05 -6.21303916e-05]]\n",
      "u_act=\n",
      " tensor([[ 0.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0., -1.],\n",
      "        [ 0.,  0.],\n",
      "        [ 0.,  0.],\n",
      "        [ 0.,  0.]])\n",
      "u_pred=\n",
      " [[ 2.35438347e-06 -1.37239695e-05]\n",
      " [ 5.15580177e-06 -4.29898500e-06]\n",
      " [ 9.61403728e-01  2.54764780e-02]\n",
      " [ 5.41037321e-03 -9.97737408e-01]\n",
      " [-4.59253788e-05  5.27277589e-05]\n",
      " [ 3.04132700e-05 -6.21303916e-05]]\n",
      "u_act=\n",
      " tensor([[ 0.,  0.],\n",
      "        [ 0.,  0.],\n",
      "        [ 1.,  0.],\n",
      "        [ 0., -1.],\n",
      "        [ 0.,  0.],\n",
      "        [ 0.,  0.]])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEJCAYAAABPBDiyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOhElEQVR4nO3df4wc5X3H8c8nOHEU7F6iYIKqoJBaQP6wcKSuEwqVwmIFoVROUQQXVSIQFHTimhSIqCBq6xawIqVuVCC0ufbUECtAf1xEEYpCCZWy0JCois8qIJTwy5KbVJDkHJqrD4JJ4Ns/dhbss+9uz+fvMzt775c0Gs/szM7XntuPn3lmnxtHhAAgw5vqLgDA8CJgAKQhYACkIWAApCFgAKQhYACkIWAApCkSMLbfaftK2/faftb2L23P2n7E9qdsE3TAEHKJL9rZvkrShKTnJXUk/UjSuyR9TNKIpHskXRJ86w8YKqUC5nxJJ0r6ZkS8dsj6UyR9X9Kpki6OiHvSiwFQTJFLk4j4dkR849Bwqdb/RNLfVYvn9fNetseOc3kohHPXbMdy/gah7+NX1fzXfW4/1D+ktrfVXUMizl2zNStgbK+RdFm1+ECdtQyQYf8hHWacu3mK9MEseHD7i5Kuk3R/RPzeItuNqUrPtWvX/vamTZsKVVje7OysRkZG6i4jxczMjDZs2FB3GWmG+dxJ0p49ew5KeuKQVZMRMbnYPrUFjO2rJd0m6UlJ50bEC/3s12q1Ynp6OrU2AEeyvSciWsvZp5ZLJNufUTdcfiCp3W+4AGiW4gFj+1pJt6vb1GpXd5IADKGiAWP7Bkm3SHpU3XD5WcnjAyirWMDY3i7pC5L2SNoaEftLHRtAPdaUOIjtyyXdLOlVSd+RdLXt+Zvti4hdJeoBUEaRgJH03mp+gqRrF9jmYUm7ShQDoIxSQwVujAgvMZ1XohYA5QzCUAEAQ4qAAZCGgAGQhoABkIaAAZCGgAGQhoABkIaAAZCGgAGQhoABkIaAAZCGgAGQhoABkIaAAZCGgAGQhoABkIaAAZCGgAGQhoABkKYxAWN7m+3J2dnZuksBVqsR25O2t/W7Q23Ppj5WPJsaqEdjnk0NYHUgYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQpFjC2L7Z9u+3v2P4/22H7rlLHB1DemoLH+jNJmyXNSfofSe8reGwANSh5ifRZSWdI+g1J4wWPC6AmxQImIjoR8Uw07TkpwCJ27typTqdz2LpOp6OdO3fWVNFgoZMXWIEtW7ZodHT09ZDpdDoaHR3Vli1baq5sMJTsgwGGTrvd1tTUlEZHRzU+Pq6JiQlNTU2p3W7XXdpAaEQLxvaY7Wnb0zMzM3WXAxym3W5rfHxcO3bs0Pj4+DCHy0m9z2E1jS21QyMCJiImI6IVEa0NGzbUXQ5wmE6no4mJCW3fvl0TExNH9MkMkf29z2E1TS61QyMCBhhUvT6Xqakp3Xzzza9fLg1xyCwLAQOswO7duw/rc+n1yezevbvmygaD67hrbPs8SR1Jd0fEpcvZt9VqxfT0dEZZABZhe09EtJazDy0YAGmK3aa2fZGki6rFU6r579jeVf15f0T8cal6AOQr+T2Y90u6fN6636omSfpvSQQMMERKDhW4MSK8yHRaqVoAlEEfDIA0BAyANAQMgDQEDIA0BAyANAQMgDQEDIA0BAyANAQMgDQEDIA0BAyANAQMgDQEDIA0BAyANAQMgDQEDIA0BAyANAQMgDSNCRjb22xPzs7O1l0KsFqN2J60va3fHWp5LtJK8FwkoB48FwnAQCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCkaMLbfbfsO28/ZPmh7n+1bbb+jZB0AylhT6kC2N0r6nqSTJd0n6UlJH5B0jaQLbZ8bET8vVQ+AfCVbMF9WN1yujoiLIuJzEXG+pFsknSnp8wVrAVBAkYCpWi8XSNon6W/nvfwXkl6U9AnbJ5aoB+XM2Xps/frD1j22fr3m7JoqQkmlWjDtav5gRLx26AsRcUDSdyW9TdLZhepBIXvXrdNZc3Ovh8xj69frrLk57V23rubKUEKpgDmzmj+9wOvPVPMzCtSCgjYfOKDHq5B52dZZc3N6fN06bT5woO7SUECpgBmp5gs997W3/u1He9H2mO1p29MzMzPHuzYk23zggA5Kequkg9UyGumk3uewmsaW2qHYXaSViIhJSZNS99GxNZeDZXps/XqdJellSWurZUKmkfYP6qNjey2UkQVe763/RX4pKKnX5/L4unV6a8Trl0vzO34xnEoFzFPVfKE+ltOr+UJ9NGiojfP6XHp9Mhvn5mquDCWUukTqVPMLbL/p0DtJttdLOlfSS5L+s1A9KGRdhDbPW8fl0epRpAUTEXslPSjpNEmfnvfyTZJOlHRnRLxYoh4AZZTs5P1DdYcKfMn2Vkk/lPRBdb8j87SkPy1YC4ACig0VqFoxLUm71A2W6yRtlHSbpLMZhwQMn6K3qSPix5KuKHlMAPXh98EASEPAAEhDwABIQ8AASEPAAEhDwABIQ8AASEPAAEhDwABIQ8AASEPAAEhDwABIQ8AASEPAAEhDwABIQ8AASEPAAEhDwABI05iAsb3N9uTs7EJPnwWQbMT2pO1t/e7giGY9ibXVasX09HTdZQCrju09g/roWACrEAEDIA0BAyANAQMgDQEDIA0BAyANAQMgDQEDIA0BAyANAQMgDQEDIA0BAyANAQMgDQEDIA0BAyANAQMgDQEDIA0BAyANAQMgTXrA2H6z7Wtsf9X2o7ZfsR22r8w+NoB6rSlwjBMl3Vr9+aeSfiLp1ALHBVCzEpdIL0n6iKTfjIhTJN1R4JgABkB6wETEKxHxbxHxfPaxGmvnTqnTOXxdp9NdDzQYnbyDYMsWaXT0jZDpdLrLW7bUWxewQiX6YLCUdluamuqGyvi4NDHRXW63664MWJFGtGBsj9metj09MzNTdzk52u1uuOzY0Z0TLhg8J/U+h9U0ttQOfQWM7X3VreV+p7tW/nd5Q0RMRkQrIlobNmw4nm89ODqdbstl+/bufH6fDFC//b3PYTVNLrVDv5dIeyW9vIxCnlvGtuj1ufQui9rtw5eBhuorYCJia3Yhq9ru3YeHSa9PZvduAgaNRifvILj++iPX9VoyQIM1opMXQDMVacHY/pyk91WL76/mV9j+3erPj0TEP5SoBUA5pS6RLpT0oXnrzqmmHgIGGDJFAiYizitxHACDhT4YAGkIGABpCBgAaQgYAGkIGABpCBgAaQgYAGkIGABpCBgAaQgYAGkIGABpCBgAaQgYAGkIGABpCBgAaQgYAGkIGABpCBgAaQgYAGkaEzC2t9menJ2drbsUYLUasT1pe1u/OzgiMgs67lqtVkxPT9ddBrDq2N4TEa3l7NOYFgyA5iFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApEkPGNun277B9rdt/9j2K7Z/avs+2+3s4wOoz5oCx9gh6eOSfiDpfkkvSDpT0kclfdT2NRHxpQJ1ACisRMA8IOkvI+K/Dl1p+0OS/l3SX9n+ekQ8X6AWAAWlXyJFxK754VKtf1jSQ5LeIumc7DoAlFd3J++vqvmva60CQIraAsb2eyRtlfSSpP+oqw4AeUr0wRzB9lpJd0taK+n6iPjfJbYfkzRWLR60/URyiXUakTSsz8c9SdL+uotINMznTpI22T70saqTETG52A59PTrW9j5J71lGIXdHxKULvNcJkv5J0iWS/kXSH8Qynl9re3q5j69sEtuTETG29JbNw7lrtmM5f/22YPZKenkZ7/vc0VZW4XKXuuEyJenS5YTLKvGNugvAMePczdNXwETE1pUeyPab1b0sukTSP0q6LCJeXen7DpuI4Ie0oTh3RyrSB2P7Leq2WH5f0tckXRERrx3j2y16zYeBxrlrtmWfv776YFai6tD9V0kfkfQVSWMrCBcADVIiYL4q6ZPq3j34sqSjHfChiHgotRAAxZW4RHpvNT9J0p8vst1D+aUAKKnEUIHzIsJLTDcu930Zpd0Mtt9t+w7bz9k+aHuf7Vttv6Pu2rAw2++0faXte20/a/uXtmdtP2L7U7b7yo70S6Qstv9Zb4zSfkSHj9I+QRKjtGtme6Ok70k6WdJ9kp6U9AFJbUlPSTo3In5eX4VYiO2rJE1Iel5SR9KPJL1L0sfU/ULhPZIuWeprJk0OmE9KemyRUdoh6TRGadfH9rckXSDp6oi4/ZD1fy3ps5L+PiKuqqs+LMz2+ZJOlPTNQ2/K2D5F0vclnSrp4oi4Z9H3aWrALMb2g5I+rD7+AZCjar08K2mfpI3zfkjXq/s/oyWdHBEv1lIkjontP5H0eUl/ExF/tNi2dY+mzsIo7fr1+sEenP+1hIg4IOm7kt4m6ezShWHF+v58DV3AMEp7YJxZzZ9e4PVnqvkZBWrBcWJ7jaTLqsUHltq+ltHUWZY7ShupRqr5QqOLe+vfnl8KjqMvSNok6f6I+NZSG9fagqluWcYyprsWea8TJN0p6Vx1R2l/sdTfA1gNbF8t6Tp17wZ+op996m7BMEp7ePVaKCMLvN5b/4v8UrBStj8j6TZ1vxayNSJe6Ge/WgOGUdpD7alqvlAfy+nVfKE+GgwI29dKukXSE+qGy8/63rfJ/9Ef51HaOI64TT0cbN+gbr/Lo5I+HBHL+o2Ejb2LVHXo3qtuuHxFhMtAiYi9kh6UdJqkT897+SZ1v8R1J+EyuGxvVzdc9qjbcln2rzttbAuGUdqD7yhDBX4o6YPqfkfmaUnnMFRgMNm+XNIuSa9Kul1Hvxu4LyJ2LfY+dXfyrgSjtAdcROy13ZJ0s6QL1f2dQM+r21l4E18jGGi9z9cJkq5dYJuH1Q2hBTW2BQNg8DW2DwbA4CNgAKQhYACkIWAApCFgAKQhYACkIWAApCFgAKQhYACkIWAApPl/CUFtR+bZomgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_prediction(model, data, title):\n",
    "    ax = utl.PltErr(None,None,Plot=False)\n",
    "    u_pred = model(data.x, data.edge_index)\n",
    "        \n",
    "    u_pred = u_pred.cpu().detach().numpy()\n",
    "    u_act  = data.y.cpu()\n",
    "\n",
    "    print('u_pred=\\n',np.c_[u_pred])\n",
    "    print('u_act=\\n',u_act)\n",
    "    colors='black red green'.split()\n",
    "    for idime in range(2):\n",
    "        utl.PltErr(u_act[:,idime],u_pred[:,idime],\n",
    "               attrs={'fmt':'x','color':colors[idime]},\n",
    "              ax=ax, Plot=False,\n",
    "              )\n",
    "\n",
    "    utl.PltErr( None,None,\n",
    "               Plot=False,\n",
    "    ax=ax,\n",
    "            xlim=(-2,2),ylim=(-2,2),\n",
    "               title=title\n",
    "              )\n",
    "    \n",
    "def main(data_train, data_test):\n",
    "# Example usage\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    model = torch.load('best_model/best_model.pth').to(device)\n",
    "    make_prediction(model, data_train.to(device), title='png/disp_train.png')\n",
    "    make_prediction(model, data_test.to(device), title='png/disp_test.png')\n",
    "\n",
    "main(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bdc7e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# class GraphNeuralNet(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dims, output_dims, activation):\n",
    "#         super(GraphNeuralNet, self).__init__()\n",
    "#         self.output_dims = output_dims\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
    "#         self.hidden_layers = nn.ModuleList()\n",
    "#         for i in range(len(hidden_dims) - 1):\n",
    "#             self.hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "#         self.fc_out = nn.ModuleList([nn.Linear(hidden_dims[-1], dim) for dim in output_dims])\n",
    "#         self.activation = activation\n",
    "\n",
    "#     def forward(self, x, adj_matrices):\n",
    "#         x = self.activation(self.fc1(x))\n",
    "#         for hidden_layer in self.hidden_layers:\n",
    "#             x = self.activation(hidden_layer(x))\n",
    "#         outputs = []\n",
    "#         for adj_matrix in adj_matrices:\n",
    "#             hidden = torch.matmul(adj_matrix, x)\n",
    "#             for fc_out in self.fc_out:\n",
    "#                 outputs.append(fc_out(hidden))\n",
    "#         return outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(): # Example usage\n",
    "#     input_dim = eval(confParser['gnn']['input_dim']) #3  # Dimensionality of atom positions (e.g., x, y, z coordinates)\n",
    "#     hidden_dim = eval(confParser['gnn']['hidden_dim']) #[64]  # Dimensionality of hidden layers\n",
    "#     output_dims = eval(confParser['gnn']['output_dims']) #[3]  # Dimensionality of displacement vectors for each snapshot\n",
    "#     activation = eval(confParser['gnn']['activation']) #nn.ReLU() #nn.Identity()) #F.relu)\n",
    "#     lr = eval(confParser['gnn']['lr'])# 1.0e-4\n",
    "#     ntrain = eval(confParser['gnn']['ntrain'])#100\n",
    "#     num_epochs = eval(confParser['gnn']['num_epochs'])#20000\n",
    "#     noise_std   = eval(confParser['gnn']['noise_std'])#0.1\n",
    "\n",
    "#     num_snapshots = len( transition_paths )\n",
    "#     snapshots     = range(num_snapshots)\n",
    "\n",
    "#     model = GraphNeuralNet(input_dim, hidden_dim, output_dims,activation) #\n",
    "\n",
    "\n",
    "#     # Define optimizer and loss function\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "#     # Example training data\n",
    "#     num_atoms = [ len(transition_paths[ i ]['id']) for i in snapshots ]\n",
    "#     input_data = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "\n",
    "\n",
    "#     # Example target data (displacement vectors for each snapshot and each path)\n",
    "#     target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots for dim in output_dims]\n",
    "\n",
    "\n",
    "#     # Augment the dataset to have order 100 snapshots\n",
    "#     augmented_input_data = []\n",
    "#     augmented_target_displacements = []\n",
    "#     input_data_tensor = torch.stack(input_data)\n",
    "#     ntrain_initial = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "#     n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "#     for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "#         augmented_input, augmented_target = augment_data(input_data, target_displacements, noise_std)\n",
    "#         augmented_input_data.extend(augmented_input)\n",
    "#         augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "#     adj_matrices = compute_adjacency_matrices(augmented_input_data, rcut=3.0) #[torch.randint(0, 2, (num_atoms[i], num_atoms[i])).float() for i in range(num_snapshots)]  # Random adjacency matrices for each snapshot\n",
    "\n",
    "\n",
    "\n",
    "#     # Concatenate input data along a new dimension to form a single tensor\n",
    "#     input_data_tensor = torch.stack(augmented_input_data)\n",
    "#     print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "#     # Standardize the augmented input data\n",
    "#     mean = input_data_tensor.mean(dim=(0, 1))\n",
    "#     std = input_data_tensor.std(dim=(0, 1))\n",
    "#     standardized_input_data = [standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "\n",
    "\n",
    "#     # Convert input data to tensors\n",
    "#     #input_data_tensor = torch.stack(augmented_input_data)\n",
    "#     target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "\n",
    "#     total_loss_hist = []\n",
    "#     for epoch in range(num_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         predicted_displacements = model(input_data_tensor, adj_matrices)\n",
    "#     #    predicted_displacements_tensor = torch.stack( predicted_displacements )\n",
    "#         losses = []\n",
    "#         for indx, i in enumerate(snapshots):\n",
    "#             pred = predicted_displacements[ indx ][ indx ]\n",
    "#             snapshot_losses = criterion(pred, augmented_target_displacements[indx])\n",
    "#     #        snapshot_losses = [criterion(pred, augmented_target_displacements[indx]) for pred in predicted_displacements[indx]]\n",
    "#     #        pdb.set_trace()\n",
    "#             losses.append(snapshot_losses)\n",
    "#     #        losses.extend(snapshot_losses)\n",
    "#     #    loss = criterion(predicted_displacements_tensor, target_displacements_tensor)\n",
    "#         total_loss = sum(losses)\n",
    "#         total_loss.backward()\n",
    "#     #    loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss_hist += [total_loss.detach().numpy()]\n",
    "#         if epoch % 100 == 0:\n",
    "#             print(f'Epoch {epoch}, Total Loss: {total_loss.item()}')\n",
    "\n",
    "# #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09399b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d',)\n",
    "\n",
    "# batch_indx = 0\n",
    "# filtr = data.batch == batch_indx\n",
    "\n",
    "# xyz = data.x \n",
    "# adj_mat = data.edge_index.T\n",
    "\n",
    "\n",
    "# ax.plot(xyz[filtr][:,0],xyz[filtr][:,1],xyz[filtr][:,2],\n",
    "#         '.', ms=20,\n",
    "#         )\n",
    "\n",
    "# min_node_indx = data.ptr[ batch_indx ]\n",
    "# max_node_indx = data.ptr[ batch_indx + 1 ]\n",
    "# for nodes in (adj_mat):\n",
    "#     i = nodes[0]\n",
    "#     j = nodes[1]\n",
    "#     if i < min_node_indx or i >= max_node_indx: \n",
    "#         continue\n",
    "#     if j < min_node_indx or j >= max_node_indx: \n",
    "#         continue\n",
    "#     ax.plot([xyz[i,0],xyz[j,0]],[xyz[i,1],xyz[j,1]],[xyz[i,2],xyz[j,2]],\n",
    "#             '-', color='black',\n",
    "#             )\n",
    "\n",
    "#     u = data.y\n",
    "\n",
    "# ax.plot(([xyz[filtr][17,0],xyz[filtr][17,0]+u[filtr][17,0]]),\n",
    "#         ([xyz[filtr][17,1],xyz[filtr][17,1]+u[filtr][17,1]]),\n",
    "#         ([xyz[filtr][17,2],xyz[filtr][17,2]+u[filtr][17,2]]),\n",
    "#         '-', color='red',\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3c829",
   "metadata": {},
   "source": [
    "## mpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c862a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# class MPNN(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(MPNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def message_passing_layer(self, x, adj_matrices):\n",
    "#         # Ensure adj_matrices is a list of tensors\n",
    "#         adj_matrices = [adj.unsqueeze(0) for adj in adj_matrices]\n",
    "\n",
    "#         # Expand node features to include neighboring node features\n",
    "# #        expanded_x = [torch.matmul(adj.unsqueeze(0), x.unsqueeze(0)).squeeze(0) for adj in adj_matrices]\n",
    "#         expanded_x = [torch.matmul(adj,yy) for adj, yy in zip(adj_matrices,x)]\n",
    "# #        expanded_x = [torch.matmul(adj.unsqueeze(0), adj).squeeze(0) for adj in adj_matrices]\n",
    "\n",
    "#         # Concatenate node features with neighboring node features\n",
    "#         pdb.set_trace()\n",
    "#         concatenated_x = [torch.cat((x, exp_x), dim=1) for exp_x in expanded_x]\n",
    "\n",
    "#         # Apply linear transformation\n",
    "#         transformed_x = [self.fc1(cat_x) for cat_x in concatenated_x]\n",
    "\n",
    "#         # Apply activation function\n",
    "#         x = [F.relu(trans_x) for trans_x in transformed_x]\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "#     def readout_layer(self, x):\n",
    "#         # Concatenate tensors in the list along the batch dimension\n",
    "#         concatenated_x = torch.stack(x, dim=0)\n",
    "\n",
    "#         # Apply global pooling operation (e.g., mean or sum) along the batch dimension\n",
    "#         return torch.mean(concatenated_x, dim=0)\n",
    "\n",
    "#     def forward(self, x, adj_matrices):\n",
    "#         x = self.message_passing_layer(x, adj_matrices)\n",
    "#         output = self.readout_layer(x)\n",
    "#         return output\n",
    "\n",
    "# # Example usage\n",
    "# input_dim = 3  # Dimensionality of atom positions (e.g., x, y, z coordinates)\n",
    "# hidden_dim = 64  # Dimensionality of hidden layers\n",
    "# output_dim = 3  # Dimensionality of displacement vectors for each snapshot\n",
    "\n",
    "# # Create model instance\n",
    "# model = MPNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# # Define optimizer and loss function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1.0e-4)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# # Example training data\n",
    "# # Assuming input_data is a list of tensors containing initial positions for each snapshot\n",
    "# # Assuming adj_matrices is a list of adjacency matrices for each snapshot\n",
    "# # Assuming target_displacements is a list of tensors containing displacement vectors for each snapshot\n",
    "# # You need to replace these with your actual data\n",
    "# input_data = [torch.randn(10, input_dim).float() for _ in range(10)]  # Example random initial positions\n",
    "# adj_matrices = [torch.randint(0, 2, (10, 10)).float() for _ in range(10)]  # Example random adjacency matrices\n",
    "# target_displacements = [torch.randn(10, output_dim) for _ in range(10)]  # Example random target displacements\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 1000\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     predicted_displacements = model(input_data, adj_matrices)\n",
    "#     loss = criterion(predicted_displacements, target_displacements)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     if epoch % 100 == 0:\n",
    "#         print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d47449",
   "metadata": {},
   "source": [
    "## tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7268a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# class GraphNeuralNetwork(tf.keras.Model):\n",
    "#     def __init__(self, hidden_dim, output_dim):\n",
    "#         super(GraphNeuralNetwork, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.output_dim = output_dim\n",
    "        \n",
    "#         # Define layers\n",
    "#         self.fc1 = tf.keras.layers.Dense(hidden_dim, activation='relu')\n",
    "#         self.fc2 = tf.keras.layers.Dense(hidden_dim, activation='relu')\n",
    "#         self.fc_out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "#     def call(self, x, adj_matrices):\n",
    "#         # x: Node features (batch_size, num_nodes, input_dim)\n",
    "#         # adj_matrices: Adjacency matrices (batch_size, num_nodes, num_nodes)\n",
    "        \n",
    "#         # Apply first fully connected layer\n",
    "#         x = self.fc1(x)\n",
    "        \n",
    "#         # Iterate over adjacency matrices and update node features\n",
    "#         for adj_matrix in adj_matrices:\n",
    "#             x = tf.matmul(adj_matrix, x)\n",
    "#             x = self.fc2(x)\n",
    "        \n",
    "#         # Apply output fully connected layer\n",
    "#         output = self.fc_out(x)\n",
    "        \n",
    "#         return output\n",
    "\n",
    "# def compute_adjacency_matrices_tf(input_data, rcut):\n",
    "#     adj_matrices = []\n",
    "    \n",
    "#     for positions in input_data:\n",
    "#         num_atoms = positions.shape[0]\n",
    "#         adj_matrix = np.zeros(num_atoms*num_atoms).reshape((num_atoms, num_atoms))\n",
    "        \n",
    "#         for i in range(num_atoms):\n",
    "#             for j in range(i + 1, num_atoms):\n",
    "#                 distance = torch.norm(positions[i] - positions[j])\n",
    "#                 if distance <= rcut:\n",
    "#                     adj_matrix[i, j] = 1\n",
    "#                     adj_matrix[j, i] = 1\n",
    "#             assert adj_matrix[i,:].sum() > 0, 'dangling node : increase the cutoff!'\n",
    "#         adj_matrices.append(adj_matrix)\n",
    "    \n",
    "#     #--- assert no \n",
    "#     return np.c_[adj_matrices]\n",
    "\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     hidden_dim = 32  # Dimensionality of hidden layers\n",
    "#     output_dim = 3  # Dimensionality of output vectors\n",
    "#     snapshots = [0] #range(len(transition_paths))\n",
    "\n",
    "#     model = GraphNeuralNetwork(hidden_dim, output_dim)\n",
    "\n",
    "#     # Define optimizer and loss function\n",
    "#     optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#     loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "#     # Generate dummy input data and adjacency matrices\n",
    "# #     batch_size = 2\n",
    "# #     num_nodes = 10\n",
    "#     input_dim = 3\n",
    "\n",
    "#     #x = tf.random.normal((batch_size, num_nodes, input_dim))\n",
    "#     x = np.c_[[np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] for i in snapshots]]\n",
    "#     x = tf.convert_to_tensor(x,dtype=tf.float32)\n",
    "\n",
    "#     #adj_matrices = tf.random.uniform((batch_size, num_nodes, num_nodes)) # for _ in range(2)]  # Example with 2 adjacency matrices\n",
    "#     input_data = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "#     adj_matrices = compute_adjacency_matrices_tf(torch.stack(input_data), rcut=3.0)\n",
    "#     adj_matrices = tf.convert_to_tensor(adj_matrices,dtype=tf.float32)\n",
    "\n",
    "#     # Example target data\n",
    "#     #target = tf.random.normal((batch_size, num_nodes, output_dim))\n",
    "#     target = np.c_[[np.c_[pd.DataFrame(transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] for i in snapshots]]\n",
    "#     target = tf.convert_to_tensor(target,dtype=tf.float32)\n",
    "\n",
    "\n",
    "#     # Training loop\n",
    "#     total_loss_hist = []\n",
    "#     num_epochs = 5000 #100000\n",
    "#     for epoch in range(num_epochs):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             predictions = model(x, adj_matrices)\n",
    "#     #         pdb.set_trace()\n",
    "#             loss = loss_fn(target, predictions)\n",
    "\n",
    "#         gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#         optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "#         if epoch == 0:\n",
    "#             loss_min = loss.numpy()\n",
    "#             best_model = model\n",
    "#         total_loss_hist.append(loss.numpy())\n",
    "#         if epoch % 100 == 0: \n",
    "#             print('Epoch %s, Loss: %e'%(epoch,loss.numpy()))\n",
    "#             if loss.numpy() < loss_min:\n",
    "#                 loss_min = loss.numpy()\n",
    "#                 best_model = model     \n",
    "#     print('min loss:%e'%loss_min)\n",
    "#     return best_model, num_epochs, total_loss_hist\n",
    "\n",
    "# #model, num_epochs, total_loss_hist = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff93c42",
   "metadata": {},
   "source": [
    "## pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standard libraries\n",
    "# import os\n",
    "\n",
    "# # For downloading pre-trained models\n",
    "# import urllib.request\n",
    "# from urllib.error import HTTPError\n",
    "\n",
    "# # PyTorch Lightning\n",
    "# import lightning as L\n",
    "\n",
    "# # PyTorch\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # PyTorch geometric\n",
    "# import torch_geometric\n",
    "# import torch_geometric.data as geom_data\n",
    "# import torch_geometric.nn as geom_nn\n",
    "\n",
    "# # PL callbacks\n",
    "# from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "# from torch import Tensor\n",
    "\n",
    "# AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "# BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "# # Path to the folder where the datasets are/should be downloaded\n",
    "# DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# # Path to the folder where the pretrained models are saved\n",
    "# CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/GNNs/\")\n",
    "\n",
    "# # Setting the seed\n",
    "# L.seed_everything(42)\n",
    "\n",
    "# # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Github URL where saved models are stored for this tutorial\n",
    "# base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "# # Files to download\n",
    "# pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "# # Create checkpoint path if it doesn't exist yet\n",
    "# os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# # For each file, check whether it already exists. If not, try downloading it.\n",
    "# for file_name in pretrained_files:\n",
    "#     file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "#     if \"/\" in file_name:\n",
    "#         os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "#     if not os.path.isfile(file_path):\n",
    "#         file_url = base_url + file_name\n",
    "#         print(\"Downloading %s...\" % file_url)\n",
    "#         try:\n",
    "#             urllib.request.urlretrieve(file_url, file_path)\n",
    "#         except HTTPError as e:\n",
    "#             print(\n",
    "#                 \"Something went wrong. Please try to download the file from the GDrive folder,\"\n",
    "#                 \" or contact the author with the full output including the following error:\\n\",\n",
    "#                 e,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78ccb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCNLayer(nn.Module):\n",
    "#     def __init__(self, c_in, c_out):\n",
    "#         super().__init__()\n",
    "#         self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "#     def forward(self, node_feats, adj_matrix):\n",
    "#         \"\"\"Forward.\n",
    "\n",
    "#         Args:\n",
    "#             node_feats: Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
    "#             adj_matrix: Batch of adjacency matrices of the graph. If there is an edge from i to j,\n",
    "#                          adj_matrix[b,i,j]=1 else 0. Supports directed edges by non-symmetric matrices.\n",
    "#                          Assumes to already have added the identity connections.\n",
    "#                          Shape: [batch_size, num_nodes, num_nodes]\n",
    "#         \"\"\"\n",
    "#         # Num neighbours = number of incoming edges\n",
    "#         num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "#         node_feats = self.projection(node_feats)\n",
    "#         node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "#         node_feats = node_feats / num_neighbours\n",
    "#         return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "# adj_matrix = Tensor([[[1, 1, 0, 0], [1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1]]])\n",
    "\n",
    "# print(\"Node features:\\n\", node_feats)\n",
    "# print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31269515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer = GCNLayer(c_in=2, c_out=2)\n",
    "# layer.projection.weight.data = Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "# layer.projection.bias.data = Tensor([0.0, 0.0])\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "# print(\"Adjacency matrix\", adj_matrix)\n",
    "# print(\"Input features\", node_feats)\n",
    "# print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777baf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482df1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Small function for printing the test scores\n",
    "# def print_results(result_dict):\n",
    "#     if \"train\" in result_dict:\n",
    "#         print(\"Train accuracy: %4.2f%%\" % (100.0 * result_dict[\"train\"]))\n",
    "#     if \"val\" in result_dict:\n",
    "#         print(\"Val accuracy:   %4.2f%%\" % (100.0 * result_dict[\"val\"]))\n",
    "#     print(\"Test accuracy:  %4.2f%%\" % (100.0 * result_dict[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e976a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Data object:\", tu_dataset.data)\n",
    "# print(\"Length:\", len(tu_dataset))\n",
    "# print(\"Average label: %4.2f\" % (tu_dataset.data.y.float().mean().item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181abf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# tu_dataset.shuffle()\n",
    "# train_dataset = tu_dataset[:150]\n",
    "# test_dataset = tu_dataset[150:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=BATCH_SIZE)  # Additional loader for a larger datasets\n",
    "# graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926dec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(graph_test_loader))\n",
    "# print(\"Batch:\", batch)\n",
    "# print(\"Labels:\", batch.y[:10])\n",
    "# print(\"Batch indices:\", batch.batch[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebadc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GNNModel(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         c_in,\n",
    "#         c_hidden,\n",
    "#         c_out,\n",
    "#         num_layers=2,\n",
    "#         layer_name=\"GCN\",\n",
    "#         dp_rate=0.1,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         \"\"\"GNNModel.\n",
    "\n",
    "#         Args:\n",
    "#             c_in: Dimension of input features\n",
    "#             c_hidden: Dimension of hidden features\n",
    "#             c_out: Dimension of the output features. Usually number of classes in classification\n",
    "#             num_layers: Number of \"hidden\" graph layers\n",
    "#             layer_name: String of the graph layer to use\n",
    "#             dp_rate: Dropout rate to apply throughout the network\n",
    "#             kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         gnn_layer_by_name = {\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}\n",
    "#         gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "#         layers = []\n",
    "#         in_channels, out_channels = c_in, c_hidden\n",
    "#         for l_idx in range(num_layers - 1):\n",
    "#             layers += [\n",
    "#                 gnn_layer(in_channels=in_channels, out_channels=out_channels, **kwargs),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Dropout(dp_rate),\n",
    "#             ]\n",
    "#             in_channels = c_hidden\n",
    "#         layers += [gnn_layer(in_channels=in_channels, out_channels=c_out, **kwargs)]\n",
    "#         self.layers = nn.ModuleList(layers)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         \"\"\"Forward.\n",
    "\n",
    "#         Args:\n",
    "#             x: Input features per node\n",
    "#             edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "#         \"\"\"\n",
    "#         for layer in self.layers:\n",
    "#             # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "#             # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "#             # we can simply check the class type.\n",
    "#             if isinstance(layer, geom_nn.MessagePassing):\n",
    "# #                 pdb.set_trace()\n",
    "#                 x = layer(x, edge_index)\n",
    "#             else:\n",
    "#                 x = layer(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c1b18",
   "metadata": {},
   "source": [
    "### toturial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def main(): # Example usage\n",
    "\n",
    "    \n",
    "#     c_in=input_dim=3\n",
    "#     c_hidden = 16\n",
    "#     hidden_dim = [c_hidden]\n",
    "#     c_out  = 3\n",
    "#     output_dims=[c_out]\n",
    "#     num_layers = 2\n",
    "#     ntrain = 100\n",
    "#     num_epochs=100\n",
    "#     noise_std=0.001\n",
    "#     lr=1e-4\n",
    "#     batch_size = 12  # or any desired batch size\n",
    "\n",
    "\n",
    "#     num_snapshots = len( transition_paths )\n",
    "#     print('num_snapshots=',num_snapshots)\n",
    "#     snapshots     = range(num_snapshots)\n",
    "\n",
    "# #     model = GraphNeuralNet(input_dim, hidden_dim, output_dims,activation) #\n",
    "#     model = GNNModel(c_in,\n",
    "#         c_hidden,\n",
    "#         c_out,\n",
    "#         num_layers=num_layers,\n",
    "# )\n",
    "\n",
    "\n",
    "#     # Define optimizer and loss function\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "#     # Example training data\n",
    "#     input_data = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     # Example target data (displacement vectors for each snapshot and each path)\n",
    "#     target_displacements = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] ).float() for i in snapshots for dim in output_dims]\n",
    "\n",
    "\n",
    "#     # Augment the dataset to have order 100 snapshots\n",
    "#     augmented_input_data = []\n",
    "#     augmented_target_displacements = []\n",
    "#     input_data_tensor = torch.stack(input_data)\n",
    "#     ntrain_initial = input_data_tensor.shape[0]*input_data_tensor.shape[1]\n",
    "#     n_repeat = np.max([1,int(ntrain/ntrain_initial)])\n",
    "\n",
    "#     for _ in range(n_repeat):  # Repeat the augmentation process 10 times\n",
    "#         augmented_input, augmented_target = augment_data(input_data, target_displacements, noise_std)\n",
    "#         augmented_input_data.extend(augmented_input)\n",
    "#         augmented_target_displacements.extend(augmented_target)\n",
    "\n",
    "#     adj_matrices = torch.stack(compute_adjacency_matrices(augmented_input_data, rcut=3.0)) \n",
    "    \n",
    "\n",
    "\n",
    "#     # Concatenate input data along a new dimension to form a single tensor\n",
    "#     input_data_tensor = torch.stack(augmented_input_data)\n",
    "#     print('input_data_tensor.shape:',input_data_tensor.shape)\n",
    "\n",
    "#     # Standardize the augmented input data\n",
    "#     mean = input_data_tensor.mean(dim=(0, 1))\n",
    "#     std = input_data_tensor.std(dim=(0, 1))\n",
    "#     standardized_input_data = [standardize_data(data, mean, std) for data in augmented_input_data]\n",
    "\n",
    "\n",
    "#     # Convert input data to tensors\n",
    "#     target_displacements_tensor = torch.stack(augmented_target_displacements)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Concatenate nodes and edges for each graph\n",
    "#     graphs = []\n",
    "#     for i in range(len(input_data)):\n",
    "#         x = input_data_tensor[i]  # Node features\n",
    "#         edge_index = adj_matrices[i].nonzero().t()  # Edge indices\n",
    "#         y = target_displacements_tensor[i]  # Target displacements\n",
    "\n",
    "#         # Create a Data object for each graph\n",
    "#         data = Data(x=x, edge_index=edge_index, y=y)\n",
    "#         graphs.append(data)\n",
    "#     # Create a single large graph by concatenating Data objects\n",
    "#     large_graph = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "\n",
    "#     # Define batch size and create DataLoader\n",
    "#     loader = DataLoader(large_graph, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# #     # Accessing batches in the DataLoader\n",
    "#     data=loader.dataset #next(iter(loader))\n",
    "# #     pdb.set_trace()\n",
    "# #    for data in loader:\n",
    "# #    print(data)\n",
    "\n",
    "\n",
    "#     total_loss_hist = []\n",
    "#     for epoch in range(num_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         predicted_displacements = model(data.x, data.edge_index)\n",
    "#         total_loss = criterion(predicted_displacements,data.y )\n",
    "#         total_loss.backward()\n",
    "#     #    loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss_hist += [total_loss.detach().numpy()]\n",
    "#         if epoch % 100 == 0:\n",
    "#             print(f'Epoch {epoch}, Total Loss: {total_loss.item()}')\n",
    "\n",
    "#     return model, num_epochs, total_loss_hist, data\n",
    "\n",
    "\n",
    "\n",
    "# gnn_layer_by_name = {\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}\n",
    "\n",
    "# model, num_epochs, total_loss_hist, data = main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GraphGNNModel(nn.Module):\n",
    "#     def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "#         \"\"\"GraphGNNModel.\n",
    "\n",
    "#         Args:\n",
    "#             c_in: Dimension of input features\n",
    "#             c_hidden: Dimension of hidden features\n",
    "#             c_out: Dimension of output features (usually number of classes)\n",
    "#             dp_rate_linear: Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "#             kwargs: Additional arguments for the GNNModel object\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.GNN = GNNModel(c_in=c_in, c_hidden=c_hidden, c_out=c_hidden, **kwargs)  # Not our prediction output yet!\n",
    "#         self.head = nn.Sequential(nn.Dropout(dp_rate_linear), nn.Linear(c_hidden, c_out))\n",
    "\n",
    "#     def forward(self, x, edge_index, batch_idx):\n",
    "#         \"\"\"Forward.\n",
    "\n",
    "#         Args:\n",
    "#             x: Input features per node\n",
    "#             edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "#             batch_idx: Index of batch element for each node\n",
    "#         \"\"\"\n",
    "#         x = self.GNN(x, edge_index)\n",
    "#         x = geom_nn.global_mean_pool(x, batch_idx)  # Average pooling\n",
    "#         x = self.head(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5968c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GraphLevelGNN(L.LightningModule):\n",
    "#     def __init__(self, **model_kwargs):\n",
    "#         super().__init__()\n",
    "#         # Saving hyperparameters\n",
    "#         self.save_hyperparameters()\n",
    "\n",
    "#         self.model = GraphGNNModel(**model_kwargs)\n",
    "#         self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, data, mode=\"train\"):\n",
    "#         x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "#         x = self.model(x, edge_index, batch_idx)\n",
    "#         x = x.squeeze(dim=-1)\n",
    "\n",
    "#         if self.hparams.c_out == 1:\n",
    "#             preds = (x > 0).float()\n",
    "#             data.y = data.y.float()\n",
    "#         else:\n",
    "#             preds = x.argmax(dim=-1)\n",
    "#         loss = self.loss_module(x, data.y)\n",
    "#         acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "#         return loss, acc\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         # High lr because of small dataset and small model\n",
    "#         optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "#         return optimizer\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         loss, acc = self.forward(batch, mode=\"train\")\n",
    "#         self.log(\"train_loss\", loss)\n",
    "#         self.log(\"train_acc\", acc)\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         _, acc = self.forward(batch, mode=\"val\")\n",
    "#         self.log(\"val_acc\", acc)\n",
    "\n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         _, acc = self.forward(batch, mode=\"test\")\n",
    "#         self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_graph_classifier(model_name, **model_kwargs):\n",
    "#     L.seed_everything(42)\n",
    "\n",
    "#     # Create a PyTorch Lightning trainer with the generation callback\n",
    "#     root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
    "#     os.makedirs(root_dir, exist_ok=True)\n",
    "#     trainer = L.Trainer(\n",
    "#         default_root_dir=root_dir,\n",
    "#         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "# #        accelerator=\"cuda\",\n",
    "# #        devices=AVAIL_GPUS,\n",
    "#         max_epochs=500,\n",
    "#         enable_progress_bar=False,\n",
    "#     )\n",
    "#     trainer.logger._default_hp_metric = None\n",
    "\n",
    "#     # Check whether pretrained model exists. If yes, load it and skip training\n",
    "#     pretrained_filename = os.path.join(CHECKPOINT_PATH, \"GraphLevel%s.ckpt\" % model_name)\n",
    "#     if os.path.isfile(pretrained_filename):\n",
    "#         print(\"Found pretrained model, loading...\")\n",
    "#         model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "#     else:\n",
    "#         L.seed_everything(42)\n",
    "#         model = GraphLevelGNN(\n",
    "#             c_in=tu_dataset.num_node_features,\n",
    "#             c_out=1 if tu_dataset.num_classes == 2 else tu_dataset.num_classes,\n",
    "#             **model_kwargs,\n",
    "#         )\n",
    "#         trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "#         model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "#     # Test best model on validation and test set\n",
    "#     train_result = trainer.test(model, dataloaders=graph_train_loader, verbose=False)\n",
    "#     test_result = trainer.test(model, dataloaders=graph_test_loader, verbose=False)\n",
    "#     result = {\"test\": test_result[0][\"test_acc\"], \"train\": train_result[0][\"test_acc\"]}\n",
    "#     return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff892dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, result = train_graph_classifier(\n",
    "#     model_name=\"GraphConv\", c_hidden=256, layer_name=\"GraphConv\", num_layers=3, dp_rate_linear=0.5, dp_rate=0.0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bca0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_prediction(model, input_data, adj_matrices, target_displacements):\n",
    "#     ax = utl.PltErr(None,None,Plot=False)\n",
    "#     predicted_displacements = model(input_data, adj_matrices)\n",
    "#     for i_snapshot,u_pred in enumerate(predicted_displacements):\n",
    "        \n",
    "#         u_act  = target_displacements[i_snapshot]\n",
    "\n",
    "#         colors='black red green'.split()\n",
    "#         for idime in range(3):\n",
    "#             utl.PltErr(u_act[:,idime],u_pred[:,idime],\n",
    "#                    attrs={'fmt':'x','color':colors[idime]},\n",
    "#                   ax=ax, Plot=False,\n",
    "#                   )\n",
    "\n",
    "#         utl.PltErr( None,None,\n",
    "#                    Plot=False,\n",
    "#         ax=ax,\n",
    "#                 #xlim=(-2,2),ylim=(-2,2),\n",
    "#                    title='png/disp.png'\n",
    "#                   )\n",
    "\n",
    "\n",
    "# snapshots = [0] #range(len(transition_paths))\n",
    "# x = np.c_[[np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] for i in snapshots]]\n",
    "# x = tf.convert_to_tensor(x,dtype=tf.float32)\n",
    "\n",
    "# #adj_matrices = tf.random.uniform((batch_size, num_nodes, num_nodes)) # for _ in range(2)]  # Example with 2 adjacency matrices\n",
    "# input_data = [torch.from_numpy( np.c_[pd.DataFrame(transition_paths[ i ])['x y z'.split()]] ).float() for i in snapshots]  \n",
    "# adj_matrices = compute_adjacency_matrices(torch.stack(input_data), rcut=3.0)\n",
    "# adj_matrices = tf.convert_to_tensor(adj_matrices,dtype=tf.float32)\n",
    "\n",
    "# # Example target data\n",
    "# #target = tf.random.normal((batch_size, num_nodes, output_dim))\n",
    "# target = np.c_[[np.c_[pd.DataFrame(transition_paths[ i ])['ux_fin uy_fin uz_fin'.split()]] for i in snapshots]]\n",
    "# target = tf.convert_to_tensor(target,dtype=tf.float32)\n",
    "\n",
    "\n",
    "# make_prediction(model, x, adj_matrices, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f72c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
